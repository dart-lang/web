{
  "__meta__": {
    "source": "[MDN Web Docs](https://developer.mozilla.org/en-US/docs/Web)",
    "license": "[CC-BY-SA 2.5](https://creativecommons.org/licenses/by-sa/2.5/)"
  },
  "abortcontroller": {
    "docs": "\n\nThe **`AbortController`** interface represents a controller object that allows you to abort one or more Web requests as and when desired.\n\nYou can create a new `AbortController` object using the [AbortController.AbortController] constructor. Communicating with a DOM request is done using an [AbortSignal] object.",
    "properties": {
      "abort": "\n\nThe **`abort()`** method of the [AbortController] interface aborts a DOM request before it has completed.\nThis is able to abort [fetch requests](/en-US/docs/Web/API/fetch), the consumption of any response bodies, or streams.",
      "signal": "\n\nThe **`signal`** read-only property of the [AbortController] interface returns an [AbortSignal] object instance, which can be used to communicate with/abort a DOM request as desired."
    }
  },
  "abortsignal": {
    "docs": "\n\nThe **`AbortSignal`** interface represents a signal object that allows you to communicate with a DOM request (such as a fetch request) and abort it if required via an [AbortController] object.\n\n",
    "properties": {
      "abort_event": "\n\nThe **`abort`** event of the [AbortSignal] is fired when the associated request is aborted, i.e. using [AbortController.abort].",
      "abort_static": "\n\nThe **`AbortSignal.abort()`** static method returns an [AbortSignal] that is already set as aborted (and which does not trigger an [AbortSignal/abort_event] event).\n\nThis is shorthand for the following code:\n\n```js\nconst controller = new AbortController();\ncontroller.abort();\nreturn controller.signal;\n```\n\nThis could, for example, be passed to a fetch method in order to run its abort logic (i.e. it may be that code is organized such that the abort logic should be run even if the intended fetch operation has not been started).\n\n> **Note:** The method is similar in purpose to `Promise.reject`.",
      "aborted": "\n\nThe **`aborted`** read-only property returns a value that indicates whether the DOM requests the signal is communicating with are aborted (`true`) or not (`false`).",
      "any_static": "\n\nThe **`AbortSignal.any()`** static method takes an iterable of abort signals and returns an [AbortSignal]. The returned abort signal is aborted when any of the input iterable abort signals are aborted. The [AbortSignal.reason] will be set to the reason of the first signal that is aborted. If any of the the given abort signals are already aborted then so will be the returned [AbortSignal].",
      "reason": "\n\nThe **`reason`** read-only property returns a JavaScript value that indicates the abort reason.\n\nThe property is `undefined` when the signal has not been aborted.\nIt can be set to a specific value when the signal is aborted, using [AbortController.abort] or [AbortSignal/abort_static].\nIf not explicitly set in those methods, it defaults to \"AbortError\" [DOMException].",
      "throwifaborted": "\n\nThe **`throwIfAborted()`** method throws the signal's abort [AbortSignal.reason] if the signal has been aborted; otherwise it does nothing.\n\nAn API that needs to support aborting can accept an [AbortSignal] object and use `throwIfAborted()` to test and throw when the [`abort`](/en-US/docs/Web/API/AbortSignal/abort_event) event is signalled.\n\nThis method can also be used to abort operations at particular points in code, rather than passing to functions that take a signal.",
      "timeout_static": "\n\nThe **`AbortSignal.timeout()`** static method returns an [AbortSignal] that will automatically abort after a specified time.\n\nThe signal aborts with a `TimeoutError` [DOMException] on timeout, or with `AbortError` [DOMException] due to pressing a browser stop button (or some other inbuilt \"stop\" operation).\nThis allows UIs to differentiate timeout errors, which typically require user notification, from user-triggered aborts that do not.\n\nThe timeout is based on active rather than elapsed time, and will effectively be paused if the code is running in a suspended worker, or while the document is in a back-forward cache (\"[bfcache](https://web.dev/articles/bfcache)\").\n\nTo combine multiple signals, you can use [AbortSignal/any_static], for example, to directly abort a download using either a timeout signal or by calling [AbortController.abort]."
    }
  },
  "absoluteorientationsensor": {
    "docs": "\n\nThe **`AbsoluteOrientationSensor`** interface of the [Sensor APIs](/en-US/docs/Web/API/Sensor_APIs) describes the device's physical orientation in relation to the Earth's reference coordinate system.\n\nTo use this sensor, the user must grant permission to the `'accelerometer'`, `'gyroscope'`, and `'magnetometer'` device sensors through the [Permissions API](/en-US/docs/Web/API/Permissions_API).\n\nThis feature may be blocked by a [Permissions Policy](/en-US/docs/Web/HTTP/Permissions_Policy) set on your server.\n\n"
  },
  "abstractrange": {
    "docs": "\n\nThe **`AbstractRange`** abstract interface is the base class upon which all  range types are defined. A **range** is an object that indicates the start and end points of a section of content within the document.\n\n> **Note:** As an abstract interface, you will not directly instantiate an object of type `AbstractRange`. Instead, you will use the [Range] or [StaticRange] interfaces. To understand the difference between those two interfaces, and how to choose which is appropriate for your needs, consult each interface's documentation.\n\n",
    "properties": {
      "collapsed": "\n\nThe read-only **`collapsed`** property of the [AbstractRange] interface returns `true` if the range's start position and end position are the same.",
      "endcontainer": "\n\nThe read-only **`endContainer`** property of the [AbstractRange] interface returns the [Node] in which the end of the range is located.",
      "endoffset": "\n\nThe **`endOffset`** property of the [AbstractRange] interface returns the offset into the end node of the range's end position.",
      "startcontainer": "\n\nThe read-only **`startContainer`** property of the [AbstractRange] interface returns the start [Node] for the range.",
      "startoffset": "\n\nThe read-only **`startOffset`** property of the [AbstractRange] interface returns the offset into the start node of the range's start position."
    }
  },
  "accelerometer": {
    "docs": "\n\nThe **`Accelerometer`** interface of the [Sensor APIs](/en-US/docs/Web/API/Sensor_APIs) provides on each reading the acceleration applied to the device along all three axes.\n\nTo use this sensor, the user must grant permission to the `'accelerometer'`, device sensor through the [Permissions API](/en-US/docs/Web/API/Permissions_API).\n\nThis feature may be blocked by a [Permissions Policy](/en-US/docs/Web/HTTP/Permissions_Policy) set on your server.\n\n",
    "properties": {
      "x": "\n\nThe **`x`** read-only property of the [Accelerometer] interface returns a number specifying the acceleration of the device along its x-axis.",
      "y": "\n\nThe **`y`** read-only property of the [Accelerometer] interface returns a number specifying the acceleration of the device along its y-axis.",
      "z": "\n\nThe **`z`** read-only property of the [Accelerometer] interface returns a number specifying the acceleration of the device along its z-axis."
    }
  },
  "aescbcparams": {
    "docs": "\n\nThe **`AesCbcParams`** dictionary of the [Web Crypto API](/en-US/docs/Web/API/Web_Crypto_API) represents the object that should be passed as the `algorithm` parameter into [SubtleCrypto.encrypt], [SubtleCrypto.decrypt], [SubtleCrypto.wrapKey], or [SubtleCrypto.unwrapKey], when using the [AES-CBC](/en-US/docs/Web/API/SubtleCrypto/encrypt#aes-cbc) algorithm."
  },
  "aesctrparams": {
    "docs": "\n\nThe **`AesCtrParams`** dictionary of the [Web Crypto API](/en-US/docs/Web/API/Web_Crypto_API) represents the object that should be passed as the `algorithm` parameter into [SubtleCrypto.encrypt], [SubtleCrypto.decrypt], [SubtleCrypto.wrapKey], or [SubtleCrypto.unwrapKey], when using the [AES-CTR](/en-US/docs/Web/API/SubtleCrypto/encrypt#aes-ctr) algorithm.\n\nAES is a block cipher, meaning that it splits the message into blocks and encrypts it a block at a time. In CTR mode, every time a block of the message is encrypted, an extra block of data is mixed in. This extra block is called the \"counter block\".\n\nA given counter block value must never be used more than once with the same key:\n\n- Given a message _n_ blocks long, a different counter block must be used for every block.\n- If the same key is used to encrypt more than one message, a different counter block must be used for all blocks across all messages.\n\nTypically this is achieved by splitting the initial counter block value into two concatenated parts:\n\n- A [nonce](https://en.wikipedia.org/wiki/Cryptographic_nonce) (that is, a number that may only be used once). The nonce part of the block stays the same for every block in the message. Each time a new message is to be encrypted, a new nonce is chosen. Nonces don't have to be secret, but they must not be reused with the same key.\n- A counter. This part of the block gets incremented each time a block is encrypted.\n\nEssentially: the nonce should ensure that counter blocks are not reused from one message to the next, while the counter should ensure that counter blocks are not reused within a single message.\n\n> **Note:** See [Appendix B of the NIST SP800-38A standard](https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-38a.pdf#%5B%7B%22num%22%3A70%2C%22gen%22%3A0%7D%2C%7B%22name%22%3A%22Fit%22%7D%5D) for more information."
  },
  "aesgcmparams": {
    "docs": "\n\nThe **`AesGcmParams`** dictionary of the [Web Crypto API](/en-US/docs/Web/API/Web_Crypto_API) represents the object that should be passed as the `algorithm` parameter into [SubtleCrypto.encrypt], [SubtleCrypto.decrypt], [SubtleCrypto.wrapKey], or [SubtleCrypto.unwrapKey], when using the [AES-GCM](/en-US/docs/Web/API/SubtleCrypto/encrypt#aes-gcm) algorithm.\n\nFor details of how to supply appropriate values for this parameter, see the specification for AES-GCM: [NIST SP800-38D](https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-38d.pdf), in particular section 5.2.1.1 on Input Data."
  },
  "aeskeygenparams": {
    "docs": "\n\nThe **`AesKeyGenParams`** dictionary of the [Web Crypto API](/en-US/docs/Web/API/Web_Crypto_API) represents the object that should be passed as the `algorithm` parameter into [SubtleCrypto.generateKey], when generating an AES key: that is, when the algorithm is identified as any of [AES-CBC](/en-US/docs/Web/API/SubtleCrypto/encrypt#aes-cbc), [AES-CTR](/en-US/docs/Web/API/SubtleCrypto/encrypt#aes-ctr), [AES-GCM](/en-US/docs/Web/API/SubtleCrypto/encrypt#aes-gcm), or [AES-KW](/en-US/docs/Web/API/SubtleCrypto/wrapKey#aes-kw)."
  },
  "ambientlightsensor": {
    "docs": "\n\nThe **`AmbientLightSensor`** interface of the [Sensor APIs](/en-US/docs/Web/API/Sensor_APIs) returns the current light level or illuminance of the ambient light around the hosting device.\n\nTo use this sensor, the user must grant permission to the `'ambient-light-sensor'` device sensor through the [Permissions API](/en-US/docs/Web/API/Permissions_API).\n\nThis feature may be blocked by a [Permissions Policy](/en-US/docs/Web/HTTP/Permissions_Policy) set on your server.\n\n",
    "properties": {
      "illuminance": "\n\nThe **`illuminance`** property of the [AmbientLightSensor] interface returns the current light level in [lux](https://en.wikipedia.org/wiki/Lux) of the ambient light level around the hosting device."
    }
  },
  "analysernode": {
    "docs": "\n\nThe **`AnalyserNode`** interface represents a node able to provide real-time frequency and time-domain analysis information. It is an [AudioNode] that passes the audio stream unchanged from the input to the output, but allows you to take the generated data, process it, and create audio visualizations.\n\nAn `AnalyserNode` has exactly one input and one output. The node works even if the output is not connected.\n\n![Without modifying the audio stream, the node allows to get the frequency and time-domain data associated to it, using a FFT.](fttaudiodata_en.svg)\n\n<table class=\"properties\">\n  <tbody>\n    <tr>\n      <th scope=\"row\">Number of inputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Number of outputs</th>\n      <td><code>1</code> (but may be left unconnected)</td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count mode</th>\n      <td><code>\"max\"</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count</th>\n      <td><code>2</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel interpretation</th>\n      <td><code>\"speakers\"</code></td>\n    </tr>\n  </tbody>\n</table>",
    "properties": {
      "fftsize": "\n\nThe **`fftSize`** property of the [AnalyserNode] interface is an unsigned long value and represents the window size in samples that is used when performing a [Fast Fourier Transform](https://en.wikipedia.org/wiki/Fast_Fourier_transform) (FFT) to get frequency domain data.",
      "frequencybincount": "\n\nThe **`frequencyBinCount`** read-only property of the [AnalyserNode] interface contains the total number of data points available to [AudioContext] [BaseAudioContext.sampleRate]. This is half of the `value` of the [AnalyserNode.fftSize]. The two methods' indices have a linear relationship with the frequencies they represent, between 0 and the [Nyquist frequency](https://en.wikipedia.org/wiki/Nyquist_frequency).",
      "getbytefrequencydata": "\n\nThe **`getByteFrequencyData()`** method of the [AnalyserNode] interface copies the current frequency data into a `Uint8Array` (unsigned byte array) passed into it.\n\nThe frequency data is composed of integers on a scale from 0 to 255.\n\nEach item in the array represents the decibel value for a specific frequency. The frequencies are spread linearly from 0 to 1/2 of the sample rate. For example, for `48000` sample rate, the last item of the array will represent the decibel value for `24000` Hz.\n\nIf the array has fewer elements than the [AnalyserNode.frequencyBinCount], excess elements are dropped. If it has more elements than needed, excess elements are ignored.",
      "getbytetimedomaindata": "\n\nThe **`getByteTimeDomainData()`** method of the [AnalyserNode] Interface copies the current waveform, or time-domain, data into a `Uint8Array` (unsigned byte array) passed into it.\n\nIf the array has fewer elements than the [AnalyserNode.fftSize], excess elements are dropped. If it has more elements than needed, excess elements are ignored.",
      "getfloatfrequencydata": "\n\nThe **`getFloatFrequencyData()`** method of the [AnalyserNode] Interface copies the current frequency data into a `Float32Array` array passed into it. Each array value is a _sample_, the magnitude of the signal at a particular time.\n\nEach item in the array represents the decibel value for a specific frequency. The frequencies are spread linearly from 0 to 1/2 of the sample rate. For example, for a `48000` Hz sample rate, the last item of the array will represent the decibel value for `24000` Hz.\n\nIf you need higher performance and don't care about precision, you can use [AnalyserNode.getByteFrequencyData] instead, which works on a `Uint8Array`.",
      "getfloattimedomaindata": "\n\nThe **`getFloatTimeDomainData()`** method of the [AnalyserNode] Interface copies the current waveform, or time-domain, data into a `Float32Array` array passed into it. Each array value is a _sample_, the magnitude of the signal at a particular time.",
      "maxdecibels": "\n\nThe **`maxDecibels`** property of the [AnalyserNode] interface is a double value representing the maximum power value in the scaling range for the FFT analysis data, for conversion to unsigned byte values — basically, this specifies the maximum value for the range of results when using `getByteFrequencyData()`.",
      "mindecibels": "\n\nThe **`minDecibels`** property of the [AnalyserNode] interface is a double value representing the minimum power value in the scaling range for the FFT analysis data, for conversion to unsigned byte values — basically, this specifies the minimum value for the range of results when using `getByteFrequencyData()`.",
      "smoothingtimeconstant": "\n\nThe **`smoothingTimeConstant`** property of the [AnalyserNode] interface is a double value representing the averaging constant with the last analysis frame. It's basically an average between the current buffer and the last buffer the `AnalyserNode` processed, and results in a much smoother set of value changes over time."
    }
  },
  "angle_instanced_arrays": {
    "docs": "\n\nThe **`ANGLE_instanced_arrays`** extension is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and allows to draw the same object, or groups of similar objects multiple times, if they share the same vertex data, primitive count and type.\n\nWebGL extensions are available using the [WebGLRenderingContext.getExtension] method. For more information, see also [Using Extensions](/en-US/docs/Web/API/WebGL_API/Using_Extensions) in the [WebGL tutorial](/en-US/docs/Web/API/WebGL_API/Tutorial).\n\n> **Note:** This extension is only available to [WebGLRenderingContext] contexts. In [WebGL2RenderingContext], the functionality of this extension is available on the WebGL2 context by default and the constants and methods are available without the \"`ANGLE`\" suffix.\n>\n> Despite the name \"ANGLE\", this extension works on any device if the hardware supports it and not just on Windows when using the ANGLE library. \"ANGLE\" just indicates that this extension has been written by the ANGLE library authors.",
    "properties": {
      "drawarraysinstancedangle": "\n\nThe **`ANGLE_instanced_arrays.drawArraysInstancedANGLE()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) renders primitives from array data like the [WebGLRenderingContext.drawArrays] method. In addition, it can execute multiple instances of the range of elements.\n\n> **Note:** When using [WebGL2RenderingContext], this method is available as [WebGL2RenderingContext.drawArraysInstanced] by default.",
      "drawelementsinstancedangle": "\n\nThe **`ANGLE_instanced_arrays.drawElementsInstancedANGLE()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) renders primitives from array data like the [WebGLRenderingContext.drawElements] method. In addition, it can execute multiple instances of a set of elements.\n\n> **Note:** When using [WebGL2RenderingContext], this method is available as [WebGL2RenderingContext.drawElementsInstanced] by default.",
      "vertexattribdivisorangle": "\n\nThe **ANGLE_instanced_arrays.vertexAttribDivisorANGLE()** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) modifies the rate at which generic vertex attributes advance when rendering multiple instances of primitives with [ANGLE_instanced_arrays.drawArraysInstancedANGLE] and [ANGLE_instanced_arrays.drawElementsInstancedANGLE].\n\n> **Note:** When using [WebGL2RenderingContext], this method is available as [WebGL2RenderingContext.vertexAttribDivisor] by default."
    }
  },
  "animation": {
    "docs": "\n\nThe **`Animation`** interface of the [Web Animations API](/en-US/docs/Web/API/Web_Animations_API) represents a single animation player and provides playback controls and a timeline for an animation node or source.\n\n",
    "properties": {
      "cancel": "\n\nThe Web Animations API's **`cancel()`** method of the [Animation] interface clears all [KeyframeEffect]s caused by this animation and aborts its playback.\n\n> **Note:** When an animation is cancelled, its [Animation.startTime] and [Animation.currentTime] are set to `null`.",
      "cancel_event": "\n\nThe **`cancel`** event of the [Animation] interface is fired when the [Animation.cancel] method is called or when the animation enters the `\"idle\"` play state from another state, such as when the animation is removed from an element before it finishes playing.\n\n> **Note:** Creating a new animation that is initially idle does not trigger a `cancel` event on the new animation.",
      "commitstyles": "\n\nThe `commitStyles()` method of the [Web Animations API](/en-US/docs/Web/API/Web_Animations_API)'s [Animation] interface writes the [computed values](/en-US/docs/Web/CSS/computed_value) of the animation's current styles into its target element's [`style`](/en-US/docs/Web/HTML/Global_attributes#style) attribute. `commitStyles()` works even if the animation has been [automatically removed](/en-US/docs/Web/API/Web_Animations_API/Using_the_Web_Animations_API#automatically_removing_filling_animations).\n\n`commitStyles()` can be used in combination with `fill` to cause the final state of an animation to persist after the animation ends. The same effect could be achieved with `fill` alone, but [using indefinitely filling animations is discouraged](https://drafts.csswg.org/web-animations-1/#fill-behavior). Animations [take precedence over all static styles](/en-US/docs/Web/CSS/Cascade#cascading_order), so an indefinite filling animation can prevent the target element from ever being styled normally.\n\nUsing `commitStyles()` writes the styling state into the element's [`style`](/en-US/docs/Web/HTML/Global_attributes#style) attribute, where they can be modified and replaced as normal.",
      "currenttime": "\n\nThe **`Animation.currentTime`** property of the [Web Animations API](/en-US/docs/Web/API/Web_Animations_API) returns and sets the current time value of the animation in milliseconds, whether running or paused.\n\nIf the animation lacks a [AnimationTimeline], is inactive, or hasn't been played yet, `currentTime`'s return value is `null`.",
      "effect": "\n\nThe **`Animation.effect`** property of the [Web Animations API](/en-US/docs/Web/API/Web_Animations_API) gets and sets the target effect of an animation. The target effect may be either an effect object of a type based on [AnimationEffect], such as [KeyframeEffect], or `null`.",
      "finish": "\n\nThe **`finish()`** method of the [Web Animations API](/en-US/docs/Web/API/Web_Animations_API)'s [Animation] Interface sets the current playback time to the end of the animation corresponding to the current playback direction.\n\nThat is, if the animation is playing forward, it sets the playback time to the length of the animation sequence, and if the animation is playing in reverse (having had its [Animation.reverse] method called), it sets the playback time to 0.",
      "finish_event": "\n\nThe **`finish`** event of the [Animation] interface is fired when the animation finishes playing, either when the animation completes naturally, or\nwhen the [Animation.finish] method is called to immediately cause the\nanimation to finish up.\n\n> **Note:** The `\"paused\"` play state supersedes the `\"finished\"` play\n> state; if the animation is both paused and finished, the `\"paused\"` state\n> is the one that will be reported. You can force the animation into the\n> `\"finished\"` state by setting its [Animation.startTime] to\n> `document.timeline.currentTime - (Animation.currentTime * Animation.playbackRate)`.",
      "finished": "\n\nThe **`Animation.finished`** read-only property of the [Web Animations API](/en-US/docs/Web/API/Web_Animations_API) returns a `Promise` which resolves once the animation has finished playing.\n\n> **Note:** Every time the animation leaves the `finished` play state (that is, when it starts playing again), a new `Promise` is created for this property. The new `Promise` will resolve once the new animation sequence has completed.",
      "id": "\n\nThe **`Animation.id`** property of the [Web Animations API](/en-US/docs/Web/API/Web_Animations_API) returns or sets a string used to identify the animation.",
      "pause": "\n\nThe **`pause()`** method of the [Web Animations API](/en-US/docs/Web/API/Web_Animations_API)'s [Animation] interface suspends playback of the animation.",
      "pending": "\n\nThe read-only **`Animation.pending`** property of the [Web Animations API](/en-US/docs/Web/API/Web_Animations_API) indicates whether the animation is currently waiting for an asynchronous operation such as initiating playback or pausing a running animation.",
      "persist": "\n\nThe `persist()` method of the [Web Animations API](/en-US/docs/Web/API/Web_Animations_API)'s [Animation] interface explicitly persists an animation, preventing it from being [automatically removed](/en-US/docs/Web/API/Web_Animations_API/Using_the_Web_Animations_API#automatically_removing_filling_animations) when it is replaced by another animation.",
      "play": "\n\nThe **`play()`** method of the [Web Animations API](/en-US/docs/Web/API/Web_Animations_API)'s [Animation] Interface starts or resumes playing of an animation. If the animation is finished, calling `play()` restarts the animation, playing it from the beginning.",
      "playbackrate": "\n\nThe **`Animation.playbackRate`** property of the [Web Animations API](/en-US/docs/Web/API/Web_Animations_API) returns or sets the playback rate of the animation.\n\nAnimations have a **playback rate** that provides a scaling factor from the rate of change of the animation's [DocumentTimeline] time values to the animation's current time. The playback rate is initially `1`.",
      "playstate": "\n\nThe read-only **`Animation.playState`** property of the [Web Animations API](/en-US/docs/Web/API/Web_Animations_API) returns an enumerated value describing the playback state of an animation.",
      "ready": "\n\nThe read-only **`Animation.ready`** property of the [Web Animations API](/en-US/docs/Web/API/Web_Animations_API) returns a `Promise` which resolves when the animation is ready to play. A new promise is created every time the animation enters the `\"pending\"` [play state](/en-US/docs/Web/API/Animation/playState) as well as when the animation is canceled, since in both of those scenarios, the animation is ready to be started again.\n\n> **Note:** Since the same `Promise` is used for both pending `play` and pending `pause` requests, authors are advised to check the state of the animation when the promise is resolved.",
      "remove_event": "\n\nThe **`remove`** event of the [Animation] interface fires when the animation is [automatically removed](/en-US/docs/Web/API/Web_Animations_API/Using_the_Web_Animations_API#automatically_removing_filling_animations) by the browser.",
      "replacestate": "\n\nThe read-only **`Animation.replaceState`** property of the [Web Animations API](/en-US/docs/Web/API/Web_Animations_API) indicates whether the animation has been [removed by the browser automatically](/en-US/docs/Web/API/Web_Animations_API/Using_the_Web_Animations_API#automatically_removing_filling_animations) after being replaced by another animation.",
      "reverse": "\n\nThe **`Animation.reverse()`** method of the [Animation] Interface reverses the playback direction, meaning the animation ends at its beginning. If called on an unplayed animation, the whole animation is played backwards. If called on a paused animation, the animation will continue in reverse.",
      "starttime": "\n\nThe **`Animation.startTime`** property of the [Animation] interface is a double-precision floating-point value which indicates the scheduled time when an animation's playback should begin.\n\nAn animation's **start time** is the time value of its [DocumentTimeline] when its target [KeyframeEffect] is scheduled to begin playback. An animation's **start time** is initially unresolved (meaning that it's `null` because it has no value).",
      "timeline": "\n\nThe **`Animation.timeline`** property of the [Animation] interface returns or sets the [AnimationTimeline] associated with this animation. A timeline is a source of time values for synchronization purposes, and is an [AnimationTimeline]-based object. By default, the animation's timeline and the [Document]'s timeline are the same.",
      "updateplaybackrate": "\n\nThe **`updatePlaybackRate()`** method of the [Web Animations API](/en-US/docs/Web/API/Web_Animations_API)'s\n[Animation] Interface sets the speed of an animation after first\nsynchronizing its playback position.\n\nIn some cases, an animation may run on a separate thread or process and will continue\nupdating even while long-running JavaScript delays the main thread. In such a case,\nsetting the [Animation.playbackRate] on the animation\ndirectly may cause the animation's playback position to jump since its playback\nposition on the main thread may have drifted from the playback position where it is\ncurrently running.\n\n`updatePlaybackRate()` is an asynchronous method that sets the speed of an\nanimation after synchronizing with its current playback position, ensuring that the\nresulting change in speed does not produce a sharp jump. After calling\n`updatePlaybackRate()` the animation's [Animation.playbackRate] is _not_ immediately updated. It will be updated once the\nanimation's [Animation.ready] promise is resolved."
    }
  },
  "animationeffect": {
    "docs": "\n\nThe `AnimationEffect` interface of the [Web Animations API](/en-US/docs/Web/API/Web_Animations_API) is an interface representing animation effects.\n\n`AnimationEffect` is an abstract interface and so isn't directly instantiable. However, concrete interfaces such as [KeyframeEffect] inherit from it, and instances of these interfaces can be passed to [Animation] objects for playing, and may also be used by [CSS Animations](/en-US/docs/Web/CSS/CSS_animations) and [Transitions](/en-US/docs/Web/CSS/CSS_transitions).",
    "properties": {
      "getcomputedtiming": "\n\nThe `getComputedTiming()` method of the [AnimationEffect] interface returns the calculated timing properties for this animation effect.\n\n> **Note:** These values are comparable to the computed styles of an Element returned using `window.getComputedStyle(elem)`.",
      "gettiming": "\n\nThe `AnimationEffect.getTiming()` method of the [AnimationEffect] interface returns an object containing the timing properties for the Animation Effect.\n\n> **Note:** Several of the timing properties returned by `getTiming()` may take on the placeholder value `\"auto\"`. To obtain resolved values for use in timing computations, instead use [AnimationEffect.getComputedTiming].\n>\n> In the future, `\"auto\"` or similar values might be added to the types of more timing properties, and new types of [AnimationEffect] might resolve `\"auto\"` to different values.",
      "updatetiming": "\n\nThe `updateTiming()` method of the [AnimationEffect] interface updates the specified timing properties for an animation effect."
    }
  },
  "animationevent": {
    "docs": "\n\nThe **`AnimationEvent`** interface represents events providing information related to [animations](/en-US/docs/Web/CSS/CSS_animations/Using_CSS_animations).\n\n",
    "properties": {
      "animationname": "\n\nThe **`AnimationEvent.animationName`** read-only property is a\nstring containing the value of the  CSS\nproperty associated with the transition.",
      "elapsedtime": "\n\nThe **`AnimationEvent.elapsedTime`** read-only property is a\n`float` giving the amount of time the animation has been running, in seconds,\nwhen this event fired, excluding any time the animation was paused. For an\n[Element/animationstart_event] event,\n`elapsedTime` is `0.0` unless there was a negative value for\n, in which case the event will be fired with\n`elapsedTime` containing `(-1 * delay)`.",
      "pseudoelement": "\n\nThe **`AnimationEvent.pseudoElement`** read-only property is a\nstring, starting with `'::'`, containing the name of the [pseudo-element](/en-US/docs/Web/CSS/Pseudo-elements) the animation runs on.\nIf the animation doesn't run on a pseudo-element but on the element, an empty string: `''`."
    }
  },
  "animationplaybackevent": {
    "docs": "\n\nThe AnimationPlaybackEvent interface of the [Web Animations API](/en-US/docs/Web/API/Web_Animations_API) represents animation events.\n\nAs animations play, they report changes to their [Animation.playState] through animation events.\n\n",
    "properties": {
      "currenttime": "\n\nThe **`currentTime`** read-only property of the [AnimationPlaybackEvent] interface represents the current time of the animation that generated the event at the moment the event is queued. This will be unresolved if the animation was `idle` at the time the event was generated.",
      "timelinetime": "\n\nThe **`timelineTime`** read-only property of the [AnimationPlaybackEvent] interface represents the time value of the animation's [AnimationTimeline] at the moment the event is queued. This will be unresolved if the animation was not associated with a timeline at the time the event was generated or if the associated timeline was inactive."
    }
  },
  "animationtimeline": {
    "docs": "\n\nThe `AnimationTimeline` interface of the [Web Animations API](/en-US/docs/Web/API/Web_Animations_API) represents the timeline of an animation. This interface exists to define timeline features, inherited by other timeline types:\n\n- [DocumentTimeline]\n- [ScrollTimeline]\n- [ViewTimeline]",
    "properties": {
      "currenttime": "\n\nThe **`currentTime`** read-only property of the [Web Animations API](/en-US/docs/Web/API/Web_Animations_API)'s [AnimationTimeline] interface returns the timeline's current time in milliseconds, or `null` if the timeline is inactive."
    }
  },
  "attr": {
    "docs": "\n\nThe **`Attr`** interface represents one of an element's attributes as an object. In most situations, you will directly retrieve the attribute value as a string (e.g., [Element.getAttribute]), but certain functions (e.g., [Element.getAttributeNode]) or means of iterating return `Attr` instances.\n\nThe core idea of an object of type `Attr` is the association between a _name_ and a _value_. An attribute may also be part of a _namespace_ and, in this case, it also has a URI identifying the namespace, and a prefix that is an abbreviation for the namespace.\n\nThe name is deemed _local_ when it ignores the eventual namespace prefix and deemed _qualified_ when it includes the prefix of the namespace, if any, separated from the local name by a colon (`:`). We have three cases: an attribute outside of a namespace, an attribute inside a namespace without a prefix defined, an attribute inside a namespace with a prefix:\n\n| Attribute | Namespace name | Namespace prefix | Attribute local name | Attribute qualified name |\n| --------- | -------------- | ---------------- | -------------------- | ------------------------ |\n| `myAttr`  | _none_         | _none_           | `myAttr`             | `myAttr`                 |\n| `myAttr`  | `mynamespace`  | _none_           | `myAttr`             | `myAttr`                 |\n| `myAttr`  | `mynamespace`  | `myns`           | `myAttr`             | `myns:myAttr`            |\n\n> **Note:** This interface represents only attributes present in the tree representation of the [Element], being a SVG, an HTML or a MathML element. It doesn't represent the _property_ of an interface associated with such element, such as [HTMLTableElement] for a `table` element. (See  for more information about attributes and how they are _reflected_ into properties.)",
    "properties": {
      "localname": "\n\nThe read-only **`localName`** property of the [Attr] interface returns the _local part_ of the _qualified name_ of an attribute, that is the name of the attribute, stripped from any namespace in front of it. For example, if the qualified name is `xml:lang`, the returned local name is `lang`, if the element supports that namespace.\n\nThe local name is always in lower case, whatever case at the attribute creation.\n\n> **Note:** HTML only supports a fixed set of namespaces on SVG and MathML elements. These are `xml` (for the `xml:lang` attribute), `xlink` (for the `xlink:href`, `xlink:show`, `xlink:target` and `xlink:title` attributes) and `xpath`.\n>\n> That means that the local name of an attribute of an HTML element is always be equal to its qualified name: Colons are treated as regular characters. In XML, like in SVG or MathML, the colon denotes the end of the prefix and what is before is the namespace; the local name may be different from the qualified name.",
      "name": "\n\nThe read-only **`name`** property of the [Attr] interface returns the _qualified name_ of an attribute, that is the name of the attribute, with the namespace prefix, if any, in front of it. For example, if the local name is `lang` and the namespace prefix is `xml`, the returned qualified name is `xml:lang`.\n\nThe qualified name is always in lower case, whatever case at the attribute creation.",
      "namespaceuri": "\n\nThe read-only **`namespaceURI`** property of the [Attr] interface returns the namespace URI of the attribute,\nor `null` if the element is not in a namespace.\n\nThe namespace URI is set at the [Attr] creation and cannot be changed.\nAn attribute with a namespace can be created using [Element.setAttributeNS].\n\n> **Note:** an attribute does not inherit its namespace from the element it is attached to.\n> If an attribute is not explicitly given a namespace, it has no namespace.\n\nThe browser does not handle or enforce namespace validation per se. It is up to the JavaScript\napplication to do any necessary validation. Note, too, that the namespace prefix, once it\nis associated with a particular attribute node, cannot be changed.",
      "ownerelement": "\n\nThe read-only **`ownerElement`** property of the [Attr] interface returns the [Element] the attribute belongs to.",
      "prefix": "\n\nThe read-only **`prefix`** property of the [Attr] returns the namespace prefix of the attribute, or `null` if no prefix is specified.\n\nThe prefix is always in lower case, whatever case is used at the attribute creation.\n\n> **Note:** Only XML supports namespaces. HTML does not. That means that the prefix of an attribute of an HTML element will always be `null`.\n\nAlso, only the `xml` (for the `xml:lang` attribute), `xlink` (for the `xlink:href`, `xlink:show`, `xlink:target` and `xlink:title` attributes) and `xpath` namespaces are supported, and only on SVG and MathML elements.",
      "specified": "\n\nThe read-only **`specified`** property of the [Attr] interface always returns `true`.",
      "value": "\n\nThe **`value`** property of the [Attr] interface contains the value of the attribute."
    }
  },
  "audiobuffer": {
    "docs": "\n\nThe **`AudioBuffer`** interface represents a short audio asset residing in memory, created from an audio file using the [BaseAudioContext/decodeAudioData] method, or from raw data using [BaseAudioContext/createBuffer]. Once put into an AudioBuffer, the audio can then be played by being passed into an [AudioBufferSourceNode].\n\nObjects of these types are designed to hold small audio snippets, typically less than 45 s. For longer sounds, objects implementing the [MediaElementAudioSourceNode] are more suitable. The buffer contains the audio signal waveform encoded as a series of amplitudes in the following format: non-interleaved IEEE754 32-bit linear PCM with a nominal range between `-1` and `+1`, that is, a 32-bit floating point buffer, with each sample between -1.0 and 1.0. If the [AudioBuffer] has multiple channels, they are stored in separate buffers.",
    "properties": {
      "copyfromchannel": "\n\nThe\n**`copyFromChannel()`** method of the\n[AudioBuffer] interface copies the audio sample data from the specified\nchannel of the `AudioBuffer` to a specified\n`Float32Array`.",
      "copytochannel": "\n\nThe `copyToChannel()` method of the [AudioBuffer] interface copies\nthe samples to the specified channel of the `AudioBuffer`, from the source array.",
      "duration": "\n\nThe **`duration`** property of the [AudioBuffer] interface returns a double representing the duration, in seconds, of the PCM data\nstored in the buffer.",
      "getchanneldata": "\n\nThe **`getChannelData()`** method of the [AudioBuffer] Interface returns a `Float32Array` containing the PCM data associated with the channel, defined by the channel parameter (with 0 representing the first channel).",
      "length": "\n\nThe **`length`** property of the [AudioBuffer]\ninterface returns an integer representing the length, in sample-frames, of the PCM data\nstored in the buffer.",
      "numberofchannels": "\n\nThe `numberOfChannels` property of the [AudioBuffer]\ninterface returns an integer representing the number of discrete audio channels\ndescribed by the PCM data stored in the buffer.",
      "samplerate": "\n\nThe **`sampleRate`** property of the [AudioBuffer] interface returns a float representing the sample rate, in\nsamples per second, of the PCM data stored in the buffer."
    }
  },
  "audiobuffersourcenode": {
    "docs": "\n\nThe **`AudioBufferSourceNode`** interface is an [AudioScheduledSourceNode] which represents an audio source consisting of in-memory audio data, stored in an [AudioBuffer].\n\nThis interface is especially useful for playing back audio which has particularly stringent timing accuracy requirements, such as for sounds that must match a specific rhythm and can be kept in memory rather than being played from disk or the network. To play sounds which require accurate timing but must be streamed from the network or played from disk, use a [AudioWorkletNode] to implement its playback.\n\nAn `AudioBufferSourceNode` has no inputs and exactly one output, which has the same number of channels as the `AudioBuffer` indicated by its [AudioBufferSourceNode.buffer] property. If there's no buffer set—that is, if `buffer` is `null`—the output contains a single channel of silence (every sample is 0).\n\nAn `AudioBufferSourceNode` can only be played once; after each call to [AudioBufferSourceNode.start], you have to create a new node if you want to play the same sound again. Fortunately, these nodes are very inexpensive to create, and the actual `AudioBuffer`s can be reused for multiple plays of the sound. Indeed, you can use these nodes in a \"fire and forget\" manner: create the node, call `start()` to begin playing the sound, and don't even bother to hold a reference to it. It will automatically be garbage-collected at an appropriate time, which won't be until sometime after the sound has finished playing.\n\nMultiple calls to [AudioScheduledSourceNode/stop] are allowed. The most recent call replaces the previous one, if the `AudioBufferSourceNode` has not already reached the end of the buffer.\n\n![The AudioBufferSourceNode takes the content of an AudioBuffer and m](webaudioaudiobuffersourcenode.png)\n\n<table class=\"properties\">\n  <tbody>\n    <tr>\n      <th scope=\"row\">Number of inputs</th>\n      <td><code>0</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Number of outputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count</th>\n      <td>defined by the associated [AudioBuffer]</td>\n    </tr>\n  </tbody>\n</table>",
    "properties": {
      "buffer": "\n\nThe **`buffer`** property of the [AudioBufferSourceNode] interface provides the ability to play back audio\nusing an [AudioBuffer] as the source of the sound data.\n\nIf the `buffer` property is set to the value `null`, the node\ngenerates a single channel containing silence (that is, every sample is 0).",
      "detune": "\n\nThe **`detune`** property of the\n[AudioBufferSourceNode] interface is a [k-rate](/en-US/docs/Web/API/AudioParam#k-rate) [AudioParam]\nrepresenting detuning of oscillation in [cents](https://en.wikipedia.org/wiki/Cent_%28music%29).\n\nFor example, values of +100 and -100 detune the source up or down by one semitone,\nwhile +1200 and -1200 detune it up or down by one octave.",
      "loop": "\n\nThe `loop` property of the [AudioBufferSourceNode]\ninterface is a Boolean indicating if the audio asset must be replayed when the end of\nthe [AudioBuffer] is reached.\n\nThe `loop` property's default value is `false`.",
      "loopend": "\n\nThe `loopEnd` property of the [AudioBufferSourceNode]\ninterface specifies is a floating point number specifying, in seconds, at what offset\ninto playing the [AudioBuffer] playback should loop back to the time\nindicated by the [AudioBufferSourceNode.loopStart] property.\nThis is only used if the [AudioBufferSourceNode.loop] property is\n`true`.",
      "loopstart": "\n\nThe **`loopStart`** property of the [AudioBufferSourceNode] interface is a floating-point value indicating, in\nseconds, where in the [AudioBuffer] the restart of the play must happen.\n\nThe `loopStart` property's default value is `0`.",
      "playbackrate": "\n\nThe **`playbackRate`** property of\nthe [AudioBufferSourceNode] interface Is a [k-rate](/en-US/docs/Web/API/AudioParam#k-rate) [AudioParam] that\ndefines the speed at which the audio asset will be played.\n\nA value of 1.0 indicates it should play at the same speed as its sampling rate,\nvalues less than 1.0 cause the sound to play more slowly, while values greater than\n1.0 result in audio playing faster than normal. The default value is `1.0`.\nWhen set to another value, the `AudioBufferSourceNode` resamples the audio\nbefore sending it to the output.",
      "start": "\n\nThe `start()` method of the [AudioBufferSourceNode]\nInterface is used to schedule playback of the audio data contained in the buffer, or\nto begin playback immediately."
    }
  },
  "audiocontext": {
    "docs": "\n\nThe `AudioContext` interface represents an audio-processing graph built from audio modules linked together, each represented by an [AudioNode].\n\nAn audio context controls both the creation of the nodes it contains and the execution of the audio processing, or decoding. You need to create an `AudioContext` before you do anything else, as everything happens inside a context. It's recommended to create one AudioContext and reuse it instead of initializing a new one each time, and it's OK to use a single `AudioContext` for several different audio sources and pipeline concurrently.\n\n",
    "properties": {
      "baselatency": "\n\nThe **`baseLatency`** read-only property of the\n[AudioContext] interface returns a double that represents the number of\nseconds of processing latency incurred by the `AudioContext` passing an audio\nbuffer from the [AudioDestinationNode] — i.e. the end of the audio graph —\ninto the host system's audio subsystem ready for playing.\n\n> **Note:** You can request a certain latency during\n> [AudioContext.AudioContext] with the\n> `latencyHint` option, but the browser may ignore the option.",
      "close": "\n\nThe `close()` method of the [AudioContext] Interface closes the audio context, releasing any system audio resources that it uses.\n\nThis function does not automatically release all `AudioContext`-created objects, unless other references have been released as well; however, it will forcibly release any system audio resources that might prevent additional `AudioContexts` from being created and used, suspend the progression of audio time in the audio context, and stop processing audio data. The returned `Promise` resolves when all `AudioContext`-creation-blocking resources have been released. This method throws an `INVALID_STATE_ERR` exception if called on an [OfflineAudioContext].",
      "createmediaelementsource": "\n\nThe `createMediaElementSource()` method of the [AudioContext] Interface is used to create a new [MediaElementAudioSourceNode] object, given an existing HTML `audio` or `video` element, the audio from which can then be played and manipulated.\n\nFor more details about media element audio source nodes, check out the [MediaElementAudioSourceNode] reference page.",
      "createmediastreamdestination": "\n\nThe `createMediaStreamDestination()` method of the [AudioContext] Interface is used to create a new [MediaStreamAudioDestinationNode] object associated with a [WebRTC](/en-US/docs/Web/API/WebRTC_API) [MediaStream] representing an audio stream, which may be stored in a local file or sent to another computer.\n\nThe [MediaStream] is created when the node is created and is accessible via the [MediaStreamAudioDestinationNode]'s `stream` attribute. This stream can be used in a similar way as a `MediaStream` obtained via [navigator.getUserMedia] — it can, for example, be sent to a remote peer using the `addStream()` method of `RTCPeerConnection`.\n\nFor more details about media stream destination nodes, check out the [MediaStreamAudioDestinationNode] reference page.",
      "createmediastreamsource": "\n\nThe `createMediaStreamSource()` method of the [AudioContext]\nInterface is used to create a new [MediaStreamAudioSourceNode]\nobject, given a media stream (say, from a [MediaDevices.getUserMedia]\ninstance), the audio from which can then be played and manipulated.\n\nFor more details about media stream audio source nodes, check out the [MediaStreamAudioSourceNode] reference page.",
      "createmediastreamtracksource": "\n\nThe **`createMediaStreamTrackSource()`** method of the [AudioContext] interface creates and returns a\n[MediaStreamTrackAudioSourceNode] which represents an audio source whose\ndata comes from the specified [MediaStreamTrack].\n\nThis differs from [AudioContext.createMediaStreamSource], which creates a\n[MediaStreamAudioSourceNode] whose audio comes from the audio track in a\nspecified [MediaStream] whose [MediaStreamTrack.id] is\nfirst, lexicographically (alphabetically).",
      "getoutputtimestamp": "\n\nThe\n**`getOutputTimestamp()`** method of the\n[AudioContext] interface returns a new `AudioTimestamp` object\ncontaining two audio timestamp values relating to the current audio context.\n\nThe two values are as follows:\n\n- `AudioTimestamp.contextTime`: The time of the sample frame currently\n  being rendered by the audio output device (i.e., output audio stream position), in the\n  same units and origin as the context's [BaseAudioContext/currentTime].\n  Basically, this is the time after the audio context was first created.\n- `AudioTimestamp.performanceTime`: An estimation of the moment when the\n  sample frame corresponding to the stored `contextTime` value was rendered\n  by the audio output device, in the same units and origin as\n  [performance.now]. This is the time after the document containing the\n  audio context was first rendered.",
      "outputlatency": "\n\nThe **`outputLatency`** read-only property of\nthe [AudioContext] Interface provides an estimation of the output latency\nof the current audio context.\n\nThis is the time, in seconds, between the browser passing an audio buffer out of an\naudio graph over to the host system's audio subsystem to play, and the time at which the\nfirst sample in the buffer is actually processed by the audio output device.\n\nIt varies depending on the platform and the available hardware.",
      "resume": "\n\nThe **`resume()`** method of the [AudioContext]\ninterface resumes the progression of time in an audio context that has previously been\nsuspended.\n\nThis method will cause an `INVALID_STATE_ERR` exception to be thrown if\ncalled on an [OfflineAudioContext].",
      "setsinkid": "\n\nThe **`setSinkId()`** method of the [AudioContext] interface sets the output audio device for the `AudioContext`. If a sink ID is not explicitly set, the default system audio output device will be used.\n\nTo set the audio device to a device different than the default one, the developer needs permission to access to audio devices. If required, the user can be prompted to grant the required permission via a [MediaDevices.getUserMedia] call.\n\nIn addition, this feature may be blocked by a [`speaker-selection`](/en-US/docs/Web/HTTP/Headers/Permissions-Policy/speaker-selection) [Permissions Policy](/en-US/docs/Web/HTTP/Permissions_Policy).",
      "sinkchange_event": "\n\nThe **`sinkchange`** event of the [AudioContext] interface is fired when the output audio device (and therefore, the [AudioContext.sinkId]) has changed.",
      "sinkid": "\n\nThe **`sinkId`** read-only property of the\n[AudioContext] interface returns the sink ID of the current output audio device.",
      "suspend": "\n\nThe `suspend()` method of the [AudioContext] Interface suspends the progression of time in the audio context, temporarily halting audio hardware access and reducing CPU/battery usage in the process — this is useful if you want an application to power down the audio hardware when it will not be using an audio context for a while.\n\nThis method will cause an `INVALID_STATE_ERR` exception to be thrown if called on an [OfflineAudioContext]."
    }
  },
  "audiodata": {
    "docs": "\n\nThe **`AudioData`** interface of the [WebCodecs API](/en-US/docs/Web/API/WebCodecs_API) represents an audio sample.\n\n`AudioData` is a [transferable object](/en-US/docs/Web/API/Web_Workers_API/Transferable_objects).",
    "properties": {
      "allocationsize": "\n\nThe **`allocationSize()`** method of the [AudioData] interface returns the size in bytes required to hold the current sample as filtered by options passed into the method.",
      "clone": "\n\nThe **`clone()`** method of the [AudioData] interface creates a new `AudioData` object with reference to the same media resource as the original.",
      "close": "\n\nThe **`close()`** method of the [AudioData] interface clears all states and releases the reference to the media resource.",
      "copyto": "\n\nThe **`copyTo()`** method of the [AudioData] interface copies a plane of an `AudioData` object to a destination buffer.",
      "duration": "\n\nThe **`duration`** read-only property of the [AudioData] interface returns the duration in microseconds of this `AudioData` object.",
      "format": "\n\nThe **`format`** read-only property of the [AudioData] interface returns the sample format of the `AudioData` object.",
      "numberofchannels": "\n\nThe **`numberOfChannels`** read-only property of the [AudioData] interface returns the number of channels in the `AudioData` object.",
      "numberofframes": "\n\nThe **`numberOfFrames`** read-only property of the [AudioData] interface returns the number of frames in the `AudioData` object.",
      "samplerate": "\n\nThe **`sampleRate`** read-only property of the [AudioData] interface returns the sample rate in Hz.",
      "timestamp": "\n\nThe **`duration`** read-only property of the [AudioData] interface returns the timestamp of this `AudioData` object."
    }
  },
  "audiodecoder": {
    "docs": "\n\nThe **`AudioDecoder`** interface of the [WebCodecs API] decodes chunks of audio.\n\n",
    "properties": {
      "close": "\n\nThe **`close()`** method of the [AudioDecoder] interface ends all pending work and releases system resources.",
      "configure": "\n\nThe **`configure()`** method of the [AudioDecoder] interface enqueues a control message to configure the audio decoder for decoding chunks.",
      "decode": "\n\nThe **`decode()`** method of the [AudioDecoder] interface enqueues a control message to decode a given chunk of audio.",
      "decodequeuesize": "\n\nThe **`decodeQueueSize`** read-only property of the [AudioDecoder] interface returns the number of pending decode requests in the queue.",
      "dequeue_event": "\n\nThe **`dequeue`** event of the [AudioDecoder] interface fires to signal a decrease in [AudioDecoder.decodeQueueSize].\n\nThis eliminates the need for developers to use a [setTimeout] poll to determine when the queue has decreased, and more work should be queued up.",
      "flush": "\n\nThe **`flush()`** method of the [AudioDecoder] interface returns a Promise that resolves once all pending messages in the queue have been completed.",
      "isconfigsupported_static": "\n\nThe **`isConfigSupported()`** static method of the [AudioDecoder] interface checks if the given config is supported (that is, if [AudioDecoder] objects can be successfully configured with the given config).",
      "reset": "\n\nThe **`reset()`** method of the [AudioDecoder] interface resets all states including configuration, control messages in the control message queue, and all pending callbacks.",
      "state": "\n\nThe **`state`** read-only property of the [AudioDecoder] interface returns the current state of the underlying codec."
    }
  },
  "audiodestinationnode": {
    "docs": "\n\nThe `AudioDestinationNode` interface represents the end destination of an audio graph in a given context — usually the speakers of your device. It can also be the node that will \"record\" the audio data when used with an `OfflineAudioContext`.\n\n`AudioDestinationNode` has no output (as it _is_ the output, no more `AudioNode` can be linked after it in the audio graph) and one input. The number of channels in the input must be between `0` and the `maxChannelCount` value or an exception is raised.\n\nThe `AudioDestinationNode` of a given `AudioContext` can be retrieved using the [BaseAudioContext/destination] property.\n\n<table class=\"properties\">\n  <tbody>\n    <tr>\n      <th scope=\"row\">Number of inputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Number of outputs</th>\n      <td><code>0</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count mode</th>\n      <td><code>\"explicit\"</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count</th>\n      <td><code>2</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel interpretation</th>\n      <td><code>\"speakers\"</code></td>\n    </tr>\n  </tbody>\n</table>",
    "properties": {
      "maxchannelcount": "\n\nThe `maxchannelCount` property of the [AudioDestinationNode] interface is an `unsigned long` defining the maximum amount of channels that the physical device can handle.\n\nThe [AudioNode.channelCount] property can be set between 0 and this value (both included). If `maxChannelCount` is `0`, like in [OfflineAudioContext], the channel count cannot be changed."
    }
  },
  "audioencoder": {
    "docs": "\n\nThe **`AudioEncoder`** interface of the [WebCodecs API](/en-US/docs/Web/API/WebCodecs_API) encodes [AudioData] objects.\n\n",
    "properties": {
      "close": "\n\nThe **`close()`** method of the [AudioEncoder] interface ends all pending work and releases system resources.",
      "configure": "\n\nThe **`configure()`** method of the [AudioEncoder] interface enqueues a control message to configure the audio encoder for encoding chunks.",
      "dequeue_event": "\n\nThe **`dequeue`** event of the [AudioEncoder] interface fires to signal a decrease in [AudioEncoder.encodeQueueSize].\n\nThis eliminates the need for developers to use a [setTimeout] poll to determine when the queue has decreased, and more work should be queued up.",
      "encode": "\n\nThe **`encode()`** method of the [AudioEncoder] interface enqueues a control message to encode a given [AudioData] object.",
      "encodequeuesize": "\n\nThe **`encodeQueueSize`** read-only property of the [AudioEncoder] interface returns the number of pending encode requests in the queue.",
      "flush": "\n\nThe **`flush()`** method of the [AudioEncoder] interface returns a Promise that resolves once all pending messages in the queue have been completed.",
      "isconfigsupported_static": "\n\nThe **`isConfigSupported()`** static method of the [AudioEncoder] interface checks if the given config is supported (that is, if [AudioEncoder] objects can be successfully configured with the given config).",
      "reset": "\n\nThe **`reset()`** method of the [AudioEncoder] interface resets all states including configuration, control messages in the control message queue, and all pending callbacks.",
      "state": "\n\nThe **`state`** read-only property of the [AudioEncoder] interface returns the current state of the underlying codec."
    }
  },
  "audiolistener": {
    "docs": "\n\nThe `AudioListener` interface represents the position and orientation of the unique person listening to the audio scene, and is used in [audio spatialization](/en-US/docs/Web/API/Web_Audio_API/Web_audio_spatialization_basics). All [PannerNode]s spatialize in relation to the `AudioListener` stored in the [BaseAudioContext.listener] attribute.\n\nIt is important to note that there is only one listener per context and that it isn't an [AudioNode].\n\n![We see the position, up and front vectors of an AudioListener, with the up and front vectors at 90° from the other.](webaudiolistenerreduced.png)",
    "properties": {
      "forwardx": "\n\nThe `forwardX` read-only property of the [AudioListener] interface is an [AudioParam] representing the x value of the direction vector defining the forward direction the listener is pointing in.\n\n> **Note:** The parameter is _a-rate_ when used with a [PannerNode] whose [PannerNode.panningModel] is set to equalpower, or _k-rate_ otherwise.",
      "forwardy": "\n\nThe `forwardY` read-only property of the [AudioListener] interface is an [AudioParam] representing the y value of the direction vector defining the forward direction the listener is pointing in.\n\n> **Note:** The parameter is _a-rate_ when used with a [PannerNode] whose [PannerNode.panningModel] is set to equalpower, or _k-rate_ otherwise.",
      "forwardz": "\n\nThe `forwardZ` read-only property of the [AudioListener] interface is an [AudioParam] representing the z value of the direction vector defining the forward direction the listener is pointing in.\n\n> **Note:** The parameter is _a-rate_ when used with a [PannerNode] whose [PannerNode.panningModel] is set to equalpower, or _k-rate_ otherwise.",
      "positionx": "\n\nThe `positionX` read-only property of the [AudioListener] interface is an [AudioParam] representing the x position of the listener in 3D cartesian space.\n\n> **Note:** The parameter is _a-rate_ when used with a [PannerNode] whose [PannerNode.panningModel] is set to equalpower, or _k-rate_ otherwise.",
      "positiony": "\n\nThe `positionY` read-only property of the [AudioListener] interface is an [AudioParam] representing the y position of the listener in 3D cartesian space.\n\n> **Note:** The parameter is _a-rate_ when used with a [PannerNode] whose [PannerNode.panningModel] is set to equalpower, or _k-rate_ otherwise.",
      "positionz": "\n\nThe `positionZ` read-only property of the [AudioListener] interface is an [AudioParam] representing the z position of the listener in 3D cartesian space.\n\n> **Note:** The parameter is _a-rate_ when used with a [PannerNode] whose [PannerNode.panningModel] is set to equalpower, or _k-rate_ otherwise.",
      "setorientation": "\n\nThe `setOrientation()` method of the [AudioListener] interface defines the orientation of the listener.\n\nIt consists of two direction vectors:\n\n- The _front vector_, defined by the three unitless parameters `x`, `y` and `z`, describes the direction of the face of the listener, that is the direction the nose of the person is pointing towards. The front vector's default value is `(0, 0, -1)`.\n- The _up vector_, defined by three unitless parameters `xUp`, `yUp` and `zUp`, describes the direction of the top of the listener's head. The up vector's default value is `(0, 1, 0)`.\n\nThe two vectors must be separated by an angle of 90° — in linear analysis terms, they must be perpendicular to each other.",
      "setposition": " \n\nThe `setPosition()` method of the [AudioListener] Interface defines the position of the listener.\n\nThe three parameters `x`, `y` and `z` are unitless and describe the listener's position in 3D space according to the right-hand Cartesian coordinate system. [PannerNode] objects use this position relative to individual audio sources for spatialization.\n\nThe default value of the position vector is `(0, 0, 0)`.\n\n> **Note:** As this method is deprecated, use the three [AudioListener.positionX], [AudioListener.positionY], and [AudioListener.positionZ] properties instead.",
      "upx": "\n\nThe `upX` read-only property of the [AudioListener] interface is an [AudioParam] representing the x value of the direction vector defining the up direction the listener is pointing in.\n\n> **Note:** The parameter is _a-rate_ when used with a [PannerNode] whose [PannerNode.panningModel] is set to equalpower, or _k-rate_ otherwise.",
      "upy": "\n\nThe `upY` read-only property of the [AudioListener] interface is an [AudioParam] representing the y value of the direction vector defining the up direction the listener is pointing in.\n\n> **Note:** The parameter is _a-rate_ when used with a [PannerNode] whose [PannerNode.panningModel] is set to equalpower, or _k-rate_ otherwise.",
      "upz": "\n\nThe `upZ` read-only property of the [AudioListener] interface is an [AudioParam] representing the z value of the direction vector defining the up direction the listener is pointing in.\n\n> **Note:** The parameter is _a-rate_ when used with a [PannerNode] whose [PannerNode.panningModel] is set to equalpower, or _k-rate_ otherwise."
    }
  },
  "audionode": {
    "docs": "\n\nThe **`AudioNode`** interface is a generic interface for representing an audio processing module.\n\nExamples include:\n\n- an audio source (e.g. an HTML `audio` or `video` element, an [OscillatorNode], etc.),\n- the audio destination,\n- intermediate processing module (e.g. a filter like [BiquadFilterNode] or [ConvolverNode]), or\n- volume control (like [GainNode])\n\n> **Note:** An `AudioNode` can be target of events, therefore it implements the [EventTarget] interface.",
    "properties": {
      "channelcount": "\n\nThe **`channelCount`** property of the [AudioNode] interface represents an integer used to determine how many channels are used when [up-mixing and down-mixing](/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#up-mixing_and_down-mixing) connections to any inputs to the node.\n\n`channelCount`'s usage and precise definition depend on the value of [AudioNode.channelCountMode]:\n\n- It is ignored if the `channelCountMode` value is `max`.\n- It is used as a maximum value if the `channelCountMode` value is `clamped-max`.\n- It is used as the exact value if the `channelCountMode` value is `explicit`.",
      "channelcountmode": "\n\nThe `channelCountMode` property of the [AudioNode] interface represents an enumerated value describing the way channels must be matched between the node's inputs and outputs.",
      "channelinterpretation": "\n\nThe **`channelInterpretation`** property of the [AudioNode] interface represents an enumerated value describing how input channels are mapped to output channels when the number of inputs/outputs is different. For example, this setting defines how a mono input will be up-mixed to a stereo or 5.1 channel output, or how a quad channel input will be down-mixed to a stereo or mono output.\n\nThe property has two options: `speakers` and `discrete`. These are documented in [Basic concepts behind Web Audio API > up-mixing and down-mixing](/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#up-mixing_and_down-mixing).",
      "connect": "\n\nThe `connect()` method of the [AudioNode] interface lets\nyou connect one of the node's outputs to a target, which may be either another\n`AudioNode` (thereby directing the sound data to the specified node) or an\n[AudioParam], so that the node's output data is automatically used to\nchange the value of that parameter over time.",
      "context": "\n\nThe read-only `context` property of the\n[AudioNode] interface returns the associated\n[BaseAudioContext], that is the object representing the processing graph\nthe node is participating in.",
      "disconnect": "\n\nThe **`disconnect()`** method of the [AudioNode] interface lets you disconnect one or more nodes from the node on which the method is called.",
      "numberofinputs": "\n\nThe `numberOfInputs` property of\nthe [AudioNode] interface returns the number of inputs feeding the\nnode. Source nodes are defined as nodes having a `numberOfInputs`\nproperty with a value of 0.",
      "numberofoutputs": "\n\nThe `numberOfOutputs` property of\nthe [AudioNode] interface returns the number of outputs coming out of\nthe node. Destination nodes — like [AudioDestinationNode] — have\na value of 0 for this attribute."
    }
  },
  "audioparam": {
    "docs": "\n\nThe Web Audio API's `AudioParam` interface represents an audio-related parameter, usually a parameter of an [AudioNode] (such as [GainNode.gain]).\n\nAn `AudioParam` can be set to a specific value or a change in value, and can be scheduled to happen at a specific time and following a specific pattern.\n\nEach `AudioParam` has a list of events, initially empty, that define when and how values change. When this list is not empty, changes using the `AudioParam.value` attributes are ignored. This list of events allows us to schedule changes that have to happen at very precise times, using arbitrary timeline-based automation curves. The time used is the one defined in [BaseAudioContext/currentTime].",
    "properties": {
      "cancelandholdattime": "\n\nThe **`cancelAndHoldAtTime()`** method of the\n[AudioParam] interface cancels all scheduled future changes to the\n`AudioParam` but holds its value at a given time until further changes are\nmade using other methods.",
      "cancelscheduledvalues": "\n\nThe `cancelScheduledValues()` method of the [AudioParam]\nInterface cancels all scheduled future changes to the `AudioParam`.",
      "defaultvalue": "\n\nThe **`defaultValue`**\nread-only property of the [AudioParam] interface represents the initial\nvalue of the attributes as defined by the specific [AudioNode] creating\nthe `AudioParam`.",
      "exponentialramptovalueattime": "\n\nThe **`exponentialRampToValueAtTime()`** method of the [AudioParam] Interface schedules a gradual exponential change in the value\nof the [AudioParam]. The change starts at the time specified for the\n_previous_ event, follows an exponential ramp to the new value given in the\n`value` parameter, and reaches the new value at the time given in the\n`endTime` parameter.\n\n> **Note:** Exponential ramps are considered more useful when changing\n> frequencies or playback rates than linear ramps because of the way the human ear\n> works.",
      "linearramptovalueattime": "\n\nThe `linearRampToValueAtTime()` method of the [AudioParam]\nInterface schedules a gradual linear change in the value of the\n`AudioParam`. The change starts at the time specified for the\n_previous_ event, follows a linear ramp to the new value given in the\n`value` parameter, and reaches the new value at the time given in the\n`endTime` parameter.",
      "maxvalue": "\n\nThe **`maxValue`**\nread-only property of the [AudioParam] interface represents the maximum\npossible value for the parameter's nominal (effective) range.",
      "minvalue": "\n\nThe **`minValue`**\nread-only property of the [AudioParam] interface represents the minimum\npossible value for the parameter's nominal (effective) range.",
      "settargetattime": "\n\nThe `setTargetAtTime()` method of the\n[AudioParam] interface schedules the start of a gradual change to the\n`AudioParam` value. This is useful for decay or release portions of ADSR\nenvelopes.",
      "setvalueattime": "\n\nThe `setValueAtTime()` method of the\n[AudioParam] interface schedules an instant change to the\n`AudioParam` value at a precise time, as measured against\n[BaseAudioContext/currentTime]. The new value is given in the value parameter.",
      "setvaluecurveattime": "\n\nThe\n**`setValueCurveAtTime()`** method of the\n[AudioParam] interface schedules the parameter's value to change\nfollowing a curve defined by a list of values.\n\nThe curve is a linear\ninterpolation between the sequence of values defined in an array of floating-point\nvalues, which are scaled to fit into the given interval starting at\n`startTime` and a specific duration.",
      "value": "\n\nThe [Web Audio API's](/en-US/docs/Web/API/Web_Audio_API)\n[AudioParam] interface property **`value`** gets\nor sets the value of this [AudioParam] at the current time. Initially, the value is set to [AudioParam.defaultValue].\n\nSetting `value` has the same effect as\ncalling [AudioParam.setValueAtTime] with the time returned by the\n`AudioContext`'s [BaseAudioContext/currentTime]\nproperty."
    }
  },
  "audioparamdescriptor": {
    "docs": "\n\nThe **`AudioParamDescriptor`** dictionary of the [Web Audio API](/en-US/docs/Web/API/Web_Audio_API) specifies properties for [AudioParam] objects.\n\nIt is used to create custom `AudioParam`s on an [AudioWorkletNode]. If the underlying [AudioWorkletProcessor] has a [AudioWorkletProcessor.parameterDescriptors] static getter, then the returned array of objects based on this dictionary is used internally by `AudioWorkletNode` constructor to populate its [AudioWorkletNode.parameters] property accordingly."
  },
  "audioparammap": {
    "docs": "\n\nThe **`AudioParamMap`** interface of the [Web Audio API](/en-US/docs/Web/API/Web_Audio_API) represents an iterable and read-only set of multiple audio parameters.\n\nAn `AudioParamMap` instance is a read-only [`Map`-like object](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map#map-like_browser_apis), in which each key is the name string for a parameter, and the corresponding value is an [AudioParam] containing the value of that parameter."
  },
  "audioprocessingevent": {
    "docs": "\n\nThe `AudioProcessingEvent` interface of the [Web Audio API](/en-US/docs/Web/API/Web_Audio_API) represents events that occur when a [ScriptProcessorNode] input buffer is ready to be processed.\n\nAn `audioprocess` event with this interface is fired on a [ScriptProcessorNode] when audio processing is required. During audio processing, the input buffer is read and processed to produce output audio data, which is then written to the output buffer.\n\n> **Warning:** This feature has been deprecated and should be replaced by an [`AudioWorklet`](/en-US/docs/Web/API/AudioWorklet).\n\n",
    "properties": {
      "inputbuffer": "\n\nThe **`inputBuffer`** read-only property of the [AudioProcessingEvent] interface represents the input buffer of an audio processing event.\n\nThe input buffer is represented by an [AudioBuffer] object, which contains a collection of audio channels, each of which is an array of floating-point values representing the audio signal waveform encoded as a series of amplitudes. The number of channels and the length of each channel are determined by the channel count and buffer size properties of the `AudioBuffer`.",
      "outputbuffer": "\n\nThe **`outputBuffer`** read-only property of the [AudioProcessingEvent] interface represents the output buffer of an audio processing event.\n\nThe output buffer is represented by an [AudioBuffer] object, which contains a collection of audio channels, each of which is an array of floating-point values representing the audio signal waveform encoded as a series of amplitudes. The number of channels and the length of each channel are determined by the channel count and buffer size properties of the `AudioBuffer`.",
      "playbacktime": "\n\nThe **`playbackTime`** read-only property of the [AudioProcessingEvent] interface represents the time when the audio will be played. It is in the same coordinate system as the time used by the [AudioContext]."
    }
  },
  "audioscheduledsourcenode": {
    "docs": "\n\nThe `AudioScheduledSourceNode` interface—part of the Web Audio API—is a parent interface for several types of audio source node interfaces which share the ability to be started and stopped, optionally at specified times. Specifically, this interface defines the [AudioScheduledSourceNode.start] and [AudioScheduledSourceNode.stop] methods, as well as the [AudioScheduledSourceNode.ended_event] event.\n\n> **Note:** You can't create an `AudioScheduledSourceNode` object directly. Instead, use an interface which extends it, such as [AudioBufferSourceNode], [OscillatorNode] or [ConstantSourceNode].\n\nUnless stated otherwise, nodes based upon `AudioScheduledSourceNode` output silence when not playing (that is, before `start()` is called and after `stop()` is called). Silence is represented, as always, by a stream of samples with the value zero (0).\n\n",
    "properties": {
      "ended_event": "`Web Audio API`\n\nThe `ended` event of the [AudioScheduledSourceNode] interface is fired when the source node has stopped playing.\n\nThis event occurs when a [AudioScheduledSourceNode] has stopped playing, either because it's reached a predetermined stop time, the full duration of the audio has been performed, or because the entire buffer has been played.\n\nThis event is not cancelable and does not bubble.",
      "start": "\n\nThe `start()` method on\n[AudioScheduledSourceNode] schedules a sound to begin playback at the\nspecified time. If no time is specified, then the sound begins playing\nimmediately.",
      "stop": "\n\nThe `stop()` method on [AudioScheduledSourceNode] schedules a\nsound to cease playback at the specified time. If no time is specified, then the sound\nstops playing immediately.\n\nEach time you call `stop()` on the same node, the specified time replaces\nany previously-scheduled stop time that hasn't occurred yet. If the node has already\nstopped, this method has no effect.\n\n> **Note:** If a scheduled stop time occurs before the node's scheduled\n> start time, the node never starts to play."
    }
  },
  "audiosinkinfo": {
    "docs": "\n\nThe **`AudioSinkInfo`** interface of the [Web Audio API] represents information describing an [AudioContext]'s sink ID, retrieved via [AudioContext.sinkId].\n\n",
    "properties": {
      "type": "\n\nThe **`type`** read-only property of the [AudioSinkInfo] interface returns the type of the audio output device."
    }
  },
  "audiotrack": {
    "docs": "\n\nThe **`AudioTrack`** interface represents a single audio track from one of the HTML media elements, `audio` or `video`.\n\nThe most common use for accessing an `AudioTrack` object is to toggle its [AudioTrack.enabled] property in order to mute and unmute the track.",
    "properties": {
      "enabled": "\n\nThe **[AudioTrack]** property\n**`enabled`** specifies whether or not the described audio\ntrack is currently enabled for use. If the track is disabled by setting\n`enabled` to `false`, the track is muted and does not produce\naudio.",
      "id": "\n\nThe **`id`** property contains a\nstring which uniquely identifies the track represented by the\n**[AudioTrack]**.\n\nThis ID can be used with the\n[AudioTrackList.getTrackById] method to locate a specific track within\nthe media associated with a media element. The track ID can also be used as the fragment of a URL that loads the specific track\n(if the media supports media fragments).",
      "kind": "\n\nThe **`kind`** property contains a\nstring indicating the category of audio contained in the\n**[AudioTrack]**.\n\nThe `kind` can be used\nto determine the scenarios in which specific tracks should be enabled or disabled. See\n[Audio track kind strings](#audio_track_kind_strings) for a list of the kinds available for audio tracks.",
      "label": "\n\nThe read-only **[AudioTrack]**\nproperty **`label`** returns a string specifying the audio\ntrack's human-readable label, if one is available; otherwise, it returns an empty\nstring.",
      "language": "\n\nThe read-only **[AudioTrack]**\nproperty **`language`** returns a string identifying the\nlanguage used in the audio track.\n\nFor tracks that include multiple languages\n(such as a movie in English in which a few lines are spoken in other languages), this\nshould be the video's primary language.",
      "sourcebuffer": "\n\nThe read-only **[AudioTrack]**\nproperty **`sourceBuffer`** returns the\n[SourceBuffer] that created the track, or null if the track was not\ncreated by a [SourceBuffer] or the [SourceBuffer] has been\nremoved from the [MediaSource.sourceBuffers] attribute of its parent\nmedia source."
    }
  },
  "audiotracklist": {
    "docs": "\n\nThe **`AudioTrackList`** interface is used to represent a list of the audio tracks contained within a given HTML media element, with each track represented by a separate [AudioTrack] object in the list.\n\nRetrieve an instance of this object with [HTMLMediaElement.audioTracks]. The individual tracks can be accessed using array syntax.\n\n",
    "properties": {
      "addtrack_event": "\n\nThe `addtrack` event is fired when a track is added to an [`AudioTrackList`](/en-US/docs/Web/API/AudioTrackList).",
      "change_event": "\n\nThe `change` event is fired when an audio track is enabled or disabled, for example by changing the track's [`enabled`](/en-US/docs/Web/API/AudioTrack/enabled) property.\n\nThis event is not cancelable and does not bubble.",
      "gettrackbyid": "\n\nThe **[AudioTrackList]** method\n**`getTrackById()`** returns the first\n[AudioTrack] object from the track list whose [AudioTrack.id] matches the specified string. This lets you find a specified track if\nyou know its ID string.",
      "length": "\n\nThe read-only **[AudioTrackList]**\nproperty **`length`** returns the number of entries in the\n`AudioTrackList`, each of which is an [AudioTrack]\nrepresenting one audio track in the media element. A value of 0 indicates that\nthere are no audio tracks in the media.",
      "removetrack_event": "\n\nThe `removetrack` event is fired when a track is removed from an [`AudioTrackList`](/en-US/docs/Web/API/AudioTrackList)."
    }
  },
  "audioworklet": {
    "docs": "\n\nThe **`AudioWorklet`** interface of the [Web Audio API](/en-US/docs/Web/API/Web_Audio_API) is used to supply custom audio processing scripts that execute in a separate thread to provide very low latency audio processing.\n\nThe worklet's code is run in the [AudioWorkletGlobalScope] global execution context, using a separate Web Audio thread which is shared by the worklet and other audio nodes.\n\nAccess the audio context's instance of `AudioWorklet` through the [BaseAudioContext.audioWorklet] property.\n\n"
  },
  "audioworkletglobalscope": {
    "docs": "\n\nThe **`AudioWorkletGlobalScope`** interface of the [Web Audio API](/en-US/docs/Web/API/Web_Audio_API) represents a global execution context for user-supplied code, which defines custom [AudioWorkletProcessor]-derived classes.\n\nEach [BaseAudioContext] has a single [AudioWorklet] available under the [BaseAudioContext.audioWorklet] property, which runs its code in a single `AudioWorkletGlobalScope`.\n\nAs the global execution context is shared across the current `BaseAudioContext`, it's possible to define any other variables and perform any actions allowed in worklets — apart from defining `AudioWorkletProcessor` derived classes.\n\n",
    "properties": {
      "currentframe": "\n\nThe read-only **`currentFrame`** property of the [AudioWorkletGlobalScope] interface returns an integer that represents the ever-increasing current sample-frame of the audio block being processed. It is incremented by 128 (the size of a render quantum) after the processing of each audio block.",
      "currenttime": "\n\nThe read-only **`currentTime`** property of the [AudioWorkletGlobalScope] interface returns a double that represents the ever-increasing context time of the audio block being processed. It is equal to the [BaseAudioContext.currentTime] property of the [BaseAudioContext] the worklet belongs to.",
      "registerprocessor": "\n\nThe **`registerProcessor`** method of the\n[AudioWorkletGlobalScope] interface registers a class constructor derived\nfrom [AudioWorkletProcessor] interface under a specified _name_.",
      "samplerate": "\n\nThe read-only **`sampleRate`** property of the [AudioWorkletGlobalScope] interface returns a float that represents the sample rate of the associated [BaseAudioContext] the worklet belongs to."
    }
  },
  "audioworkletnode": {
    "docs": "\n\n> **Note:** Although the interface is available outside [secure contexts](/en-US/docs/Web/Security/Secure_Contexts), the [BaseAudioContext.audioWorklet] property is not, thus custom [AudioWorkletProcessor]s cannot be defined outside them.\n\nThe **`AudioWorkletNode`** interface of the [Web Audio API](/en-US/docs/Web/API/Web_Audio_API) represents a base class for a user-defined [AudioNode], which can be connected to an audio routing graph along with other nodes. It has an associated [AudioWorkletProcessor], which does the actual audio processing in a Web Audio rendering thread.\n\n",
    "properties": {
      "parameters": "\n\nThe read-only **`parameters`** property of the\n[AudioWorkletNode] interface returns the associated\n[AudioParamMap] — that is, a `Map`-like collection of\n[AudioParam] objects. They are instantiated during creation of the\nunderlying [AudioWorkletProcessor] according to its\n[AudioWorkletProcessor.parameterDescriptors] static\ngetter.",
      "port": "\n\nThe read-only **`port`** property of the\n[AudioWorkletNode] interface returns the associated\n[MessagePort]. It can be used to communicate between the node and its\nassociated [AudioWorkletProcessor].\n\n> **Note:** The port at the other end of the channel is\n> available under the [AudioWorkletProcessor.port] property of the\n> processor.",
      "processorerror_event": "\n\nThe `processorerror` event fires when the underlying [AudioWorkletProcessor] behind the node throws an exception in its constructor, the [AudioWorkletProcessor.process] method, or any user-defined class method.\n\nOnce an exception is thrown, the processor (and thus the node) will output silence throughout its lifetime."
    }
  },
  "audioworkletprocessor": {
    "docs": "\n\nThe **`AudioWorkletProcessor`** interface of the [Web Audio API](/en-US/docs/Web/API/Web_Audio_API) represents an audio processing code behind a custom [AudioWorkletNode]. It lives in the [AudioWorkletGlobalScope] and runs on the Web Audio rendering thread. In turn, an [AudioWorkletNode] based on it runs on the main thread.",
    "properties": {
      "parameterdescriptors": "\n\nThe read-only **`parameterDescriptors`** property of an [AudioWorkletProcessor]-derived class is a _static getter_,\nwhich returns an iterable of [AudioParamDescriptor]-based objects.\n\nThe property is not a part of the [AudioWorkletProcessor]\ninterface, but, if defined, it is called internally by the\n[AudioWorkletProcessor] constructor to create a list of custom\n[AudioParam] objects in the [AudioWorkletNode.parameters] property of the associated [AudioWorkletNode].\n\nDefining the getter is optional.",
      "port": "\n\nThe read-only **`port`** property of the\n[AudioWorkletProcessor] interface returns the associated\n[MessagePort]. It can be used to communicate between the processor and the\n[AudioWorkletNode] to which it belongs.\n\n> **Note:** The port at the other end of the channel is\n> available under the [AudioWorkletNode.port] property of the node.",
      "process": "\n\nThe **`process()`**\nmethod of an [AudioWorkletProcessor]-derived class implements the audio\nprocessing algorithm for the audio processor worklet.\n\nAlthough the method is\nnot a part of the [AudioWorkletProcessor] interface, any implementation\nof `AudioWorkletProcessor` must provide a `process()` method.\n\nThe method is called synchronously from the audio rendering thread, once for each block\nof audio (also known as a rendering quantum) being directed through the processor's\ncorresponding [AudioWorkletNode]. In other words, every time a new block of\naudio is ready for your processor to manipulate, your `process()` function is\ninvoked to do so.\n\n> **Note:** Currently, audio data blocks are always 128 frames\n> long—that is, they contain 128 32-bit floating-point samples for each of the inputs'\n> channels. However, plans are already in place to revise the specification to allow the\n> size of the audio blocks to be changed depending on circumstances (for example, if the\n> audio hardware or CPU utilization is more efficient with larger block sizes).\n> Therefore, you _must always check the size of the sample array_ rather than\n> assuming a particular size.\n>\n> This size may even be allowed to change over time, so you mustn't look at just the\n> first block and assume the sample buffers will always be the same size."
    }
  },
  "authenticatorassertionresponse": {
    "docs": "\n\nThe **`AuthenticatorAssertionResponse`** interface of the [Web Authentication API](/en-US/docs/Web/API/Web_Authentication_API) contains a [digital signature](/en-US/docs/Glossary/Signature/Security) from the private key of a particular WebAuthn credential. The relying party's server can verify this signature to authenticate a user, for example when they sign in.\n\nAn `AuthenticatorAssertionResponse` object instance is available in the [PublicKeyCredential.response] property of a [PublicKeyCredential] object returned by a successful [CredentialsContainer.get] call.\n\nThis interface inherits from [AuthenticatorResponse].\n\n> **Note:** This interface is restricted to top-level contexts. Use from within an `iframe` element will not have any effect.",
    "properties": {
      "authenticatordata": "\n\nThe **`authenticatorData`** property of the [AuthenticatorAssertionResponse] interface returns an `ArrayBuffer` containing information from the authenticator such as the Relying Party ID Hash (rpIdHash), a signature counter, test of user presence, user verification flags, and any extensions processed by the authenticator.",
      "signature": "\n\nThe **`signature`** read-only property of the\n[AuthenticatorAssertionResponse] interface is an `ArrayBuffer`\nobject which is the signature of the authenticator for both\n[AuthenticatorAssertionResponse.authenticatorData] and a SHA-256 hash of\nthe client data\n([AuthenticatorResponse.clientDataJSON]).\n\nThis signature will be sent to the server for control, as part of the response. It\nprovides the proof that an authenticator does possess the private key which was used for\nthe credential's generation.",
      "userhandle": "\n\nThe **`userHandle`** read-only property of the [AuthenticatorAssertionResponse] interface is an `ArrayBuffer` object providing an opaque identifier for the given user. Such an identifier can be used by the relying party's server to link the user account with its corresponding credentials and other data.\n\nThis value is specified as `user.id` in the options passed to the originating [CredentialsContainer.create] call."
    }
  },
  "authenticatorattestationresponse": {
    "docs": "\n\nThe **`AuthenticatorAttestationResponse`** interface of the [Web Authentication API](/en-US/docs/Web/API/Web_Authentication_API) is the result of a WebAuthn credential registration. It contains information about the credential that the server needs to perform WebAuthn assertions, such as its credential ID and public key.\n\nAn `AuthenticatorAttestationResponse` object instance is available in the [PublicKeyCredential.response] property of a [PublicKeyCredential] object returned by a successful [CredentialsContainer.create] call.\n\nThis interface inherits from [AuthenticatorResponse].\n\n> **Note:** This interface is restricted to top-level contexts. Use of its features from within an `iframe` element will not have any effect.",
    "properties": {
      "attestationobject": "\n\nThe **`attestationObject`** property of the\n[AuthenticatorAttestationResponse] interface returns an\n`ArrayBuffer` containing the new public key, as well as signature over the\nentire `attestationObject` with a private key that is stored in the\nauthenticator when it is manufactured.\n\nAs part of the [CredentialsContainer.create] call, an authenticator will\ncreate a new keypair as well as an `attestationObject` for that keypair. The public key\nthat corresponds to the private key that has created the attestation signature is well\nknown; however, there are various well known attestation public key chains for different\necosystems (for example, Android or TPM attestations).",
      "getauthenticatordata": "\n\nThe **`getAuthenticatorData()`** method of the [AuthenticatorAttestationResponse] interface returns an `ArrayBuffer` containing the authenticator data contained within the [AuthenticatorAttestationResponse.attestationObject] property.\n\nThis is a convenience function, created to allow easy access to the authenticator data without having to write extra parsing code to extract it from the `attestationObject`.",
      "getpublickey": "\n\nThe **`getPublicKey()`** method of the [AuthenticatorAttestationResponse] interface returns an `ArrayBuffer` containing the DER `SubjectPublicKeyInfo` of the new credential (see [Subject Public Key Info](https://www.rfc-editor.org/rfc/rfc5280#section-4.1.2.7)), or `null` if this is not available.\n\nThis is a convenience function, created to allow easy access to the public key. This key will need to be stored in order to verify future authentication operations (i.e., using [CredentialsContainer.get]).",
      "getpublickeyalgorithm": "\n\nThe **`getPublicKeyAlgorithm()`** method of the [AuthenticatorAttestationResponse] interface returns a number that is equal to a [COSE Algorithm Identifier](https://www.iana.org/assignments/cose/cose.xhtml#algorithms), representing the cryptographic algorithm used for the new credential.\n\nThis is a convenience function created to allow easy access to the algorithm type. This information will need to be stored in order to verify future authentication operations (i.e., using [CredentialsContainer.get]).",
      "gettransports": "\n\nThe **`getTransports()`** method of the [AuthenticatorAttestationResponse] interface returns an array of strings describing the different transports which may be used by the authenticator.\n\nSuch transports may be USB, NFC, BLE, internal (applicable when the authenticator is not removable from the device), or a hybrid approach. Sites should not interpret this array but instead store it along with the rest of the credential information. In a subsequent [CredentialsContainer.get] call, the `transports` value(s) specified inside `publicKey.allowCredentials` should be set to the stored array value. This provides a hint to the browser as to which types of authenticators to try when making an assertion for this credential."
    }
  },
  "authenticatorresponse": {
    "docs": "\n\nThe **`AuthenticatorResponse`** interface of the [Web Authentication API](/en-US/docs/Web/API/Web_Authentication_API) is the base interface for interfaces that provide a cryptographic root of trust for a key pair. The child interfaces include information from the browser such as the challenge origin and either may be returned from [PublicKeyCredential.response].",
    "properties": {
      "clientdatajson": "\n\nThe **`clientDataJSON`** property of the [AuthenticatorResponse] interface stores a [JSON](/en-US/docs/Learn/JavaScript/Objects/JSON) string in an\n`ArrayBuffer`, representing the client data that was passed to [CredentialsContainer.create] or [CredentialsContainer.get]. This property is only accessed on one of the child objects of `AuthenticatorResponse`, specifically [AuthenticatorAttestationResponse] or [AuthenticatorAssertionResponse]."
    }
  },
  "backgroundfetchevent": {
    "docs": "\n\nThe **`BackgroundFetchEvent`** interface of the [Background Fetch API] is the event type for background fetch events dispatched on the [ServiceWorkerGlobalScope].\n\nIt is the event type passed to `onbackgroundfetchabort` and `onbackgroundfetchclick`.\n\n",
    "properties": {
      "registration": "\n\nThe **`registration`** read-only property of the [BackgroundFetchEvent] interface returns a [BackgroundFetchRegistration] object."
    }
  },
  "backgroundfetchmanager": {
    "docs": "\n\nThe **`BackgroundFetchManager`** interface of the [Background Fetch API] is a map where the keys are background fetch IDs and the values are [BackgroundFetchRegistration] objects.",
    "properties": {
      "fetch": "\n\nThe **`fetch()`** method of the [BackgroundFetchManager] interface initiates a background fetch operation, given one or more URLs or [Request] objects.",
      "get": "\n\nThe **`get()`** method of the [BackgroundFetchManager] interface returns a `Promise` that resolves with the [BackgroundFetchRegistration] associated with the provided `id` or `undefined` if the `id` is not found.",
      "getids": "\n\nThe **`getIds()`** method of the [BackgroundFetchManager] interface returns the IDs of all registered background fetches."
    }
  },
  "backgroundfetchrecord": {
    "docs": "\n\nThe **`BackgroundFetchRecord`** interface of the [Background Fetch API] represents an individual request and response.\n\nA `BackgroundFetchRecord` is created by the [BackgroundFetchRegistration.match] method, therefore there is no constructor for this interface.\n\nThere will be one `BackgroundFetchRecord` for each resource requested by `fetch()`.",
    "properties": {
      "request": "\n\nThe **`request`** read-only property of the [BackgroundFetchRecord] interface returns the details of the resource to be fetched.",
      "responseready": "\n\nThe **`responseReady`** read-only property of the [BackgroundFetchRecord] interface returns a `Promise` that resolves with a [Response]."
    }
  },
  "backgroundfetchregistration": {
    "docs": "\n\nThe **`BackgroundFetchRegistration`** interface of the [Background Fetch API] represents an individual background fetch.\n\nA `BackgroundFetchRegistration` instance is returned by the [BackgroundFetchManager.fetch] or [BackgroundFetchManager.get] methods, and therefore there has no constructor.\n\n",
    "properties": {
      "abort": "\n\nThe **`abort()`** method of the [BackgroundFetchRegistration] interface aborts an active background fetch.",
      "downloaded": "\n\nThe **`downloaded`** read-only property of the [BackgroundFetchRegistration] interface returns the size in bytes that has been downloaded, initially `0`.\n\nIf the value of this property changes, the [progress](/en-US/docs/Web/API/BackgroundFetchRegistration/progress_event) event is fired at the associated [BackgroundFetchRegistration] object.",
      "downloadtotal": "\n\nThe **`downloadTotal`** read-only property of the [BackgroundFetchRegistration] interface returns the total size in bytes of this download. This is set when the background fetch was registered, or `0` if not set.",
      "failurereason": "\n\nThe **`failureReason`** read-only property of the [BackgroundFetchRegistration] interface returns a string with a value that indicates a reason for a background fetch failure.\n\nIf the value of this property changes, the [progress](/en-US/docs/Web/API/BackgroundFetchRegistration/progress_event) event is fired at the associated [BackgroundFetchRegistration] object.",
      "id": "\n\nThe **`id`** read-only property of the [BackgroundFetchRegistration] interface returns a copy of the background fetch's `ID`.",
      "match": "\n\nThe **`match()`** method of the [BackgroundFetchRegistration] interface returns the first matching [BackgroundFetchRecord].",
      "matchall": "\n\nThe **`matchAll()`** method of the [BackgroundFetchRegistration] interface returns an array of matching [BackgroundFetchRecord] objects.",
      "progress_event": "\n\nThe **`progress`** event of the [BackgroundFetchRegistration] interface thrown when the associated background fetch progresses.\n\nPractically, this event is fired when any of the following properties will return a new value:\n\n- [BackgroundFetchRegistration.uploaded],\n- [BackgroundFetchRegistration.downloaded],\n- [BackgroundFetchRegistration.result], or\n- [BackgroundFetchRegistration.failureReason].",
      "recordsavailable": "\n\nThe **`recordsAvailable`** read-only property of the [BackgroundFetchRegistration] interface returns `true` if there are requests and responses to be accessed. If this returns false then [BackgroundFetchRegistration.match] and [BackgroundFetchRegistration.matchAll] can't be used.",
      "result": "\n\nThe **`result`** read-only property of the [BackgroundFetchRegistration] interface returns a string indicating whether the background fetch was successful or failed.\n\nIf the value of this property changes, the [progress](/en-US/docs/Web/API/BackgroundFetchRegistration/progress_event) event is fired at the associated [BackgroundFetchRegistration] object.",
      "uploaded": "\n\nThe **`uploaded`** read-only property of the [BackgroundFetchRegistration] interface returns the size in bytes successfully sent, initially `0`.\n\nIf the value of this property changes, the [progress](/en-US/docs/Web/API/BackgroundFetchRegistration/progress_event) event is fired at the associated [BackgroundFetchRegistration] object.",
      "uploadtotal": "\n\nThe **`uploadTotal`** read-only property of the [BackgroundFetchRegistration] interface returns the total number of bytes to be sent to the server."
    }
  },
  "backgroundfetchupdateuievent": {
    "docs": "\n\nThe **`BackgroundFetchUpdateUIEvent`** interface of the [Background Fetch API] is an event type for the [ServiceWorkerGlobalScope.backgroundfetchsuccess_event] and [ServiceWorkerGlobalScope.backgroundfetchfail_event] events, and provides a method for updating the title and icon of the app to inform a user of the success or failure of a background fetch.\n\n",
    "properties": {
      "updateui": "\n\nThe **`updateUI()`** method of the [BackgroundFetchUpdateUIEvent] interface updates the title and icon in the user interface to show the status of a background fetch.\n\nThis method may only be run once, to notify the user on a failed or a successful fetch."
    }
  },
  "barcodedetector": {
    "docs": "\n\nThe **`BarcodeDetector`** interface of the [Barcode Detection API] allows detection of linear and two dimensional barcodes in images.",
    "properties": {
      "detect": "\n\nThe **`detect()`** method of the\n[BarcodeDetector] interface returns a `Promise` which fulfills\nwith an `Array` of detected barcodes within an image.",
      "getsupportedformats_static": "\n\nThe **`getSupportedFormats()`** static method\nof the [BarcodeDetector] interface returns a `Promise` which\nfulfills with an `Array` of supported barcode format types."
    }
  },
  "barprop": {
    "docs": "\n\nThe **`BarProp`** interface of the [Document Object Model] represents the web browser user interface elements that are exposed to scripts in web pages. Each of the following interface elements are represented by a `BarProp` object.\n\n- [Window.locationbar]\n  - : The browser location bar.\n- [Window.menubar]\n  - : The browser menu bar.\n- [Window.personalbar]\n  - : The browser personal bar.\n- [Window.scrollbars]\n  - : The browser scrollbars.\n- [Window.statusbar]\n  - : The browser status bar.\n- [Window.toolbar]\n  - : The browser toolbar.\n\nThe `BarProp` interface is not accessed directly, but via one of these elements.",
    "properties": {
      "visible": "\n\nThe **`visible`** read-only property of the [BarProp] interface returns `true` if the user interface element it represents is visible."
    }
  },
  "baseaudiocontext": {
    "docs": "\n\nThe `BaseAudioContext` interface of the [Web Audio API](/en-US/docs/Web/API/Web_Audio_API) acts as a base definition for online and offline audio-processing graphs, as represented by [AudioContext] and [OfflineAudioContext] respectively. You wouldn't use `BaseAudioContext` directly — you'd use its features via one of these two inheriting interfaces.\n\nA `BaseAudioContext` can be a target of events, therefore it implements the [EventTarget] interface.\n\n",
    "properties": {
      "audioworklet": "\n\nThe `audioWorklet` read-only property of the\n[BaseAudioContext] interface returns an instance of\n[AudioWorklet] that can be used for adding\n[AudioWorkletProcessor]-derived classes which implement custom audio\nprocessing.",
      "createanalyser": "\n\nThe `createAnalyser()` method of the\n[BaseAudioContext] interface creates an [AnalyserNode], which\ncan be used to expose audio time and frequency data and create data visualizations.\n\n> **Note:** The [AnalyserNode.AnalyserNode] constructor is the\n> recommended way to create an [AnalyserNode]; see\n> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).\n\n> **Note:** For more on using this node, see the\n> [AnalyserNode] page.",
      "createbiquadfilter": "\n\nThe `createBiquadFilter()` method of the [BaseAudioContext]\ninterface creates a [BiquadFilterNode], which represents a second order\nfilter configurable as several different common filter types.\n\n> **Note:** The [BiquadFilterNode.BiquadFilterNode] constructor is the\n> recommended way to create a [BiquadFilterNode]; see\n> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).",
      "createbuffer": "\n\nThe `createBuffer()` method of the [BaseAudioContext]\nInterface is used to create a new, empty [AudioBuffer] object, which\ncan then be populated by data, and played via an [AudioBufferSourceNode]\n\nFor more details about audio buffers, check out the [AudioBuffer]\nreference page.\n\n> **Note:** `createBuffer()` used to be able to take compressed\n> data and give back decoded samples, but this ability was removed from the specification,\n> because all the decoding was done on the main thread, so\n> `createBuffer()` was blocking other code execution. The asynchronous method\n> `decodeAudioData()` does the same thing — takes compressed audio, such as an\n> MP3 file, and directly gives you back an [AudioBuffer] that you can\n> then play via an [AudioBufferSourceNode]. For simple use cases\n> like playing an MP3, `decodeAudioData()` is what you should be using.",
      "createbuffersource": "\n\nThe `createBufferSource()` method of the [BaseAudioContext]\nInterface is used to create a new [AudioBufferSourceNode], which can be\nused to play audio data contained within an [AudioBuffer] object. [AudioBuffer]s are created using\n[BaseAudioContext.createBuffer] or returned by\n[BaseAudioContext.decodeAudioData] when it successfully decodes an audio\ntrack.\n\n> **Note:** The [AudioBufferSourceNode.AudioBufferSourceNode]\n> constructor is the recommended way to create a [AudioBufferSourceNode]; see\n> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).",
      "createchannelmerger": "\n\nThe `createChannelMerger()` method of the [BaseAudioContext] interface creates a [ChannelMergerNode],\nwhich combines channels from multiple audio streams into a single audio stream.\n\n> **Note:** The [ChannelMergerNode.ChannelMergerNode] constructor is the\n> recommended way to create a [ChannelMergerNode]; see\n> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).",
      "createchannelsplitter": "\n\nThe `createChannelSplitter()` method of the [BaseAudioContext] Interface is used to create a [ChannelSplitterNode],\nwhich is used to access the individual channels of an audio stream and process them separately.\n\n> **Note:** The [ChannelSplitterNode.ChannelSplitterNode]\n> constructor is the recommended way to create a [ChannelSplitterNode]; see\n> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).",
      "createconstantsource": "\n\nThe **`createConstantSource()`**\nproperty of the [BaseAudioContext] interface creates a\n[ConstantSourceNode] object, which is an audio source that continuously\noutputs a monaural (one-channel) sound signal whose samples all have the same\nvalue.\n\n> **Note:** The [ConstantSourceNode.ConstantSourceNode]\n> constructor is the recommended way to create a [ConstantSourceNode]; see\n> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).",
      "createconvolver": "\n\nThe `createConvolver()` method of the [BaseAudioContext]\ninterface creates a [ConvolverNode], which is commonly used to apply\nreverb effects to your audio. See the [spec definition of Convolution](https://webaudio.github.io/web-audio-api/#background-3) for more information.\n\n> **Note:** The [ConvolverNode.ConvolverNode]\n> constructor is the recommended way to create a [ConvolverNode]; see\n> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).",
      "createdelay": "\n\nThe `createDelay()` method of the\n[BaseAudioContext] Interface is used to create a [DelayNode],\nwhich is used to delay the incoming audio signal by a certain amount of time.\n\n> **Note:** The [DelayNode.DelayNode]\n> constructor is the recommended way to create a [DelayNode]; see\n> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).",
      "createdynamicscompressor": "\n\nThe `createDynamicsCompressor()` method of the [BaseAudioContext] Interface is used to create a\n[DynamicsCompressorNode], which can be used to apply compression to an\naudio signal.\n\nCompression lowers the volume of the loudest parts of the signal and raises the volume\nof the softest parts. Overall, a louder, richer, and fuller sound can be achieved. It is\nespecially important in games and musical applications where large numbers of individual\nsounds are played simultaneously, where you want to control the overall signal level and\nhelp avoid clipping (distorting) of the audio output.\n\n> **Note:** The [DynamicsCompressorNode.DynamicsCompressorNode]\n> constructor is the recommended way to create a [DynamicsCompressorNode]; see\n> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).",
      "creategain": "\n\nThe `createGain()` method of the [BaseAudioContext]\ninterface creates a [GainNode], which can be used to control the\noverall gain (or volume) of the audio graph.\n\n> **Note:** The [GainNode.GainNode]\n> constructor is the recommended way to create a [GainNode]; see\n> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).",
      "createiirfilter": "\n\nThe **`createIIRFilter()`** method of the [BaseAudioContext] interface creates an [IIRFilterNode],\nwhich represents a general **[infinite impulse response](https://en.wikipedia.org/wiki/Infinite_impulse_response)** (IIR) filter which can be configured to serve as various types\nof filter.\n\n> **Note:** The [IIRFilterNode.IIRFilterNode]\n> constructor is the recommended way to create a [IIRFilterNode]; see\n> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).",
      "createoscillator": "\n\nThe `createOscillator()` method of the [BaseAudioContext]\ninterface creates an [OscillatorNode], a source representing a periodic\nwaveform. It basically generates a constant tone.\n\n> **Note:** The [OscillatorNode.OscillatorNode]\n> constructor is the recommended way to create a [OscillatorNode]; see\n> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).",
      "createpanner": "\n\nThe `createPanner()` method of the [BaseAudioContext]\nInterface is used to create a new [PannerNode], which is used to\nspatialize an incoming audio stream in 3D space.\n\nThe panner node is spatialized in relation to the AudioContext's\n[AudioListener] (defined by the [BaseAudioContext/listener]\nattribute), which represents the position and orientation of the person listening to the\naudio.\n\n> **Note:** The [PannerNode.PannerNode]\n> constructor is the recommended way to create a [PannerNode]; see\n> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).",
      "createperiodicwave": "\n\nThe `createPeriodicWave()` method of the [BaseAudioContext] Interface\nis used to create a [PeriodicWave], which is used to define a periodic waveform\nthat can be used to shape the output of an [OscillatorNode].",
      "createscriptprocessor": "\n\nThe `createScriptProcessor()` method of the [BaseAudioContext] interface\ncreates a [ScriptProcessorNode] used for direct audio processing.\n\n> **Note:** This feature was replaced by [AudioWorklets](/en-US/docs/Web/API/AudioWorklet) and the [AudioWorkletNode] interface.",
      "createstereopanner": "\n\nThe `createStereoPanner()` method of the [BaseAudioContext] interface creates a [StereoPannerNode], which can be used to apply\nstereo panning to an audio source.\nIt positions an incoming audio stream in a stereo image using a [low-cost panning algorithm](https://webaudio.github.io/web-audio-api/#stereopanner-algorithm).\n\n> **Note:** The [StereoPannerNode.StereoPannerNode]\n> constructor is the recommended way to create a [StereoPannerNode]; see\n> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).",
      "createwaveshaper": "\n\nThe `createWaveShaper()` method of the [BaseAudioContext]\ninterface creates a [WaveShaperNode], which represents a non-linear\ndistortion. It is used to apply distortion effects to your audio.\n\n> **Note:** The [WaveShaperNode.WaveShaperNode]\n> constructor is the recommended way to create a [WaveShaperNode]; see\n> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).",
      "currenttime": "\n\nThe `currentTime` read-only property of the [BaseAudioContext]\ninterface returns a double representing an ever-increasing hardware timestamp in seconds that\ncan be used for scheduling audio playback, visualizing timelines, etc. It starts at 0.",
      "decodeaudiodata": "\n\nThe `decodeAudioData()` method of the [BaseAudioContext]\nInterface is used to asynchronously decode audio file data contained in an\n`ArrayBuffer` that is loaded from [fetch],\n[XMLHttpRequest], or [FileReader]. The decoded\n[AudioBuffer] is resampled to the [AudioContext]'s sampling\nrate, then passed to a callback or promise.\n\nThis is the preferred method of creating an audio source for Web Audio API from an\naudio track. This method only works on complete file data, not fragments of audio file\ndata.\n\nThis function implements two alternative ways to asynchronously return the audio data or error messages: it returns a `Promise` that fulfills with the audio data, and also accepts callback arguments to handle success or failure. The primary method of interfacing with this function is via its Promise return value, and the callback parameters are provided for legacy reasons.",
      "destination": "\n\nThe `destination` property of the [BaseAudioContext]\ninterface returns an [AudioDestinationNode] representing the final\ndestination of all audio in the context. It often represents an actual audio-rendering\ndevice such as your device's speakers.",
      "listener": "\n\nThe `listener` property of the [BaseAudioContext] interface\nreturns an [AudioListener] object that can then be used for\nimplementing 3D audio spatialization.",
      "samplerate": "\n\nThe `sampleRate` property of the [BaseAudioContext] interface returns a floating point number representing\nthe sample rate, in samples per second, used by all nodes in this audio\ncontext. This limitation means that sample-rate converters are not supported.",
      "state": "\n\nThe `state` read-only property of the [BaseAudioContext]\ninterface returns the current state of the `AudioContext`.",
      "statechange_event": "\n\nA `statechange` event is fired at a [BaseAudioContext] object when its [BaseAudioContext.state] member changes."
    }
  },
  "batterymanager": {
    "docs": "\n\nThe `BatteryManager` interface of the [Battery Status API] provides information about the system's battery charge level. The [navigator.getBattery] method returns a promise that resolves with a `BatteryManager` interface.\n\nSince Chrome 103, the `BatteryManager` interface of [Battery Status API] only expose to secure context.\n\n",
    "properties": {
      "charging": "\n\nThe **`BatteryManager.charging`** property is a Boolean value indicating whether or not the device's battery is currently being charged. When its value changes, the [BatteryManager/chargingchange_event] event is fired.\n\nIf the battery is charging or the user agent is unable to report the battery status information, this value is `true`. Otherwise, it is `false`.",
      "chargingchange_event": "\n\nThe **`chargingchange`** event of the [Battery Status API] is fired when the battery [BatteryManager.charging] property is updated.",
      "chargingtime": "\n\nThe **`BatteryManager.chargingTime`** property indicates the amount of time, in seconds, that remain until the battery is fully charged, or `0` if the battery is already fully charged or the user agent is unable to report the battery status information.\nIf the battery is currently discharging, its value is `Infinity`.\nWhen its value changes, the [BatteryManager/chargingtimechange_event] event is fired.\n\n> **Note:** Even if the time returned is precise to the second,\n> browsers round them to a higher interval\n> (typically to the closest 15 minutes) for privacy reasons.",
      "chargingtimechange_event": "\n\nThe **`chargingtimechange`** event of the [Battery Status API] is fired when the battery [BatteryManager.chargingTime] property is updated.",
      "dischargingtime": "\n\nThe **`BatteryManager.dischargingTime`** property indicates the amount of time, in seconds, that remains until the battery is fully discharged,\nor `Infinity` if the battery is currently charging rather than discharging or the user agent is unable to report the battery status information.\nWhen its value changes, the [BatteryManager/dischargingtimechange_event] event is fired.\n\n> **Note:** Even if the time returned is precise to the second, browsers round them to a higher\n> interval (typically to the closest 15 minutes) for privacy reasons.",
      "dischargingtimechange_event": "\n\nThe **`dischargingtimechange`** event of the [Battery Status API] is fired when the battery [BatteryManager.dischargingTime] property is updated.",
      "level": "\n\nThe **`BatteryManager.level`** property indicates the current battery charge level as a value between `0.0` and `1.0`.\nA value of `0.0` means the battery is empty and the system is about to be suspended.\nA value of `1.0` means the battery is full or the user agent is unable to report the battery status information.\nWhen its value changes, the [BatteryManager/levelchange_event] event is fired.",
      "levelchange_event": "\n\nThe **`levelchange`** event of the [Battery Status API] is fired when the battery [BatteryManager.level] property is updated."
    }
  },
  "beforeinstallpromptevent": {
    "docs": "\n\nThe **`BeforeInstallPromptEvent`** is the interface of the [Window.beforeinstallprompt_event] event fired at the [Window] object before a user is prompted to \"install\" a website to a home screen on mobile.\n\nThis interface inherits from the [Event] interface.\n\n",
    "properties": {
      "platforms": "\n\nThe **`platforms`** property of the [BeforeInstallPromptEvent] interface lists the platforms on which the event was dispatched. This is provided for user agents that want to present a choice of versions to the user such as, for example, \"web\" or \"play\" which would allow the user to choose between a web version or an Android version.",
      "prompt": "\n\nThe **`prompt()`** method of the [BeforeInstallPromptEvent] interface allows a developer to show the\ninstall prompt at a time of their own choosing. Typically this will be called in the event handler for the app's custom install UI.\n\nThis method must be called in the event handler for a user action (such as a button click) and may only be called once on a given `BeforeInstallPromptEvent` instance.",
      "userchoice": "\n\nThe **`userChoice`** property of the [BeforeInstallPromptEvent] interface represents the installation choice that the user made, when they were prompted to install the app."
    }
  },
  "beforeunloadevent": {
    "docs": "\n\nThe **`BeforeUnloadEvent`** interface represents the event object for the [Window/beforeunload_event] event, which is fired when the current window, contained document, and associated resources are about to be unloaded.\n\nSee the [Window/beforeunload_event] event reference for detailed guidance on using this event.\n\n",
    "properties": {
      "returnvalue": "\n\nThe **`returnValue`** property of the\n[BeforeUnloadEvent] interface, when set to a truthy value, triggers a browser-generated confirmation dialog asking users to confirm if they _really_ want to leave the page when they try to close or reload it, or navigate somewhere else. This is intended to help prevent loss of unsaved data.\n\n> **Note:** `returnValue` is a legacy feature, and best practice is to trigger the dialog by invoking [Event.preventDefault] on the `BeforeUnloadEvent` object, while also setting `returnValue` to support legacy cases. See the [Window/beforeunload_event] event reference for detailed up-to-date guidance."
    }
  },
  "biquadfilternode": {
    "docs": "\n\nThe `BiquadFilterNode` interface represents a simple low-order filter, and is created using the [BaseAudioContext/createBiquadFilter] method. It is an [AudioNode] that can represent different kinds of filters, tone control devices, and graphic equalizers. A `BiquadFilterNode` always has exactly one input and one output.\n\n<table class=\"properties\">\n  <tbody>\n    <tr>\n      <th scope=\"row\">Number of inputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Number of outputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count mode</th>\n      <td><code>\"max\"</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count</th>\n      <td><code>2</code> (not used in the default count mode)</td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel interpretation</th>\n      <td><code>\"speakers\"</code></td>\n    </tr>\n  </tbody>\n</table>",
    "properties": {
      "detune": "\n\nThe `detune` property of the [BiquadFilterNode] interface is an [a-rate](/en-US/docs/Web/API/AudioParam#a-rate) [AudioParam] representing detuning of the frequency in [cents](https://en.wikipedia.org/wiki/Cent_%28music%29).",
      "frequency": "\n\nThe `frequency` property of the [BiquadFilterNode] interface is an [a-rate](/en-US/docs/Web/API/AudioParam#a-rate) [AudioParam] — a double representing a frequency in the current filtering algorithm measured in hertz (Hz).\n\nIts default value is `350`, with a nominal range of `10` to the [Nyquist frequency](https://en.wikipedia.org/wiki/Nyquist_frequency) — that is, half of the sample rate.",
      "gain": "\n\nThe `gain` property of the [BiquadFilterNode] interface is an [a-rate](/en-US/docs/Web/API/AudioParam#a-rate) [AudioParam] — a double representing the [gain](https://en.wikipedia.org/wiki/Gain) used in the current filtering algorithm.\n\nWhen its value is positive, it represents a real gain; when negative, it represents an attenuation.\n\nIt is expressed in dB, has a default value of `0`, and can take a value in a nominal range of `-40` to `40`.",
      "getfrequencyresponse": "\n\nThe `getFrequencyResponse()` method of the [BiquadFilterNode] interface takes the current filtering algorithm's settings and calculates the\nfrequency response for frequencies specified in a specified array of frequencies.\n\nThe two output arrays, `magResponseOutput` and\n`phaseResponseOutput`, must be created before calling this method; they\nmust be the same size as the array of input frequency values\n(`frequencyArray`).",
      "q": "\n\nThe `Q` property of the [BiquadFilterNode] interface is an [a-rate](/en-US/docs/Web/API/AudioParam#a-rate) [AudioParam], a double representing a [Q factor](https://en.wikipedia.org/wiki/Q_factor), or _quality factor_.\n\nIt is a dimensionless value with a default value of `1` and a nominal range of `0.0001` to `1000`.",
      "type": "\n\nThe `type` property of the [BiquadFilterNode] interface is a string (enum) value defining the kind of filtering algorithm the node is implementing."
    }
  },
  "blob": {
    "docs": "\n\nThe **`Blob`** object represents a blob, which is a file-like object of immutable, raw data; they can be read as text or binary data, or converted into a [ReadableStream] so its methods can be used for processing the data.\n\nBlobs can represent data that isn't necessarily in a JavaScript-native format. The [File] interface is based on `Blob`, inheriting blob functionality and expanding it to support files on the user's system.",
    "properties": {
      "arraybuffer": "\n\nThe **`arrayBuffer()`** method of the [Blob]\ninterface returns a `Promise` that resolves with the contents of the blob as\nbinary data contained in an `ArrayBuffer`.",
      "size": "\n\nThe **`size`** read-only property of the [Blob] interface returns\nthe size of the [Blob] or [File] in bytes.",
      "slice": "\n\nThe **`slice()`** method of the [Blob] interface\ncreates and returns a new `Blob` object which contains data from a subset of\nthe blob on which it's called.",
      "stream": "\n\nThe **`stream()`** method of the [Blob] interface returns a [ReadableStream] which upon reading returns the data contained within the `Blob`.",
      "text": "\n\nThe **`text()`** method of the\n[Blob] interface returns a `Promise` that resolves with a\nstring containing the contents of the blob, interpreted as UTF-8.",
      "type": "\n\nThe **`type`** read-only property of the [Blob] interface returns the  of the file.\n\n> **Note:** Based on the current implementation, browsers won't actually read the bytestream of a file to determine its media type.\n> It is assumed based on the file extension; a PNG image file renamed to .txt would give \"_text/plain_\" and not \"_image/png_\". Moreover, `blob.type` is generally reliable only for common file types like images, HTML documents, audio and video.\n> Uncommon file extensions would return an empty string.\n> Client configuration (for instance, the Windows Registry) may result in unexpected values even for common types. **Developers are advised not to rely on this property as a sole validation scheme.**"
    }
  },
  "blobevent": {
    "docs": "\n\nThe **`BlobEvent`** interface of the [MediaStream Recording API](/en-US/docs/Web/API/MediaStream_Recording_API) represents events associated with a [Blob]. These blobs are typically, but not necessarily, associated with media content.\n\n",
    "properties": {
      "data": "\n\nThe **`data`** read-only property of the [BlobEvent] interface represents a [Blob] associated with the event.",
      "timecode": "\n\nThe **`timecode`** read-only property of the [BlobEvent] interface indicates the difference between the timestamp of the first chunk of data, and the timestamp of the first chunk in the first `BlobEvent` produced by this recorder.\n\nNote that the `timecode` in the first produced `BlobEvent` does not need to be zero."
    }
  },
  "bluetooth": {
    "docs": "\n\nThe **`Bluetooth`** interface of the [Web Bluetooth API](/en-US/docs/Web/API/Web_Bluetooth_API) returns a\n`Promise` to a [BluetoothDevice] object with the specified\noptions.\n\n",
    "properties": {
      "getavailability": "\n\nThe **`getAvailability()`** method of the [Bluetooth] interface returns `true` if the device has a Bluetooth adapter, and false otherwise (unless the user has configured the browser to not expose a real value).\n\n> **Note:** A user might not allow use of Web Bluetooth API, even if\n> `getAvailability()` returns `true`\n> ([Bluetooth.requestDevice] might\n> not resolve with a [BluetoothDevice]). Also, a user can configure their browser to return a fixed value instead of a real one.",
      "getdevices": "\n\nThe **`getDevices()`** method of\n[Bluetooth] interface of [Web Bluetooth API](/en-US/docs/Web/API/Web_Bluetooth_API) exposes the\nBluetooth devices this origin is allowed to access. This method does not display any\npermission prompts.\n\n> **Note:** This method returns a [BluetoothDevice] for each\n> device the origin is currently allowed to access, even the ones that are out of range\n> or powered off.",
      "requestdevice": " \n\nThe **`Bluetooth.requestDevice()`** method of the\n[Bluetooth] interface returns a `Promise` to a\n[BluetoothDevice] object with the specified options. If there is no chooser\nUI, this method returns the first device matching the criteria."
    }
  },
  "bluetoothcharacteristicproperties": {
    "docs": "\n\nThe **`BluetoothCharacteristicProperties`** interface of the [Web Bluetooth API](/en-US/docs/Web/API/Web_Bluetooth_API) provides the operations that are valid on the given [BluetoothRemoteGATTCharacteristic].\n\nThis interface is returned by calling [BluetoothRemoteGATTCharacteristic.properties].",
    "properties": {
      "authenticatedsignedwrites": "\n\nThe **`authenticatedSignedWrites`** read-only\nproperty of the [BluetoothCharacteristicProperties] interface returns a\n`boolean` that is `true` if signed writing to the characteristic\nvalue is permitted.",
      "broadcast": "\n\nThe **`broadcast`** read-only property of the\n[BluetoothCharacteristicProperties] interface returns a\n`boolean` that is `true` if the broadcast of the characteristic\nvalue is permitted using the Server Characteristic Configuration Descriptor.",
      "indicate": "\n\nThe **`indicate`** read-only property of the\n[BluetoothCharacteristicProperties] interface returns a\n`boolean` that is `true` if indications of the characteristic\nvalue with acknowledgement is permitted.",
      "notify": "\n\nThe **`notify`** read-only property of the\n[BluetoothCharacteristicProperties] interface returns a\n`boolean` that is `true` if notifications of the characteristic\nvalue without acknowledgement is permitted.",
      "read": "\n\nThe **`read`** read-only property of the\n[BluetoothCharacteristicProperties] interface returns a\n`boolean` that is `true` if the reading of the characteristic\nvalue is permitted.",
      "reliablewrite": "\n\nThe **`reliableWrite`** read-only property of\nthe [BluetoothCharacteristicProperties] interface returns a\n`boolean` that is `true` if reliable writes to the characteristic\nis permitted.",
      "writableauxiliaries": "\n\nThe **`writableAuxiliaries`** read-only\nproperty of the [BluetoothCharacteristicProperties] interface returns a\n`boolean` that is `true` if reliable writes to the characteristic\ndescriptor is permitted.",
      "write": "\n\nThe **`write`** read-only property of the\n[BluetoothCharacteristicProperties] interface returns a\n`boolean` that is `true` if the writing to the characteristic with\nresponse is permitted.",
      "writewithoutresponse": "\n\nThe **`writeWithoutResponse`** read-only\nproperty of the [BluetoothCharacteristicProperties] interface returns a\n`boolean` that is `true` if the writing to the characteristic\nwithout response is permitted."
    }
  },
  "bluetoothdevice": {
    "docs": "\n\nThe BluetoothDevice interface of the [Web Bluetooth API](/en-US/docs/Web/API/Web_Bluetooth_API) represents a Bluetooth device inside a particular script execution\nenvironment.\n\n",
    "properties": {
      "gatt": "\n\nThe\n**`BluetoothDevice.gatt`** read-only property returns\na reference to the device's [BluetoothRemoteGATTServer].",
      "id": "\n\nThe **`BluetoothDevice.id`** read-only property returns a\nstring that uniquely identifies a device.",
      "name": "\n\nThe **`BluetoothDevice.name`** read-only property returns a\nstring that provides a human-readable name for the device."
    }
  },
  "bluetoothremotegattcharacteristic": {
    "docs": "\n\nThe `BluetoothRemoteGattCharacteristic` interface of the [Web Bluetooth API](/en-US/docs/Web/API/Web_Bluetooth_API) represents a GATT Characteristic, which is a basic data element that provides further information about a peripheral's service.\n\n",
    "properties": {
      "getdescriptor": "\n\nThe **`BluetoothRemoteGATTCharacteristic.getDescriptor()`** method\nreturns a `Promise` that resolves to the\nfirst [BluetoothRemoteGATTDescriptor] for a given descriptor UUID.",
      "getdescriptors": "\n\nThe **`BluetoothRemoteGATTCharacteristic.getDescriptors()`** method\nreturns a `Promise` that resolves to an `Array` of all\n[BluetoothRemoteGATTDescriptor] objects for a given descriptor UUID.",
      "properties": "\n\nThe **`BluetoothRemoteGATTCharacteristic.properties`**\nread-only property returns a [BluetoothCharacteristicProperties] instance\ncontaining the properties of this characteristic.",
      "readvalue": "\n\nThe **`BluetoothRemoteGATTCharacteristic.readValue()`** method\nreturns a `Promise` that resolves to a `DataView` holding a\nduplicate of the `value` property if it is available and supported. Otherwise\nit throws an error.",
      "service": "\n\nThe **`BluetoothRemoteGATTCharacteristic.service`** read-only\nproperty returns the [BluetoothRemoteGATTService] this characteristic belongs to.",
      "startnotifications": "\n\nThe **`BluetoothRemoteGATTCharacteristic.startNotifications()`** method\nreturns a `Promise` to the BluetoothRemoteGATTCharacteristic instance when\nthere is an active notification on it.",
      "stopnotifications": "\n\nThe **`BluetoothRemoteGATTCharacteristic.stopNotifications()`** method\nreturns a `Promise` to the BluetoothRemoteGATTCharacteristic instance when\nthere is no longer an active notification on it.",
      "uuid": "\n\nThe **`BluetoothRemoteGATTCharacteristic.uuid`** read-only\nproperty returns a string containing the UUID of the characteristic, for\nexample `'00002a37-0000-1000-8000-00805f9b34fb'` for the Heart Rate\nMeasurement characteristic.",
      "value": "\n\nThe **`BluetoothRemoteGATTCharacteristic.value`** read-only\nproperty returns currently cached characteristic value. This value gets updated when the\nvalue of the characteristic is read or updated via a notification or indication.",
      "writevalue": "\n\nUse [BluetoothRemoteGATTCharacteristic.writeValueWithResponse] and [BluetoothRemoteGATTCharacteristic.writeValueWithoutResponse] instead.\n\nThe **`BluetoothRemoteGATTCharacteristic.writeValue()`** method sets a [BluetoothRemoteGATTCharacteristic] object's `value` property to the bytes contained in a given `ArrayBuffer`, calls [`WriteCharacteristicValue`(_this_=`this`, _value=value_, _response_=`\"optional\"`)](https://webbluetoothcg.github.io/web-bluetooth/#writecharacteristicvalue), and returns the resulting `Promise`.",
      "writevaluewithoutresponse": "\n\nThe **`BluetoothRemoteGATTCharacteristic.writeValueWithoutResponse()`** method sets a [BluetoothRemoteGATTCharacteristic] object's `value` property to the bytes contained in a given `ArrayBuffer`, calls [`WriteCharacteristicValue`(_this_=`this`, _value=value_, _response_=`\"never\"`)](https://webbluetoothcg.github.io/web-bluetooth/#writecharacteristicvalue), and returns the resulting `Promise`.",
      "writevaluewithresponse": "\n\nThe **`BluetoothRemoteGATTCharacteristic.writeValueWithResponse()`** method sets a [BluetoothRemoteGATTCharacteristic] object's `value` property to the bytes contained in a given `ArrayBuffer`, calls [`WriteCharacteristicValue`(_this_=`this`, _value=value_, _response_=`\"required\"`)](https://webbluetoothcg.github.io/web-bluetooth/#writecharacteristicvalue), and returns the resulting `Promise`."
    }
  },
  "bluetoothremotegattdescriptor": {
    "docs": "\n\nThe `BluetoothRemoteGATTDescriptor` interface of the [Web Bluetooth API](/en-US/docs/Web/API/Web_Bluetooth_API) provides a GATT Descriptor,\nwhich provides further information about a characteristic's value.",
    "properties": {
      "characteristic": "\n\nThe **`BluetoothRemoteGATTDescriptor.characteristic`**\nread-only property returns the [BluetoothRemoteGATTCharacteristic] this\ndescriptor belongs to.",
      "readvalue": "\n\nThe\n**`BluetoothRemoteGATTDescriptor.readValue()`**\nmethod returns a `Promise` that resolves to\nan `ArrayBuffer` holding a duplicate of the `value` property if\nit is available and supported. Otherwise it throws an error.",
      "uuid": "\n\nThe **`BluetoothRemoteGATTDescriptor.uuid`** read-only property returns the  of the characteristic descriptor.\nFor example '`00002902-0000-1000-8000-00805f9b34fb`' for theClient Characteristic Configuration descriptor.",
      "value": "\n\nThe **`BluetoothRemoteGATTDescriptor.value`**\nread-only property returns an `ArrayBuffer` containing the currently cached\ndescriptor value. This value gets updated when the value of the descriptor is read.",
      "writevalue": "\n\nThe **`BluetoothRemoteGATTDescriptor.writeValue()`**\nmethod sets the value property to the bytes contained in\nan `ArrayBuffer` and returns a `Promise`."
    }
  },
  "bluetoothremotegattserver": {
    "docs": "\n\nThe **`BluetoothRemoteGATTServer`** interface of the [Web Bluetooth API](/en-US/docs/Web/API/Web_Bluetooth_API) represents a GATT\nServer on a remote device.",
    "properties": {
      "connect": "\n\nThe\n**`BluetoothRemoteGATTServer.connect()`** method causes the\nscript execution environment to connect to `this.device`.",
      "connected": "\n\nThe **`BluetoothRemoteGATTServer.connected`** read-only\nproperty returns a boolean value that returns true while this script execution\nenvironment is connected to `this.device`. It can be false while the user\nagent is physically connected.",
      "device": "\n\nThe **`BluetoothRemoteGATTServer.device`** read-only property\nreturns a reference to the [BluetoothDevice] running the server.",
      "disconnect": "\n\nThe **`BluetoothRemoteGATTServer.disconnect()`** method causes\nthe script execution environment to disconnect from `this.device`.",
      "getprimaryservice": "\n\nThe **`BluetoothRemoteGATTServer.getPrimaryService()`** method\nreturns a promise to the primary [BluetoothRemoteGATTService] offered by the\nBluetooth device for a specified bluetooth service UUID.",
      "getprimaryservices": "\n\nThe **BluetoothRemoteGATTServer.getPrimaryServices()** method returns a\npromise to a list of primary [BluetoothRemoteGATTService] objects offered by the\nBluetooth device for a specified `BluetoothServiceUUID`."
    }
  },
  "bluetoothremotegattservice": {
    "docs": "\n\nThe `BluetoothRemoteGATTService` interface of the [Web Bluetooth API](/en-US/docs/Web/API/Web_Bluetooth_API) represents a\nservice provided by a GATT server, including a device, a list of referenced services,\nand a list of the characteristics of this service.\n\n",
    "properties": {
      "device": "\n\nThe **`BluetoothGATTService.device`** read-only property\nreturns information about a Bluetooth device through an instance of\n[BluetoothDevice].",
      "getcharacteristic": "\n\nThe **`BluetoothGATTService.getCharacteristic()`** method\nreturns a `Promise` to an instance of\n[BluetoothRemoteGATTCharacteristic] for a given universally unique identifier\n(UUID).",
      "getcharacteristics": "\n\nThe **`BluetoothGATTService.getCharacteristics()`** method\nreturns a `Promise` to a list of [BluetoothRemoteGATTCharacteristic]\ninstances for a given universally unique identifier (UUID).",
      "isprimary": "\n\nThe **`BluetoothGATTService.isPrimary`** read-only property\nreturns a boolean value that indicates whether this is a primary service. If it\nis not a primary service, it is a secondary service.",
      "uuid": "\n\nThe **`BluetoothGATTService.uuid`** read-only property\nreturns a string representing the UUID of this service."
    }
  },
  "bluetoothuuid": {
    "docs": "\n\nThe **`BluetoothUUID`** interface of the [Web Bluetooth API] provides a way to look up Universally Unique Identifier (UUID) values by name in the\n[registry](https://www.bluetooth.com/specifications/assigned-numbers/) maintained by the Bluetooth SIG.",
    "properties": {
      "canonicaluuid_static": "\n\nThe **`canonicalUUID()`** static method of the [BluetoothUUID] interface returns the 128-bit UUID when passed a 16- or 32-bit UUID alias.",
      "getcharacteristic_static": "\n\nThe **`getCharacteristic()`** static method of the [BluetoothUUID] interface returns a UUID representing a registered characteristic when passed a name or the 16- or 32-bit UUID alias.",
      "getdescriptor_static": "\n\nThe **`getDescriptor()`** static method of the [BluetoothUUID] interface returns a UUID representing a registered descriptor when passed a name or the 16- or 32-bit UUID alias.",
      "getservice_static": "\n\nThe **`getService()`** static method of the [BluetoothUUID] interface returns a UUID representing a registered service when passed a name or the 16- or 32-bit UUID alias."
    }
  },
  "broadcastchannel": {
    "docs": "\n\nThe **`BroadcastChannel`** interface represents a named channel that any  of a given  can subscribe to. It allows communication between different documents (in different windows, tabs, frames or iframes) of the same origin. Messages are broadcasted via a [BroadcastChannel/message_event] event fired at all `BroadcastChannel` objects listening to the channel, except the object that sent the message.\n\n",
    "properties": {
      "close": "\n\nThe **`BroadcastChannel.close()`** terminates the connection to\nthe underlying channel, allowing the object to be garbage collected.\nThis is a necessary step to perform\nas there is no other way for a browser to know\nthat this channel is not needed anymore.\n\n",
      "message_event": "\n\nThe `message` event is fired on a [BroadcastChannel] object when a message arrives on that channel.",
      "messageerror_event": "\n\nThe `messageerror` event is fired on a [BroadcastChannel] object when a message that can't be deserialized arrives on the channel.",
      "name": "\n\nThe read-only **`BroadcastChannel.name`** property returns a string, which uniquely identifies the given channel with its name. This name is passed to the [BroadcastChannel.BroadCastChannel] constructor at creation time and is therefore read-only.\n\n",
      "postmessage": "\n\nThe **`BroadcastChannel.postMessage()`** sends a message,\nwhich can be of any kind of `Object`,\nto each listener in any  with the same .\nThe message is transmitted as a ['message'](/en-US/docs/Web/API/BroadcastChannel/message_event) event\ntargeted at each [BroadcastChannel] bound to the channel.\n\n"
    }
  },
  "bytelengthqueuingstrategy": {
    "docs": "\n\nThe **`ByteLengthQueuingStrategy`** interface of the [Streams API](/en-US/docs/Web/API/Streams_API) provides a built-in byte length queuing strategy that can be used when constructing streams.",
    "properties": {
      "highwatermark": "\n\nThe read-only **`ByteLengthQueuingStrategy.highWaterMark`** property returns the total number of bytes that can be contained in the internal queue before [backpressure](/en-US/docs/Web/API/Streams_API/Concepts#backpressure) is applied.\n\n> **Note:** Unlike [`CountQueuingStrategy()`](/en-US/docs/Web/API/CountQueuingStrategy/CountQueuingStrategy) where the `highWaterMark` property specifies a simple count of the number of chunks, with `ByteLengthQueuingStrategy()`, the `highWaterMark` parameter specifies a number of _bytes_ — specifically, given a stream of chunks, how many bytes worth of those chunks (rather than a count of how many of those chunks) can be contained in the internal queue before backpressure is applied.",
      "size": "\n\nThe **`size()`** method of the\n[ByteLengthQueuingStrategy] interface returns the given chunk's\n`byteLength` property."
    }
  },
  "cache": {
    "docs": "\n\nThe **`Cache`** interface provides a persistent storage mechanism for [Request] / [Response] object pairs that are cached in long lived memory. How long a `Cache` object lives is browser dependent, but a single origin's scripts can typically rely on the presence of a previously populated `Cache` object. Note that the `Cache` interface is exposed to windowed scopes as well as workers. You don't have to use it in conjunction with service workers, even though it is defined in the service worker spec.\n\nAn origin can have multiple, named `Cache` objects. You are responsible for implementing how your script (e.g. in a [ServiceWorker]) handles `Cache` updates. Items in a `Cache` do not get updated unless explicitly requested; they don't expire unless deleted. Use [CacheStorage.open] to open a specific named `Cache` object and then call any of the `Cache` methods to maintain the `Cache`.\n\nYou are also responsible for periodically purging cache entries. Each browser has a hard limit on the amount of cache storage that a given origin can use. `Cache` quota usage estimates are available via the [StorageManager.estimate] method. The browser does its best to manage disk space, but it may delete the `Cache` storage for an origin. The browser will generally delete all of the data for an origin or none of the data for an origin. Make sure to version caches by name and use the caches only from the version of the script that they can safely operate on. See [Deleting old caches](/en-US/docs/Web/API/Service_Worker_API/Using_Service_Workers#deleting_old_caches) for more information.\n\n> **Note:** The key matching algorithm depends on the [VARY header](https://www.fastly.com/blog/best-practices-using-vary-header) in the value. So matching a new key requires looking at both key and value for entries in the `Cache` object.\n\n> **Note:** The caching API doesn't honor HTTP caching headers.\n\n",
    "properties": {
      "add": "\n\nThe **`add()`** method of the [Cache] interface takes a URL, retrieves it, and adds the resulting response object to the given cache.\n\nThe `add()` method is functionally equivalent to the following:\n\n```js\nfetch(url).then((response) => {\n  if (!response.ok) {\n    throw new TypeError(\"bad response status\");\n  }\n  return cache.add(url);\n});\n```\n\nFor more complex operations, you'll need to use [Cache.put] directly.\n\n> **Note:** `add()` will overwrite any key/value pair previously stored in the cache that matches the request.",
      "addall": "\n\nThe **`addAll()`** method of the [Cache] interface takes an array of URLs, retrieves them, and adds the resulting response objects to the given cache. The request objects created during retrieval become keys to the stored response operations.\n\n> **Note:** `addAll()` will overwrite any key/value pairs\n> previously stored in the cache that match the request, but will fail if a\n> resulting `put()` operation would overwrite a previous cache entry stored by the same `addAll()` method.",
      "delete": "\n\nThe **`delete()`** method of the [Cache] interface finds the [Cache] entry whose key is the request, and if found, deletes the [Cache] entry and returns a `Promise` that resolves to `true`.\nIf no [Cache] entry is found, it resolves to `false`.",
      "keys": "\n\nThe **`keys()`** method of the [Cache] interface returns a\n`Promise` that resolves to an array of [Request] objects\nrepresenting the keys of the [Cache].\n\nThe requests are returned in the same order that they were inserted.\n\n> **Note:** Requests with duplicate URLs but different headers can be\n> returned if their responses have the `VARY` header set on them.",
      "match": "\n\nThe **`match()`** method of the [Cache] interface returns a `Promise` that resolves to the [Response] associated with the first matching request in the [Cache] object.\nIf no match is found, the `Promise` resolves to `undefined`.",
      "matchall": "\n\nThe **`matchAll()`** method of the [Cache]\ninterface returns a `Promise` that resolves to an array of all matching\nresponses in the [Cache] object.",
      "put": "\n\nThe **`put()`** method of the\n[Cache] interface allows key/value pairs to be added to the current\n[Cache] object.\n\nOften, you will just want to [fetch]\none or more requests, then add the result straight to your cache. In such cases you are\nbetter off using\n[Cache.add]/[Cache.addAll], as\nthey are shorthand functions for one or more of these operations.\n\n```js\nfetch(url).then((response) => {\n  if (!response.ok) {\n    throw new TypeError(\"Bad response status\");\n  }\n  return cache.put(url, response);\n});\n```\n\n> **Note:** `put()` will overwrite any key/value pair\n> previously stored in the cache that matches the request.\n\n> **Note:** [Cache.add]/[Cache.addAll] do not\n> cache responses with `Response.status` values that are not in the 200\n> range, whereas [Cache.put] lets you store any request/response pair. As a\n> result, [Cache.add]/[Cache.addAll] can't be used to store\n> opaque responses, whereas [Cache.put] can."
    }
  },
  "cachestorage": {
    "docs": "\n\nThe **`CacheStorage`** interface represents the storage for [Cache] objects.\n\nThe interface:\n\n- Provides a master directory of all the named caches that can be accessed by a [ServiceWorker] or other type of worker or [window] scope (you're not limited to only using it with service workers).\n- Maintains a mapping of string names to corresponding [Cache] objects.\n\nUse [CacheStorage.open] to obtain a [Cache] instance.\n\nUse [CacheStorage.match] to check if a given [Request] is a key in any of the [Cache] objects that the `CacheStorage` object tracks.\n\nYou can access `CacheStorage` through the global [caches] property.\n\n> **Note:** `CacheStorage` always rejects with a `SecurityError` on untrusted origins (i.e. those that aren't using HTTPS, although this definition will likely become more complex in the future.) When testing on Firefox, you can get around this by checking the **Enable Service Workers over HTTP (when toolbox is open)** option in the Firefox Devtools options/gear menu. Furthermore, because `CacheStorage` requires file-system access, it may be unavailable in private mode in Firefox.\n\n> **Note:** [CacheStorage.match] is a convenience method. Equivalent functionality to match a cache entry can be implemented by returning an array of cache names from [CacheStorage.keys], opening each cache with [CacheStorage.open], and matching the one you want with [Cache.match].\n\n",
    "properties": {
      "delete": "\n\nThe **`delete()`** method of the [CacheStorage] interface finds the [Cache] object matching the `cacheName`, and if found, deletes the [Cache] object and returns a `Promise` that resolves to `true`.\nIf no [Cache] object is found, it resolves to `false`.\n\nYou can access `CacheStorage` through the global [caches] property.",
      "has": "\n\nThe **`has()`** method of the [CacheStorage]\ninterface returns a `Promise` that resolves to `true` if a\n[Cache] object matches the `cacheName`.\n\nYou can access `CacheStorage` through the global [caches] property.",
      "keys": "\n\nThe **`keys()`** method of the [CacheStorage] interface returns a `Promise` that will resolve with an array containing strings corresponding to all of the named [Cache] objects tracked by the [CacheStorage] object in the order they were created.\nUse this method to iterate over a list of all [Cache] objects.\n\nYou can access `CacheStorage` through the global [caches] property.",
      "match": "\n\nThe **`match()`** method of the [CacheStorage] interface checks if a given [Request] or URL string is a key for a stored [Response].\nThis method returns a `Promise` for a [Response], or a `Promise` which resolves to `undefined` if no match is found.\n\nYou can access `CacheStorage` through the global\n[caches] property.\n\n`Cache` objects are searched in creation order.\n\n> **Note:** [CacheStorage.match] is a convenience method.\n> Equivalent functionality is to call [cache.match] on each cache (in the order returned by [CacheStorage.keys]) until a [Response] is returned.",
      "open": "\n\nThe **`open()`** method of the\n[CacheStorage] interface returns a `Promise` that resolves to\nthe [Cache] object matching the `cacheName`.\n\nYou can access `CacheStorage` through the global\n[caches] property.\n\n> **Note:** If the specified [Cache] does not exist, a new\n> cache is created with that `cacheName` and a `Promise` that\n> resolves to this new [Cache] object is returned."
    }
  },
  "canmakepaymentevent": {
    "docs": "\n\nThe **`CanMakePaymentEvent`** interface of the [Payment Handler API] is the event object for the [ServiceWorkerGlobalScope.canmakepayment_event] event, fired on a payment app's service worker to check whether it is ready to handle a payment. Specifically, it is fired when the merchant website calls [PaymentRequest.PaymentRequest].\n\n",
    "properties": {
      "respondwith": "\n\nThe **`respondWith()`** method of the [CanMakePaymentEvent] interface enables the service worker to respond appropriately to signal whether it is ready to handle payments."
    }
  },
  "canvascapturemediastreamtrack": {
    "docs": "\n\nThe **`CanvasCaptureMediaStreamTrack`** interface of the [Media Capture and Streams API] represents the video track contained in a [MediaStream] being generated from a `canvas` following a call to [HTMLCanvasElement.captureStream].\n\n",
    "properties": {
      "canvas": "\n\nThe **`canvas`** read-only property of the [CanvasCaptureMediaStreamTrack] interface returns the [HTMLCanvasElement] from which frames are being captured.",
      "requestframe": "\n\nThe **`requestFrame()`** method of the [CanvasCaptureMediaStreamTrack] interface requests that a frame be captured from the canvas and sent to the stream.\n\nApplications that need to carefully control\nthe timing of rendering and frame capture can use `requestFrame()` to\ndirectly specify when it's time to capture a frame.\n\nTo prevent automatic capture of frames, so that frames are only captured when\n`requestFrame()` is called, specify a value of 0 for the\n[HTMLCanvasElement.captureStream] method when creating\nthe stream."
    }
  },
  "canvasgradient": {
    "docs": "\n\nThe **`CanvasGradient`** interface represents an [opaque object](https://en.wikipedia.org/wiki/Opaque_data_type) describing a gradient. It is returned by the methods [CanvasRenderingContext2D.createLinearGradient], [CanvasRenderingContext2D.createConicGradient] or [CanvasRenderingContext2D.createRadialGradient].\n\nIt can be used as a [CanvasRenderingContext2D.fillStyle] or [CanvasRenderingContext2D.strokeStyle].",
    "properties": {
      "addcolorstop": "\n\nThe **`CanvasGradient.addColorStop()`** method adds a new color stop,\ndefined by an `offset` and a `color`, to a given canvas gradient."
    }
  },
  "canvaspattern": {
    "docs": "\n\nThe **`CanvasPattern`** interface represents an [opaque object](https://en.wikipedia.org/wiki/Opaque_data_type) describing a pattern, based on an image, a canvas, or a video, created by the [CanvasRenderingContext2D.createPattern] method.\n\nIt can be used as a [CanvasRenderingContext2D.fillStyle] or [CanvasRenderingContext2D.strokeStyle].",
    "properties": {
      "settransform": "\n\nThe **`CanvasPattern.setTransform()`** method uses a [DOMMatrix] object as the pattern's transformation matrix and invokes it on the pattern."
    }
  },
  "canvasrenderingcontext2d": {
    "docs": "\n\nThe **`CanvasRenderingContext2D`** interface, part of the [Canvas API](/en-US/docs/Web/API/Canvas_API), provides the 2D rendering context for the drawing surface of a `canvas` element.\nIt is used for drawing shapes, text, images, and other objects.\n\nThe interface's properties and methods are described in the reference section of this page.\nThe [Canvas tutorial](/en-US/docs/Web/API/Canvas_API/Tutorial) has more explanation, examples, and resources, as well.\n\nFor [`OffscreenCanvas`](/en-US/docs/Web/API/OffscreenCanvas), there is an equivalent interface that provides the rendering context.\nThe offscreen rendering context inherits most of the same properties and methods as the `CanvasRenderingContext2D` and is described in more detail in the [OffscreenCanvasRenderingContext2D] reference page.",
    "properties": {
      "arc": "\n\nThe\n**`CanvasRenderingContext2D.arc()`**\nmethod of the [Canvas 2D API](/en-US/docs/Web/API/CanvasRenderingContext2D) adds a circular arc to the current sub-path.",
      "arcto": "\n\nThe **`CanvasRenderingContext2D.arcTo()`** method of the Canvas 2D API adds a circular arc to the current sub-path, using the given control points and radius.\nThe arc is automatically connected to the path's latest point with a straight line if necessary, for example if the starting point and control points are in a line.\n\nThis method is commonly used for making rounded corners.\n\n> **Note:** You may get unexpected results when using a\n> relatively large radius: the arc's connecting line will go in whatever direction it\n> must to meet the specified radius.",
      "beginpath": "\n\nThe\n**`CanvasRenderingContext2D.beginPath()`**\nmethod of the Canvas 2D API starts a new path by emptying the list of sub-paths. Call\nthis method when you want to create a new path.\n\n> **Note:** To create a new sub-path, i.e., one matching the current\n> canvas state, you can use [CanvasRenderingContext2D.moveTo].",
      "beziercurveto": "\n\nThe\n**`CanvasRenderingContext2D.bezierCurveTo()`**\nmethod of the Canvas 2D API adds a cubic [Bézier curve](/en-US/docs/Glossary/Bezier_curve) to the current\nsub-path. It requires three points: the first two are control points and the third one\nis the end point. The starting point is the latest point in the current path, which can\nbe changed using [CanvasRenderingContext2D.moveTo] before\ncreating the Bézier curve.",
      "canvas": "\n\nThe **`CanvasRenderingContext2D.canvas`** property, part of the\n[Canvas API](/en-US/docs/Web/API/Canvas_API), is a read-only reference to the\n[HTMLCanvasElement] object that is associated with a given context. It\nmight be [`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null) if there is no associated `canvas` element.",
      "clearrect": "\n\nThe\n**`CanvasRenderingContext2D.clearRect()`**\nmethod of the Canvas 2D API erases the pixels in a rectangular area by setting them to\ntransparent black.\n\n> **Note:** Be aware that `clearRect()` may cause unintended\n> side effects if you're not [using paths properly](/en-US/docs/Web/API/Canvas_API/Tutorial/Drawing_shapes#drawing_paths). Make sure to call\n> [CanvasRenderingContext2D.beginPath] before starting to\n> draw new items after calling `clearRect()`.",
      "clip": "\n\nThe\n**`CanvasRenderingContext2D.clip()`**\nmethod of the Canvas 2D API turns the current or given path into the current clipping\nregion. The previous clipping region, if any, is intersected with the current or given\npath to create the new clipping region.\n\nIn the image below, the red outline represents a clipping region shaped like a star.\nOnly those parts of the checkerboard pattern that are within the clipping region get\ndrawn.\n\n![Star-shaped clipping region](canvas_clipping_path.png)\n\n> **Note:** Be aware that the clipping region is only constructed from\n> shapes added to the path. It doesn't work with shape primitives drawn directly to the\n> canvas, such as [CanvasRenderingContext2D.fillRect].\n> Instead, you'd have to use [CanvasRenderingContext2D.rect] to\n> add a rectangular shape to the path before calling `clip()`.\n\n> **Note:** Clip paths cannot be reverted directly. You must save your canvas state using [CanvasRenderingContext2D/save] before calling `clip()`, and restore it once you have finished drawing in the clipped area using [CanvasRenderingContext2D/restore].",
      "closepath": "\n\nThe\n**`CanvasRenderingContext2D.closePath()`**\nmethod of the Canvas 2D API attempts to add a straight line from the current point to\nthe start of the current sub-path. If the shape has already been closed or has only one\npoint, this function does nothing.\n\nThis method doesn't draw anything to the canvas directly. You can render the path using\nthe [CanvasRenderingContext2D.stroke] or\n[CanvasRenderingContext2D.fill] methods.",
      "createconicgradient": "\n\nThe **`CanvasRenderingContext2D.createConicGradient()`** method of the Canvas 2D API creates a gradient around a point with given coordinates.\n\nThis method returns a conic [CanvasGradient]. To be applied to a shape, the gradient must first be assigned to the [CanvasRenderingContext2D.fillStyle] or [CanvasRenderingContext2D.strokeStyle] properties.\n\n> **Note:** Gradient coordinates are global, i.e., relative to the current coordinate space. When applied to a shape, the coordinates are NOT relative to the shape's coordinates.",
      "createimagedata": "\n\nThe **`CanvasRenderingContext2D.createImageData()`** method of\nthe Canvas 2D API creates a new, blank [ImageData] object with the\nspecified dimensions. All of the pixels in the new object are transparent black.",
      "createlineargradient": "\n\nThe\n**`CanvasRenderingContext2D.createLinearGradient()`**\nmethod of the Canvas 2D API creates a gradient along the line connecting two given\ncoordinates.\n\n![The gradient transitions colors along the gradient line, starting at point x0, y0 and going to x1, y1, even if those points extend the gradient line beyond the edges of the element on which the gradient is drawn.](mdn-canvas-lineargradient.png)\n\nThis method returns a linear [CanvasGradient]. To be applied to a shape,\nthe gradient must first be assigned to the\n[CanvasRenderingContext2D.fillStyle] or\n[CanvasRenderingContext2D.strokeStyle] properties.\n\n> **Note:** Gradient coordinates are global, i.e., relative to the current\n> coordinate space. When applied to a shape, the coordinates are NOT relative to the\n> shape's coordinates.",
      "createpattern": "\n\nThe **`CanvasRenderingContext2D.createPattern()`** method of the Canvas 2D API creates a pattern using the specified image and repetition.\nThis method returns a [CanvasPattern].\n\nThis method doesn't draw anything to the canvas directly.\nThe pattern it creates must be assigned to the [CanvasRenderingContext2D.fillStyle] or [CanvasRenderingContext2D.strokeStyle] properties, after which it is applied to any subsequent drawing.",
      "createradialgradient": "\n\nThe\n**`CanvasRenderingContext2D.createRadialGradient()`**\nmethod of the Canvas 2D API creates a radial gradient using the size and coordinates of\ntwo circles.\n\nThis method returns a [CanvasGradient]. To be applied to a shape, the\ngradient must first be assigned to the [CanvasRenderingContext2D.fillStyle] or [CanvasRenderingContext2D.strokeStyle]\nproperties.\n\n> **Note:** Gradient coordinates are global, i.e., relative to the current\n> coordinate space. When applied to a shape, the coordinates are NOT relative to the\n> shape's coordinates.",
      "direction": "\n\nThe\n**`CanvasRenderingContext2D.direction`**\nproperty of the Canvas 2D API specifies the current text direction used to draw text.",
      "drawfocusifneeded": "\n\nThe\n**`CanvasRenderingContext2D.drawFocusIfNeeded()`**\nmethod of the Canvas 2D API draws a focus ring around the current or given path, if the\nspecified element is focused.",
      "drawimage": "\n\nThe **`CanvasRenderingContext2D.drawImage()`** method of the\nCanvas 2D API provides different ways to draw an image onto the canvas.",
      "ellipse": "\n\nThe\n**`CanvasRenderingContext2D.ellipse()`**\nmethod of the Canvas 2D API adds an elliptical arc to the current sub-path.",
      "fill": "\n\nThe\n**`CanvasRenderingContext2D.fill()`**\nmethod of the Canvas 2D API fills the current or given path with the current\n[CanvasRenderingContext2D.fillStyle].",
      "fillrect": "\n\nThe\n**`CanvasRenderingContext2D.fillRect()`**\nmethod of the Canvas 2D API draws a rectangle that is filled according to the current\n[CanvasRenderingContext2D.fillStyle].\n\nThis method draws directly to the canvas without modifying the current path, so any\nsubsequent [CanvasRenderingContext2D.fill] or\n[CanvasRenderingContext2D.stroke] calls will have no effect\non it.",
      "fillstyle": "\n\nThe\n**`CanvasRenderingContext2D.fillStyle`**\nproperty of the [Canvas 2D API](/en-US/docs/Web/API/Canvas_API) specifies the\ncolor, gradient, or pattern to use inside shapes. The default style is `#000`\n(black).\n\n> **Note:** For more examples of fill and stroke styles, see [Applying styles and color](/en-US/docs/Web/API/Canvas_API/Tutorial/Applying_styles_and_colors) in the [Canvas tutorial](/en-US/docs/Web/API/Canvas_API/Tutorial).",
      "filltext": "\n\nThe [CanvasRenderingContext2D] method\n**`fillText()`**, part of the Canvas 2D API, draws a text string\nat the specified coordinates, filling the string's characters with the current\n[CanvasRenderingContext2D.fillStyle]. An optional parameter\nallows specifying a maximum width for the rendered text, which the  will achieve by condensing the text or by using a lower font size.\n\nThis method draws directly to the canvas without modifying the current path, so any\nsubsequent [CanvasRenderingContext2D.fill] or\n[CanvasRenderingContext2D.stroke] calls will have no effect\non it.\n\nThe text is rendered using the font and text layout configuration as defined by the\n[CanvasRenderingContext2D.font],\n[CanvasRenderingContext2D.textAlign],\n[CanvasRenderingContext2D.textBaseline], and\n[CanvasRenderingContext2D.direction] properties.\n\n> **Note:** To draw the outlines of the characters in a string, call the context's\n> [CanvasRenderingContext2D.strokeText] method.",
      "filter": "\n\nThe\n**`CanvasRenderingContext2D.filter`**\nproperty of the Canvas 2D API provides filter effects such as blurring and grayscaling.\nIt is similar to the CSS `filter` property and accepts the same values.",
      "font": "\n\nThe **`CanvasRenderingContext2D.font`** property of the Canvas 2D API specifies the current text style to use when drawing text.\nThis string uses the same syntax as the [CSS font](/en-US/docs/Web/CSS/font) specifier.",
      "fontkerning": "\n\nThe **`CanvasRenderingContext2D.fontKerning`** property of the [Canvas API](/en-US/docs/Web/API/Canvas_API) specifies how font kerning information is used.\n\nKerning adjusts how adjacent letters are spaced in a proportional font, allowing them to edge into each other's visual area if there is space available.\nFor example, in well-kerned fonts, the characters `AV`, `Ta` and `We` nest together and make character spacing more uniform and pleasant to read than the equivalent text without kerning.\n\nThe property corresponds to the [`font-kerning`](/en-US/docs/Web/CSS/font-kerning) CSS property.",
      "fontstretch": "\n\nThe **`CanvasRenderingContext2D.fontStretch`** property of the [Canvas API](/en-US/docs/Web/API/Canvas_API) specifies how the font may be expanded or condensed when drawing text.\n\nThe property corresponds to the [`font-stretch`](/en-US/docs/Web/CSS/font-stretch) CSS property when used with keywords (percentage values are not supported).",
      "fontvariantcaps": "\n\nThe **`CanvasRenderingContext2D.fontVariantCaps`** property of the [Canvas API](/en-US/docs/Web/API/Canvas_API) specifies an alternative capitalization of the rendered text.\n\nThis corresponds to the CSS [`font-variant-caps`](/en-US/docs/Web/CSS/font-variant-caps) property.",
      "getcontextattributes": "\n\nThe **`CanvasRenderingContext2D.getContextAttributes()`** method returns an object that contains attributes used by the context.\n\nNote that context attributes may be requested when creating the context with [`HTMLCanvasElement.getContext()`](/en-US/docs/Web/API/HTMLCanvasElement/getContext), but the attributes that are actually supported and used may differ.",
      "getimagedata": "\n\nThe [CanvasRenderingContext2D] method\n**`getImageData()`** of the Canvas 2D API returns an\n[ImageData] object representing the underlying pixel data for a specified\nportion of the canvas.\n\nThis method is not affected by the canvas's transformation matrix. If the specified\nrectangle extends outside the bounds of the canvas, the pixels outside the canvas are\ntransparent black in the returned `ImageData` object.\n\n> **Note:** Image data can be painted onto a canvas using the\n> [CanvasRenderingContext2D.putImageData] method.\n\nYou can find more information about `getImageData()` and general\nmanipulation of canvas contents in [Pixel manipulation with canvas](/en-US/docs/Web/API/Canvas_API/Tutorial/Pixel_manipulation_with_canvas).",
      "getlinedash": "\n\nThe **`getLineDash()`** method of the Canvas 2D API's\n[CanvasRenderingContext2D] interface gets the current line dash pattern.",
      "gettransform": "\n\nThe **`CanvasRenderingContext2D.getTransform()`** method of the Canvas 2D API retrieves the current transformation matrix being applied to the context.",
      "globalalpha": "\n\nThe\n**`CanvasRenderingContext2D.globalAlpha`**\nproperty of the Canvas 2D API specifies the alpha (transparency) value that is applied\nto shapes and images before they are drawn onto the canvas.\n\n> **Note:** See also the chapter [Applying styles and color](/en-US/docs/Web/API/Canvas_API/Tutorial/Applying_styles_and_colors) in the [Canvas Tutorial](/en-US/docs/Web/API/Canvas_API/Tutorial).",
      "globalcompositeoperation": "\n\nThe\n**`CanvasRenderingContext2D.globalCompositeOperation`**\nproperty of the Canvas 2D API sets the type of compositing operation to apply when\ndrawing new shapes.\n\nSee also [Compositing and clipping](/en-US/docs/Web/API/Canvas_API/Tutorial/Compositing) in the [Canvas Tutorial](/en-US/docs/Web/API/Canvas_API/Tutorial).",
      "imagesmoothingenabled": "\n\nThe **`imageSmoothingEnabled`** property of the\n[CanvasRenderingContext2D] interface, part of the [Canvas API](/en-US/docs/Web/API/Canvas_API), determines whether scaled images\nare smoothed (`true`, default) or not (`false`). On getting the\n`imageSmoothingEnabled` property, the last value it was set to is returned.\n\nThis property is useful for games and other apps that use pixel art. When enlarging\nimages, the default resizing algorithm will blur the pixels. Set this property to\n`false` to retain the pixels' sharpness.\n\n> **Note:** You can adjust the smoothing quality with the\n> [CanvasRenderingContext2D.imageSmoothingQuality]\n> property.",
      "imagesmoothingquality": "\n\nThe **`imageSmoothingQuality`** property of the\n[CanvasRenderingContext2D] interface, part of the [Canvas API](/en-US/docs/Web/API/Canvas_API), lets you set the quality of\nimage smoothing.\n\n> **Note:** For this property to have an effect,\n> [CanvasRenderingContext2D.imageSmoothingEnabled]\n> must be `true`.",
      "iscontextlost": "\n\nThe **`CanvasRenderingContext2D.isContextLost()`** method of the Canvas 2D API returns `true` if the rendering context is lost (and has not yet been reset).\nThis might occur due to driver crashes, running out of memory, and so on.\n\nIf the user agent detects that the canvas backing storage is lost it will fire the [`contextlost` event](/en-US/docs/Web/API/HTMLCanvasElement/contextlost_event) at the associated [`HTMLCanvasElement`](/en-US/docs/Web/API/HTMLCanvasElement).\nIf this event is not cancelled it will attempt to reset the backing storage to the default state (this is equivalent to calling [CanvasRenderingContext2D.reset]).\nOn success it will fire the [`contextrestored` event](/en-US/docs/Web/API/HTMLCanvasElement/contextrestored_event), indicating that the context is ready to reinitialize and redraw.",
      "ispointinpath": "\n\nThe\n**`CanvasRenderingContext2D.isPointInPath()`**\nmethod of the Canvas 2D API reports whether or not the specified point is contained in\nthe current path.",
      "ispointinstroke": "\n\nThe\n**`CanvasRenderingContext2D.isPointInStroke()`**\nmethod of the Canvas 2D API reports whether or not the specified point is inside the\narea contained by the stroking of a path.",
      "letterspacing": "\n\nThe **`CanvasRenderingContext2D.letterSpacing`** property of the [Canvas API](/en-US/docs/Web/API/Canvas_API) specifies the spacing between letters when drawing text.\n\nThis corresponds to the CSS [`letter-spacing`](/en-US/docs/Web/CSS/letter-spacing) property.",
      "linecap": "\n\nThe\n**`CanvasRenderingContext2D.lineCap`**\nproperty of the Canvas 2D API determines the shape used to draw the end points of lines.\n\n> **Note:** Lines can be drawn with the\n> [CanvasRenderingContext2D.stroke], [CanvasRenderingContext2D.strokeRect],\n> and [CanvasRenderingContext2D.strokeText] methods.",
      "linedashoffset": "\n\nThe\n**`CanvasRenderingContext2D.lineDashOffset`**\nproperty of the Canvas 2D API sets the line dash offset, or \"phase.\"\n\n> **Note:** Lines are drawn by calling the\n> [CanvasRenderingContext2D.stroke] method.",
      "linejoin": "\n\nThe\n**`CanvasRenderingContext2D.lineJoin`**\nproperty of the Canvas 2D API determines the shape used to join two line segments where\nthey meet.\n\nThis property has no effect wherever two connected segments have the same direction,\nbecause no joining area will be added in this case. Degenerate segments with a length of\nzero (i.e., with all endpoints and control points at the exact same position) are also\nignored.\n\n> **Note:** Lines can be drawn with the\n> [CanvasRenderingContext2D.stroke],\n> [CanvasRenderingContext2D.strokeRect],\n> and [CanvasRenderingContext2D.strokeText] methods.",
      "lineto": "\n\nThe [CanvasRenderingContext2D] method\n**`lineTo()`**, part of the Canvas 2D API, adds a straight line\nto the current sub-path by connecting the sub-path's last point to the specified\n`(x, y)` coordinates.\n\nLike other methods that modify the current path, this method does not directly render\nanything. To draw the path onto a canvas, you can use the\n[CanvasRenderingContext2D.fill] or\n[CanvasRenderingContext2D.stroke] methods.",
      "linewidth": "\n\nThe\n**`CanvasRenderingContext2D.lineWidth`**\nproperty of the Canvas 2D API sets the thickness of lines.\n\n> **Note:** Lines can be drawn with the\n> [CanvasRenderingContext2D.stroke],\n> [CanvasRenderingContext2D.strokeRect],\n> and [CanvasRenderingContext2D.strokeText] methods.",
      "measuretext": "\n\nThe\n`CanvasRenderingContext2D.measureText()`\nmethod returns a [TextMetrics] object that contains information about the\nmeasured text (such as its width, for example).",
      "miterlimit": "\n\nThe **`CanvasRenderingContext2D.miterLimit`** property of the\nCanvas 2D API sets the miter limit ratio.\n\n> **Note:** For more info about miters, see [Applying styles and color](/en-US/docs/Web/API/Canvas_API/Tutorial/Applying_styles_and_colors) in the [Canvas tutorial](/en-US/docs/Web/API/Canvas_API/Tutorial).",
      "moveto": "\n\nThe\n**`CanvasRenderingContext2D.moveTo()`**\nmethod of the Canvas 2D API begins a new sub-path at the point specified by the given\n`(x, y)` coordinates.",
      "putimagedata": "\n\nThe **`CanvasRenderingContext2D.putImageData()`**\nmethod of the Canvas 2D API paints data from the given [ImageData] object\nonto the canvas. If a dirty rectangle is provided, only the pixels from that rectangle\nare painted. This method is not affected by the canvas transformation matrix.\n\n> **Note:** Image data can be retrieved from a canvas using the\n> [CanvasRenderingContext2D.getImageData] method.\n\nYou can find more information about `putImageData()` and general\nmanipulation of canvas contents in the article [Pixel manipulation with canvas](/en-US/docs/Web/API/Canvas_API/Tutorial/Pixel_manipulation_with_canvas).",
      "quadraticcurveto": "\n\nThe\n**`CanvasRenderingContext2D.quadraticCurveTo()`**\nmethod of the Canvas 2D API adds a quadratic [Bézier curve](/en-US/docs/Glossary/Bezier_curve) to the current\nsub-path. It requires two points: the first one is a control point and the second one is\nthe end point. The starting point is the latest point in the current path, which can be\nchanged using [CanvasRenderingContext2D.moveTo] before creating\nthe quadratic Bézier curve.",
      "rect": "\n\nThe\n**`CanvasRenderingContext2D.rect()`**\nmethod of the Canvas 2D API adds a rectangle to the current path.\n\nLike other methods that modify the current path, this method does not directly render\nanything. To draw the rectangle onto a canvas, you can use the\n[CanvasRenderingContext2D.fill] or\n[CanvasRenderingContext2D.stroke] methods.\n\n> **Note:** To both create and render a rectangle in one step, use the\n> [CanvasRenderingContext2D.fillRect] or\n> [CanvasRenderingContext2D.strokeRect] methods.",
      "reset": "\n\nThe **`CanvasRenderingContext2D.reset()`** method of the Canvas 2D API resets the rendering context to its default state, allowing it to be reused for drawing something else without having to explicitly reset all the properties.\n\nResetting clears the backing buffer, drawing state stack, any defined paths, and styles.\nThis includes the current [transformation](/en-US/docs/Web/API/CanvasRenderingContext2D#transformations) matrix, [compositing](/en-US/docs/Web/API/CanvasRenderingContext2D#compositing) properties, clipping region, dash list, [line styles](/en-US/docs/Web/API/CanvasRenderingContext2D#line_styles), [text styles](/en-US/docs/Web/API/CanvasRenderingContext2D#text_styles), [shadows](/en-US/docs/Web/API/CanvasRenderingContext2D#shadows), [image smoothing](/en-US/docs/Web/API/CanvasRenderingContext2D#image_smoothing), [filters](/en-US/docs/Web/API/CanvasRenderingContext2D#filters), and so on.",
      "resettransform": "\n\nThe\n**`CanvasRenderingContext2D.resetTransform()`**\nmethod of the Canvas 2D API resets the current transform to the identity matrix.",
      "restore": "\n\nThe\n**`CanvasRenderingContext2D.restore()`**\nmethod of the Canvas 2D API restores the most recently saved canvas state by popping the\ntop entry in the drawing state stack. If there is no saved state, this method does\nnothing.\n\nFor more information about the [drawing state](/en-US/docs/Web/API/CanvasRenderingContext2D/save#drawing_state), see [CanvasRenderingContext2D.save].",
      "rotate": "\n\nThe\n**`CanvasRenderingContext2D.rotate()`**\nmethod of the Canvas 2D API adds a rotation to the transformation matrix.",
      "roundrect": "\n\nThe **`CanvasRenderingContext2D.roundRect()`** method of the Canvas 2D API adds a rounded rectangle to the current path.\n\nThe radii of the corners can be specified in much the same way as the CSS [`border-radius`](/en-US/docs/Web/CSS/border-radius) property.\n\nLike other methods that modify the current path, this method does not directly render anything.\nTo draw the rounded rectangle onto a canvas, you can use the [CanvasRenderingContext2D.fill] or [CanvasRenderingContext2D.stroke] methods.",
      "save": "\n\nThe\n**`CanvasRenderingContext2D.save()`**\nmethod of the Canvas 2D API saves the entire state of the canvas by pushing the current\nstate onto a stack.\n\n### The drawing state\n\nThe drawing state that gets saved onto a stack consists of:\n\n- The current transformation matrix.\n- The current clipping region.\n- The current dash list.\n- The current values of the following attributes:\n  [CanvasRenderingContext2D.strokeStyle],\n  [CanvasRenderingContext2D.fillStyle],\n  [CanvasRenderingContext2D.globalAlpha],\n  [CanvasRenderingContext2D.lineWidth],\n  [CanvasRenderingContext2D.lineCap],\n  [CanvasRenderingContext2D.lineJoin],\n  [CanvasRenderingContext2D.miterLimit],\n  [CanvasRenderingContext2D.lineDashOffset],\n  [CanvasRenderingContext2D.shadowOffsetX],\n  [CanvasRenderingContext2D.shadowOffsetY],\n  [CanvasRenderingContext2D.shadowBlur],\n  [CanvasRenderingContext2D.shadowColor],\n  [CanvasRenderingContext2D.globalCompositeOperation], [CanvasRenderingContext2D.font],\n  [CanvasRenderingContext2D.textAlign],\n  [CanvasRenderingContext2D.textBaseline],\n  [CanvasRenderingContext2D.direction],\n  [CanvasRenderingContext2D.imageSmoothingEnabled].",
      "scale": "\n\nThe\n**`CanvasRenderingContext2D.scale()`**\nmethod of the Canvas 2D API adds a scaling transformation to the canvas units\nhorizontally and/or vertically.\n\nBy default, one unit on the canvas is exactly one pixel. A scaling transformation\nmodifies this behavior. For instance, a scaling factor of 0.5 results in a unit size of\n0.5 pixels; shapes are thus drawn at half the normal size. Similarly, a scaling factor\nof 2.0 increases the unit size so that one unit becomes two pixels; shapes are thus\ndrawn at twice the normal size.",
      "scrollpathintoview": " \n\nThe\n**`CanvasRenderingContext2D.scrollPathIntoView()`**\nmethod of the Canvas 2D API scrolls the current or given path into view. It is similar\nto [Element.scrollIntoView].",
      "setlinedash": "\n\nThe **`setLineDash()`** method of the Canvas 2D API's\n[CanvasRenderingContext2D] interface sets the line dash pattern used when\nstroking lines. It uses an array of values that specify alternating lengths of lines\nand gaps which describe the pattern.\n\n> **Note:** To return to using solid lines, set the line dash list to an\n> empty array.",
      "settransform": "\n\nThe\n**`CanvasRenderingContext2D.setTransform()`**\nmethod of the Canvas 2D API resets (overrides) the current transformation to the\nidentity matrix, and then invokes a transformation described by the arguments of this\nmethod. This lets you scale, rotate, translate (move), and skew the context.\n\n> **Note:** See also the [CanvasRenderingContext2D.transform] method; instead of overriding the current transform matrix, it\n> multiplies it with a given one.",
      "shadowblur": "\n\nThe\n**`CanvasRenderingContext2D.shadowBlur`**\nproperty of the Canvas 2D API specifies the amount of blur applied to shadows. The\ndefault is `0` (no blur).\n\n> **Note:** Shadows are only drawn if the\n> [CanvasRenderingContext2D.shadowColor] property is set to\n> a non-transparent value. One of the `shadowBlur`,\n> [CanvasRenderingContext2D.shadowOffsetX], or\n> [CanvasRenderingContext2D.shadowOffsetY] properties must\n> be non-zero, as well.",
      "shadowcolor": "\n\nThe\n**`CanvasRenderingContext2D.shadowColor`**\nproperty of the Canvas 2D API specifies the color of shadows.\n\nBe aware that the shadow's rendered opacity will be affected by the opacity of the\n[CanvasRenderingContext2D.fillStyle] color when filling, and\nof the [CanvasRenderingContext2D.strokeStyle] color when\nstroking.\n\n> **Note:** Shadows are only drawn if the `shadowColor`\n> property is set to a non-transparent value. One of the\n> [CanvasRenderingContext2D.shadowBlur],\n> [CanvasRenderingContext2D.shadowOffsetX], or\n> [CanvasRenderingContext2D.shadowOffsetY] properties must\n> be non-zero, as well.",
      "shadowoffsetx": "\n\nThe\n**`CanvasRenderingContext2D.shadowOffsetX`**\nproperty of the Canvas 2D API specifies the distance that shadows will be offset\nhorizontally.\n\n> **Note:** Shadows are only drawn if the\n> [CanvasRenderingContext2D.shadowColor] property is set to\n> a non-transparent value. One of the [CanvasRenderingContext2D.shadowBlur], `shadowOffsetX`, or\n> [CanvasRenderingContext2D.shadowOffsetY] properties must\n> be non-zero, as well.",
      "shadowoffsety": "\n\nThe\n**`CanvasRenderingContext2D.shadowOffsetY`**\nproperty of the Canvas 2D API specifies the distance that shadows will be offset\nvertically.\n\n> **Note:** Shadows are only drawn if the\n> [CanvasRenderingContext2D.shadowColor] property is set to\n> a non-transparent value. One of the [CanvasRenderingContext2D.shadowBlur],\n> [CanvasRenderingContext2D.shadowOffsetX], or `shadowOffsetY` properties must be non-zero, as\n> well.",
      "stroke": "\n\nThe\n**`CanvasRenderingContext2D.stroke()`**\nmethod of the Canvas 2D API strokes (outlines) the current or given path with the\ncurrent stroke style.\n\nStrokes are aligned to the center of a path; in other words, half of the stroke is\ndrawn on the inner side, and half on the outer side.\n\nThe stroke is drawn using the [non-zero winding rule](https://en.wikipedia.org/wiki/Nonzero-rule), which\nmeans that path intersections will still get filled.",
      "strokerect": "\n\nThe\n**`CanvasRenderingContext2D.strokeRect()`**\nmethod of the Canvas 2D API draws a rectangle that is stroked (outlined) according to\nthe current [CanvasRenderingContext2D.strokeStyle] and other\ncontext settings.\n\nThis method draws directly to the canvas without modifying the current path, so any\nsubsequent [CanvasRenderingContext2D.fill] or\n[CanvasRenderingContext2D.stroke] calls will have no effect\non it.",
      "strokestyle": "\n\nThe **`CanvasRenderingContext2D.strokeStyle`** property of the\nCanvas 2D API specifies the color, gradient, or pattern to use for the strokes\n(outlines) around shapes. The default is `#000` (black).\n\n> **Note:** For more examples of stroke and fill styles, see [Applying styles and color](/en-US/docs/Web/API/Canvas_API/Tutorial/Applying_styles_and_colors) in the [Canvas tutorial](/en-US/docs/Web/API/Canvas_API/Tutorial).",
      "stroketext": "\n\nThe [CanvasRenderingContext2D] method\n**`strokeText()`**, part of the Canvas 2D API, strokes — that\nis, draws the outlines of — the characters of a text string at the specified\ncoordinates. An optional parameter allows specifying a maximum width for the rendered\ntext, which the  will achieve by condensing the text or by\nusing a lower font size.\n\nThis method draws directly to the canvas without modifying the current path, so any\nsubsequent [CanvasRenderingContext2D.fill] or\n[CanvasRenderingContext2D.stroke] calls will have no effect\non it.\n\n> **Note:** Use the [CanvasRenderingContext2D.fillText] method to\n> fill the text characters rather than having just their outlines drawn.",
      "textalign": "\n\nThe\n**`CanvasRenderingContext2D.textAlign`**\nproperty of the Canvas 2D API specifies the current text alignment used when drawing\ntext.\n\nThe alignment is relative to the `x` value of the\n[CanvasRenderingContext2D.fillText] method. For example, if\n`textAlign` is `\"center\"`, then the text's left edge will be at\n`x - (textWidth / 2)`.",
      "textbaseline": "\n\nThe\n**`CanvasRenderingContext2D.textBaseline`**\nproperty of the Canvas 2D API specifies the current text baseline used when drawing\ntext.",
      "textrendering": "\n\nThe **`CanvasRenderingContext2D.textRendering`** property of the [Canvas API](/en-US/docs/Web/API/Canvas_API) provides information to the rendering engine about what to optimize for when rendering text.\n\nThe values correspond to the SVG [`text-rendering`](/en-US/docs/Web/SVG/Attribute/text-rendering) attribute (and CSS [`text-rendering`](/en-US/docs/Web/CSS/text-rendering) property).",
      "transform": "\n\nThe\n**`CanvasRenderingContext2D.transform()`**\nmethod of the Canvas 2D API multiplies the current transformation with the matrix\ndescribed by the arguments of this method. This lets you scale, rotate, translate\n(move), and skew the context.\n\n> **Note:** See also the\n> [CanvasRenderingContext2D.setTransform] method, which\n> resets the current transform to the identity matrix and then invokes\n> `transform()`.",
      "translate": "\n\nThe\n**`CanvasRenderingContext2D.translate()`**\nmethod of the Canvas 2D API adds a translation transformation to the current matrix.",
      "wordspacing": "\n\nThe **`CanvasRenderingContext2D.wordSpacing`** property of the [Canvas API](/en-US/docs/Web/API/Canvas_API) specifies the spacing between words when drawing text.\n\nThis corresponds to the CSS [`word-spacing`](/en-US/docs/Web/CSS/word-spacing) property."
    }
  },
  "capturecontroller": {
    "docs": "\n\nThe **`CaptureController`** interface provides methods that can be used to further manipulate a capture session separate from its initiation via [MediaDevices.getDisplayMedia].\n\nA `CaptureController` object is associated with a capture session by passing it into a [MediaDevices.getDisplayMedia] call as the value of the options object's `controller` property.",
    "properties": {
      "setfocusbehavior": "\n\nThe [CaptureController] interface's **`setFocusBehavior()`** method controls whether the captured tab or window will be focused when an associated [MediaDevices.getDisplayMedia] `Promise` fulfills, or whether the focus will remain with the tab containing the capturing app.\n\nYou can set this behavior multiple times before the [MediaDevices.getDisplayMedia] call, or once immediately after its `Promise` resolves. After that, the focus behavior is said to be finalized, and can't be changed."
    }
  },
  "caretposition": {
    "docs": " \n\nThe `CaretPosition` interface represents the caret position, an indicator for the text insertion point. You can get a `CaretPosition` using the [Document.caretPositionFromPoint] method."
  },
  "cdatasection": {
    "docs": "\n\nThe **`CDATASection`** interface represents a CDATA section\nthat can be used within XML to include extended portions of unescaped text.\nWhen inside a CDATA section, the symbols `<` and `&` don't need escaping\nas they normally do.\n\nIn XML, a CDATA section looks like:\n\n```xml\n<![CDATA[ … ]]>\n```\n\nFor example:\n\n```html\n<foo>\n  Here is a CDATA section: <![CDATA[ < > & ]]> with all kinds of unescaped text.\n</foo>\n```\n\nThe only sequence which is not allowed within a CDATA section is the closing sequence\nof a CDATA section itself, `]]>`.\n\n> **Note:** CDATA sections should not be used within HTML they are considered as comments and not displayed.\n\n"
  },
  "channelmergernode": {
    "docs": "\n\nThe `ChannelMergerNode` interface, often used in conjunction with its opposite, [ChannelSplitterNode], reunites different mono inputs into a single output. Each input is used to fill a channel of the output. This is useful for accessing each channels separately, e.g. for performing channel mixing where gain must be separately controlled on each channel.\n\n![Default channel merger node with six mono inputs combining to form a single output.](webaudiomerger.png)\n\nIf `ChannelMergerNode` has one single output, but as many inputs as there are channels to merge; the number of inputs is defined as a parameter of its constructor and the call to [BaseAudioContext/createChannelMerger]. In the case that no value is given, it will default to `6`.\n\nUsing a `ChannelMergerNode`, it is possible to create outputs with more channels than the rendering hardware is able to process. In that case, when the signal is sent to the [BaseAudioContext/listener] object, supernumerary channels will be ignored.\n\n<table class=\"properties\">\n  <tbody>\n    <tr>\n      <th scope=\"row\">Number of inputs</th>\n      <td>variable; default to <code>6</code>.</td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Number of outputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count mode</th>\n      <td><code>\"explicit\"</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count</th>\n      <td><code>2 </code>(not used in the default count mode)</td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel interpretation</th>\n      <td><code>\"speakers\"</code></td>\n    </tr>\n  </tbody>\n</table>"
  },
  "channelsplitternode": {
    "docs": "\n\nThe `ChannelSplitterNode` interface, often used in conjunction with its opposite, [ChannelMergerNode], separates the different channels of an audio source into a set of mono outputs. This is useful for accessing each channel separately, e.g. for performing channel mixing where gain must be separately controlled on each channel.\n\n![Default channel splitter node with a single input splitting to form 6 mono outputs.](webaudiosplitter.png)\n\nIf your `ChannelSplitterNode` always has one single input, the amount of outputs is defined by a parameter on its constructor and the call to [BaseAudioContext/createChannelSplitter]. In the case that no value is given, it will default to `6`. If there are fewer channels in the input than there are outputs, supernumerary outputs are silent.\n\n<table class=\"properties\">\n  <tbody>\n    <tr>\n      <th scope=\"row\">Number of inputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Number of outputs</th>\n      <td>variable; default to <code>6</code>.</td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count mode</th>\n      <td>\n        <code>\"explicit\"</code> Older implementations, as per earlier versions\n        of the spec use <code>\"max\"</code>.\n      </td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count</th>\n      <td>\n        Fixed to the number of outputs. Older implementations, as per earlier\n        versions of the spec use <code>2 </code>(not used in the default count\n        mode).\n      </td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel interpretation</th>\n      <td><code>\"discrete\"</code></td>\n    </tr>\n  </tbody>\n</table>"
  },
  "characterdata": {
    "docs": "\n\nThe **`CharacterData`** abstract interface represents a [Node] object that contains characters. This is an abstract interface, meaning there aren't any objects of type `CharacterData`: it is implemented by other interfaces like [Text], [Comment], [CDATASection], or [ProcessingInstruction], which aren't abstract.\n\n",
    "properties": {
      "after": "\n\nThe **`after()`** method of the [CharacterData] interface\ninserts a set of [Node] objects or strings in the children list of the\nobject's parent, just after the object itself.\n\nStrings are inserted as [Text] nodes; the string is being passed as argument to the [Text/Text] constructor.",
      "appenddata": "\n\nThe **`appendData()`** method of the [CharacterData] interface\nadds the provided data to the end of the node's current data.",
      "before": "\n\nThe **`before()`** method of the [CharacterData] interface\ninserts a set of [Node] objects and strings\nin the children list of the `CharacterData`'s parent, just before the `CharacterData` node.\n\nStrings are inserted as [Text] nodes; the string is being passed as argument to the [Text/Text] constructor.",
      "data": "\n\nThe **`data`** property of the [CharacterData] interface represent the value of the current object's data.",
      "deletedata": "\n\nThe **`deleteData()`** method of the [CharacterData] interface\nremoves all or part of the data from this `CharacterData` node.",
      "insertdata": "\n\nThe **`insertData()`** method of the [CharacterData] interface\ninserts the provided data into this `CharacterData` node's current data,\nat the provided offset from the start of the existing data.\nThe provided data is spliced into the existing data.",
      "length": "\n\nThe read-only **`CharacterData.length`** property\nreturns the number of characters in the contained data, as a positive integer.",
      "nextelementsibling": "\n\nThe read-only **`nextElementSibling`** property of the [CharacterData] interface\nreturns the first [Element] node following the specified one in its parent's\nchildren list, or `null` if the specified element is the last one in the list.",
      "previouselementsibling": "\n\nThe read-only **`previousElementSibling`** of the [CharacterData] interface\nreturns the first [Element] before the current node in its parent's children list,\nor `null` if there is none.",
      "remove": "\n\nThe **`remove()`** method of the [CharacterData] removes the text contained in the node.",
      "replacedata": "\n\nThe **`replaceData()`** method of the [CharacterData] interface removes a certain number of characters of the existing text in a given `CharacterData` node and replaces those characters with the text provided.",
      "replacewith": "\n\nThe **`replaceWith()`** method of the [CharacterData] interface\nreplaces this node in the children list of its parent\nwith a set of [Node] objects or string.\n\nStrings are inserted as [Text] nodes; the string is being passed as argument to the [Text/Text] constructor.",
      "substringdata": "\n\nThe **`substringData()`** method of the [CharacterData] interface\nreturns a portion of the existing data,\nstarting at the specified index\nand extending for a given number of characters afterwards."
    }
  },
  "client": {
    "docs": "\n\nThe `Client` interface represents an executable context such as a [Worker], or a [SharedWorker]. [Window] clients are represented by the more-specific [WindowClient]. You can get `Client`/`WindowClient` objects from methods such as [Clients.matchAll] and [Clients.get].",
    "properties": {
      "frametype": "\n\nThe **`frameType`** read-only property of the [Client] interface indicates the type of browsing context of the current [Client]. This value can be one of `\"auxiliary\"`, `\"top-level\"`, `\"nested\"`, or `\"none\"`.",
      "id": "\n\nThe **`id`** read-only property of the [Client] interface returns the universally unique identifier of the [Client] object.",
      "postmessage": "\n\nThe **`postMessage()`** method of the\n[Client] interface allows a service worker to send a message to a client\n(a [Window], [Worker], or [SharedWorker]). The\nmessage is received in the \"`message`\" event on\n[ServiceWorkerContainer].",
      "type": "\n\nThe **`type`** read-only property of the [Client]\ninterface indicates the type of client the service worker is controlling.",
      "url": "\n\nThe **`url`** read-only property of the [Client]\ninterface returns the URL of the current service worker client."
    }
  },
  "clients": {
    "docs": "\n\nThe `Clients` interface provides access to [Client] objects. Access it via `[ServiceWorkerGlobalScope].clients` within a [service worker](/en-US/docs/Web/API/Service_Worker_API).",
    "properties": {
      "claim": "\n\nThe **`claim()`** method of the [Clients] interface allows an active service worker to set itself as the [ServiceWorkerContainer.controller] for all clients within its [ServiceWorkerRegistration.scope].\nThis triggers a \"`controllerchange`\" event on [ServiceWorkerContainer] in any clients that become controlled by this service worker.\n\nWhen a service worker is initially registered, pages won't use it until they next\nload. The `claim()` method causes those pages to be controlled immediately.\nBe aware that this results in your service worker controlling pages that loaded\nregularly over the network, or possibly via a different service worker.",
      "get": "\n\nThe **`get()`** method of the\n[Clients] interface gets a service worker client matching a given\n`id` and returns it in a `Promise`.",
      "matchall": "\n\nThe **`matchAll()`** method of the [Clients]\ninterface returns a `Promise` for a list of service worker\n[Client] objects. Include the `options` parameter to return all service worker\nclients whose origin is the same as the associated service worker's origin. If options\nare not included, the method returns only the service worker clients controlled by the\nservice worker.",
      "openwindow": "\n\nThe **`openWindow()`** method of the [Clients]\ninterface creates a new top level browsing context and loads a given URL. If the calling\nscript doesn't have permission to show popups, `openWindow()` will throw an\n`InvalidAccessError`.\n\nIn Firefox, the method is allowed to show popups only when called as the result of a\nnotification click event.\n\nIn Chrome for Android, the method may instead open the URL in an existing browsing\ncontext provided by a [standalone web app](/en-US/docs/Web/Progressive_web_apps) previously added to the user's home screen. As of recently, this also works on\nChrome for Windows."
    }
  },
  "clipboard": {
    "docs": "\n\nThe **`Clipboard`** interface implements the [Clipboard API](/en-US/docs/Web/API/Clipboard_API), providing—if the user grants permission—both read and write access to the contents of the system clipboard. The Clipboard API can be used to implement cut, copy, and paste features within a web application.\n\nThe system clipboard is exposed through the global [Navigator.clipboard] property.\n\nCalls to the methods of the `Clipboard` object will not succeed if the user hasn't granted the needed permissions using the [Permissions API](/en-US/docs/Web/API/Permissions_API) and the `'clipboard-read'` or `'clipboard-write'` permission as appropriate.\n\n> **Note:** In reality, at this time browser requirements for access to the clipboard vary significantly. Please see the section [Clipboard availability](#clipboard_availability) for details.\n\nAll of the Clipboard API methods operate asynchronously; they return a `Promise` which is resolved once the clipboard access has been completed. The promise is rejected if clipboard access is denied.",
    "properties": {
      "read": "\n\nThe **`read()`** method of the\n[Clipboard] interface requests a copy of the clipboard's contents,\ndelivering the data to the returned `Promise` when the promise is\nresolved. Unlike [Clipboard.readText], the\n`read()` method can return arbitrary data, such as images. This method can\nalso return text.\n\n> **Note:** The asynchronous Clipboard and [Permissions APIs](/en-US/docs/Web/API/Permissions_API) are still in the\n> process of being integrated into most browsers, so they often deviate from the\n> official rules for permissions and the like. Be sure to review the [compatibility table](#browser_compatibility) before using these methods.",
      "readtext": "\n\nThe **[Clipboard]** interface's\n**`readText()`** method returns a `Promise` which\nresolves with a copy of the textual contents of the system clipboard.",
      "write": "\n\nThe [Clipboard] method\n**`write()`** writes arbitrary data, such as images, to the\nclipboard. This can be used to implement cut and copy functionality.\n\nThe `\"clipboard-write\"` permission of the [Permissions API](/en-US/docs/Web/API/Permissions_API), is granted\nautomatically to pages when they are in the active tab.\n\n> **Note:** Browser support for the asynchronous clipboard APIs is still\n> in the process of being implemented. Be sure to check the [compatibility table](#browser_compatibility) as well as\n> [Clipboard availability](/en-US/docs/Web/API/Clipboard#clipboard_availability) for more\n> information.\n\n> **Note:** For parity with Google Chrome, Firefox only allows this function to work with text, HTML, and PNG data.",
      "writetext": "\n\nThe [Clipboard] interface's **`writeText()`**\nproperty writes the specified text string to the system clipboard. Text may be read back\nusing either [Clipboard.read] or [Clipboard.readText]."
    }
  },
  "clipboardevent": {
    "docs": "\n\nThe **`ClipboardEvent`** interface represents events providing information related to modification of the clipboard, that is [Element/cut_event], [Element/copy_event], and [Element/paste_event] events.\n\n",
    "properties": {
      "clipboarddata": "\n\nThe **`ClipboardEvent.clipboardData`** property holds a [DataTransfer] object, which can be used:\n\n- to specify what data should be put into the clipboard from the [Element/cut_event] and\n  [Element/copy_event] event handlers, typically with a [DataTransfer.setData] call;\n- to obtain the data to be pasted from the [Element/paste_event] event handler, typically\n  with a [DataTransfer.getData] call.\n\nSee the [Element/cut_event], [Element/copy_event], and [Element/paste_event] events\ndocumentation for more information."
    }
  },
  "clipboarditem": {
    "docs": "\n\nThe **`ClipboardItem`** interface of the [Clipboard API] represents a single item format, used when reading or writing data via the [Clipboard API]. That is [clipboard.read] and [clipboard.write] respectively.\n\nThe benefit of having the **`ClipboardItem`** interface to represent data, is that it enables developers to cope with the varying scope of file types and data easily.\n\nAccess to the contents of the clipboard is gated behind the [Permissions API](/en-US/docs/Web/API/Permissions_API): The `clipboard-write` permission is granted automatically to pages when they are in the active tab. The `clipboard-read` permission must be requested, which you can do by trying to read data from the clipboard.\n\n> **Note:** To work with text see the [Clipboard.readText] and [Clipboard.writeText] methods of the [Clipboard] interface.\n\n> **Note:** You can only pass in one clipboard item at a time.",
    "properties": {
      "gettype": "\n\nThe **`getType()`** method of the [ClipboardItem] interface returns a `Promise` that resolves with a [Blob] of the requested  or an error if the MIME type is not found.",
      "presentationstyle": "\n\nThe read-only\n**`presentationStyle`** property of the [ClipboardItem]\ninterface returns a string indicating how an item should be presented.",
      "types": "\n\nThe read-only\n**`types`** property of the [ClipboardItem]\ninterface returns an `Array` of \navailable within the [ClipboardItem]"
    }
  },
  "closeevent": {
    "docs": "\n\nA `CloseEvent` is sent to clients using  when the connection is closed. This is delivered to the listener indicated by the `WebSocket` object's `onclose` attribute.\n\n",
    "properties": {
      "code": "\n\nThe **`code`** read-only property of the [CloseEvent] interface returns a [WebSocket connection close code](https://www.rfc-editor.org/rfc/rfc6455.html#section-7.1.5) indicating the reason the server gave for closing the connection.",
      "reason": "\n\nThe **`reason`** read-only property of the [CloseEvent] interface returns the [WebSocket connection close reason](https://www.rfc-editor.org/rfc/rfc6455.html#section-7.1.6) the server gave for closing the connection; that is, a concise human-readable prose explanation for the closure.",
      "wasclean": "\n\nThe **`wasClean`** read-only property of the [CloseEvent] interface returns `true` if the connection closed cleanly."
    }
  },
  "comment": {
    "docs": "\n\nThe **`Comment`** interface represents textual notations within markup; although it is generally not visually shown, such comments are available to be read in the source view.\n\nComments are represented in HTML and XML as content between '`<!--`' and '`-->`'. In XML, like inside SVG or MathML markup, the character sequence '`--`' cannot be used within a comment.\n\n"
  },
  "compositionevent": {
    "docs": "\n\nThe DOM **`CompositionEvent`** represents events that occur due to the user indirectly entering text.\n\n",
    "properties": {
      "data": "\n\nThe **`data`** read-only property of the\n[CompositionEvent] interface returns the characters generated by the input\nmethod that raised the event; its exact nature varies depending on the type of event\nthat generated the `CompositionEvent` object.",
      "initcompositionevent": "\n\nThe **`initCompositionEvent()`**\nmethod of the [CompositionEvent] interface initializes the attributes of a\n`CompositionEvent` object instance.\n\n> **Note:** The correct way of creating a [CompositionEvent] is to use\n> the constructor [CompositionEvent.CompositionEvent].",
      "locale": "\n\nThe **`locale`** read-only property of the\n[CompositionEvent] interface returns the locale of current input method\n(for example, the keyboard layout locale if the composition is associated with IME).\n\n> **Warning:** Even for browsers supporting it, don't trust the value contained in this property.\n> Even if technically it is accessible, the way to set it up when creating a [CompositionEvent]\n> is not guaranteed to be coherent."
    }
  },
  "compressionstream": {
    "docs": "\n\nThe **`CompressionStream`** interface of the [Compression Streams API] is an API for compressing a stream of data.",
    "properties": {
      "readable": "\n\nThe **`readable`** read-only property of the [CompressionStream] interface returns a [ReadableStream].",
      "writable": "\n\nThe **`writable`** read-only property of the [CompressionStream] interface returns a [WritableStream]."
    }
  },
  "console": {
    "docs": "\n\nThe **`console`** object provides access to the debugging console (e.g., the [Web console](https://firefox-source-docs.mozilla.org/devtools-user/web_console/index.html) in Firefox). The specifics of how it works vary from browser to browser or server runtimes (Node.js, for example), but there is a _de facto_ set of features that are typically provided.\n\nThe `console` object can be accessed from any global object. [Window] on browsing scopes and [WorkerGlobalScope] as specific variants in workers via the property console. It's exposed as [Window.console], and can be referenced as `console`. For example:\n\n```js\nconsole.log(\"Failed to open the specified link\");\n```\n\nThis page documents the [Methods](#methods) available on the `console` object and gives a few [Usage](#usage) examples.\n\n> **Note:** Certain online IDEs and editors may implement the console API differently than the browsers. As a result, certain functionality of the console API, such as the timer methods, may not be outputted in the console of online IDEs or editors. Always open your browser's DevTools console to see the logs as shown in this documentation.",
    "properties": {
      "assert_static": "\n\nThe **`console.assert()`** static method writes an error message to the console if the assertion is false. If the assertion is true, nothing happens.\n\n",
      "clear_static": "\n\nThe **`console.clear()`** static method clears the console if the console allows it. A graphical console, like those running on browsers, will allow it; a console displaying on the terminal, like the one running on Node, will not support it, and will have no effect (and no error).",
      "count_static": "\n\nThe **`console.count()`** static method logs the number of times that this particular call to `count()` has been called.\n\n",
      "countreset_static": "\n\nThe **`console.countReset()`** static method resets counter used with [console/count_static].\n\n",
      "debug_static": "\n\nThe **`console.debug()`** static method outputs a message to the console at the \"debug\" log level. The message is only displayed to the user if the console is configured to display debug output. In most cases, the log level is configured within the console UI. This log level might correspond to the `Debug` or `Verbose` log level.\n\n",
      "dir_static": "\n\nThe **`console.dir()`** static method displays an interactive list of the properties of the specified JavaScript object. The output is presented as a hierarchical listing with disclosure triangles that let you see the contents of child objects.\n\nIn other words, `console.dir()` is the way to see all the properties of a specified JavaScript object in console by which the developer can easily get the properties of the object.\n\n![A screenshot of the Firefox console where console.dir(document.location) is run. We can see the URL of the page, followed by a block of properties. If the property is a function or an object, a disclosure triangle is prepended.](console-dir.png)",
      "dirxml_static": "\n\nThe **`console.dirxml()`** static method displays an interactive tree of the descendant elements of the specified XML/HTML element. If it is not possible to display as an element the JavaScript Object view is shown instead. The output is presented as a hierarchical listing of expandable nodes that let you see the contents of child nodes.",
      "error_static": "\n\nThe **`console.error()`** static method outputs an error message to the console.\n\n",
      "group_static": "\n\nThe **`console.group()`** static method creates a new inline group in the [Web console](https://firefox-source-docs.mozilla.org/devtools-user/web_console/index.html) log, causing any subsequent console messages to be indented by an additional level, until [console/groupend_static] is called.\n\n",
      "groupcollapsed_static": "\n\nThe **`console.groupCollapsed()`** static method creates a new inline group in the console. Unlike [console/group_static], however, the new group is created collapsed. The user will need to use the disclosure button next to it to expand it, revealing the entries created in the group.\n\nCall [console/groupEnd_static] to back out to the parent group.\n\nSee [Using groups in the console](/en-US/docs/Web/API/console#using_groups_in_the_console) in the [console] documentation for details and examples.\n\n",
      "groupend_static": "\n\nThe **`console.groupEnd()`** static method exits the current inline group in the console. See [Using groups in the console](/en-US/docs/Web/API/console#using_groups_in_the_console) in the [console] documentation for details and examples.\n\n",
      "info_static": "\n\nThe **`console.info()`** static method outputs an informational message to the console. In Firefox, a small \"i\" icon is displayed next to these items in the console's log.\n\n",
      "log_static": "\n\nThe **`console.log()`** static method outputs a message to the console. The message may be a single string (with optional substitution values), or it may be any one or more JavaScript objects.\n\n",
      "profile_static": "\n\nThe **`console.profile()`** static method starts recording a performance profile (for example, the [Firefox performance tool](https://firefox-source-docs.mozilla.org/devtools-user/performance/index.html)).\n\nYou can optionally supply an argument to name the profile and this then enables you to stop only that profile if multiple profiles being recorded. See [console/profileEnd_static] to see how this argument is interpreted.\n\nTo stop recording call [console/profileEnd_static].\n\n",
      "profileend_static": "\n\nThe **`console.profileEnd()`** static method stops recording a profile previously started with [console/profile_static].\n\nYou can optionally supply an argument to name the profile. Doing so enables you to stop only that profile if you have multiple profiles being recorded.\n\n- If `console.profileEnd()` is passed a profile name, and it matches the name of a profile being recorded, then that profile is stopped.\n- If `console.profileEnd()` is passed a profile name and it does not match the name of a profile being recorded, no changes will be made.\n- If `console.profileEnd()` is not passed a profile name, the most recently started profile is stopped.\n\n",
      "table_static": "\n\nThe **`console.table()`** static method displays tabular data as a table.\n\nThis function takes one mandatory argument `data`, which must be an array or an object, and one additional optional parameter `columns`.\n\nIt logs `data` as a table. Each element in the array (or enumerable property if `data` is an object) will be a row in the table.\n\nThe first column in the table will be labeled `(index)`. If `data` is an array, then its values will be the array indices. If `data` is an object, then its values will be the property names. Note that (in Firefox) `console.table` is limited to displaying 1000 rows (first row is the labeled index).\n\n### Collections of primitive types\n\nThe `data` argument may be an array or an object.\n\n```js\n// an array of strings\n\nconsole.table([\"apples\", \"oranges\", \"bananas\"]);\n```\n\n| (index) | Values    |\n| ------- | --------- |\n| 0       | 'apples'  |\n| 1       | 'oranges' |\n| 2       | 'bananas' |\n\n```js\n// an object whose properties are strings\n\nfunction Person(firstName, lastName) {\n  this.firstName = firstName;\n  this.lastName = lastName;\n}\n\nconst me = new Person(\"Tyrone\", \"Jones\");\n\nconsole.table(me);\n```\n\n| (index)   | Values   |\n| --------- | -------- |\n| firstName | 'Tyrone' |\n| lastName  | 'Jones'  |\n\n### Collections of compound types\n\nIf the elements in the array, or properties in the object, are themselves arrays or objects, then their elements or properties are enumerated in the row, one per column:\n\n```js\n// an array of arrays\n\nconst people = [\n  [\"Tyrone\", \"Jones\"],\n  [\"Janet\", \"Smith\"],\n  [\"Maria\", \"Cruz\"],\n];\nconsole.table(people);\n```\n\n| (index) | 0        | 1       |\n| ------- | -------- | ------- |\n| 0       | 'Tyrone' | 'Jones' |\n| 1       | 'Janet'  | 'Smith' |\n| 2       | 'Maria'  | 'Cruz'  |\n\n```js\n// an array of objects\n\nfunction Person(firstName, lastName) {\n  this.firstName = firstName;\n  this.lastName = lastName;\n}\n\nconst tyrone = new Person(\"Tyrone\", \"Jones\");\nconst janet = new Person(\"Janet\", \"Smith\");\nconst maria = new Person(\"Maria\", \"Cruz\");\n\nconsole.table([tyrone, janet, maria]);\n```\n\nNote that if the array contains objects, then the columns are labeled with the property name.\n\n| (index) | firstName | lastName |\n| ------- | --------- | -------- |\n| 0       | 'Tyrone'  | 'Jones'  |\n| 1       | 'Janet'   | 'Smith'  |\n| 2       | 'Maria'   | 'Cruz'   |\n\n```js\n// an object whose properties are objects\n\nconst family = {};\n\nfamily.mother = new Person(\"Janet\", \"Jones\");\nfamily.father = new Person(\"Tyrone\", \"Jones\");\nfamily.daughter = new Person(\"Maria\", \"Jones\");\n\nconsole.table(family);\n```\n\n| (index)  | firstName | lastName |\n| -------- | --------- | -------- |\n| daughter | 'Maria'   | 'Jones'  |\n| father   | 'Tyrone'  | 'Jones'  |\n| mother   | 'Janet'   | 'Jones'  |\n\n### Restricting the columns displayed\n\nBy default, `console.table()` lists all elements in each row. You can use the optional `columns` parameter to select a subset of columns to display:\n\n```js\n// an array of objects, logging only firstName\n\nfunction Person(firstName, lastName) {\n  this.firstName = firstName;\n  this.lastName = lastName;\n}\n\nconst tyrone = new Person(\"Tyrone\", \"Jones\");\nconst janet = new Person(\"Janet\", \"Smith\");\nconst maria = new Person(\"Maria\", \"Cruz\");\n\nconsole.table([tyrone, janet, maria], [\"firstName\"]);\n```\n\n| (index) | firstName |\n| ------- | --------- |\n| 0       | 'Tyrone'  |\n| 1       | 'Janet'   |\n| 2       | 'Maria'   |\n\n### Sorting columns\n\nYou can sort the table by a particular column by clicking on that column's label.",
      "time_static": "\n\nThe **`console.time()`** static method starts a timer you can use to track how long an operation takes. You give each timer a unique name, and may have up to 10,000 timers running on a given page. When you call [console/timeEnd_static] with the same name, the browser will output the time, in milliseconds, that elapsed since the timer was started.\n\nSee [Timers](/en-US/docs/Web/API/console#timers) in the [console] documentation for details and examples.\n\n",
      "timeend_static": "\n\nThe **`console.timeEnd()`** static method stops a timer that was previously started by calling [console/time_static].\n\nSee [Timers](/en-US/docs/Web/API/console#timers) in the documentation for details and examples.\n\n",
      "timelog_static": "\n\nThe **`console.timeLog()`** static method logs the current value of a timer that was previously started by calling [console/time_static].",
      "timestamp_static": "\n\nThe **`console.timeStamp()`** static method adds a single marker to the browser's Performance tool ([Firefox](https://profiler.firefox.com/docs/#/), [Chrome](https://developer.chrome.com/docs/devtools/evaluate-performance/reference/)). This lets you correlate a point in your code with the other events recorded in the timeline, such as layout and paint events.\n\nYou can optionally supply an argument to label the timestamp, and this label will then be shown alongside the marker.\n\n",
      "trace_static": "\n\nThe **`console.trace()`** static method outputs a stack trace to the console.\n\n> **Note:** In some browsers, `console.trace()` may also output the sequence of calls and asynchronous events leading to the current `console.trace()` which are not on the call stack — to help identify the origin of the current event evaluation loop.\n\nSee [Stack traces](/en-US/docs/Web/API/console#stack_traces) in the [console] documentation for details and examples.",
      "warn_static": "\n\nThe **`console.warn()`** static method outputs a warning message to the console.\n\n> **Note:** In Chrome and Firefox, warnings have a small exclamation point icon next to them in the console log."
    }
  },
  "constantsourcenode": {
    "docs": "\n\nThe `ConstantSourceNode` interface—part of the Web Audio API—represents an audio source (based upon [AudioScheduledSourceNode]) whose output is single unchanging value. This makes it useful for cases in which you need a constant value coming in from an audio source. In addition, it can be used like a constructible [AudioParam] by automating the value of its [ConstantSourceNode.offset] or by connecting another node to it; see [Controlling multiple parameters with ConstantSourceNode](/en-US/docs/Web/API/Web_Audio_API/Controlling_multiple_parameters_with_ConstantSourceNode).\n\nA `ConstantSourceNode` has no inputs and exactly one monaural (one-channel) output. The output's value is always the same as the value of the [ConstantSourceNode.offset] parameter.\n\n<table class=\"properties\">\n  <tbody>\n    <tr>\n      <th scope=\"row\">Number of inputs</th>\n      <td><code>0</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Number of outputs</th>\n      <td><code>1</code></td>\n    </tr>\n  </tbody>\n</table>",
    "properties": {
      "offset": "\n\nThe read-only `offset` property of the [ConstantSourceNode]\ninterface returns a [AudioParam] object indicating the numeric [a-rate](/en-US/docs/Web/API/AudioParam#a-rate) value which is always returned\nby the source when asked for the next sample.\n\n> **Note:** While the `AudioParam` named `offset` is read-only, the\n> `value` property within is not. So you can change the value of\n> `offset` by setting the value of\n> `ConstantSourceNode.offset.value`:\n>\n> ```js\n> myConstantSourceNode.offset.value = newValue;\n> ```"
    }
  },
  "contactaddress": {
    "docs": "\n\nThe **`ContactAddress`** interface of the [contact_picker_api] represents a physical address. Instances of this interface are retrieved from the `address` property of the objects returned by [ContactsManager.getProperties].\n\nIt may be useful to refer to the Universal Postal Union website's [Addressing S42 standard](https://www.upu.int/en/Postal-Solutions/Programmes-Services/Addressing-Solutions#addressing-s42-standard) materials, which provide information about international standards for postal addresses."
  },
  "contactsmanager": {
    "docs": "\n\nThe **`ContactsManager`** interface of the [Contact Picker API] allows users to select entries from their contact list and share limited details of the selected entries with a website or application.\n\nThe `ContactsManager` is available through the global [navigator.contacts] property.",
    "properties": {
      "getproperties": "\n\nThe **`getProperties()`** method of the\n[ContactsManager] interface returns a `Promise` which resolves\nwith an `Array` of `strings` indicating which contact\nproperties are available.",
      "select": "\n\nThe **`select()`** method of the\n[ContactsManager] interface returns a `Promise` which, when\nresolved, presents the user with a contact picker which allows them to select contact(s)\nthey wish to share. This method requires a user gesture for the `Promise` to\nresolve."
    }
  },
  "contentindex": {
    "docs": "\n\nThe **`ContentIndex`** interface of the [Content Index API](/en-US/docs/Web/API/Content_Index_API) allows developers to register their offline enabled content with the browser.",
    "properties": {
      "add": "\n\nThe **`add()`** method of the\n[ContentIndex] interface registers an item with the [content index](/en-US/docs/Web/API/Content_Index_API).",
      "delete": "\n\nThe **`delete()`** method of the\n[ContentIndex] interface unregisters an item from the currently indexed\ncontent.\n\n> **Note:** Calling `delete()` only affects the index. It does not delete anything\n> from the [Cache].",
      "getall": "\n\nThe **`getAll()`** method of the\n[ContentIndex] interface returns a `Promise` that resolves with\nan iterable list of content index entries."
    }
  },
  "contentindexevent": {
    "docs": "\n\nThe **`ContentIndexEvent`** interface of the [content index](/en-US/docs/Web/API/Content_Index_API) defines the object used to represent the [ServiceWorkerGlobalScope.contentdelete_event] event.\n\nThis event is sent to the [global scope](/en-US/docs/Web/API/ServiceWorkerGlobalScope) of a [ServiceWorker]. It contains the id of the indexed content to be removed.\n\nThe [ServiceWorkerGlobalScope.contentdelete_event] event is only fired when the deletion happens due to interaction with the browser's built-in user interface. It is not fired when the [ContentIndex.delete] method is called.\n\n",
    "properties": {
      "id": "\n\nThe read-only **`id`** property of the\n[ContentIndexEvent] interface is a `String` which identifies\nthe deleted content index via its `id`."
    }
  },
  "contentvisibilityautostatechangeevent": {
    "docs": "\n\nThe **`ContentVisibilityAutoStateChangeEvent`** interface is the event object for the [element/contentvisibilityautostatechange_event] event, which fires on any element with  set on it when it starts or stops being [relevant to the user](/en-US/docs/Web/CSS/CSS_containment#relevant_to_the_user) and [skipping its contents](/en-US/docs/Web/CSS/CSS_containment#skips_its_contents).\n\nWhile the element is not relevant (between the start and end events), the user agent skips an element's rendering, including layout and painting.\nThis can significantly improve page rendering speed.\nThe [element/contentvisibilityautostatechange_event] event provides a way for an app's code to also start or stop rendering processes (e.g. drawing on a `canvas`) when they are not needed, thereby conserving processing power.\n\nNote that even when hidden from view, element contents will remain semantically relevant (e.g. to assistive technology users), so this signal should not be used to skip significant semantic DOM updates.\n\n",
    "properties": {
      "skipped": "\n\nThe `skipped` read-only property of the [ContentVisibilityAutoStateChangeEvent] interface returns `true` if the user agent [skips the element's contents](/en-US/docs/Web/CSS/CSS_containment#skips_its_contents), or `false` otherwise."
    }
  },
  "convolvernode": {
    "docs": "\n\nThe `ConvolverNode` interface is an [AudioNode] that performs a Linear Convolution on a given [AudioBuffer], often used to achieve a reverb effect. A `ConvolverNode` always has exactly one input and one output.\n\n> **Note:** For more information on the theory behind Linear Convolution, see the [Convolution article on Wikipedia](https://en.wikipedia.org/wiki/Convolution).\n\n<table class=\"properties\">\n  <tbody>\n    <tr>\n      <th scope=\"row\">Number of inputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Number of outputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count mode</th>\n      <td><code>\"clamped-max\"</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count</th>\n      <td><code>1</code>, <code>2</code>, or <code>4</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel interpretation</th>\n      <td><code>\"speakers\"</code></td>\n    </tr>\n  </tbody>\n</table>",
    "properties": {
      "buffer": "\n\nThe **`buffer`** property of the [ConvolverNode] interface represents a mono, stereo, or 4-channel [AudioBuffer] containing the (possibly multichannel) impulse response used by the `ConvolverNode` to create the reverb effect.\n\nThis is normally a simple recording of as-close-to-an-impulse as can be found in the space you want to model. For example, if you want to model the reverb in your bathroom, you might set up a microphone near the door to record the sound of a balloon pop or synthesized impulse from the sink. That audio recording could then be used as the buffer.\n\nThis audio buffer must have the same sample-rate as the `AudioContext` or an exception will be thrown. At the time when this attribute is set, the buffer and the state of the attribute will be used to configure the `ConvolverNode` with this impulse response having the given normalization. The initial value of this attribute is `null`.",
      "normalize": "\n\nThe `normalize` property of the [ConvolverNode] interface\nis a boolean that controls whether the impulse response from the buffer will be\nscaled by an equal-power normalization when the `buffer` attribute is set,\nor not.\n\nIts default value is `true` in order to achieve a more uniform output\nlevel from the convolver, when loaded with diverse impulse responses. If normalize is\nset to `false`, then the convolution will be rendered with no\npre-processing/scaling of the impulse response. Changes to this value do not take\neffect until the next time the `buffer` attribute is set."
    }
  },
  "cookiechangeevent": {
    "docs": "\n\nThe **`CookieChangeEvent`** interface of the [Cookie Store API] is the event type of the [CookieStore/change_event] event fired at a [CookieStore] when any cookie changes occur. A cookie change consists of a cookie and a type (either \"changed\" or \"deleted\").\n\nCookie changes that will cause the `CookieChangeEvent` to be dispatched are:\n\n- A cookie is newly created and not immediately removed. In this case `type` is \"changed\".\n- A cookie is newly created and immediately removed. In this case `type` is \"deleted\".\n- A cookie is removed. In this case `type` is \"deleted\".\n\n> **Note:** A cookie that is replaced due to the insertion of another cookie with the same name, domain, and path, is ignored and does not trigger a change event.\n\n",
    "properties": {
      "changed": "\n\nThe **`changed`** read-only property of the [CookieChangeEvent] interface returns an array of the cookies that have been changed.",
      "deleted": "\n\nThe **`deleted`** read-only property of the [CookieChangeEvent] interface returns an array of the cookies that have been deleted by the given `CookieChangeEvent` instance."
    }
  },
  "cookiestore": {
    "docs": "\n\nThe **`CookieStore`** interface of the [Cookie Store API] provides methods for getting and setting cookies asynchronously from either a page or a service worker.\n\nThe `CookieStore` is accessed via attributes in the global scope in a [Window] or [ServiceWorkerGlobalScope] context. Therefore there is no constructor.\n\n",
    "properties": {
      "change_event": "\n\nA `change` event is fired at a [CookieStore] object when a change is made to any cookie.",
      "delete": "\n\nThe **`delete()`** method of the [CookieStore] interface deletes a cookie with the given name or options object. The `delete()` method expires the cookie by changing the date to one in the past.\n\n",
      "get": "\n\nThe **`get()`** method of the [CookieStore] interface returns a single cookie with the given name or options object. The method will return the first matching cookie for the passed parameters.\n\n",
      "getall": "\n\nThe **`getAll()`** method of the [CookieStore] interface returns a list of cookies that match the name or options passed to it. Passing no parameters will return all cookies for the current context.\n\n",
      "set": "\n\nThe **`set()`** method of the [CookieStore] interface sets a cookie with the given name and value or options object.\n\n"
    }
  },
  "cookiestoremanager": {
    "docs": "\n\nThe **`CookieStoreManager`** interface of the [Cookie Store API] allows service workers to subscribe to cookie change events. Call [CookieStoreManager.subscribe] on a particular service worker registration to receive change events.\n\nA `CookieStoreManager` has an associated [ServiceWorkerRegistration]. Each service worker registration has a cookie change subscription list, which is a list of cookie change subscriptions each containing a name and URL. The methods in this interface allow the service worker to add and remove subscriptions from this list, and to get a list of all subscriptions.\n\nTo get a `CookieStoreManager`, call [ServiceWorkerRegistration.cookies].\n\n",
    "properties": {
      "getsubscriptions": "\n\nThe **`getSubscriptions()`** method of the [CookieStoreManager] interface returns a list of all the cookie change subscriptions for this [ServiceWorkerRegistration].\n\n",
      "subscribe": "\n\nThe **`subscribe()`** method of the [CookieStoreManager] interface subscribes a [ServiceWorkerRegistration] to cookie change events.\n\n",
      "unsubscribe": "\n\nThe **`unsubscribe()`** method of the [CookieStoreManager] interface stops the [ServiceWorkerRegistration] from receiving previously subscribed events.\n\n"
    }
  },
  "countqueuingstrategy": {
    "docs": "\n\nThe **`CountQueuingStrategy`** interface of the [Streams API](/en-US/docs/Web/API/Streams_API) provides a built-in chunk counting queuing strategy that can be used when constructing streams.",
    "properties": {
      "highwatermark": "\n\nThe read-only **`CountQueuingStrategy.highWaterMark`** property returns the total number of chunks that can be contained in the internal queue before backpressure is applied.",
      "size": "\n\nThe **`size()`** method of the\n[CountQueuingStrategy] interface always returns `1`, so that the\ntotal queue size is a count of the number of chunks in the queue."
    }
  },
  "credential": {
    "docs": "\n\nThe **`Credential`** interface of the [Credential Management API](/en-US/docs/Web/API/Credential_Management_API) provides information about an entity (usually a user) normally as a prerequisite to a trust decision.\n\n`Credential` objects may be of four different types:\n\n- [FederatedCredential]\n- [IdentityCredential]\n- [PasswordCredential]\n- [PublicKeyCredential]",
    "properties": {
      "id": "\n\nThe **`id`** property of the\n[Credential] interface returns a string containing the\ncredential's identifier. This might be any one of a GUID, username, or email\naddress.",
      "type": "\n\nThe **`type`** property of the\n[Credential] interface returns a string containing the\ncredential's type. Valid values are `password`, `federated` and\n`public-key`."
    }
  },
  "credentialscontainer": {
    "docs": "\n\nThe **`CredentialsContainer`** interface of the [Credential Management API](/en-US/docs/Web/API/Credential_Management_API) exposes methods to request credentials and notify the user agent when events such as successful sign in or sign out happen. This interface is accessible from [Navigator.credentials].",
    "properties": {
      "create": "\n\nThe **`create()`** method of the [CredentialsContainer] interface returns a `Promise` that resolves with a new credential instance based on the provided options, the information from which can then be stored and later used to authenticate users via [CredentialsContainer.get].\n\nThis is used by multiple different credential-related APIs with significantly different purposes:\n\n- The [Credential Management API](/en-US/docs/Web/API/Credential_Management_API) uses `create()` to create basic federated credentials or username/password credentials.\n- The [Web Authentication API](/en-US/docs/Web/API/Web_Authentication_API) uses `create()` to create public key credentials (based on asymmetric cryptography).\n\nThe below reference page starts with a syntax section that explains the general method call structure and parameters that apply to all the different APIs. After that, it is split into separate sections providing parameters, return values, and examples specific to each API.\n\n> **Note:** This method is restricted to top-level  (i.e., a document running directly inside a browser tab, and not embedded inside another document). Calls to it from within an `<iframe>` element will resolve without effect.",
      "get": "\n\nThe **`get()`** method of the [CredentialsContainer] interface returns a `Promise` that fulfills with a single credential instance that matches the provided parameters, which the browser can then use to authenticate with a relying party. This is used by several different credential-related APIs with significantly different purposes:\n\n- The [Credential Management API](/en-US/docs/Web/API/Credential_Management_API) uses `get()` to authenticate using basic federated credentials or username/password credentials.\n- The [Web Authentication API](/en-US/docs/Web/API/Web_Authentication_API) uses `get()` to authenticate or provide additional factors during MFA with public key credentials (based on asymmetric cryptography).\n- The [Federated Credential Management (FedCM) API](/en-US/docs/Web/API/FedCM_API) uses `get()` to authenticate with federated identity providers (IdPs).\n- The [WebOTP API](/en-US/docs/Web/API/WebOTP_API) uses `get()` to request retrieval of a one-time password (OTP) from a specially-formatted SMS message sent by an app server.\n\nThe below reference page starts with a syntax section that explains the general method call structure and parameters that apply to all the different APIs. After that, it is split into separate sections providing parameters, return values, and examples specific to each API.",
      "preventsilentaccess": "\n\nThe **`preventSilentAccess()`** method\nof the [CredentialsContainer] interface sets a flag that specifies\nwhether automatic log in is allowed for future visits to the current origin, then\nreturns an empty [`Promise`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise). For\nexample, you might call this, after a user signs out of a website to ensure that\nthey aren't automatically signed in on the next site visit. Mediation varies by origin,\nand is an added check point of browser stored credentials, informing a user of an\naccount login status. This method is typically called after a user signs out of a\nwebsite, ensuring this user's login information is not automatically passed on the next\nsite visit.\n\nEarlier versions of the spec called this method `requireUserMediation()`.\nThe [Browser compatibility](/en-US/docs/Web/API/CredentialsContainer#browser_compatibility) section has support details.",
      "store": "\n\nThe **`store()`** method of the\n[CredentialsContainer] stores a set of credentials for the user inside a\n[Credential] instance, returning this in a `Promise`.\n\n> **Note:** This method is restricted to top-level contexts. Calls to it within an\n> `<iframe>` element will resolve without effect."
    }
  },
  "crypto": {
    "docs": "\n\nThe **`Crypto`** interface represents basic cryptography features available in the current context.\nIt allows access to a cryptographically strong random number generator and to cryptographic primitives.\n\nThe [Web Crypto API](/en-US/docs/Web/API/Web_Crypto_API) is accessed through the global [crypto_property] property, which is a `Crypto` object.",
    "properties": {
      "getrandomvalues": "\n\nThe **`Crypto.getRandomValues()`** method lets you get cryptographically strong random values.\nThe array given as the parameter is filled with random numbers (random in its cryptographic meaning).\n\nTo guarantee enough performance, implementations are not using a truly random number generator, but they are using a pseudo-random number generator _seeded_ with a value with enough entropy.\nThe pseudo-random number generator algorithm (PRNG) may vary across , but is suitable for cryptographic purposes.\n\n`getRandomValues()` is the only member of the `Crypto` interface which can be used from an insecure context.",
      "randomuuid": "\n\nThe **`randomUUID()`** method of the [Crypto] interface is used to generate a v4  using a cryptographically secure random number generator.",
      "subtle": "\n\nThe **`Crypto.subtle`** read-only property returns a\n[SubtleCrypto] which can then be used to perform low-level\ncryptographic operations."
    }
  },
  "cryptokey": {
    "docs": "\n\nThe **`CryptoKey`** interface of the [Web Crypto API](/en-US/docs/Web/API/Web_Crypto_API) represents a cryptographic  obtained from one of the [SubtleCrypto] methods [SubtleCrypto.generateKey], [SubtleCrypto.deriveKey], [SubtleCrypto.importKey], or [SubtleCrypto.unwrapKey].\n\nFor security reasons, the `CryptoKey` interface can only be used in a [secure context](/en-US/docs/Web/Security/Secure_Contexts).",
    "properties": {
      "algorithm": "\n\nThe read-only **`algorithm`** property of the [CryptoKey] interface returns an object describing the algorithm for which this key can be used, and any associated extra parameters.\n\nThe object returned depends of the algorithm used to generate the key.",
      "extractable": "\n\nThe read-only **`extractable`** property of the [CryptoKey] interface indicates whether or not the key may be extracted using [`SubtleCrypto.exportKey()`](/en-US/docs/Web/API/SubtleCrypto/exportKey) or [`SubtleCrypto.wrapKey()`](/en-US/docs/Web/API/SubtleCrypto/wrapKey).\n\nIf the key cannot be exported, [`exportKey()`](/en-US/docs/Web/API/SubtleCrypto/exportKey) or [`wrapKey()`](/en-US/docs/Web/API/SubtleCrypto/wrapKey) will throw an exception if used to extract it.",
      "type": "\n\nThe read-only **`type`** property of the [CryptoKey] interface indicates which kind of key is represented by the object. It can have the following values:\n\n- `\"secret\"`: This key is a secret key for use with a .\n- `\"private\"`: This key is the private half of an  [`CryptoKeyPair`](/en-US/docs/Web/API/CryptoKeyPair).\n- `\"public\"`: This key is the public half of an  [`CryptoKeyPair`](/en-US/docs/Web/API/CryptoKeyPair).",
      "usages": "\n\nThe read-only **`usages`** property of the [CryptoKey] interface indicates what can be done with the key."
    }
  },
  "cryptokeypair": {
    "docs": "\n\nThe **`CryptoKeyPair`** dictionary of the [Web Crypto API](/en-US/docs/Web/API/Web_Crypto_API) represents a key pair for an asymmetric cryptography algorithm, also known as a public-key algorithm.\n\nA `CryptoKeyPair` object can be obtained using [SubtleCrypto.generateKey], when the selected algorithm is one of the asymmetric algorithms: RSASSA-PKCS1-v1_5, RSA-PSS, RSA-OAEP, ECDSA, or ECDH.\n\nIt contains two properties, which are both [`CryptoKey`](/en-US/docs/Web/API/CryptoKey) objects: a `privateKey` property containing the private key and a `publicKey` property containing the public key."
  },
  "cspviolationreportbody": {
    "docs": "\n\nThe `CSPViolationReportBody` interface contains the report data for a Content Security Policy (CSP) violation. CSP violations are thrown when the webpage attempts to load a resource that violates the CSP set by the  HTTP header.\n\n> **Note:** this interface is similar, but not identical to, the [JSON objects](/en-US/docs/Web/HTTP/CSP#violation_report_syntax) sent back to the [`report-uri`](/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/report-uri) or [`report-to`](/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/report-to) policy directive of the  header.\n\n"
  },
  "css": {
    "docs": "\n\nThe **`CSS`** interface holds useful CSS-related methods. No objects with this interface are implemented: it contains only static methods and is therefore a utilitarian interface.",
    "properties": {
      "escape_static": "\n\nThe **`CSS.escape()`** static method returns a\nstring containing the escaped string passed as parameter, mostly for\nuse as part of a CSS selector.",
      "factory_functions_static": "\n\nThe **CSS numeric factory\nfunctions**, such as `CSS.em()` and\n`CSS.turn()` are methods that return [CSSUnitValues](/en-US/docs/Web/API/CSSUnitValue) with the value being\nthe numeric argument and the unit being the name of the method used. These\nfunctions create new numeric values less verbosely than using the\n[CSSUnitValue.CSSUnitValue] constructor.",
      "highlights_static": "\n\nThe static, read-only **`highlights`** property of the [CSS] interface provides access to the `HighlightRegistry` used to style arbitrary text ranges using the [css_custom_highlight_api].",
      "paintworklet_static": "\n\nThe static, read-only **`paintWorklet`** property of the [CSS] interface provides access to the\npaint [worklet](/en-US/docs/Web/API/Worklet), which programmatically generates an image where a CSS\nproperty expects a file.",
      "registerproperty_static": "\n\nThe **`CSS.registerProperty()`** static method registers\n, allowing for property type checking, default\nvalues, and properties that do or do not inherit their value.\n\nRegistering a custom property allows you to tell the browser how the custom property\nshould behave; what types are allowed, whether the custom property inherits its value,\nand what the default value of the custom property is.",
      "supports_static": "\n\nThe **`CSS.supports()`** static method returns a boolean value\nindicating if the browser supports a given CSS feature, or not."
    }
  },
  "cssanimation": {
    "docs": "\n\nThe **`CSSAnimation`** interface of the [Web Animations API] represents an [Animation] object.\n\n",
    "properties": {
      "animationname": "\n\nThe **`animationName`** property of the\n[CSSAnimation] interface returns the . This\nspecifies one or more keyframe at-rules which describe the animation applied to the\nelement."
    }
  },
  "cssconditionrule": {
    "docs": "\n\nAn object implementing the **`CSSConditionRule`** interface represents a single condition CSS [at-rule](/en-US/docs/Web/CSS/At-rule), which consists of a condition and a statement block.\n\nThree objects derive from `CSSConditionRule`: [CSSMediaRule], [CSSContainerRule] and [CSSSupportsRule].\n\n",
    "properties": {
      "conditiontext": "\n\nThe **`conditionText`** property of\nthe [CSSConditionRule] interface returns or sets the text of the CSS\nrule."
    }
  },
  "csscontainerrule": {
    "docs": "\n\nThe **`CSSContainerRule`** interface represents a single CSS  rule.\n\nAn object of this type can be used to get the query conditions for the , along with the container name if one is defined.\nNote that the container name and query together define the \"condition text\", which can be obtained using [CSSConditionRule.conditionText].\n\n",
    "properties": {
      "containername": "\n\nThe read-only **`containerName`** property of the [CSSContainerRule] interface represents the container name of the associated CSS  at-rule.\n\nFor example, the value of `containerName` for the  below is `sidebar`:\n\n```css\n@container sidebar (min-width: 700px) {\n  .card {\n    font-size: 2em;\n  }\n}\n```",
      "containerquery": "\n\nThe read-only **`containerQuery`** property of the [CSSContainerRule] interface returns a string representing the container conditions that are evaluated when the container changes size in order to determine if the styles in the associated  are applied.\n\nFor example, the value of `containerQuery` for the  below is `(min-width: 700px)`:\n\n```css\n@container sidebar (min-width: 700px) {\n  .card {\n    font-size: 2em;\n  }\n}\n```"
    }
  },
  "csscounterstylerule": {
    "docs": "\n\nThe **`CSSCounterStyleRule`** interface represents an  [at-rule](/en-US/docs/Web/CSS/At-rule).\n\n",
    "properties": {
      "additivesymbols": "`CSS Counter Styles`\n\nThe **`additiveSymbols`** property of the [CSSCounterStyleRule] interface gets and sets the value of the  descriptor. If the descriptor does not have a value set, this attribute returns an empty string.",
      "fallback": "`CSS Counter Styles`\n\nThe **`fallback`** property of the [CSSCounterStyleRule] interface gets and sets the value of the  descriptor. If the descriptor does not have a value set, this attribute returns an empty string.",
      "name": "`CSS Counter Styles`\n\nThe **`name`** property of the [CSSCounterStyleRule] interface gets and sets the  defined as the `name` for the associated rule.",
      "negative": "`CSS Counter Styles`\n\nThe **`negative`** property of the [CSSCounterStyleRule] interface gets and sets the value of the  descriptor. If the descriptor does not have a value set, this attribute returns an empty string.",
      "pad": "`CSS Counter Styles`\n\nThe **`pad`** property of the [CSSCounterStyleRule] interface gets and sets the value of the  descriptor. If the descriptor does not have a value set, this attribute returns an empty string.",
      "prefix": "`CSS Counter Styles`\n\nThe **`prefix`** property of the [CSSCounterStyleRule] interface gets and sets the value of the  descriptor. If the descriptor does not have a value set, this attribute returns an empty string.",
      "range": "`CSS Counter Styles`\n\nThe **`range`** property of the [CSSCounterStyleRule] interface gets and sets the value of the  descriptor. If the descriptor does not have a value set, this attribute returns an empty string.",
      "speakas": "`CSS Counter Styles`\n\nThe **`speakAs`** property of the [CSSCounterStyleRule] interface gets and sets the value of the  descriptor. If the descriptor does not have a value set, this attribute returns an empty string.",
      "suffix": "`CSS Counter Styles`\n\nThe **`suffix`** property of the [CSSCounterStyleRule] interface gets and sets the value of the  descriptor. If the descriptor does not have a value set, this attribute returns an empty string.",
      "symbols": "`CSS Counter Styles`\n\nThe **`symbols`** property of the [CSSCounterStyleRule] interface gets and sets the value of the  descriptor. If the descriptor does not have a value set, this attribute returns an empty string.",
      "system": "`CSS Counter Styles`\n\nThe **`system`** property of the [CSSCounterStyleRule] interface gets and sets the value of the  descriptor. If the descriptor does not have a value set, this attribute returns an empty string."
    }
  },
  "cssfontfacerule": {
    "docs": "\n\nThe **`CSSFontFaceRule`** interface represents an  [at-rule](/en-US/docs/Web/CSS/At-rule).\n\n",
    "properties": {
      "style": "\n\nThe read-only **`style`** property of the [CSSFontFaceRule] interface returns the style information from the  [at-rule](/en-US/docs/Web/CSS/At-rule). This will be in the form of a [CSSStyleDeclaration] object."
    }
  },
  "cssfontfeaturevaluesrule": {
    "docs": "\n\nThe **`CSSFontFeatureValuesRule`** interface represents an  [at-rule](/en-US/docs/Web/CSS/At-rule), letting developers assign for each font face a common name to specify features indices to be used in .\n\n",
    "properties": {
      "fontfamily": "\n\nThe **`fontFamily`** property of the [CSSConditionRule] interface represents the name of the font family it applies to."
    }
  },
  "cssfontpalettevaluesrule": {
    "docs": "\n\nThe **`CSSFontPaletteValuesRule`** interface represents an  [at-rule](/en-US/docs/Web/CSS/At-rule).\n\n",
    "properties": {
      "basepalette": "\n\nThe read-only **`basePalette`** property of the [CSSFontPaletteValuesRule] interface indicates the base palette associated with the rule.",
      "fontfamily": "\n\nThe read-only **`fontFamily`** property of the [CSSFontPaletteValuesRule] interface lists the font families the rule can be applied to. The font families must be _named_ families; _generic_ families like `courier` are not valid.",
      "name": "\n\nThe read-only **`name`** property of the [CSSFontPaletteValuesRule] interface represents the name identifying the associated  at-rule. A valid name always starts with two dashes, such as `--Alternate`.",
      "overridecolors": "\n\nThe read-only **`overrideColors`** property of the [CSSFontPaletteValuesRule] interface is a string containing a list of color index and color pair that are to be used instead. It is specified in the same format as the corresponding  descriptor."
    }
  },
  "cssgroupingrule": {
    "docs": "\n\nThe **`CSSGroupingRule`** interface of the [CSS Object Model](/en-US/docs/Web/API/CSS_Object_Model) represents any CSS [at-rule](/en-US/docs/Web/CSS/At-rule) that contains other rules nested within it.\n\n",
    "properties": {
      "cssrules": "\n\nThe **`cssRules`** property of the\n[CSSGroupingRule] interface returns a [CSSRuleList] containing\na collection of [CSSRule] objects.",
      "deleterule": "\n\nThe **`deleteRule()`** method of the\n[CSSGroupingRule] interface removes a CSS rule from a list of child CSS\nrules.",
      "insertrule": "\n\nThe **`insertRule()`** method of the\n[CSSGroupingRule] interface adds a new CSS rule to a list of CSS rules."
    }
  },
  "cssimagevalue": {
    "docs": "\n\nThe **`CSSImageValue`** interface of the [CSS Typed Object Model API](/en-US/docs/Web/API/CSS_Object_Model#css_typed_object_model) represents values for properties that take an image, for example , , or .\n\nThe CSSImageValue object represents an [`<image>`](/en-US/docs/Web/CSS/image) that involves a URL, such as [`url()`](/en-US/docs/Web/CSS/url) or [`image()`](/en-US/docs/Web/CSS/image), but not [`linear-gradient()`](/en-US/docs/Web/CSS/gradient/linear-gradient) or [`element()`](/en-US/docs/Web/CSS/element).\n\n"
  },
  "cssimportrule": {
    "docs": "\n\nThe **`CSSImportRule`** interface represents an  [at-rule](/en-US/docs/Web/CSS/At-rule).\n\n",
    "properties": {
      "href": "\n\nThe read-only **`href`** property of the\n[CSSImportRule] interface returns the URL specified by the\n [at-rule](/en-US/docs/Web/CSS/At-rule).\n\nThe resolved URL will be the [`href`](/en-US/docs/Web/HTML/Element/link#href) attribute of the\nassociated stylesheet.",
      "layername": "\n\nThe read-only **`layerName`** property of the [CSSImportRule] interface returns the name of the cascade layer created by the  [at-rule](/en-US/docs/Web/CSS/At-rule).\n\nIf the created layer is anonymous, the string is empty (`\"\"`), if no layer has been\ncreated, it is the `null` object.",
      "media": "\n\nThe read-only **`media`** property of the\n[CSSImportRule] interface returns a [MediaList] object,\ncontaining the value of the `media` attribute of the associated stylesheet.",
      "stylesheet": "\n\nThe read-only **`styleSheet`** property of the\n[CSSImportRule] interface returns the CSS Stylesheet specified by the\n [at-rule](/en-US/docs/Web/CSS/At-rule). This will be\nin the form of a [CSSStyleSheet] object.\n\nAn  [at-rule](/en-US/docs/Web/CSS/At-rule) always has\nan associated stylesheet.",
      "supportstext": "\n\nThe read-only **`supportsText`** property of the [CSSImportRule] interface returns the supports condition specified by the  [at-rule](/en-US/docs/Web/CSS/At-rule)."
    }
  },
  "csskeyframerule": {
    "docs": "\n\nThe **`CSSKeyframeRule`** interface describes an object representing a set of styles for a given keyframe. It corresponds to the contents of a single keyframe of a  [at-rule](/en-US/docs/Web/CSS/At-rule).\n\n",
    "properties": {
      "keytext": "\n\nThe **`keyText`** property of the [CSSKeyframeRule] interface represents the keyframe selector as a comma-separated list of percentage values. The from and to keywords map to 0% and 100%, respectively.",
      "style": "\n\nThe read-only **`CSSKeyframeRule.style`** property is the [CSSStyleDeclaration] interface for the [declaration block](https://www.w3.org/TR/1998/REC-CSS2-19980512/syndata.html#block) of the [CSSKeyframeRule]."
    }
  },
  "csskeyframesrule": {
    "docs": "\n\nThe **`CSSKeyframesRule`** interface describes an object representing a complete set of keyframes for a CSS animation. It corresponds to the contents of a whole  [at-rule](/en-US/docs/Web/CSS/At-rule).\n\n",
    "properties": {
      "appendrule": "\n\nThe **`appendRule()`** method of the [CSSKeyframeRule] interface appends a [CSSKeyFrameRule] to the end of the rules.",
      "cssrules": "\n\nThe read-only **`cssRules`** property of the [CSSKeyframeRule] interface returns a [CSSRuleList] containing the rules in the keyframes [at-rule](/en-US/docs/Web/CSS/At-rule).",
      "deleterule": "\n\nThe **`deleteRule()`** method of the [CSSKeyframeRule] interface deletes the [CSSKeyFrameRule] that matches the specified keyframe selector.",
      "findrule": "\n\nThe **`findRule()`** method of the [CSSKeyframeRule] interface finds the [CSSKeyFrameRule] that matches the specified keyframe selector.",
      "name": "\n\nThe **`name`** property of the [CSSKeyframeRule] interface gets and sets the name of the animation as used by the  property."
    }
  },
  "csskeywordvalue": {
    "docs": "\n\nThe **`CSSKeywordValue`** interface of the [CSS Typed Object Model API](/en-US/docs/Web/API/CSS_Object_Model#css_typed_object_model) creates an object to represent CSS keywords and other identifiers.\n\nThe interface instance name is a  meaning that when used anywhere a string is expected it will return the value of `CSSKeyword.value`.\n\n",
    "properties": {
      "value": "\n\nThe **`value`** property of the\n[CSSKeywordValue] interface returns or sets the value of the\n`CSSKeywordValue`."
    }
  },
  "csslayerblockrule": {
    "docs": "\n\nThe **`CSSLayerBlockRule`** represents a  block rule. It is a grouping at-rule meaning that it can contain other rules, and is associated to a given cascade layer, identified by its _name_.\n\n",
    "properties": {
      "name": "\n\nThe read-only **`name`** property of the [CSSLayerBlockRule] interface represents the name of the associated cascade layer."
    }
  },
  "csslayerstatementrule": {
    "docs": "\n\nThe **`CSSLayerStatementRule`** represents a  statement rule. Unlike [CSSLayerBlockRule], it doesn't contain other rules and merely defines one or several layers by providing their names.\n\nThis rule allows to explicitly declare the ordering layer that is in an apparent way at the beginning of a CSS file: the layer order is defined by the order of first occurrence of each layer name. Declaring them with a statement allows the reader to understand the layer order. It also allows inline and imported layers to be interleaved, which is not possible when using the `CSSLayerBlockRule` syntax.\n\n",
    "properties": {
      "namelist": "\n\nThe read-only **`nameList`** property of the [CSSLayerStatementRule] interface return the list of associated cascade layer names. The names can't be modified."
    }
  },
  "cssmathinvert": {
    "docs": "\n\nThe **`CSSMathInvert`** interface of the  represents a CSS `calc()` used as `calc(1 / <value>).` It inherits properties and methods from its parent [CSSNumericValue].\n\n",
    "properties": {
      "value": "\n\nThe CSSMathInvert.value read-only property of the\n[CSSMathInvert] interface returns a [CSSNumericValue] object."
    }
  },
  "cssmathmax": {
    "docs": "\n\nThe **`CSSMathMax`** interface of the  represents the CSS `max()` function. It inherits properties and methods from its parent [CSSNumericValue].\n\n",
    "properties": {
      "values": "\n\nThe CSSMathMax.values read-only property of the\n[CSSMathMax] interface returns a [CSSNumericArray] object\nwhich contains one or more [CSSNumericValue] objects."
    }
  },
  "cssmathmin": {
    "docs": "\n\nThe **`CSSMathMin`** interface of the  represents the CSS `min()` function. It inherits properties and methods from its parent [CSSNumericValue].\n\n",
    "properties": {
      "values": "\n\nThe CSSMathMin.values read-only property of the\n[CSSMathMin] interface returns a [CSSNumericArray] object\nwhich contains one or more [CSSNumericValue] objects."
    }
  },
  "cssmathnegate": {
    "docs": "\n\nThe **`CSSMathNegate`** interface of the  negates the value passed into it. It inherits properties and methods from its parent [CSSNumericValue].\n\n",
    "properties": {
      "value": "\n\nThe CSSMathNegate.value read-only property of the\n[CSSMathNegate] interface returns a [CSSNumericValue] object."
    }
  },
  "cssmathproduct": {
    "docs": "\n\nThe **`CSSMathProduct`** interface of the  represents the result obtained by calling [CSSNumericValue.add], [CSSNumericValue.sub], or [CSSNumericValue.toSum] on [CSSNumericValue]. It inherits properties and methods from its parent [CSSNumericValue].\n\n",
    "properties": {
      "values": "\n\nThe **`CSSMathProduct.values`** read-only\nproperty of the [CSSMathProduct] interface returns a\n[CSSNumericArray] object which contains one or more\n[CSSNumericValue] objects."
    }
  },
  "cssmathsum": {
    "docs": "\n\nThe **`CSSMathSum`** interface of the  represents the result obtained by calling [CSSNumericValue.add], [CSSNumericValue.sub], or [CSSNumericValue.toSum] on [CSSNumericValue].\n\nA CSSMathSum is the object type returned when the [`StylePropertyMapReadOnly.get()`](/en-US/docs/Web/API/StylePropertyMapReadOnly/get) method is used on a CSS property whose value is created with a [`calc()`](/en-US/docs/Web/CSS/calc) function.\n\n",
    "properties": {
      "values": "\n\nThe **`CSSMathSum.values`** read-only property\nof the [CSSMathSum] interface returns a [CSSNumericArray]\nobject which contains one or more [CSSNumericValue] objects."
    }
  },
  "cssmathvalue": {
    "docs": "\n\nThe **`CSSMathValue`** interface of the  a base class for classes representing complex numeric values.\n\n",
    "properties": {
      "operator": "\n\nThe **`CSSMathValue.operator`** read-only\nproperty of the [CSSMathValue] interface indicates the operator that the\ncurrent subtype represents. For example, if the current `CSSMathValue`\nsubtype is `CSSMathSum`, this property will return the string\n`\"sum\"`."
    }
  },
  "cssmatrixcomponent": {
    "docs": "\n\nThe **`CSSMatrixComponent`** interface of the  represents the [matrix()](/en-US/docs/Web/CSS/transform-function/matrix) and [matrix3d()](/en-US/docs/Web/CSS/transform-function/matrix3d) values of the individual `transform` property in CSS. It inherits properties and methods from its parent [CSSTransformValue].\n\n",
    "properties": {
      "matrix": "\n\nThe **`matrix`** property of the\n[CSSMatrixComponent] interface gets and sets a 2d or 3d matrix.\n\nSee the [matrix()](/en-US/docs/Web/CSS/transform-function/matrix) and [matrix3d()](/en-US/docs/Web/CSS/transform-function/matrix3d) pages for\nexamples."
    }
  },
  "cssmediarule": {
    "docs": "\n\nThe **`CSSMediaRule`** interface represents a single CSS  rule.\n\n",
    "properties": {
      "media": "\n\nThe read-only **`media`** property of the\n[CSSMediaRule] interface [MediaList] represents the intended\ndestination medium for style information."
    }
  },
  "cssnamespacerule": {
    "docs": "\n\nThe **`CSSNamespaceRule`** interface describes an object representing a single CSS  [at-rule](/en-US/docs/Web/CSS/At-rule).\n\n",
    "properties": {
      "namespaceuri": "\n\nThe read-only **`namespaceURI`** property of the [CSSNamespaceRule] returns a string containing the text of the URI of the given namespace.",
      "prefix": "\n\nThe read-only **`prefix`** property of the [CSSNamespaceRule] returns a string with the name of the prefix associated to this namespace. If there is no such prefix, it returns an empty string."
    }
  },
  "cssnumericarray": {
    "docs": "\n\nThe **`CSSNumericArray`** interface of the  contains a list of [CSSNumericValue] objects.",
    "properties": {
      "length": "\n\nThe read-only **`length`** property of the\n[CSSNumericArray] interface returns the number of\n[CSSNumericValue] objects in the list."
    }
  },
  "cssnumericvalue": {
    "docs": "\n\nThe **`CSSNumericValue`** interface of the [CSS Typed Object Model API](/en-US/docs/Web/API/CSS_Object_Model#css_typed_object_model) represents operations that all numeric values can perform.\n\n",
    "properties": {
      "add": "\n\nThe **`add()`** method of the\n[CSSNumericValue] interface adds a supplied number to the\n`CSSNumericValue`.",
      "div": "\n\nThe **`div()`** method of the\n[CSSNumericValue] interface divides the `CSSNumericValue` by the\nsupplied value.",
      "equals": "\n\nThe **`equals()`** method of the\n[CSSNumericValue] interface returns a boolean indicating whether the passed\nvalue are strictly equal. To return a value of `true`, all passed values must\nbe of the same type and value and must be in the same order. This allows structural\nequality to be tested quickly.",
      "max": "\n\nThe **`max()`** method of the\n[CSSNumericValue] interface returns the highest value from among the values\npassed. The passed values must be of the same type.",
      "min": "\n\nThe **`min()`** method of the\n[CSSNumericValue] interface returns the lowest value from among those\nvalues passed. The passed values must be of the same type.",
      "mul": "\n\nThe **`mul()`** method of the\n[CSSNumericValue] interface multiplies the `CSSNumericValue` by\nthe supplied value.",
      "parse_static": "\n\nThe **`parse()`** static method of the\n[CSSNumericValue] interface converts a value string into an object whose\nmembers are value and the units.",
      "sub": "\n\nThe **`sub()`** method of the\n[CSSNumericValue] interface subtracts a supplied number from the\n`CSSNumericValue`.",
      "to": "\n\nThe **`to()`** method of the\n[CSSNumericValue] interface converts a numeric value from one unit to\nanother.",
      "tosum": "\n\nThe **`toSum()`** method of the\n[CSSNumericValue] interface converts the object's value to a\n[CSSMathSum] object to values of the specified unit.",
      "type": "\n\nThe **`type()`** method of the\n[CSSNumericValue] interface returns the type of\n`CSSNumericValue`, one of `angle`, `flex`,\n`frequency`, `length`, `resolution`,\n`percent`, `percentHint`, or `time`."
    }
  },
  "csspagerule": {
    "docs": "\n\n**`CSSPageRule`** represents a single CSS  rule.\n\n",
    "properties": {
      "selectortext": "\n\nThe **`selectorText`** property of the [CSSPageRule] interface gets and sets the selectors associated with the `CSSPageRule`.",
      "style": "\n\nThe **`style`** read-only property of the [CSSPageRule] interface returns a [CSSStyleDeclaration] object. This represents an object that is a [CSS declaration block](/en-US/docs/Web/API/CSS_Object_Model/CSS_Declaration_Block), and exposes style information and various style-related methods and properties."
    }
  },
  "cssperspective": {
    "docs": "\n\nThe **`CSSPerspective`** interface of the  represents the [perspective()](/en-US/docs/Web/CSS/transform-function/perspective) value of the individual `transform` property in CSS. It inherits properties and methods from its parent [CSSTransformValue].\n\n",
    "properties": {
      "length": "\n\nThe **`length`** property of the\n[CSSPerspective] interface sets the distance from z=0.\n\nIt is used to apply a perspective transform to the element and its content. If the\nvalue is 0 or a negative number, no perspective transform is applied."
    }
  },
  "csspositionvalue": {
    "docs": "\n\nThe **`CSSPositionValue`** interface of the [CSS Typed Object Model API](/en-US/docs/Web/API/CSS_Object_Model#css_typed_object_model) represents values for properties that take a position, for example .",
    "properties": {
      "x": "\n\nThe **`x`** property of the\n[CSSPositionValue] interface returns the item's position along the web\npage's horizontal axis.",
      "y": "\n\nThe **`y`** property of the\n[CSSPositionValue] interface returns the item's position along the\nvertical axis."
    }
  },
  "cssprimitivevalue": {
    "docs": "\n\nThe **`CSSPrimitiveValue`** interface derives from the [CSSValue] interface and represents the current computed value of a CSS property.\n\n> **Note:** This interface was part of an attempt to create a typed CSS Object Model. This attempt has been abandoned, and most browsers do\n> not implement it.\n>\n> To achieve your purpose, you can use:\n>\n> - the untyped [CSS Object Model](/en-US/docs/Web/API/CSS_Object_Model), widely supported, or\n> - the modern [CSS Typed Object Model API](/en-US/docs/Web/API/CSS_Typed_OM_API), less supported and considered experimental.\n\nThis interface represents a single CSS value. It may be used to determine the value of a specific style property currently set in a block or to set a specific style property explicitly within the block. An instance of this interface might be obtained from the [CSSStyleDeclaration.getPropertyCSSValue] method of the [CSSStyleDeclaration] interface. A `CSSPrimitiveValue` object only occurs in a context of a CSS property.\n\nConversions are allowed between absolute values (from millimeters to centimeters, from degrees to radians, and so on) but not between relative values. (For example, a pixel value cannot be converted to a centimeter value.) Percentage values can't be converted since they are relative to the parent value (or another property value). There is one exception for color percentage values: since a color percentage value is relative to the range 0-255, a color percentage value can be converted to a number (see also the [RGBColor] interface).\n\n",
    "properties": {
      "getcountervalue": "\n\nThe **`getCounterValue()`** method of the\n[CSSPrimitiveValue] interface is used to get the [counter](/en-US/docs/Web/CSS/CSS_counter_styles/Using_CSS_counters)\nvalue. If this CSS value doesn't contain a counter value, a [DOMException]\nis raised. Modification to the corresponding style property can be achieved using the\n[Counter] interface.\n\n> **Note:** This method was part of an attempt to create a typed CSS Object Model. This attempt has been abandoned, and most browsers do\n> not implement it.\n>\n> To achieve your purpose, you can use:\n>\n> - the untyped [CSS Object Model](/en-US/docs/Web/API/CSS_Object_Model), widely supported, or\n> - the modern [CSS Typed Object Model API](/en-US/docs/Web/API/CSS_Typed_OM_API), less supported and considered experimental.",
      "getfloatvalue": "\n\nThe **`getFloatValue()`** method of the\n[CSSPrimitiveValue] interface is used to get a float value in a specified\nunit. If this CSS value doesn't contain a float value or can't be converted into the\nspecified unit, a [DOMException] is raised.\n\n> **Note:** This method was part of an attempt to create a typed CSS Object Model. This attempt has been abandoned, and most browsers do\n> not implement it.\n>\n> To achieve your purpose, you can use:\n>\n> - the untyped [CSS Object Model](/en-US/docs/Web/API/CSS_Object_Model), widely supported, or\n> - the modern [CSS Typed Object Model API](/en-US/docs/Web/API/CSS_Typed_OM_API), less supported and considered experimental.",
      "getrectvalue": "\n\nThe **`getRectValue()`** method of the\n[CSSPrimitiveValue] interface is used to get a rect value. If this CSS\nvalue doesn't contain a rect value, a [DOMException] is raised.\nModification to the corresponding style property can be achieved using the\n[Rect] interface.\n\n> **Note:** This method was part of an attempt to create a typed CSS Object Model. This attempt has been abandoned, and most browsers do\n> not implement it.\n>\n> To achieve your purpose, you can use:\n>\n> - the untyped [CSS Object Model](/en-US/docs/Web/API/CSS_Object_Model), widely supported, or\n> - the modern [CSS Typed Object Model API](/en-US/docs/Web/API/CSS_Typed_OM_API), less supported and considered experimental.",
      "getrgbcolorvalue": "\n\nThe **`getRGBColorValue()`** method of the\n[CSSPrimitiveValue] interface is used to get an RGB color value. If this\nCSS value doesn't contain a RGB color value, a [DOMException] is raised.\nModification to the corresponding style property can be achieved using the\n[RGBColor] interface.\n\n> **Note:** This method was part of an attempt to create a typed CSS Object Model. This attempt has been abandoned, and most browsers do\n> not implement it.\n>\n> To achieve your purpose, you can use:\n>\n> - the untyped [CSS Object Model](/en-US/docs/Web/API/CSS_Object_Model), widely supported, or\n> - the modern [CSS Typed Object Model API](/en-US/docs/Web/API/CSS_Typed_OM_API), less supported and considered experimental.",
      "getstringvalue": "\n\nThe **`getStringValue()`** method of the\n[CSSPrimitiveValue] interface is used to get a string value. If this CSS\nvalue doesn't contain a string value, a [DOMException] is raised.\n\n> **Note:** This method was part of an attempt to create a typed CSS Object Model. This attempt has been abandoned, and most browsers do\n> not implement it.\n>\n> To achieve your purpose, you can use:\n>\n> - the untyped [CSS Object Model](/en-US/docs/Web/API/CSS_Object_Model), widely supported, or\n> - the modern [CSS Typed Object Model API](/en-US/docs/Web/API/CSS_Typed_OM_API), less supported and considered experimental.",
      "primitivetype": "\n\nThe **`primitiveType`** read-only property of the\n[CSSPrimitiveValue] interface represents the type of a CSS value.\n\n> **Note:** This property was part of an attempt to create a typed CSS Object Model. This attempt has been abandoned, and most browsers do\n> not implement it.\n>\n> To achieve your purpose, you can use:\n>\n> - the untyped [CSS Object Model](/en-US/docs/Web/API/CSS_Object_Model), widely supported, or\n> - the modern [CSS Typed Object Model API](/en-US/docs/Web/API/CSS_Typed_OM_API), less supported and considered experimental.",
      "setfloatvalue": "\n\nThe **`setFloatValue()`** method of the\n[CSSPrimitiveValue] interface is used to set a float value. If the property\nattached to this value can't accept the specified unit or the float value, the value\nwill be unchanged and a [DOMException] will be raised.\n\n> **Note:** This method was part of an attempt to create a typed CSS Object Model. This attempt has been abandoned, and most browsers do\n> not implement it.\n>\n> To achieve your purpose, you can use:\n>\n> - the untyped [CSS Object Model](/en-US/docs/Web/API/CSS_Object_Model), widely supported, or\n> - the modern [CSS Typed Object Model API](/en-US/docs/Web/API/CSS_Typed_OM_API), less supported and considered experimental.",
      "setstringvalue": "\n\nThe **`setStringValue()`** method of the\n[CSSPrimitiveValue] interface is used to set a string value. If the\nproperty attached to this value can't accept the specified unit or the string value, the\nvalue will be unchanged and a [DOMException] will be raised.\n\n> **Note:** This method was part of an attempt to create a typed CSS Object Model. This attempt has been abandoned, and most browsers do\n> not implement it.\n>\n> To achieve your purpose, you can use:\n>\n> - the untyped [CSS Object Model](/en-US/docs/Web/API/CSS_Object_Model), widely supported, or\n> - the modern [CSS Typed Object Model API](/en-US/docs/Web/API/CSS_Typed_OM_API), less supported and considered experimental."
    }
  },
  "csspropertyrule": {
    "docs": "\n\nThe **`CSSPropertyRule`** interface of the [CSS Properties and Values API](/en-US/docs/Web/API/CSS_Properties_and_Values_API) represents a single CSS  rule.\n\n",
    "properties": {
      "inherits": "\n\nThe read-only **`inherits`** property of the [CSSPropertyRule] interface returns the inherit flag of the custom property registration represented by the  rule, a boolean describing whether or not the property inherits by default.",
      "initialvalue": "\n\nThe read-only **`initialValue`** nullable property of the [CSSPropertyRule] interface returns the initial value of the custom property registration represented by the  rule, controlling the property's initial value.",
      "name": "\n\nThe read-only **`name`** property of the [CSSPropertyRule] interface represents the property name, this being the serialization of the name given to the custom property in the  rule's prelude.",
      "syntax": "\n\nThe read-only **`syntax`** property of the [CSSPropertyRule] interface returns the literal syntax of the custom property registration represented by the  rule, controlling how the property's value is parsed at computed-value time."
    }
  },
  "csspseudoelement": {
    "docs": "\n\nThe **`CSSPseudoElement`** interface represents a pseudo-element that may be the target of an event or animated using the [Web Animations API]. Instances of this interface may be obtained by calling [Element.pseudo].\n\n",
    "properties": {
      "element": "\n\nThe **`element`** read-only property of the\n[CSSPseudoElement] interface returns a reference to the originating element\nof the pseudo-element, in other words its parent element.",
      "type": "\n\nThe **`type`** read-only property of the\n[CSSPseudoElement] interface returns the type of the pseudo-element as a\nstring, represented in the form of a [CSS selector](/en-US/docs/Web/CSS/CSS_selectors#pseudo-elements)."
    }
  },
  "cssrotate": {
    "docs": "\n\nThe **`CSSRotate`** interface of the  represents the rotate value of the individual `transform` property in CSS. It inherits properties and methods from its parent [CSSTransformValue].\n\n",
    "properties": {
      "angle": "\n\nThe **`angle`** property of the\n[CSSRotate] interface gets and sets the angle of rotation. A positive angle\ndenotes a clockwise rotation, a negative angle a counter-clockwise one.",
      "x": "\n\nThe **`x`** property of the\n[CSSRotate] interface gets and sets the abscissa or x-axis of the\ntranslating vector.",
      "y": "\n\nThe **`y`** property of the\n[CSSRotate] interface gets and sets the ordinate or y-axis of the\ntranslating vector.",
      "z": "\n\nThe **`z`** property of the\n[CSSRotate] interface representing the z-component of the translating\nvector. A positive value moves the element towards the viewer, and a negative value\nfarther away."
    }
  },
  "cssrule": {
    "docs": "\n\nThe **`CSSRule`** interface represents a single CSS rule. There are several types of rules which inherit properties from `CSSRule`.\n\n- [CSSGroupingRule]\n- [CSSStyleRule]\n- [CSSImportRule]\n- [CSSMediaRule]\n- [CSSFontFaceRule]\n- [CSSPageRule]\n- [CSSNamespaceRule]\n- [CSSKeyframesRule]\n- [CSSKeyframeRule]\n- [CSSCounterStyleRule]\n- [CSSSupportsRule]\n- [CSSFontFeatureValuesRule]\n- [CSSFontPaletteValuesRule]\n- [CSSLayerBlockRule]\n- [CSSLayerStatementRule]\n- [CSSPropertyRule]",
    "properties": {
      "csstext": "\n\nThe **`cssText`** property of the [CSSRule]\ninterface returns the actual text of a [CSSStyleSheet] style-rule.\n\n> **Note:** Do not confuse this property with element-style\n> [CSSStyleDeclaration.cssText].\n\nBe aware that this property can no longer be set directly, as it is [now specified](https://www.w3.org/TR/cssom-1/#changes-from-5-december-2013)\nto be _functionally_ modify-only, and silently so. In other words, attempting to\nset it _does absolutely nothing_, and doesn't even omit a warning or error.\nFurthermore, it has no settable sub-properties. Therefore, to modify it, use the\nstylesheet's [CSSRuleList]`[index]` properties\n[CSSStyleRule.selectorText] and\n[CSSStyleRule.style] (or its sub-properties). See [Using dynamic styling information](/en-US/docs/Web/API/CSS_Object_Model/Using_dynamic_styling_information) for details.",
      "parentrule": "\n\nThe **`parentRule`** property of the [CSSRule]\ninterface returns the containing rule of the current rule if this exists, or otherwise\nreturns null.",
      "parentstylesheet": "\n\nThe **`parentStyleSheet`** property of the\n[CSSRule] interface returns the [StyleSheet] object in which\nthe current rule is defined.",
      "type": "\n\nThe read-only **`type`** property of the\n[CSSRule] interface is a deprecated property that returns an integer\nindicating which type of rule the [CSSRule] represents.\n\nIf you need to distinguish different types of CSS rule, a good alternative is to use [`constructor.name`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/name):\n\n```js\nconst sheets = Array.from(document.styleSheets);\nconst rules = sheets.map((sheet) => Array.from(sheet.cssRules)).flat();\n\nfor (const rule of rules) {\n  console.log(rule.constructor.name);\n}\n```"
    }
  },
  "cssrulelist": {
    "docs": "\n\nA `CSSRuleList` represents an ordered collection of read-only [CSSRule] objects.\n\nWhile the `CSSRuleList` object is read-only, and cannot be directly modified, it is considered a `live` object, as the content can change over time.\n\nTo edit the underlying rules returned by `CSSRule` objects, use [CSSStyleSheet.insertRule] and [CSSStyleSheet.deleteRule], which are methods of [CSSStyleSheet].\n\nThe interface has no constructor. An instance of `CSSRuleList` is returned by [CSSStyleSheet.cssRules] and [CSSKeyframesRule.cssRules].\n\n> **Note:** This interface was an [attempt to create an unmodifiable list](https://stackoverflow.com/questions/74630989/why-use-domstringlist-rather-than-an-array/74641156#74641156) and only continues to be supported to not break code that's already using it. Modern APIs use types that wrap around ECMAScript array types instead, so you can treat them like ECMAScript arrays, and at the same time impose additional semantics on their usage (such as making their items read-only).",
    "properties": {
      "item": "\n\nThe **`item()`** method of the [CSSRuleList] interface returns the [CSSRule] object at the specified `index` or `null` if the specified `index` doesn't exist.",
      "length": "\n\nThe **`length`** property of the [CSSRuleList] interface returns the number of [CSSRule] objects in the list."
    }
  },
  "cssscale": {
    "docs": "\n\nThe **`CSSScale`** interface of the  represents the [scale()](/en-US/docs/Web/CSS/transform-function/scale) and [scale3d()](/en-US/docs/Web/CSS/transform-function/scale3d) values of the individual `transform` property in CSS. It inherits properties and methods from its parent [CSSTransformValue].\n\n",
    "properties": {
      "x": "\n\nThe **`x`** property of the\n[CSSScale] interface gets and sets the abscissa or x-axis of the\ntranslating vector.",
      "y": "\n\nThe **`y`** property of the\n[CSSScale] interface gets and sets the ordinate or y-axis of the\ntranslating vector.",
      "z": "\n\nThe **`z`** property of the\n[CSSScale] interface representing the z-component of the translating\nvector. A positive value moves the element towards the viewer, and a negative value\nfarther away.\n\nIf this value is present then the transform is a 3D transform and the `is2D`\nproperty will be set to false."
    }
  },
  "cssscoperule": {
    "docs": "\n\nThe **`CSSScopeRule`** interface of the [CSS Object Model](/en-US/docs/Web/API/CSS_Object_Model) represents a CSS  at-rule.\n\n",
    "properties": {
      "end": "\n\nThe **`end`** property of the [CSSScopeRule] interface returns a string containing the value of the `@scope` at-rule's scope limit.",
      "start": "\n\nThe **`start`** property of the [CSSScopeRule] interface returns a string containing the value of the `@scope` at-rule's scope root."
    }
  },
  "cssskew": {
    "docs": "\n\nThe **`CSSSkew`** interface of the  is part of the [CSSTransformValue] interface. It represents the [`skew()`](/en-US/docs/Web/CSS/transform-function/skew) value of the individual `transform` property in CSS.\n\n",
    "properties": {
      "ax": "\n\nThe **`ax`** property of the\n[CSSSkew] interface gets and sets the angle used to distort the element\nalong the x-axis (or abscissa).",
      "ay": "\n\nThe **`ay`** property of the\n[CSSSkew] interface gets and sets the angle used to distort the element\nalong the y-axis (or ordinate)."
    }
  },
  "cssskewx": {
    "docs": "\n\nThe **`CSSSkewX`** interface of the  represents the [`skewX()`](/en-US/docs/Web/CSS/transform-function/skewX) value of the individual `transform` property in CSS. It inherits properties and methods from its parent [CSSTransformValue].\n\n",
    "properties": {
      "ax": "\n\nThe **`ax`** property of the\n[CSSSkewX] interface gets and sets the angle used to distort the element\nalong the x-axis (or abscissa)."
    }
  },
  "cssskewy": {
    "docs": "\n\nThe **`CSSSkewY`** interface of the  represents the [`skewY()`](/en-US/docs/Web/CSS/transform-function/skewY) value of the individual `transform` property in CSS. It inherits properties and methods from its parent [CSSTransformValue].\n\n",
    "properties": {
      "ay": "\n\nThe **`ay`** property of the\n[CSSSkewY] interface gets and sets the angle used to distort the element\nalong the y-axis (or ordinate)."
    }
  },
  "cssstartingstylerule": {
    "docs": "\n\nThe **`CSSStartingStyleRule`** interface of the [CSS Object Model](/en-US/docs/Web/API/CSS_Object_Model) represents a CSS  at-rule.\n\n"
  },
  "cssstyledeclaration": {
    "docs": "\n\nThe **`CSSStyleDeclaration`** interface represents an object that is a CSS declaration block, and exposes style information and various style-related methods and properties.\n\nA `CSSStyleDeclaration` object can be exposed using three different APIs:\n\n- Via [HTMLElement.style], which deals with the inline styles of a single element (e.g., `<div style=\"…\">`).\n- Via the [CSSStyleSheet] API. For example, `document.styleSheets[0].cssRules[0].style` returns a `CSSStyleDeclaration` object on the first CSS rule in the document's first stylesheet.\n- Via [Window.getComputedStyle], which exposes the `CSSStyleDeclaration` object as a **read-only** interface.",
    "properties": {
      "cssfloat": "\n\nThe **`cssFloat`** property of the [CSSStyleDeclaration] interface returns the result of invoking [CSSStyleDeclaration.getPropertyValue] with `float` as an argument.\n\nWhen setting, it invokes [CSSStyleDeclaration.setProperty] with `float` as the first argument, and the given value as the second argument. The given value must be a valid value for the `float` property.",
      "csstext": "\n\nThe **`cssText`** property of the [CSSStyleDeclaration] interface returns or sets the text of the element's **inline** style declaration only.\n\nTo be able to set a **stylesheet** rule dynamically, see [Using dynamic styling information](/en-US/docs/Web/API/CSS_Object_Model/Using_dynamic_styling_information).\n\nNot to be confused with stylesheet style-rule [CSSRule.cssText].",
      "getpropertycssvalue": " \n\nThe **CSSStyleDeclaration.getPropertyCSSValue()**\nmethod interface returns a [CSSValue] containing the CSS value for a\nproperty. Note that it returns `null` if the property name is a\nshorthand property.\n\n> **Note:** This interface was part of an attempt to create a typed CSS Object Model. This attempt has been abandoned, and most browsers do\n> not implement it.\n>\n> To achieve your purpose, you can use:\n>\n> - [CSSStyleDeclaration.getPropertyValue] of the untyped [CSS Object Model](/en-US/docs/Web/API/CSS_Object_Model), widely supported, or\n> - [Element.computedStyleMap] of the modern [CSS Typed Object Model API](/en-US/docs/Web/API/CSS_Typed_OM_API), less supported and considered experimental.",
      "getpropertypriority": "\n\nThe **CSSStyleDeclaration.getPropertyPriority()** method interface returns\na string that provides all explicitly set priorities on the CSS\nproperty.",
      "getpropertyvalue": "\n\nThe **CSSStyleDeclaration.getPropertyValue()** method interface returns a\nstring containing the value of a specified CSS property.",
      "item": "\n\nThe `CSSStyleDeclaration.item()`\nmethod interface returns a CSS property name from a [CSSStyleDeclaration]\nby index.\n\nThis method doesn't throw exceptions as long as you provide\narguments; the empty string is returned if the index is out of range and a\n`TypeError` is thrown if no argument is provided.",
      "length": "\n\nThe read-only property returns an integer that represents the\nnumber of style declarations in this CSS declaration block.",
      "parentrule": "\n\nThe **CSSStyleDeclaration.parentRule** read-only\nproperty returns a [CSSRule] that is the parent of this style\nblock, e.g. a [CSSStyleRule] representing the style for a CSS\nselector.",
      "removeproperty": "\n\nThe **`CSSStyleDeclaration.removeProperty()`** method interface\nremoves a property from a CSS style declaration object.",
      "setproperty": "\n\nThe\n**`CSSStyleDeclaration.setProperty()`** method interface sets\na new value for a property on a CSS style declaration object."
    }
  },
  "cssstylerule": {
    "docs": "\n\nThe **`CSSStyleRule`** interface represents a single CSS style rule.\n\n",
    "properties": {
      "selectortext": "\n\nThe **`selectorText`** property of the [CSSStyleRule] interface gets and sets the selectors associated with the `CSSStyleRule`.",
      "style": "\n\nThe read-only **`style`** property is the [CSSStyleDeclaration] interface for the [declaration block](https://www.w3.org/TR/1998/REC-CSS2-19980512/syndata.html#block) of the [CSSStyleRule].",
      "stylemap": "\n\nThe **`styleMap`** read-only property of the\n[CSSStyleRule] interface returns a [StylePropertyMap] object\nwhich provides access to the rule's property-value pairs."
    }
  },
  "cssstylesheet": {
    "docs": "\n\nThe **`CSSStyleSheet`** interface represents a single [CSS](/en-US/docs/Web/CSS) stylesheet, and lets you inspect and modify the list of rules contained in the stylesheet. It inherits properties and methods from its parent, [StyleSheet].\n\nA stylesheet consists of a collection of [CSSRule] objects representing each of the rules in the stylesheet. The rules are contained in a [CSSRuleList], which can be obtained from the stylesheet's [CSSStyleSheet.cssRules] property.\n\nFor example, one rule might be a [CSSStyleRule] object containing a style such as:\n\n```css\nh1,\nh2 {\n  font-size: 16pt;\n}\n```\n\nAnother rule might be an _at-rule_ such as  or , and so forth.\n\nSee the [Obtaining a StyleSheet](#obtaining_a_stylesheet) section for the various ways a `CSSStyleSheet` object can be obtained. A `CSSStyleSheet` object can also be directly constructed. The constructor, and the [CSSStyleSheet.replace], and [CSSStyleSheet.replaceSync] methods are newer additions to the specification, enabling _Constructable Stylesheets_.",
    "properties": {
      "addrule": "\n\nThe obsolete [CSSStyleSheet] interface's\n**`addRule()`** _legacy method_ adds a new rule to the\nstylesheet. You should avoid using this method, and should instead use the more standard\n[CSSStyleSheet.insertRule] method.",
      "cssrules": "\n\nThe read-only [CSSStyleSheet] property\n**`cssRules`** returns a live [CSSRuleList] which\nprovides a real-time, up-to-date list of every CSS rule which comprises the\nstylesheet. Each item in the list is a [CSSRule] defining a single\nrule.",
      "deleterule": "\n\nThe [CSSStyleSheet] method\n**`deleteRule()`** removes a rule from the stylesheet\nobject.",
      "insertrule": "\n\nThe **`CSSStyleSheet.insertRule()`**\nmethod inserts a new [CSS rule](/en-US/docs/Web/API/CSSRule) into the [current style sheet](/en-US/docs/Web/API/CSSStyleSheet).\n\n> **Note:** Although `insertRule()` is exclusively a method of\n> [CSSStyleSheet], it actually inserts the rule into\n> `[CSSStyleSheet].cssRules` — its internal\n> [CSSRuleList].",
      "ownerrule": "\n\nThe read-only [CSSStyleSheet] property\n**`ownerRule`** returns the [CSSImportRule]\ncorresponding to the  at-rule which imported the stylesheet into\nthe document. If the stylesheet wasn't imported into the document using\n`@import`, the returned value is `null`.",
      "removerule": "\n\nThe obsolete [CSSStyleSheet] method\n**`removeRule()`** removes a rule from the stylesheet\nobject. It is functionally identical to the standard, preferred method\n[CSSStyleSheet.deleteRule].\n\n> **Note:** This is a _legacy method_ which has been replaced by\n> the standard method [CSSStyleSheet.deleteRule]. You\n> should use that instead.",
      "replace": "\n\nThe **`replace()`** method of the [CSSStyleSheet] interface asynchronously replaces the content of the stylesheet with the content passed into it. The method returns a promise that resolves with the `CSSStyleSheet` object.\n\nThe `replace()` and [CSSStyleSheet.replaceSync] methods can only be used on a stylesheet created with the [CSSStyleSheet.CSSStyleSheet] constructor.",
      "replacesync": "\n\nThe **`replaceSync()`** method of the [CSSStyleSheet] interface synchronously replaces the content of the stylesheet with the content passed into it.\n\nThe `replaceSync()` and [CSSStyleSheet.replace] methods can only be used on a stylesheet created with the [CSSStyleSheet.CSSStyleSheet] constructor.",
      "rules": "\n\n**`rules`** is a _deprecated_\n_legacy property_ of the [CSSStyleSheet] interface. Functionally\nidentical to the preferred [CSSStyleSheet.cssRules] property,\nit provides access to a live-updating list of the CSS rules comprising the\nstylesheet.\n\n> **Note:** As a legacy property, you should not use `rules` and\n> should instead use the preferred [CSSStyleSheet.cssRules].\n> While `rules` is unlikely to be removed soon, its availability is not as\n> widespread and using it will result in compatibility problems for your site or app."
    }
  },
  "cssstylevalue": {
    "docs": "\n\nThe **`CSSStyleValue`** interface of the [CSS Typed Object Model API](/en-US/docs/Web/API/CSS_Object_Model#css_typed_object_model) is the base class of all CSS values accessible through the Typed OM API. An instance of this class may be used anywhere a string is expected.",
    "properties": {
      "parse_static": "\n\nThe **`parse()`** static method of the [CSSStyleValue]\ninterface sets a specific CSS property to the specified values and returns the first\nvalue as a [CSSStyleValue] object.",
      "parseall_static": "\n\nThe **`parseAll()`** static method of the [CSSStyleValue]\ninterface sets all occurrences of a specific CSS property to the specified value and\nreturns an array of [CSSStyleValue] objects, each containing one of the\nsupplied values."
    }
  },
  "csssupportsrule": {
    "docs": "\n\nThe **`CSSSupportsRule`** interface represents a single CSS  [at-rule](/en-US/docs/Web/CSS/At-rule).\n\n"
  },
  "csstransformcomponent": {
    "docs": "\n\nThe **`CSSTransformComponent`** interface of the  is part of the [CSSTransformValue] interface.",
    "properties": {
      "is2d": "\n\nThe **`is2D`** read-only property of the [CSSTransformComponent] interface indicates where the transform is 2D or 3D.",
      "tomatrix": "\n\nThe **`toMatrix()`** method of the\n[CSSTransformComponent] interface returns a [DOMMatrix]\nobject.\n\nAll transform functions can be represented mathematically as a 4x4 transformation matrix. This is explained in detail in [Understanding the CSS Transforms matrix](https://dev.opera.com/articles/understanding-the-css-transforms-matrix/).\n\n> **Note:** The `is2D` property affects what transform, and therefore type of matrix that will be returned. CSS 2D and 3D transforms are different for legacy reasons. A brief explanation of 2D vs. 3D transforms can be found in [Using CSS transforms](/en-US/docs/Web/CSS/CSS_transforms/Using_CSS_transforms).",
      "tostring": "\n\nThe **`toString()`** method of the [CSSTransformComponent] interface is a  returning a [CSS Transforms](/en-US/docs/Web/CSS/CSS_transforms) function."
    }
  },
  "csstransformvalue": {
    "docs": "\n\nThe **`CSSTransformValue`** interface of the  represents `transform-list` values as used by the CSS `transform` property.\n\n",
    "properties": {
      "entries": "\n\nThe **`CSSTransformValue.entries()`** method\nreturns an array of a given object's own enumerable\nproperty `[key, value]` pairs in the same order as that provided by a\n[`for...in`](/en-US/docs/Web/JavaScript/Reference/Statements/for...in) loop (the difference being that a for-in loop enumerates\nproperties in the prototype chain as well).",
      "foreach": "\n\nThe **`CSSTransformValue.forEach()`** method executes a provided function once for each element of the `CSSTransformValue`.",
      "is2d": "\n\nThe read-only **`is2D`** property of the\n[CSSTransformValue] interface returns whether the transform is 2D or 3D.\n\nIn the case of the `CSSTransformValue` this property returns\ntrue unless any of the individual functions return false for `Is2D`, in which\ncase it returns false.",
      "keys": "\n\nThe **`CSSTransformValue.keys()`** method\nreturns a new _array iterator_ object that contains the keys\nfor each index in the array.",
      "length": "\n\nThe read-only **`length`** property of the\n[CSSTransformValue] interface returns the number of transform components in\nthe list.",
      "tomatrix": "\n\nThe **`toMatrix()`** method of the\n[CSSTransformValue] interface returns a [DOMMatrix] object.",
      "values": "\n\nThe **`CSSTransformValue.values()`** returns a\nnew _array iterator_ object that contains the values for\neach index in the CSSTransformValue object."
    }
  },
  "csstransition": {
    "docs": "\n\nThe **`CSSTransition`** interface of the [Web Animations API] represents an [Animation] object used for a [CSS Transition](/en-US/docs/Web/CSS/CSS_transitions).\n\n",
    "properties": {
      "transitionproperty": "\n\nThe **`transitionProperty`** property of the\n[CSSTransition] interface returns the **expanded transition property\nname** of the transition. This is the longhand CSS property for which the\ntransition was generated."
    }
  },
  "csstranslate": {
    "docs": "\n\nThe **`CSSTranslate`** interface of the  represents the [translate()](/en-US/docs/Web/CSS/transform-function/translate) value of the individual `transform` property in CSS. It inherits properties and methods from its parent [CSSTransformValue].\n\n",
    "properties": {
      "x": "\n\nThe **`x`** property of the\n[CSSTranslate] interface gets and sets the abscissa or x-axis of the\ntranslating vector.",
      "y": "\n\nThe **`y`** property of the\n[CSSTranslate] interface gets and sets the ordinate or y-axis of the\ntranslating vector.",
      "z": "\n\nThe **`z`** property of the\n[CSSTranslate] interface representing the z-component of the translating\nvector. A positive value moves the element towards the viewer, and a negative value\nfarther away.\n\nIf this value is present then the transform is a 3D transform and the `is2D`\nproperty will be set to false."
    }
  },
  "cssunitvalue": {
    "docs": "\n\nThe **`CSSUnitValue`** interface of the  represents values that contain a single unit type. For example, \"42px\" would be represented by a `CSSNumericValue`.\n\n",
    "properties": {
      "unit": "\n\nThe **`CSSUnitValue.unit`** read-only property\nof the [CSSUnitValue] interface returns a string\nindicating the type of unit.",
      "value": "\n\nThe **`CSSUnitValue.value`** property of the\n[CSSUnitValue] interface returns a double indicating the number of units."
    }
  },
  "cssunparsedvalue": {
    "docs": "\n\nThe **`CSSUnparsedValue`** interface of the  represents property values that reference [custom properties](/en-US/docs/Web/CSS/CSS_cascading_variables). It consists of a list of string fragments and variable references.\n\nCustom properties are represented by `CSSUnparsedValue` and `var()` references are represented using [CSSVariableReferenceValue].\n\n",
    "properties": {
      "entries": "\n\nThe **`CSSUnparsedValue.entries()`** method\nreturns an array of a given object's own enumerable property `[key, value]`\npairs in the same order as that provided by a `for...in` loop (the difference being that a for-in loop enumerates properties in the\nprototype chain as well).",
      "foreach": "\n\nThe **`CSSUnparsedValue.forEach()`** method\nexecutes a provided function once for each element of the\n[CSSUnparsedValue].",
      "keys": "\n\nThe **`CSSUnparsedValue.keys()`** method\nreturns a new _array iterator_ object that contains the keys\nfor each index in the array.",
      "length": "\n\nThe **`length`** read-only property of the\n[CSSUnparsedValue] interface returns the number of items in the object.",
      "values": "\n\nThe **`CSSUnparsedValue.values()`** method\nreturns a new _array iterator_ object that contains the\nvalues for each index in the CSSUnparsedValue object."
    }
  },
  "cssvalue": {
    "docs": "\n\nThe **`CSSValue`** interface represents the current computed value of a CSS property.\n\n> **Note:** This interface was part of an attempt to create a typed CSS Object Model. This attempt has been abandoned, and most browsers do\n> not implement it.\n>\n> To achieve your purpose, you can use:\n>\n> - the untyped [CSS Object Model](/en-US/docs/Web/API/CSS_Object_Model), widely supported, or\n> - the modern [CSS Typed Object Model API](/en-US/docs/Web/API/CSS_Typed_OM_API), less supported and considered experimental.",
    "properties": {
      "csstext": "\n\nThe **`cssText`** property of the [CSSValue]\ninterface represents the current computed CSS property value.\n\n> **Note:** This property was part of an attempt to create a typed CSS Object Model. This attempt has been abandoned, and most browsers do\n> not implement it.\n>\n> To achieve your purpose, you can use:\n>\n> - the untyped [CSS Object Model](/en-US/docs/Web/API/CSS_Object_Model), widely supported, or\n> - the modern [CSS Typed Object Model API](/en-US/docs/Web/API/CSS_Typed_OM_API), less supported and considered experimental.",
      "cssvaluetype": "\n\nThe **`cssValueType`** read-only property of the\n[CSSValue] interface represents the type of the current computed CSS\nproperty value.\n\n> **Note:** This property was part of an attempt to create a typed CSS Object Model. This attempt has been abandoned, and most browsers do\n> not implement it.\n>\n> To achieve your purpose, you can use:\n>\n> - the untyped [CSS Object Model](/en-US/docs/Web/API/CSS_Object_Model), widely supported, or\n> - the modern [CSS Typed Object Model API](/en-US/docs/Web/API/CSS_Typed_OM_API), less supported and considered experimental."
    }
  },
  "cssvaluelist": {
    "docs": "\n\nThe **`CSSValueList`** interface derives from the [CSSValue] interface and provides the abstraction of an ordered collection of CSS values.\n\n> **Note:** This interface was part of an attempt to create a typed CSS Object Model. This attempt has been abandoned, and most browsers do\n> not implement it.\n>\n> To achieve your purpose, you can use:\n>\n> - the untyped [CSS Object Model](/en-US/docs/Web/API/CSS_Object_Model), widely supported, or\n> - the modern [CSS Typed Object Model API](/en-US/docs/Web/API/CSS_Typed_OM_API), less supported and considered experimental.\n\nSome properties allow an empty list in their syntax. In that case, these properties take the `none` identifier. So, an empty list means that the property has the value `none`.\n\nThe items in the `CSSValueList` are accessible via an integral index, starting from 0.\n\n",
    "properties": {
      "item": "\n\nThe **`item()`** method of the [CSSValueList]\ninterface is used to retrieve a [CSSValue] by ordinal index.\n\nThe order in this collection represents the order of the values in the CSS style\nproperty. If the index is greater than or equal to the number of values in the list,\nthis method returns `null`.\n\n> **Note:** This method was part of an attempt to create a typed CSS Object Model. This attempt has been abandoned, and most browsers do\n> not implement it.\n>\n> To achieve your purpose, you can use:\n>\n> - the untyped [CSS Object Model](/en-US/docs/Web/API/CSS_Object_Model), widely supported, or\n> - the modern [CSS Typed Object Model API](/en-US/docs/Web/API/CSS_Typed_OM_API), less supported and considered experimental.",
      "length": "\n\nThe **`length`** read-only property of the\n[CSSValueList] interface represents the number of [CSSValue]s\nin the list. The range of valid values of the indices is `0` to\n`length-1` inclusive.\n\n> **Note:** This property was part of an attempt to create a typed CSS Object Model. This attempt has been abandoned, and most browsers do\n> not implement it.\n>\n> To achieve your purpose, you can use:\n>\n> - the untyped [CSS Object Model](/en-US/docs/Web/API/CSS_Object_Model), widely supported, or\n> - the modern [CSS Typed Object Model API](/en-US/docs/Web/API/CSS_Typed_OM_API), less supported and considered experimental."
    }
  },
  "cssvariablereferencevalue": {
    "docs": "\n\nThe **`CSSVariableReferenceValue`** interface of the  allows you to create a custom name for a built-in CSS value. This object functionality is sometimes called a \"CSS variable\" and serves the same purpose as the `var()` function. The custom name must begin with two dashes.",
    "properties": {
      "fallback": "\n\nThe **`fallback`** read-only property of the\n[CSSVariableReferenceValue] interface returns the [custom property fallback value](/en-US/docs/Web/CSS/Using_CSS_custom_properties#custom_property_fallback_values) of the [CSSVariableReferenceValue].",
      "variable": "\n\nThe **`variable`** property of the\n[CSSVariableReferenceValue] interface returns the [custom property name](/en-US/docs/Web/CSS/--*) of the\n[CSSVariableReferenceValue]."
    }
  },
  "customelementregistry": {
    "docs": "\n\nThe **`CustomElementRegistry`** interface provides methods for registering custom elements and querying registered elements. To get an instance of it, use the [window.customElements] property.",
    "properties": {
      "define": "\n\nThe **`define()`** method of the [CustomElementRegistry] interface adds a definition for a custom element to the custom element registry, mapping its name to the constructor which will be used to create it.",
      "get": "\n\nThe **`get()`** method of the\n[CustomElementRegistry] interface returns the constructor for a\npreviously-defined custom element.",
      "getname": "\n\nThe **`getName()`** method of the\n[CustomElementRegistry] interface returns the name for a\npreviously-defined custom element.",
      "upgrade": "\n\nThe **`upgrade()`** method of the\n[CustomElementRegistry] interface upgrades all shadow-containing custom\nelements in a [Node] subtree, even before they are connected to the main\ndocument.",
      "whendefined": "\n\nThe **`whenDefined()`** method of the\n[CustomElementRegistry] interface returns a `Promise` that\nresolves when the named element is defined."
    }
  },
  "customevent": {
    "docs": "\n\nThe **`CustomEvent`** interface represents events initialized by an application for any purpose.\n\n> **Note:** If used to attempt to communicate between a web extension content script and a web page script, a non-string `detail` property throws with \"Permission denied to access property\" in Firefox. To avoid this issue clone the object. See [Share objects with page scripts](/en-US/docs/Mozilla/Add-ons/WebExtensions/Sharing_objects_with_page_scripts) for more information.\n\n",
    "properties": {
      "detail": "\n\nThe read-only **`detail`** property of the [CustomEvent] interface\nreturns any data passed when initializing the event.",
      "initcustomevent": "\n\nThe **`CustomEvent.initCustomEvent()`** method initializes a [CustomEvent] object.\nIf the event has already been dispatched, this method does nothing.\n\nEvents initialized in this way must have been created with the [Document.createEvent] method.\nThis method must be called to set the event before it is dispatched using [EventTarget.dispatchEvent].\nOnce dispatched, it doesn't do anything anymore.\n\n> **Note:** **Do not use this method anymore, as it is deprecated.**\n>\n> Rather than using the feature, instead use specific event constructors, like [CustomEvent.CustomEvent].\n> The page on [Creating and triggering events](/en-US/docs/Web/Events/Creating_and_triggering_events) gives more information about the way to use those."
    }
  },
  "customstateset": {
    "docs": "\n\nThe **`CustomStateSet`** interface of the [Document Object Model](/en-US/docs/Web/API/Document_Object_Model) stores a list of states for an [autonomous custom element](/en-US/docs/Web/API/Web_components/Using_custom_elements#types_of_custom_element), and allows states to be added and removed from the set.\n\nThe interface can be used to expose the internal states of a custom element, allowing them to be used in CSS selectors by code that uses the element.",
    "properties": {
      "add": "\n\nThe **`add`** method of the [CustomStateSet] interface adds an item to the `CustomStateSet`, after checking that the value is in the correct format.",
      "clear": "\n\nThe **`clear()`** method of the [CustomStateSet] interface removes all elements from the `CustomStateSet` object.",
      "delete": "\n\nThe **`delete()`** method of the [CustomStateSet] interface deletes a single value from the `CustomStateSet`.",
      "entries": "\n\nThe **`entries`** method of the [CustomStateSet] interface returns a new [iterator](/en-US/docs/Web/JavaScript/Reference/Iteration_protocols) object, containing an array of `[value,value]` for each element in the `CustomStateSet`.",
      "foreach": "\n\nThe **`forEach()`** method of the [CustomStateSet] interface executes a provided function for each value in the `CustomStateSet` object.",
      "has": "\n\nThe **`has()`** method of the [CustomStateSet] interface returns a `Boolean` asserting whether an element is present with the given value.",
      "keys": "\n\nThe **`keys()`** method of the [CustomStateSet] interface is an alias for [CustomStateSet.values].",
      "size": "\n\nThe **`size`** property of the [CustomStateSet] interface returns the number of values in the `CustomStateSet`.",
      "values": "\n\nThe **`values()`** method of the [CustomStateSet] interface returns a new iterator object that yields the values for each element in the `CustomStateSet` object in insertion order."
    }
  },
  "datatransfer": {
    "docs": "\n\nThe **`DataTransfer`** object is used to hold the data that is being dragged during a drag and drop operation. It may hold one or more data items, each of one or more data types. For more information about drag and drop, see [HTML Drag and Drop API](/en-US/docs/Web/API/HTML_Drag_and_Drop_API).\n\nThis object is available from the [DragEvent.dataTransfer] property of all [DragEvent].",
    "properties": {
      "addelement": "\n\nThe **`DataTransfer.addElement()`** method sets the drag source\nto the given element. This element will be the element to which [HTMLElement/drag_event] and\n[HTMLElement/dragend_event] events are fired, and not the default target (the node that was\ndragged).\n\n> **Note:** This method is Firefox-specific.",
      "cleardata": "\n\nThe **`DataTransfer.clearData()`** method removes the drag\noperation's [DataTransfer] for the given type. If data for the\ngiven type does not exist, this method does nothing.\n\nIf this method is called with no arguments or the format is an empty\nstring, the data of all types will be removed.\n\nThis method does _not_ remove files from the drag operation, so it's possible\nfor there still to be an entry with the type `\"Files\"` left in the object's\n[DataTransfer.types] list if there are any files included in the drag.\n\n> **Note:** This method can only be used in the handler for the [HTMLElement/dragstart_event] event,\n> because that's the only time the drag operation's data store is writable.",
      "dropeffect": "\n\nThe **`DataTransfer.dropEffect`** property controls the\nfeedback (typically visual) the user is given during a drag and drop operation. It will\naffect which cursor is displayed while dragging. For example, when the user hovers over\na target drop element, the browser's cursor may indicate which type of operation will\noccur.\n\nWhen the [DataTransfer] object is created, `dropEffect` is set\nto a string value. On getting, it returns its current value. On setting, if the new\nvalue is one of the values listed below, then the property's current value will be set\nto the new value and other values will be ignored.\n\nFor the [HTMLElement/dragenter_event] and [HTMLElement/dragover_event] events,\n`dropEffect` will be initialized based on what action the user is requesting.\nHow this is determined is platform specific, but typically the user can press modifier\nkeys such as the alt key to adjust the desired action. Within event handlers for\n[HTMLElement/dragenter_event] and [HTMLElement/dragover_event] events, `dropEffect` should\nbe modified if a different action is desired than the action that the user is\nrequesting.\n\nFor the [HTMLElement/drop_event] and [HTMLElement/dragend_event] events, `dropEffect` will\nbe set to the action that was desired, which will be the value `dropEffect`\nhad after the last [HTMLElement/dragenter_event] or [HTMLElement/dragover_event] event. In a\n[HTMLElement/dragend_event] event, for instance, if the desired dropEffect is \"move\", then the\ndata being dragged should be removed from the source.",
      "effectallowed": "\n\nThe **`DataTransfer.effectAllowed`** property specifies the\neffect that is allowed for a drag operation. The _copy_ operation is used to\nindicate that the data being dragged will be copied from its present location to the\ndrop location. The _move_ operation is used to indicate that the data being\ndragged will be moved, and the _link_ operation is used to indicate that some\nform of relationship or connection will be created between the source and drop\nlocations.\n\nThis property should be set in the [HTMLElement/dragstart_event] event to set the desired drag\neffect for the drag source. Within the [HTMLElement/dragenter_event] and [HTMLElement/dragover_event]\nevent handlers, this property will be set to whatever value was assigned during the\n[HTMLElement/dragstart_event] event, thus `effectAllowed` may be used to determine\nwhich effect is permitted.\n\nAssigning a value to `effectAllowed` in events other than\n[HTMLElement/dragstart_event] has no effect.",
      "files": "\n\nThe **`files`** read-only property of [`DataTransfer`](/en-US/docs/Web/API/DataTransfer) objects is a [FileList] in the drag operation. If the operation includes no files, the list is empty.\n\nThis feature can be used to drag files from a user's desktop to the browser.\n\n> **Note:** The `files` property of [`DataTransfer`](/en-US/docs/Web/API/DataTransfer) objects can only be accessed from within the `drop` event. For all other events, the `files` property will be empty — because its underlying data store will be in a [protected mode](https://html.spec.whatwg.org/multipage/dnd.html#the-drag-data-store).",
      "getdata": "\n\nThe **`DataTransfer.getData()`**\nmethod retrieves drag data (as a string) for the specified type.\nIf the drag operation does not include data, this method returns an empty\nstring.\n\nExample data types are `text/plain` and `text/uri-list`.",
      "items": "\n\nThe read-only [DataTransfer] property `items` property is a\n[DataTransferItemList] of the [DataTransferItem] in a drag operation. The list includes one item for each item in the\noperation and if the operation had no items, the list is empty.",
      "setdata": "\n\nThe **`DataTransfer.setData()`** method sets the drag\noperation's [DataTransfer] to the specified data and type. If\ndata for the given type does not exist, it is added at the end of the drag data store,\nsuch that the last item in the [DataTransfer.types] list will be\nthe new type. If data for the given type already exists, the existing data is replaced\nin the same position. That is, the order of the\n[DataTransfer.types] list is not changed when replacing data of the\nsame type.\n\nExample data types are `text/plain` and `text/uri-list`.",
      "setdragimage": "\n\nWhen a drag occurs, a translucent image is generated from the drag target (the element\nthe [HTMLElement/dragstart_event] event is fired at), and follows the mouse pointer during the\ndrag. This image is created automatically, so you do not need to create it yourself.\nHowever, if a custom image is desired, the\n**`DataTransfer.setDragImage()`** method can be used to set the\ncustom image to be used. The image will typically be an `img` element\nbut it can also be a `canvas` or any other visible element.\n\nThe method's `x` and `y` coordinates define how the image should\nappear relative to the mouse pointer. These coordinates define the offset into the image\nwhere the mouse cursor should be. For instance, to display the image so that the pointer\nis at its center, use values that are half the width and height of the image.\n\nThis method must be called in the [HTMLElement/dragstart_event] event handler.",
      "types": "\n\nThe **`DataTransfer.types`** read-only property returns the available types\nthat exist in the [DataTransfer.items]."
    }
  },
  "datatransferitem": {
    "docs": "\n\nThe **`DataTransferItem`** object represents one drag data item. During a _drag operation_, each [DragEvent] has a [DragEvent.dataTransfer] property which contains a [DataTransferItemList] of drag data items. Each item in the list is a `DataTransferItem` object.\n\nThis interface has no constructor.",
    "properties": {
      "getasfile": "\n\nIf the item is a file, the **`DataTransferItem.getAsFile()`**\nmethod returns the drag data item's [File] object. If the item is not a\nfile, this method returns `null`.",
      "getasfilesystemhandle": "\n\nThe **`getAsFileSystemHandle()`** method of the\n[DataTransferItem] interface returns a [FileSystemFileHandle]\nif the dragged item is a file, or a [FileSystemDirectoryHandle] if the\ndragged item is a directory.",
      "getasstring": "\n\nThe **`DataTransferItem.getAsString()`** method invokes the\ngiven callback with the drag data item's string data as the argument if the item's\n[DataTransferItem.kind] is a _Plain unicode string_ (i.e.\n`kind` is `string`).",
      "kind": "\n\nThe read-only **`DataTransferItem.kind`** property returns a\n[DataTransferItem] representing the _drag data item_ kind: some text\nor some file.",
      "type": "\n\nThe read-only **`DataTransferItem.type`** property returns the\ntype (format) of the [DataTransferItem] object representing the drag data\nitem. The `type` is a Unicode string generally given by a MIME type, although\na MIME type is not required.\n\nSome example types are: `text/plain` and `text/html`.",
      "webkitgetasentry": "\n\nIf the item described by the [DataTransferItem] is a file, `webkitGetAsEntry()` returns a [FileSystemFileEntry] or [FileSystemDirectoryEntry] representing it. If the item isn't a file, `null` is returned.\n\n> **Note:** This function is implemented as `webkitGetAsEntry()` in non-WebKit browsers including Firefox at this time; it may be renamed to\n> `getAsEntry()` in the future, so you should code defensively, looking for both."
    }
  },
  "datatransferitemlist": {
    "docs": "\n\nThe **`DataTransferItemList`** object is a list of [DataTransferItem] objects representing items being dragged. During a _drag operation_, each [DragEvent] has a [DragEvent.dataTransfer] property and that property is a `DataTransferItemList`.\n\nThe individual items can be accessed using the [bracket notation](/en-US/docs/Web/JavaScript/Reference/Operators/Property_accessors#bracket_notation) `[]`.\n\nThis interface has no constructor.",
    "properties": {
      "add": "\n\nThe **`DataTransferItemList.add()`** method creates a new\n[DataTransferItem] using the specified data and adds it to the drag data\nlist. The item may be a [File] or a string of a\ngiven type. If the item is successfully added to the list, the newly-created\n[DataTransferItem] object is returned.",
      "clear": "\n\nThe [DataTransferItemList] method\n**`clear()`** removes all [DataTransferItem]\nobjects from the drag data items list, leaving the list empty.\n\nThe drag data store in which this list is kept is only writable while handling the\n[HTMLElement/dragstart_event] event. While handling [HTMLElement/drop_event], the drag data store is\nin read-only mode, and this method silently does nothing. No exception is thrown.",
      "length": "\n\nThe read-only **`length`** property of the\n[DataTransferItemList] interface returns the number of items currently in\nthe drag item list.",
      "remove": "\n\nThe **`DataTransferItemList.remove()`** method removes the\n[DataTransferItem] at the specified index from the list. If the index is\nless than zero or greater than one less than the length of the list, the list will not\nbe changed."
    }
  },
  "decompressionstream": {
    "docs": "\n\nThe **`DecompressionStream`** interface of the [Compression Streams API] is an API for decompressing a stream of data.",
    "properties": {
      "readable": "\n\nThe **`readable`** read-only property of the [DecompressionStream] interface returns a [ReadableStream].",
      "writable": "\n\nThe **`writable`** read-only property of the [DecompressionStream] interface returns a [WritableStream]."
    }
  },
  "dedicatedworkerglobalscope": {
    "docs": "\n\nThe **`DedicatedWorkerGlobalScope`** object (the [Worker] global scope) is accessible through the [WorkerGlobalScope.self] keyword. Some additional global functions, namespaces objects, and constructors, not typically associated with the worker global scope, but available on it, are listed in the [JavaScript Reference](/en-US/docs/Web/JavaScript/Reference). See also: [Functions available to workers](/en-US/docs/Web/API/Web_Workers_API/Functions_and_classes_available_to_workers).\n\n",
    "properties": {
      "cancelanimationframe": "\n\nThe **`cancelAnimationFrame()`** method of the [DedicatedWorkerGlobalScope] interface cancels an animation frame request previously scheduled through a call to [DedicatedWorkerGlobalScope.requestAnimationFrame].\n\nCalling the `cancelAnimationFrame()` method requires the current worker to have an associated owner [Window]. That means that the current worker must be created by [Window] or by a dedicated worker that also has an associated owner [Window].",
      "close": "\n\nThe **`close()`** method of the [DedicatedWorkerGlobalScope] interface discards any tasks queued in the `DedicatedWorkerGlobalScope`'s event loop, effectively closing this particular scope.",
      "message_event": "\n\nThe `message` event is fired on a [DedicatedWorkerGlobalScope] object when the worker receives a message from its parent (i.e. when the parent sends a message using [`Worker.postMessage()`](/en-US/docs/Web/API/Worker/postMessage)).\n\nThis event is not cancellable and does not bubble.",
      "messageerror_event": "\n\nThe `messageerror` event is fired on a [DedicatedWorkerGlobalScope] object when it receives a message that can't be deserialized.\n\nThis event is not cancellable and does not bubble.",
      "name": "\n\nThe **`name`** read-only property of the\n[DedicatedWorkerGlobalScope] interface returns the name that the\n[Worker] was (optionally) given when it was created. This is the name that\nthe [Worker.Worker] constructor can pass to get a reference to\nthe [DedicatedWorkerGlobalScope].",
      "postmessage": "\n\nThe **`postMessage()`** method of the [DedicatedWorkerGlobalScope] interface sends a message to the main thread that spawned it.\n\nThis accepts a data parameter, which contains data to copy from the worker to the main thread.\nThe data may be any value or JavaScript object handled by the [structured clone](/en-US/docs/Web/API/Web_Workers_API/Structured_clone_algorithm) algorithm, which includes cyclical references.\n\nThe method also accepts an optional array of [transferable objects](/en-US/docs/Web/API/Web_Workers_API/Transferable_objects) to _transfer_ to the main thread;\nUnlike the data parameter transferred objects are no longer usable in the worker thread.\n(Where possible, objects are transferred using a high performance zero-copy operation).\n\nThe main scope that spawned the worker can send back information to the thread that spawned it using the [Worker.postMessage] method.",
      "requestanimationframe": "\n\nThe **`requestAnimationFrame()`** method of the [DedicatedWorkerGlobalScope] interface tells the browser you wish to perform an animation frame request and call a user-supplied callback function before the next repaint.\n\nThe frequency of calls to the callback function will generally match the display refresh rate. The most common refresh rate is 60 Hz, (60 cycles/frames per second), though 75 Hz, 120 Hz, and 144 Hz are also widely used. `requestAnimationFrame()` calls are paused in most browsers when running in background tabs or hidden `iframe`s, to improve performance and battery life.\n\nA call to the `requestAnimationFrame()` method schedules only one single call to the callback function. If you want to animate another frame, your callback function must call `requestAnimationFrame()` again.\n\n> **Warning:** Be sure always to use the first argument (or some other method for getting the current time) to calculate how much the animation will progress in a frame — **otherwise, the animation will run faster on high refresh-rate screens**. For ways to do that, see the examples below.\n\nCalling the `requestAnimationFrame()` method requires the current worker to have an associated owner [Window]. That means that the current worker must be created by [Window] or by a dedicated worker that also has an associated owner [Window].",
      "rtctransform_event": "\n\nThe **`rtctransform`** event is fired at a worker's [DedicatedWorkerGlobalScope] object when an encoded video or audio frame has been queued for processing by a [WebRTC API/Using Encoded Transforms].\n\nThe event's [RTCTransformEvent.transformer] property returns a [RTCRtpScriptTransformer] that exposes the [ReadableStream] on which the frame is queued, and a [WritableStream] where the frame can be written to inject it back into the WebRTC pipeline.\n\nThis event is not cancellable and does not bubble.\n\n"
    }
  },
  "delaynode": {
    "docs": "\n\nThe **`DelayNode`** interface represents a [delay-line](https://en.wikipedia.org/wiki/Digital_delay_line); an [AudioNode] audio-processing module that causes a delay between the arrival of an input data and its propagation to the output.\n\nA `DelayNode` always has exactly one input and one output, both with the same amount of channels.\n\n![The DelayNode acts as a delay-line, here with a value of 1s.](webaudiodelaynode.png)\n\nWhen creating a graph that has a cycle, it is mandatory to have at least one `DelayNode` in the cycle, or the nodes taking part in the cycle will be muted.\n\n<table class=\"properties\">\n  <tbody>\n    <tr>\n      <th scope=\"row\">Number of inputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Number of outputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count mode</th>\n      <td><code>\"max\"</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count</th>\n      <td><code>2</code> (not used in the default count mode)</td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel interpretation</th>\n      <td><code>\"speakers\"</code></td>\n    </tr>\n  </tbody>\n</table>",
    "properties": {
      "delaytime": "\n\nThe `delayTime` property of the [DelayNode] interface is an [a-rate](/en-US/docs/Web/API/AudioParam#a-rate) [AudioParam] representing the amount of delay to apply.\n\n`delayTime` is expressed in seconds, its minimal value is `0`, and its maximum value is defined by the `maxDelayTime` argument of the [BaseAudioContext.createDelay] method that created it.\n\n> **Note:** Though the [AudioParam] returned is read-only, the value it represents is not."
    }
  },
  "deprecationreportbody": {
    "docs": "\n\nThe `DeprecationReportBody` interface of the [Reporting API](/en-US/docs/Web/API/Reporting_API) represents the body of a deprecation report.\n\nA deprecation report is generated when a deprecated feature (for example a deprecated API method) is used on a document being observed by a [ReportingObserver]. In addition to the support of this API, receiving useful deprecation warnings relies on browser vendors adding these warnings for deprecated features.\n\n",
    "properties": {
      "anticipatedremoval": "\n\nThe **`anticipatedRemoval`** read-only property of the [DeprecationReportBody] interface returns the date that the browser version which removes the feature will ship. This value can be used to prioritize warnings. If this property returns `null` because the date is unknown, then the deprecation should be considered low priority.",
      "columnnumber": "\n\nThe **`columnNumber`** read-only property of the [DeprecationReportBody] interface returns the line in the source file in which the deprecated feature was used.\n\n> **Note:** This property is most useful alongside [DeprecationReportBody.sourceFile] and [DeprecationReportBody.lineNumber] as it enables the location of the column in that file and line where the error occurred.",
      "id": "\n\nThe **`id`** read-only property of the [DeprecationReportBody] interface returns a string representing the feature or API that is deprecated. This can be used to group or count related reports.",
      "linenumber": "\n\nThe **`lineNumber`** read-only property of the [DeprecationReportBody] interface returns the line in the source file in which the deprecated feature was used.\n\n> **Note:** This property is most useful alongside [DeprecationReportBody.sourceFile] as it enables the location of the line in that file where the error occurred.",
      "message": "\n\nThe **`message`** read-only property of the [DeprecationReportBody] interface returns a human-readable description of the deprecation. This typically matches the message a browser will display in its DevTools console regarding a deprecated feature.",
      "sourcefile": "\n\nThe **`sourceFile`** read-only property of the [DeprecationReportBody] interface returns the path to the source file where the deprecated feature was used.\n\n> **Note:** This property can be used with [DeprecationReportBody.lineNumber] and [DeprecationReportBody.columnNumber] to locate the column and line in the file where the error occurred.",
      "tojson": "\n\nThe **`toJSON()`** method of the [DeprecationReportBody] interface is a _serializer_, and returns a JSON representation of the `InterventionReportBody` object."
    }
  },
  "devicemotionevent": {
    "docs": "\n\nThe **`DeviceMotionEvent`** interface of the [Device Orientation Events] provides web developers with information about the speed of changes for the device's position and orientation.\n\n> **Warning:** Currently, Firefox and Chrome do not handle the coordinates the same way. Take care about this while using them.\n\n",
    "properties": {
      "acceleration": "\n\nThe **`acceleration`** read-only property of the [DeviceMotionEvent] interface returns the amount of acceleration recorded by\nthe device, in [meters per second squared (m/s²)](https://en.wikipedia.org/wiki/Meter_per_second_squared).\nThe acceleration value does not include the effect of\nthe gravity force, in contrast to [DeviceMotionEvent.accelerationIncludingGravity].\n\n> **Note:** If the hardware doesn't know how to remove gravity from the\n> acceleration data, this value may not be present in the\n> [DeviceMotionEvent]. In this situation, you'll need to use\n> [DeviceMotionEvent.accelerationIncludingGravity] instead.",
      "accelerationincludinggravity": "\n\nThe **`accelerationIncludingGravity`** read-only property of the [DeviceMotionEvent] interface returns the\namount of acceleration recorded by the device, in [meters per second squared (m/s²)](https://en.wikipedia.org/wiki/Meter_per_second_squared). Unlike [DeviceMotionEvent.acceleration]\nwhich compensates for the influence of gravity, its value is the sum of the acceleration\nof the device as induced by the user and an acceleration equal and opposite to that\ncaused by gravity. In other words, it measures the\n[g-force](https://en.wikipedia.org/wiki/G-Force). In practice, this value represents\nthe raw data measured by an [accelerometer](https://en.wikipedia.org/wiki/Accelerometer).\n\nThis value is not typically as useful as [DeviceMotionEvent.acceleration],\nbut may be the only value available on devices that aren't able to remove gravity from\nthe acceleration data, such as on devices that don't have a gyroscope.\n\n> **Note:** `accelerationIncludingGravity`'s name can be misleading. This property represents acceleration including _the effects of_ gravity. For example, if a device is lying flat on a horizontal surface with the screen pointing up, gravity would be -9.8 along the Z axis, while `acceleration.z` would be 0 and `accelerationIncludingGravity.z` would be 9.8. Similarly, if a device is in free fall with its screen horizontal and pointing up, gravity would be -9.8 along the Z axis, while `acceleration.z` would be -9.8 and `accelerationIncludingGravity.z` would be 0.",
      "interval": "\n\nThe **`interval`** read-only property of the [DeviceMotionEvent] interface returns the interval, in milliseconds, at which data is obtained from the underlying\nhardware. You can use this to determine the granularity of motion events.",
      "rotationrate": "\n\nThe **`rotationRate`** read-only property of the [DeviceMotionEvent] interface returns the rate at which the device is rotating around each of its axes in degrees per\nsecond.\n\n> **Note:** If the hardware isn't capable of providing this\n> information, this property returns `null`."
    }
  },
  "devicemotioneventacceleration": {
    "docs": "\n\nThe **`DeviceMotionEventAcceleration`** interface of the [Device Orientation Events] provides information about the amount of acceleration the device is experiencing along all three axes.",
    "properties": {
      "x": "\n\nThe **`x`** read-only property of the [DeviceMotionEventAcceleration] interface indicates the amount of acceleration that occurred along the X\naxis in a [`DeviceMotionEventAcceleration`](/en-US/docs/Web/API/DeviceMotionEventAcceleration)\nobject.",
      "y": "\n\nThe **`y`** read-only property of the [DeviceMotionEventAcceleration] interface indicates the amount of acceleration that occurred along the Y\naxis in a [`DeviceMotionEventAcceleration`](/en-US/docs/Web/API/DeviceMotionEventAcceleration)\nobject.",
      "z": "\n\nThe **`z`** read-only property of the [DeviceMotionEventAcceleration] interface indicates the amount of acceleration that occurred along the Z\naxis in a [`DeviceMotionEventAcceleration`](/en-US/docs/Web/API/DeviceMotionEventAcceleration)\nobject."
    }
  },
  "devicemotioneventrotationrate": {
    "docs": "\n\nA **`DeviceMotionEventRotationRate`** interface of the [Device Orientation Events] provides information about the rate at which the device is rotating around all three axes.",
    "properties": {
      "alpha": "\n\nThe **`alpha`** read-only property of the [DeviceMotionEventRotationRate] interface indicates the rate of rotation around the Z axis, in degrees per second.",
      "beta": "\n\nThe **`beta`** read-only property of the [DeviceMotionEventRotationRate] interface indicates the rate of rotation around the X axis, in degrees per second.",
      "gamma": "\n\nThe **`gamma`** read-only property of the [DeviceMotionEventRotationRate] interface indicates the rate of rotation around the Y axis, in degrees per second."
    }
  },
  "deviceorientationevent": {
    "docs": "\n\nThe **`DeviceOrientationEvent`** interface of the [Device Orientation Events] provides web developers with information from the physical orientation of the device running the web page.\n\n",
    "properties": {
      "absolute": "\n\nThe **`absolute`** read-only property of the [DeviceOrientationEvent] interface indicates whether or not the device is providing orientation data absolutely (that is,\nin reference to the Earth's coordinate frame) or using some arbitrary frame determined\nby the device.\nSee [Orientation and motion data explained](/en-US/docs/Web/API/Device_orientation_events/Orientation_and_motion_data_explained) for details.",
      "alpha": "\n\nThe **`alpha`** read-only property of the [DeviceOrientationEvent] interface returns the rotation of the device around the Z axis; that is, the number of degrees by\nwhich the device is being twisted around the center of the screen.\nSee [Orientation and motion data explained](/en-US/docs/Web/API/Device_orientation_events/Orientation_and_motion_data_explained) for details.",
      "beta": "\n\nThe **`beta`** read-only property of the [DeviceOrientationEvent] interface returns the rotation of the device around the X axis; that is, the number of degrees,\nranged between -180 and 180, by which the device is tipped forward or backward.\nSee [Orientation and motion data explained](/en-US/docs/Web/API/Device_orientation_events/Orientation_and_motion_data_explained) for details.",
      "gamma": "\n\nThe **`gamma`** read-only property of the [DeviceOrientationEvent] interface returns the rotation of the device around the Y axis; that is, the number of degrees,\nranged between `-90` and `90`, by which the device is tilted left\nor right.\nSee [Orientation and motion data explained](/en-US/docs/Web/API/Device_orientation_events/Orientation_and_motion_data_explained) for details."
    }
  },
  "directoryentrysync": {
    "docs": "\n\nThe `DirectoryEntrySync` interface represents a directory in a file system. It includes methods for creating, reading, looking up, and recursively removing files in a directory.\n\n> **Warning:** This interface is deprecated and is no more on the standard track.\n> _Do not use it anymore._ Use the [File and Directory Entries API](/en-US/docs/Web/API/File_and_Directory_Entries_API) instead."
  },
  "directoryreadersync": {
    "docs": "\n\nThe `DirectoryReaderSync` interface lets you read the entries in a directory.\n\n> **Warning:** This interface is deprecated and is no more on the standard track.\n> _Do not use it anymore._ Use the [File and Directory Entries API](/en-US/docs/Web/API/File_and_Directory_Entries_API) instead."
  },
  "document": {
    "docs": "\n\nThe **`Document`** interface represents any web page loaded in the browser and serves as an entry point into the web page's content, which is the [DOM tree](/en-US/docs/Web/API/Document_object_model/Using_the_Document_Object_Model#what_is_a_dom_tree).\n\nThe DOM tree includes elements such as `body` and `table`, among [many others](/en-US/docs/Web/HTML/Element). It provides functionality globally to the document, like how to obtain the page's URL and create new elements in the document.\n\nThe `Document` interface describes the common properties and methods for any kind of document. Depending on the document's type (e.g. [HTML](/en-US/docs/Web/HTML), [XML](/en-US/docs/Web/XML), SVG, …), a larger API is available: HTML documents, served with the `\"text/html\"` content type, also implement the [HTMLDocument] interface, whereas XML and SVG documents implement the [XMLDocument] interface.",
    "properties": {
      "activeelement": "\n\nThe **`activeElement`** read-only property\nof the [Document] interface returns the [Element] within the DOM that currently has focus.\n\nOften `activeElement` will return a [HTMLInputElement] or\n[HTMLTextAreaElement] object if it has the text selection at the time. If\nso, you can get more detail by using the object's `selectionStart` and `selectionEnd` properties.\nOther times the focused element might be a `select` element (menu) or\nan `input` element.\n\nTypically a user can press the tab key to move the focus around the page among\nfocusable elements, and use the space bar to activate one (that is, to press a button or\ntoggle a radio button). Which elements are focusable varies depending on the platform\nand the browser's current configuration. For example, on macOS systems, elements that\naren't text input elements are not typically focusable by default.\n\n> **Note:** Focus (which element is receiving user input events) is not\n> the same thing as selection (the currently highlighted part of the document). You can\n> get the current selection using [window.getSelection].",
      "adoptedstylesheets": "\n\nThe **`adoptedStyleSheets`** property of the [Document] interface is used for setting an array of constructed stylesheets to be used by the document.\n\n> **Note:** A constructed stylesheet is a stylesheet created programmatically using the [`CSSStyleSheet()` constructor](/en-US/docs/Web/API/CSSStyleSheet/CSSStyleSheet) (as compared to one created by a user-agent when importing a stylesheet from a script, imported using `style` and , or linked to via `link`).\n\nThe same constructed stylesheets can also be shared with one or more [ShadowRoot] instances using the [`ShadowRoot.adoptedStyleSheets`](/en-US/docs/Web/API/ShadowRoot/adoptedStyleSheets) property.\nChanging an adopted stylesheet will affect all the objects that adopt it.\n\nStylesheets in the property are evaluated along with the document's other stylesheets using the [CSS cascade algorithm](/en-US/docs/Web/CSS/Cascade).\nWhere the resolution of rules considers stylesheet order, `adoptedStyleSheets` are assumed to be ordered after those in [`Document.styleSheets`](/en-US/docs/Web/API/Document/styleSheets).\n\nOnly stylesheets created using the [`CSSStyleSheet()` constructor](/en-US/docs/Web/API/CSSStyleSheet/CSSStyleSheet) within the context of the current [Document] may be adopted.",
      "adoptnode": "\n\n**`Document.adoptNode()`** transfers a  from another [Document] into the method's\ndocument. The adopted node and its subtree are removed from their original document (if\nany), and their [Node.ownerDocument] is changed to the\ncurrent document. The node can then be inserted into the current document.",
      "afterscriptexecute_event": "\n\nThe `afterscriptexecute` event fires when a static `script` element finishes executing its script. It does not fire if the element is added dynamically, such as with [Node.appendChild].",
      "alinkcolor": "\n\nReturns or sets the color of an active link in the document body. A link is active\nduring the time between `mousedown` and `mouseup` events.",
      "all": "\n\nThe [Document] interface's read-only **`all`** property returns an [HTMLAllCollection] rooted at the document node.\n\nRather than using `document.all` to return an [HTMLAllCollection] of all the document's elements in document order, you can use [Document.querySelectorAll] to return a [NodeList] of all the document's elements in document order:\n\n```js\nconst allElements = document.querySelectorAll(\"*\");\n```",
      "anchors": " \n\nThe **`anchors`** read-only property of the\n[Document] interface returns a list of all of the anchors in the document.",
      "append": "\n\nThe **`Document.append()`** method\ninserts a set of [Node] objects or string objects after\nthe last child of the document. String objects\nare inserted as equivalent [Text] nodes.\n\nThis method appends a child to a `Document`. To append to an arbitrary element in the tree, see [Element.append].",
      "applets": " \n\nThe **`applets`** property of the [Document] returns an empty [HTMLCollection]. This property is kept only for compatibility reasons; in older versions of browsers, it returned a list of the applets within a document.\n\n> **Note:** Support for the `<applet>` element has been removed by all browsers. Therefore, calling `document.applets` always\n> returns an empty collection.",
      "beforescriptexecute_event": "\n\nThe `beforescriptexecute` event fires when a static `script` is about to start executing. It does not fire if the element is added dynamically, such as with [Node.appendChild].",
      "bgcolor": " \n\nThe deprecated `bgColor` property gets or sets the background color of the\ncurrent document.",
      "body": "\n\nThe **`Document.body`** property represents the\n`body` or `frameset` node of the current document, or\n`null` if no such element exists.",
      "caretpositionfrompoint": "\n\nThe **`caretPositionFromPoint()`**\nmethod of the [Document] interface returns a\n[CaretPosition] object, containing the DOM node, along with the caret and\ncaret's character offset within that node.",
      "caretrangefrompoint": "\n\nThe **`caretRangeFromPoint()`** method of the\n[Document] interface returns a [Range] object for the document\nfragment under the specified coordinates.\n\nThis method is the WebKit-proprietary implementation of the [Document.caretPositionFromPoint] method.",
      "characterset": "\n\nThe **`Document.characterSet`**\nread-only property returns the [character encoding](/en-US/docs/Glossary/Character_encoding) of the\ndocument that it's currently rendered with.\n\n> **Note:** A \"character set\" and a \"character encoding\" are related, but different. Despite the\n> name of this property, it returns the _encoding_.\n\nUsers can override the developer-specified encoding inside the [Content-Type](/en-US/docs/Web/HTTP/Headers/Content-Type) header or inline\nlike `<meta charset=\"utf-8\">`, such as with Firefox's <kbd>View → Text\nEncoding</kbd> menu. This override is provided to fix incorrect developer-specified\nencodings that result in [garbled text](https://en.wikipedia.org/wiki/Mojibake).\n\n> **Note:** The properties `document.charset` and `document.inputEncoding`\n> are legacy aliases for `document.characterSet`. Do not use them any more.",
      "childelementcount": "\n\nThe **`Document.childElementCount`** read-only property\nreturns the number of child elements of the document.\n\nTo get the number of children of a specific element, see [Element.childElementCount].",
      "children": "\n\nThe read-only **`children`** property returns a live [HTMLCollection]\nwhich contains all of the child [Element] of the document upon which it was called.\n\nFor HTML documents, this is usually only the root `<html>` element.\n\nSee [Element.children] for child elements of specific HTML elements within the document.",
      "clear": "\n\nThe **`Document.clear()`** method does nothing, but doesn't raise any error.",
      "close": "\n\nThe **`Document.close()`** method finishes writing to a\ndocument, opened with [Document.open].",
      "compatmode": "\n\nThe **`Document.compatMode`** read-only property indicates\nwhether the document is rendered in [Quirks mode](/en-US/docs/Web/HTML/Quirks_Mode_and_Standards_Mode) or\nStandards mode.",
      "contenttype": "\n\nThe **`Document.contentType`** read-only property returns the\nMIME type that the document is being rendered as. This may come from HTTP headers or\nother sources of MIME information, and might be affected by automatic type conversions\nperformed by either the browser or extensions.\n\n> **Note:** This property is unaffected by `meta`\n> elements.",
      "cookie": "\n\nThe [Document] property `cookie` lets you read and write [cookies](/en-US/docs/Web/HTTP/Cookies) associated with the document.\nIt serves as a getter and setter for the actual values of the cookies.",
      "copy_event": "\n\nThe **`copy`** event fires when the user initiates a copy action through the browser's user interface.\n\nThe original target for this event is the [Element] that was the intended target of the copy action. You can listen for this event on the [Document] interface to handle it in the capture or bubbling phases. For full details on this event please see the page on the [Element: copy event](/en-US/docs/Web/API/Element/copy_event).",
      "createattribute": "\n\nThe **`Document.createAttribute()`** method creates a new\nattribute node, and returns it. The object created is a node implementing the\n[Attr] interface. The DOM does not enforce what sort of attributes can be\nadded to a particular element in this manner.\n\n> **Note:** The string given in parameter is converted to lowercase.",
      "createattributens": "\n\nThe **`Document.createAttributeNS()`** method creates a new attribute node\nwith the specified namespace URI and qualified name, and returns it.\nThe object created is a node implementing the\n[Attr] interface. The DOM does not enforce what sort of attributes can be\nadded to a particular element in this manner.",
      "createcdatasection": "\n\n**`createCDATASection()`** creates a new CDATA section node,\nand returns it.",
      "createcomment": "\n\n**`createComment()`** creates a new comment node, and returns\nit.",
      "createdocumentfragment": "\n\nCreates a new empty [DocumentFragment] into which\nDOM nodes can be added to build an offscreen DOM tree.",
      "createelement": "\n\nIn an [HTML](/en-US/docs/Web/HTML) document, the **`document.createElement()`** method creates the HTML element specified by _tagName_, or an [HTMLUnknownElement] if _tagName_ isn't recognized.",
      "createelementns": "\n\nCreates an element with the specified namespace URI and qualified name.\n\nTo create an element without specifying a namespace URI, use the\n[Document.createElement] method.",
      "createevent": "\n\n> **Warning:** Many methods used with `createEvent`, such as `initCustomEvent`, are deprecated.\n> Use [event constructors](/en-US/docs/Web/API/CustomEvent) instead.\n\nCreates an [event](/en-US/docs/Web/API/Event) of the type specified. The\nreturned object should be first initialized and can then be passed to\n[EventTarget.dispatchEvent].",
      "createexpression": "\n\nThis method compiles an [XPathExpression] which can then be used for (repeated) evaluations.\n\nYou must call this method on the same document that you run the expression against.",
      "createnodeiterator": "\n\nThe **`Document.createNodeIterator()`** method returns a new [`NodeIterator`](/en-US/docs/Web/API/NodeIterator) object.",
      "creatensresolver": "\n\nCreates an `XPathNSResolver` which resolves namespaces with respect to the definitions in scope for a specified node.",
      "createprocessinginstruction": "\n\n`createProcessingInstruction()` generates a new [processing instruction](/en-US/docs/Web/API/ProcessingInstruction) node and returns it.\n\nThe new node usually will be inserted into an XML document in order to accomplish anything with it, such as with [node.insertBefore].",
      "createrange": "\n\nThe **`Document.createRange()`** method returns a new\n[Range] object.",
      "createtextnode": "\n\nCreates a new [Text] node. This method can be used to escape HTML\ncharacters.",
      "createtouch": "\n\nThe **`Document.createTouch()`** method creates and returns a new [Touch] object.\n\n> **Note:** Use the [TouchEvent.TouchEvent] constructor.",
      "createtouchlist": "\n\nThe **`Document.createTouchList()`** method creates and returns a new [TouchList] object.",
      "createtreewalker": "\n\nThe **`Document.createTreeWalker()`** creator method returns a newly created [TreeWalker] object.",
      "currentscript": "\n\nThe **`Document.currentScript`** property returns the `script` element whose script is currently being processed and [isn't a JavaScript module](https://github.com/whatwg/html/issues/997). (For modules use [`import.meta`](/en-US/docs/Web/JavaScript/Reference/Operators/import.meta) instead.)\n\nIt's important to note that this will not reference the `script`\nelement if the code in the script is being called as a callback or event handler; it\nwill only reference the element while it's initially being processed.",
      "cut_event": "\n\nThe **`cut`** event fires when the user initiates a cut action through the browser's user interface.\n\nThe original target for this event is the [Element] that was the intended target of the cut action. You can listen for this event on the [Document] interface to handle it in the capture or bubbling phases. For full details on this event please see the page on the [Element: cut event](/en-US/docs/Web/API/Element/cut_event).",
      "defaultview": "\n\nIn browsers, **`document.defaultView`** returns the\n[Window] object associated with , or `null` if none is available.\n\nThis property is read-only.",
      "designmode": "\n\n**`document.designMode`** controls whether the entire document\nis editable. Valid values are `\"on\"` and `\"off\"`. According to the\nspecification, this property is meant to default to `\"off\"`. Firefox follows\nthis standard. The earlier versions of Chrome and IE default to `\"inherit\"`.\nStarting in Chrome 43, the default is `\"off\"` and `\"inherit\"` is\nno longer supported. In IE6-10, the value is capitalized.",
      "dir": "\n\nThe **`Document.dir`** property is a string\nrepresenting the directionality of the text of the document, whether left to right\n(default) or right to left. Possible values are `'rtl'`, right to left, and\n`'ltr'`, left to right.",
      "doctype": "\n\nReturns the Document Type Declaration (DTD) associated with current document. The\nreturned object implements the [DocumentType] interface. Use\n[DOMImplementation.createDocumentType] to create a\n`DocumentType`.\n\n- `doctype` is a read-only property.",
      "documentelement": "\n\n**`Document.documentElement`** returns the\n[Element] that is the root element of the [document] (for\nexample, the `html` element for HTML documents).",
      "documenturi": "\n\nThe **`documentURI`** read-only property of the\n[Document] interface returns the document location as a string.",
      "domain": " \n\nThe **`domain`** property of the [Document]\ninterface gets/sets the domain portion of the  of the current\ndocument, as used by the [same-origin policy](/en-US/docs/Web/Security/Same-origin_policy).",
      "domcontentloaded_event": "\n\nThe **`DOMContentLoaded`** event fires when the HTML document has been completely parsed, and all deferred scripts ([`<script defer src=\"…\">`](/en-US/docs/Web/HTML/Element/script#defer) and [`<script type=\"module\">`](/en-US/docs/Web/HTML/Element/script#module)) have downloaded and executed. It doesn't wait for other things like images, subframes, and async scripts to finish loading.\n\n`DOMContentLoaded` does not wait for stylesheets to load, however deferred scripts _do_ wait for stylesheets, and the `DOMContentLoaded` event is queued after deferred scripts. Also, scripts which aren't deferred or async (e.g. `<script>`) will wait for already-parsed stylesheets to load.\n\nA different event, [Window/load_event], should be used only to detect a fully-loaded page. It is a common mistake to use `load` where `DOMContentLoaded` would be more appropriate.\n\nThis event is not cancelable.",
      "elementfrompoint": "\n\nThe **`elementFromPoint()`**\nmethod, available on the [Document] object, returns the topmost [Element] at the specified coordinates\n(relative to the viewport).\n\nIf the element at the specified point belongs to another document (for example, the\ndocument of an `iframe`), that document's parent element is returned\n(the `<iframe>` itself). If the element at the given point is anonymous\nor XBL generated content, such as a textbox's scroll bars, then the first non-anonymous\nancestor element (for example, the textbox) is returned.\n\nElements with  set to `none` will be ignored,\nand the element below it will be returned.\n\nIf the method is run on another document (like an `<iframe>`'s\nsubdocument), the coordinates are relative to the document where the method is being\ncalled.\n\nIf the specified point is outside the visible bounds of the document or either\ncoordinate is negative, the result is `null`.\n\nIf you need to find the specific position inside the element, use\n[Document.caretPositionFromPoint].",
      "elementsfrompoint": "\n\nThe **`elementsFromPoint()`** method\nof the [Document] interface returns an array of all elements\nat the specified coordinates (relative to the viewport).\nThe elements are ordered from the topmost to the bottommost box of the viewport.\n\nIt operates in a similar way to the [Document.elementFromPoint] method.",
      "embeds": "\n\nThe **`embeds`** read-only property of the\n[Document] interface returns a list of the embedded\n`embed` elements within the current document.",
      "enablestylesheetsforset": "\n\nEnables the style sheets matching the specified name in the current style sheet set,\nand disables all other style sheets (except those without a title, which are always\nenabled).",
      "evaluate": "\n\nThe **`evaluate()`** method of the [Document] interface selects elements based on the [XPath](/en-US/docs/Web/XPath)\nexpression given in parameters.\n\nXPath expressions can be evaluated on both HTML and XML documents.",
      "execcommand": "\n\nThe **`execCommand`** method implements multiple different commands. Some of them provide access to the clipboard, while others are for editing [form inputs](/en-US/docs/Web/HTML/Element/input), [`contenteditable`](/en-US/docs/Web/HTML/Global_attributes/contenteditable) elements or entire documents (when switched to [design mode](/en-US/docs/Web/API/Document/designMode)).\n\nTo access the clipboard, the newer [Clipboard API](/en-US/docs/Web/API/Clipboard_API) is recommended over `execCommand()`. However, there is no replacement for the editing commands: unlike direct DOM manipulation, modifications performed by `execCommand()` preserve the undo buffer (edit history).\n\nMost commands affect the document's [selection](/en-US/docs/Web/API/Selection). For example, some commands (bold, italics, etc.) format the currently selected text, while others delete the selection, insert new elements (replacing the selection) or affect an entire line (indenting). Only the currently active editable element can be modified, but some commands (e.g. `copy`) can work without an editable element.\n\n> **Note:** Modifications performed by `execCommand()` may or may not trigger [Element/beforeinput_event] and [Element/input_event] events, depending on the browser and configuration. If triggered, the handlers for the events will run before `execCommand()` returns. Authors need to be careful about such recursive calls, especially if they call `execCommand()` in response to these events. From Firefox 82, nested `execCommand()` calls will always fail, see [bug 1634262](https://bugzil.la/1634262).",
      "exitfullscreen": "\n\nThe [Document] method\n**`exitFullscreen()`** requests that the element on this\ndocument which is currently being presented in fullscreen mode be taken out of\nfullscreen mode, restoring the previous state of the screen. This usually\nreverses the effects of a previous call to [Element.requestFullscreen].",
      "exitpictureinpicture": "\n\nThe **`exitPictureInPicture()`** method of the [Document] interface\nrequests that a video contained\nin this document, which is currently floating, be taken out of picture-in-picture\nmode, restoring the previous state of the screen. This usually reverses the\neffects of a previous call to [HTMLVideoElement.requestPictureInPicture].",
      "exitpointerlock": "\n\nThe **`exitPointerLock()`** method of the [Document] interface asynchronously releases a pointer lock previously requested through [Element.requestPointerLock].\n\n> **Note:** While the **`exitPointerLock()`** method is called on the document, the **`requestPointerLock()`** method is called on an element.\n\nTo track the success or failure of the request, it is necessary to listen for the [Document/pointerlockchange_event] and [Document/pointerlockerror_event] events.",
      "featurepolicy": "\n\nThe **`featurePolicy`** read-only property of the [Document] interface returns the [FeaturePolicy] interface which provides a simple API for inspecting the [Permissions Policies](/en-US/docs/Web/HTTP/Permissions_Policy) applied to a specific document.",
      "fgcolor": "\n\n**`fgColor`** gets/sets the foreground color, or text color, of\nthe current document.",
      "firstelementchild": "\n\nThe **`Document.firstElementChild`** read-only property\nreturns the document's first child [Element], or `null` if there\nare no child elements.\n\nFor HTML documents, this is usually the only child, the root `<html>` element.\n\nSee [Element.firstElementChild] for the first child element of specific elements within a document.",
      "fonts": "\n\nThe **`fonts`** property of the [Document] interface returns the [FontFaceSet] interface of the document.\n\nThis feature is part of the [CSS Font Loading API](/en-US/docs/Web/API/CSS_Font_Loading_API).",
      "forms": "\n\nThe **`forms`** read-only property of\nthe [Document] interface returns an [HTMLCollection] listing\nall the `form` elements contained in the document.\n\n> **Note:** Similarly, you can access a list of a form's component user\n> input elements using the [HTMLFormElement.elements] property.",
      "fragmentdirective": "\n\nThe **`fragmentDirective`** read-only property of the [Document] interface returns the [FragmentDirective] for the current document.",
      "fullscreen": "\n\nThe obsolete [Document] interface's **`fullscreen`** read-only property reports whether or not the document is currently displaying content in fullscreen mode.\n\nAlthough this property is read-only, it will not throw if it is modified (even in strict mode); the setter is a no-operation and it will be ignored.\n\n> **Note:** Since this property is deprecated, you can determine if fullscreen mode is active on the document by checking to see if [Document.fullscreenElement] is not `null`.",
      "fullscreenchange_event": "\n\nThe `fullscreenchange` event is fired immediately after the browser switches into or out of fullscreen mode.\n\nThe event is sent to the `Element` that is transitioning into or out of fullscreen mode, and this event then bubbles up to the `Document`.\n\nTo find out whether the `Element` is entering or exiting fullscreen mode, check the value of [Document.fullscreenElement]: if this value is `null` then the element is exiting fullscreen mode, otherwise it is entering fullscreen mode.\n\nThis event is not cancelable.",
      "fullscreenelement": "\n\nThe\n**`Document.fullscreenElement`** read-only\nproperty returns the [Element] that is currently being presented in\nfullscreen mode in this document, or `null` if fullscreen mode is not\ncurrently in use.\n\nAlthough this property is read-only, it will not throw if it is modified (even in\nstrict mode); the setter is a no-operation and it will be ignored.",
      "fullscreenenabled": "\n\nThe read-only **`fullscreenEnabled`**\nproperty on the [Document] interface indicates whether or not fullscreen\nmode is available.\n\nfullscreen mode is available only for a page that has no\nwindowed plug-ins in any of its documents, and if all `iframe` elements\nwhich contain the document have their [`allowfullscreen`](/en-US/docs/Web/HTML/Element/iframe#allowfullscreen)\nattribute set.\n\nAlthough this property is read-only, it will not throw if it is modified (even in\nstrict mode); the setter is a no-operation and it will be ignored.",
      "fullscreenerror_event": "\n\nThe `fullscreenerror` event is fired when the browser cannot switch to fullscreen mode.\n\nAs with the [`fullscreenchange` event](/en-US/docs/Web/API/Document/fullscreenchange_event), two `fullscreenerror` events are fired; the first is sent to the [Element] which failed to change modes, and the second is sent to the [Document] which owns that element.\n\nFor some reasons that switching into fullscreen mode might fail, see [the guide to the Fullscreen API](/en-US/docs/Web/API/Fullscreen_API/Guide).\n\nThis event is not cancelable.",
      "getanimations": "\n\nThe `getAnimations()` method of the [Document] interface\nreturns an array of all [Animation] objects currently in effect whose\ntarget elements are descendants of the document. This array includes [CSS Animations](/en-US/docs/Web/CSS/CSS_animations), [CSS Transitions](/en-US/docs/Web/CSS/CSS_transitions), and [Web Animations](/en-US/docs/Web/API/Web_Animations_API).",
      "getelementbyid": "\n\nThe **`getElementById()`** method of the [Document] interface returns an [Element] object representing the element whose [Element.id] property matches the specified string. Since element IDs are required to be unique if specified, they're a useful way to get access to a specific element quickly.\n\nIf you need to get access to an element which doesn't have an ID, you can use [Document.querySelector] to find the element using any .\n\n> **Note:** IDs should be unique inside a document. If two or more elements in a document have the same ID, this method returns the first element found.",
      "getelementsbyclassname": "\n\nThe **`getElementsByClassName`** method of\n[Document] interface returns an array-like object\nof all child elements which have all of the given class name(s).\n\nWhen called on\nthe [document] object, the complete document is searched, including the\nroot node. You may also call [Element.getElementsByClassName] on any element; it will return only elements which are\ndescendants of the specified root element with the given class name(s).\n\n> **Warning:** This is a live [HTMLCollection]. Changes in the DOM will\n> reflect in the array as the changes occur. If an element selected by this array no\n> longer qualifies for the selector, it will automatically be removed. Be aware of this\n> for iteration purposes.",
      "getelementsbyname": "\n\nThe **`getElementsByName()`** method\nof the [Document] object returns a [NodeList] Collection of\nelements with a given `name` attribute in the document.",
      "getelementsbytagname": "\n\nThe **`getElementsByTagName`** method of\n[Document] interface returns an\n[HTMLCollection] of elements with the given tag name.\n\nThe complete\ndocument is searched, including the root node. The returned `HTMLCollection`\nis live, meaning that it updates itself automatically to stay in sync with the DOM tree\nwithout having to call `document.getElementsByTagName()` again.",
      "getelementsbytagnamens": "\n\nReturns a list of elements with the given tag name belonging to the given namespace.\nThe complete document is searched, including the root node.",
      "getselection": "\n\nThe **`getSelection()`** method of\nthe [Document] interface returns a [Selection]\nobject representing the range of text selected by the user, or the current position of\nthe caret.",
      "hasfocus": "\n\nThe **`hasFocus()`** method of the [Document] interface returns a boolean value indicating whether the document or any element inside the document has focus.\nThis method can be used to determine whether the active element in a document has focus.\n\n> **Note:** When viewing a document, an element with focus is always the [active element](/en-US/docs/Web/API/Document/activeElement) in the document, but an active element does not necessarily have focus.\n> For example, an active element within a popup window that is not the foreground doesn't have focus.",
      "hasstorageaccess": "\n\nThe **`hasStorageAccess()`** method of the [Document] interface returns a `Promise` that resolves with a boolean value indicating whether the document has access to [third-party](/en-US/docs/Web/HTTP/Cookies#third-party_cookies), [unpartitioned](/en-US/docs/Web/API/Storage_Access_API#unpartitioned_versus_partitioned_cookies) cookies.\n\nThis method is part of the [Storage Access API](/en-US/docs/Web/API/Storage_Access_API).",
      "head": "\n\nThe **`head`** read-only property of\nthe [Document] interface returns the `head` element of\nthe current document.",
      "hidden": "\n\nThe **`Document.hidden`** read-only property returns a Boolean\nvalue indicating if the page is considered hidden or not.\n\nThe [Document.visibilityState] property provides an alternative way to determine whether the page is hidden.",
      "images": "\n\nThe **`images`** read-only property of\nthe [Document] interface returns a [collection](/en-US/docs/Web/API/HTMLCollection) of the [images](/en-US/docs/Web/API/HTMLImageElement/Image) in the current HTML document.",
      "implementation": "\n\nThe **`Document.implementation`** property returns a\n[DOMImplementation] object associated with the current document.",
      "importnode": "\n\nThe [Document] object's **`importNode()`** method creates a copy of a\n[Node] or [DocumentFragment] from another document, to be\ninserted into the current document later.\n\nThe imported node is not yet included in the document tree. To include it, you need to\ncall an insertion method such as [Node.appendChild] or\n[Node.insertBefore] with a node that _is_\ncurrently in the document tree.\n\nUnlike [document.adoptNode], the original node is not removed from its\noriginal document. The imported node is a clone of the original.",
      "lastelementchild": "\n\nThe **`Document.lastElementChild`** read-only property\nreturns the document's last child [Element], or `null` if there\nare no child elements.\n\nFor HTML documents, this is usually the only child, the root `<html>` element.\n\nSee [Element.lastElementChild] for the last child element of specific elements within a document.",
      "lastmodified": "\n\nThe **`lastModified`** property of the [Document]\ninterface returns a string containing the date and local time on which the current document\nwas last modified.",
      "laststylesheetset": "\n\nThe **`Document.lastStyleSheetSet`** property returns the last enabled style sheet set. This property's\nvalue changes whenever the [document.selectedStyleSheetSet] property is\nchanged.",
      "linkcolor": " \n\nThe **`Document.linkColor`** property gets/sets the color of\nlinks within the document.\n\nThis property is deprecated. As an alternative, you can set the CSS\n`color` property on either HTML anchor links (`a`) or on\n pseudo-classes. Another alternative is\n`document.body.link`, although this is [deprecated in HTML 4.01](https://www.w3.org/TR/html401/struct/global.html#adef-link).",
      "links": "\n\nThe **`links`** read-only property of the [Document] interface returns a collection of all `area` elements and `a` elements in a document with a value for the [href](/en-US/docs/Web/HTML/Element/a#href) attribute.",
      "location": "\n\nThe **`Document.location`** read-only property returns a\n[Location] object, which contains information about the URL of the document\nand provides methods for changing that URL and loading another URL.\n\nThough `Document.location` is a _read-only_ `Location`\nobject, you can also assign a string to it. This means that you can\nwork with document.location as if it were a string in most cases:\n`document.location = 'http://www.example.com'` is a synonym of\n`document.location.href = 'http://www.example.com'`. If you assign another\nstring to it, browser will load the website you assigned.\n\nTo retrieve just the URL as a string, the read-only [document.URL]\nproperty can also be used.\n\nIf the current document is not in a browsing context, the returned value is\n`null`.",
      "mozsetimageelement": "\n\nThe **`Document.mozSetImageElement()`** method changes the\nelement being used as the CSS background for a background with a given background\nelement ID.",
      "open": "\n\nThe **`Document.open()`** method opens a document for\n[Document.write].\n\nThis does come with some side effects. For example:\n\n- All event listeners currently registered on the document, nodes inside the document,\n  or the document's window are removed.\n- All existing nodes are removed from the document.",
      "paste_event": "\n\nThe **`paste`** event fires when the user initiates a paste action through the browser's user interface.\n\nThe original target for this event is the [Element] that was the intended target of the paste action. You can listen for this event on the [Document] interface to handle it in the capture or bubbling phases. For full details on this event please see the page on the [Element: paste event](/en-US/docs/Web/API/Element/paste_event).",
      "pictureinpictureelement": "\n\nThe read-only **`pictureInPictureElement`** property of the [Document]\ninterface returns the [Element] that is currently being\npresented in picture-in-picture mode in this document, or `null` if\npicture-in-picture mode is not currently in use.\n\nAlthough this property is read-only, it will not throw if it is modified (even in\nstrict mode); the setter is a no-operation and will be ignored.",
      "pictureinpictureenabled": "\n\nThe read-only\n**`pictureInPictureEnabled`** property of the\n[Document] interface indicates whether or not picture-in-picture mode is\navailable.\n\nPicture-in-Picture mode is available by default unless specified\notherwise by a [Permissions-Policy](/en-US/docs/Web/HTTP/Headers/Permissions-Policy/picture-in-picture).\n\nAlthough this property is read-only, it will not throw if it is modified (even in\nstrict mode); the setter is a no-operation and will be ignored.",
      "plugins": "\n\nThe **`plugins`** read-only property of the\n[Document] interface returns an [HTMLCollection] object\ncontaining one or more [HTMLEmbedElement]s representing the\n`embed` elements in the current document.\n\n> **Note:** For a list of installed plugins, use [Navigator.plugins](/en-US/docs/Web/API/Navigator/plugins)\n> instead.",
      "pointerlockchange_event": "\n\nThe **`pointerlockchange`** event is fired when the pointer is locked/unlocked.\n\nThe event handler can use [Document.pointerLockElement] to determine whether the pointer is locked, and if so, to which element it is locked.\n\nThis event is not cancelable and does not bubble.",
      "pointerlockelement": "\n\nThe **`pointerLockElement`** read-only property of the [Document] interface provides the element set as the target for mouse events while the pointer is locked.\nIt is `null` if lock is pending, pointer is unlocked, or the target is in another document.",
      "pointerlockerror_event": "\n\nThe **`pointerlockerror`** event is fired when locking the pointer failed (for technical reasons or because the permission was denied).\n\nThis event is not cancelable and does not bubble.",
      "preferredstylesheetset": "\n\nThe **`preferredStyleSheetSet`** property returns the preferred style sheet set as set by the page\nauthor.",
      "prepend": "\n\nThe **`Document.prepend()`** method\ninserts a set of [Node] objects or string objects before\nthe first child of the document. String objects\nare inserted as equivalent [Text] nodes.\n\nThis method prepends a child to a `Document`. To prepend to an arbitrary element in the tree, see [Element.prepend].",
      "prerendering": "\n\nThe `prerendering` read-only property of the [Document] interface returns `true` if the document is currently in the process of prerendering, as initiated via the [Speculation Rules API](/en-US/docs/Web/API/Speculation_Rules_API).",
      "prerenderingchange_event": "\n\nThe `prerenderingchange` event is fired on a prerendered document when it is activated (i.e. the user views the page).",
      "querycommandenabled": "\n\nThe **`Document.queryCommandEnabled()`** method reports whether\nor not the specified editor command is enabled by the browser.",
      "querycommandstate": "\n\nThe **`queryCommandState()`** method will tell you if the current selection has a certain [Document.execCommand] command applied.",
      "querycommandsupported": "\n\nThe **`Document.queryCommandSupported()`** method reports\nwhether or not the specified editor command is supported by the browser.",
      "queryselector": "\n\nThe [Document] method **`querySelector()`**\nreturns the first [Element] within the document that matches the specified\nselector, or group of selectors. If no matches are found, `null` is returned.\n\n> **Note:** The matching is done using depth-first pre-order traversal of\n> the document's nodes starting with the first element in the document's markup and\n> iterating through sequential nodes by order of the number of child nodes.",
      "queryselectorall": "\n\nThe [Document] method **`querySelectorAll()`**\nreturns a static (not live) [NodeList] representing a list of the\ndocument's elements that match the specified group of selectors.",
      "readystate": "\n\nThe **`Document.readyState`** property describes the loading state of the [document].\nWhen the value of this property changes, a [Document/readystatechange_event] event fires on the [document] object.",
      "readystatechange_event": "\n\nThe **`readystatechange`** event is fired when the [Document.readyState] attribute of a document has changed.\n\nThis event is not cancelable and does not bubble.",
      "referrer": "\n\nThe **`Document.referrer`** property returns the [URI](https://www.w3.org/Addressing/#background) of the page that linked to\nthis page.",
      "releasecapture": "\n\nThe **`releaseCapture()`** method releases mouse capture if\nit's currently enabled on an element within this document.\nOnce mouse capture is released, mouse events will no longer all be directed to the element on which capture is enabled.\n\nEnabling mouse capture on an element is done by calling [element.setCapture].",
      "replacechildren": "\n\nThe **`Document.replaceChildren()`** method replaces the\nexisting children of a `Document` with a specified new set of children.",
      "requeststorageaccess": "\n\nThe **`requestStorageAccess()`** method of the [Document] interface allows content loaded in a third-party context (i.e., embedded in an `iframe`) to request access to third-party cookies. This is relevant to user agents that, by default, block access to [third-party](/en-US/docs/Web/HTTP/Cookies#third-party_cookies), [unpartitioned](/en-US/docs/Web/API/Storage_Access_API#unpartitioned_versus_partitioned_cookies) cookies to improve privacy (e.g., to prevent tracking), and is part of the [Storage Access API](/en-US/docs/Web/API/Storage_Access_API).\n\nTo check whether permission to access third-party cookies has already been granted, you can call [Permissions.query], specifying the feature name `\"storage-access\"`.\n\n> **Note:** Usage of this feature may be blocked by a  [Permissions Policy](/en-US/docs/Web/HTTP/Permissions_Policy) set on your server. In addition, the document must pass additional browser-specific checks such as allowlists, blocklists, on-device classification, user settings, anti-[clickjacking](/en-US/docs/Glossary/Clickjacking) heuristics, or prompting the user for explicit permission.",
      "requeststorageaccessfor": "\n\nThe **`requestStorageAccessFor()`** method of the [Document] interface allows top-level sites to request third-party cookie access on behalf of embedded content originating from another site in the same [related website set](/en-US/docs/Web/API/Storage_Access_API/Related_website_sets). It returns a `Promise` that resolves if the access was granted, and rejects if access was denied.",
      "rootelement": "\n\n**`Document.rootElement`** returns the [Element]\nthat is the root element of the [document] if it is an\n element, otherwise `null`. It is deprecated in favor of\n[Document.documentElement], which returns the root element for all\ndocuments.",
      "scripts": "\n\nThe **`scripts`** property of the [Document]\ninterface returns a list of the `script`\nelements in the document. The returned object is an\n[HTMLCollection].",
      "scroll_event": "\n\nThe **`scroll`** event fires when the document view has been scrolled.\nTo detect when scrolling has completed, see the .\nFor element scrolling, see .",
      "scrollend_event": "\n\nThe **`scrollend`** event fires when the document view has completed scrolling.\nScrolling is considered completed when the scroll position has no more pending updates and the user has completed their gesture.\n\nScroll position updates include smooth or instant mouse wheel scrolling, keyboard scrolling, scroll-snap events, or other APIs and gestures which cause the scroll position to update.\nUser gestures like touch panning or trackpad scrolling aren't complete until pointers or keys have released.\nIf the scroll position did not change, then no scrollend event fires.\n\nFor detecting when scrolling inside an element is complete, see .",
      "scrollingelement": "\n\nThe **`scrollingElement`** read-only property of the\n[Document] interface returns a reference to the [Element] that\nscrolls the document. In standards mode, this is the root element of the\ndocument, [document.documentElement].\n\nWhen in quirks mode, the `scrollingElement` attribute returns the HTML\n`body` element if it exists and is [potentially scrollable](https://drafts.csswg.org/cssom-view/#potentially-scrollable), otherwise it returns null.",
      "securitypolicyviolation_event": "\n\nThe **`securitypolicyviolation`** event is fired when a [Content Security Policy](/en-US/docs/Web/HTTP/CSP) is violated.\n\nThe event is fired on the global scope when violates the policy and will bubble to the [Window] object. The event may also bubble from [Node] contained in the document tree.\n\nThe handler can be assigned using the `onsecuritypolicyviolation` event handler property or using [EventTarget.addEventListener].\n\n> **Note:** It is recommended to add the handler for this event to a top level object (i.e. [Window] or [Document]). While the property exists in HTML elements, you can't assign a handler to the property until the elements have been loaded, by which time this event will already have fired.",
      "selectedstylesheetset": "\n\nThe **`selectedStyleSheetSet`** property indicates the name of the style sheet set that's currently in use.",
      "selectionchange_event": "\n\nThe **`selectionchange`** event of the [Selection API](/en-US/docs/Web/API/Selection) is fired when the current [Selection] of a [Document] is changed.\n\nThis event is not cancelable and does not bubble.\n\nThe event can be handled by adding an event listener for `selectionchange` or using the `onselectionchange` event handler.\n\n> **Note:** This event is not quite the same as the `selectionchange` events fired when the text selection in an `input` or `textarea` element is changed. See [HTMLInputElement.selectionchange_event] for more details.",
      "startviewtransition": "\n\nThe **`startViewTransition()`** method of the\n[View Transitions API] starts a new view transition and returns a [ViewTransition] object to represent it.\n\nWhen `startViewTransition()` is invoked, a sequence of steps is followed as explained in [The view transition process](/en-US/docs/Web/API/View_Transitions_API#the_view_transition_process).",
      "stylesheets": "\n\nThe **`styleSheets`** read-only property of the [Document] interface returns a [StyleSheetList] of [CSSStyleSheet] objects, for stylesheets explicitly linked into or embedded in a document.",
      "stylesheetsets": "\n\nThe **`styleSheetSets`** read-only property returns a live list of all of the currently-available style sheet sets.",
      "timeline": "\n\nThe `timeline` readonly property of the [Document] interface represents the default timeline of the current document. This timeline is a special instance of [DocumentTimeline].\n\nThis timeline is unique to each `document` and persists for the lifetime of the `document` including calls to [Document.open].\n\nThis timeline expresses the time in milliseconds since [Performance.timeOrigin].\nPrior to the time origin, the timeline is inactive, and its [AnimationTimeline.currentTime] is `null`.\n\n> **Note:** A document timeline that is associated with a non-active document (a [Document] not associated with a [Window], `iframe`, or `frame`) is also considered to be inactive.",
      "title": "\n\nThe **`document.title`** property gets or sets the current title of the document.\nWhen present, it defaults to the value of the [`<title>`](/en-US/docs/Web/HTML/Element/title).",
      "url": "\n\nThe **`URL`** read-only property of the [Document]\ninterface returns the document location as a string.",
      "visibilitychange_event": "\n\nThe `visibilitychange` event is fired at the document when the contents of its tab have become visible or have been hidden.\n\nThe event is not cancelable.",
      "visibilitystate": "\n\nThe **`Document.visibilityState`**\nread-only property returns the visibility of the document. It can be used to check whether the document is in the background or in a minimized window, or is otherwise not visible to the user.\n\nWhen the value of this property changes, the [Document/visibilitychange_event] event is sent to the [Document].\n\nThe [Document.hidden] property provides an alternative way to determine whether the page is hidden.",
      "vlinkcolor": " \n\nThe **`Document.vlinkColor`** property gets/sets the color of\nlinks that the user has visited in the document.",
      "write": "\n\n> **Warning:** Use of the `document.write()` method is strongly discouraged.\n>\n> As [the HTML spec itself warns](<https://html.spec.whatwg.org/multipage/dynamic-markup-insertion.html#document.write()>):\n>\n> > This method has very idiosyncratic behavior. In some cases, this method can affect the state of the [HTML parser](https://html.spec.whatwg.org/multipage/parsing.html#html-parser) while the parser is running, resulting in a DOM that does not correspond to the source of the document (e.g. if the string written is the string \"`<plaintext>`\" or \"`<!--`\"). In other cases, the call can clear the current page first, as if [`document.open()`](https://html.spec.whatwg.org/multipage/dynamic-markup-insertion.html#dom-document-open) had been called. In yet more cases, the method is simply ignored, or throws an exception. Users agents are [explicitly allowed to avoid executing `script` elements inserted via this method](https://html.spec.whatwg.org/multipage/parsing.html#document-written-scripts-intervention). And to make matters even worse, the exact behavior of this method can in some cases be dependent on network latency, which can lead to failures that are very hard to debug. For all these reasons, use of this method is strongly discouraged.\n> > Therefore, avoid using `document.write()` — and if possible, update any existing code that is still using it.\n\nThe **`document.write()`** method writes a string of text to a document stream opened by [document.open].\n\n> **Note:** Because `document.write()` writes to the document **stream**, calling `document.write()` on a closed (loaded) document automatically calls `document.open()`, [which will clear the document](/en-US/docs/Web/API/Document/open#notes).",
      "writeln": "\n\n> **Warning:** Use of the `document.writeln()` method is strongly discouraged.\n>\n> As [the HTML spec itself warns](<https://html.spec.whatwg.org/multipage/dynamic-markup-insertion.html#document.write()>):\n>\n> > This method has very idiosyncratic behavior. In some cases, this method can affect the state of the [HTML parser](https://html.spec.whatwg.org/multipage/parsing.html#html-parser) while the parser is running, resulting in a DOM that does not correspond to the source of the document (e.g. if the string written is the string \"`<plaintext>`\" or \"`<!--`\"). In other cases, the call can clear the current page first, as if [`document.open()`](https://html.spec.whatwg.org/multipage/dynamic-markup-insertion.html#dom-document-open) had been called. In yet more cases, the method is simply ignored, or throws an exception. Users agents are [explicitly allowed to avoid executing `script` elements inserted via this method](https://html.spec.whatwg.org/multipage/parsing.html#document-written-scripts-intervention). And to make matters even worse, the exact behavior of this method can in some cases be dependent on network latency, which can lead to failures that are very hard to debug. For all these reasons, use of this method is strongly discouraged.\n> > Therefore, avoid using `document.writeln()` — and if possible, update any existing code that is still using it.\n\nWrites a string of text followed by a newline character to a document.",
      "xmlencoding": "\n\nReturns the encoding as determined by the XML declaration. Should be `null` if unspecified or unknown.\n\n> **Warning:** Do not use this attribute; it has been removed from the DOM Level 4 specification and is no longer supported in Firefox 10.0.\n\nConsider the following XML Declaration:\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-16\"?>\n```\n\nThen, the result should be \"UTF-16\".",
      "xmlversion": "\n\nReturns the version number as specified in the XML declaration (e.g., `<?xml version=\"1.0\"?>`) or \"1.0\" if the declaration is absent.\n\nThis attribute was never really useful, since it always returned 1.0, and has been removed in DOM Level 4. As such, Firefox 10 no longer implements it. Its primary use in the past was to detect whether or not the document was being rendered as XML rather than HTML. To detect this, you can create an element with its name in lower case, then check to see if it gets converted into all upper case (in which case the document is in the non-XML HTML mode):\n\n```js\nif (document.createElement(\"foo\").tagName === \"FOO\") {\n  /* Document is not XML */\n}\n```"
    }
  },
  "documentfragment": {
    "docs": "\n\nThe **`DocumentFragment`** interface represents a minimal document object that has no parent.\n\nIt is used as a lightweight version of [Document] that stores a segment of a document structure comprised of nodes just like a standard document. The key difference is due to the fact that the document fragment isn't part of the active document tree structure. Changes made to the fragment don't affect the document.\n\n",
    "properties": {
      "append": "\n\nThe **`DocumentFragment.append()`** method\ninserts a set of [Node] objects or string objects after\nthe last child of the document fragment. String objects\nare inserted as equivalent [Text] nodes.\n\nThis method appends a child to a `DocumentFragment`. To append to an arbitrary element in the tree, see [Element.append].",
      "childelementcount": "\n\nThe **`DocumentFragment.childElementCount`** read-only property\nreturns the number of child elements of a `DocumentFragment`.\n\nTo get the number of children of a specific element, see [Element.childElementCount].",
      "children": "\n\nThe read-only **`children`** property returns a live [HTMLCollection]\nwhich contains all of the child [Element] of the document fragment upon which it was called.",
      "firstelementchild": "\n\nThe **`DocumentFragment.firstElementChild`** read-only property\nreturns the document fragment's first child [Element], or `null` if there\nare no child elements.",
      "getelementbyid": "\n\nThe **`getElementById()`** method of the [DocumentFragment] returns an [Element] object representing the element whose [Element.id] property matches the specified string. Since element IDs are required to be unique if specified, they're a useful way to get access to a specific element quickly.\n\nIf you need to get access to an element which doesn't have an ID, you can use [Document.querySelector] to find the element using any .\n\n> **Note:** IDs should be unique inside a document fragment. If two or more elements in a document fragment have the same ID, this method returns the first element found.",
      "lastelementchild": "\n\nThe **`DocumentFragment.lastElementChild`** read-only property\nreturns the document fragment's last child [Element], or `null` if there\nare no child elements.",
      "prepend": "\n\nThe **`DocumentFragment.prepend()`** method\ninserts a set of [Node] objects or string objects before\nthe first child of the document fragment. String objects\nare inserted as equivalent [Text] nodes.\n\nThis method prepends a child to a `DocumentFragment`. To prepend to an arbitrary element in the tree, see [Element.prepend].",
      "queryselector": "\n\nThe **`DocumentFragment.querySelector()`** method returns the\nfirst element, or `null` if no matches are found, within the\n[DocumentFragment] (using depth-first pre-order traversal of the\ndocument's nodes) that matches the specified group of selectors.\n\nIf the selector matches an ID and this ID is erroneously used several times in the\ndocument, it returns the first matching element.\n\nIf the selectors specified in parameter are invalid a [DOMException] with\na `SYNTAX_ERR` value is raised.",
      "queryselectorall": "\n\nThe **`DocumentFragment.querySelectorAll()`** method returns a\n[NodeList] of elements within the [DocumentFragment] (using\ndepth-first pre-order traversal of the document's nodes) that matches the specified\ngroup of selectors.\n\nIf the selectors specified in parameter are invalid a [DOMException] with\na `SYNTAX_ERR` value is raised.",
      "replacechildren": "\n\nThe **`DocumentFragment.replaceChildren()`** method replaces the\nexisting children of a `DocumentFragment` with a specified new set of children. These\ncan be string or [Node] objects."
    }
  },
  "documentpictureinpicture": {
    "docs": "\n\nThe **`DocumentPictureInPicture`** interface of the  is the entry point for creating and handling document picture-in-picture windows.\n\nIt is accessed via the [Window.documentPictureInPicture] property.\n\n",
    "properties": {
      "enter_event": "\n\nThe **`enter`** event of the [DocumentPictureInPicture] interface is fired when the Picture-in-Picture window is successfully opened.",
      "requestwindow": "\n\nThe **`requestWindow()`** method of the\n[DocumentPictureInPicture] interface opens the Picture-in-Picture window for the current main browsing context. It returns a `Promise` that fulfills with a [Window] instance representing the browsing context inside the Picture-in-Picture window.\n\nThe `requestWindow()` method requires [transient activation](/en-US/docs/Glossary/Transient_activation), i.e. it must be invoked in response to a user action such as a mouse click or button press.",
      "window": "\n\nThe **`window`** read-only property of the\n[DocumentPictureInPicture] interface returns a [Window] instance representing the browsing context inside the Picture-in-Picture window."
    }
  },
  "documentpictureinpictureevent": {
    "docs": "\n\nThe **`DocumentPictureInPictureEvent`** interface of the  is the event object for the [DocumentPictureInPicture/enter_event] event, which fires when the Picture-in-Picture window is opened.\n\n",
    "properties": {
      "window": "\n\nThe **`window`** read-only property of the\n[DocumentPictureInPictureEvent] interface returns a [Window] instance representing the browsing context inside the `DocumentPictureInPicture` window the event was fired on."
    }
  },
  "documenttimeline": {
    "docs": "\n\nThe **`DocumentTimeline`** interface of the [Web Animations API](/en-US/docs/Web/API/Web_Animations_API) represents animation timelines, including the default document timeline (accessed via [Document.timeline]).\n\n"
  },
  "documenttype": {
    "docs": "\n\nThe **`DocumentType`** interface represents a [Node] containing a doctype.\n\n",
    "properties": {
      "after": "\n\nThe **`DocumentType.after()`** method inserts a set of\n[Node] objects or strings in the children list of the\n`DocumentType`'s parent, just after the `DocumentType`.\nStrings are inserted as equivalent [Text] nodes.",
      "before": "\n\nThe **`DocumentType.before()`** method inserts a set of\n[Node] objects or strings in the children list of the\n`DocumentType`'s parent, just before the `DocumentType`.\nStrings are inserted as equivalent [Text] nodes.",
      "name": "\n\nThe read-only **`name`** property of the [DocumentType] returns the type of the document.\n\nFor synthetic `DocumentType`, this property reflects the value given in parameter to [DOMImplementation.createDocumentType].\n\nFor HTML documents, browsers always set it up to `html`, whatever the actual `DOCTYPE` in the source code is.",
      "publicid": "\n\nThe read-only **`publicId`** property of the [DocumentType] returns a formal identifier of the document.\n\nFor synthetic `DocumentType`, this property reflects the value given in parameter to [DOMImplementation.createDocumentType].\n\nFor HTML documents, browsers always set it up to `html`, whatever the actual `DOCTYPE` in the source code is. For SVG documents, for example, it can be `\"-//W3C//DTD SVG 1.1//EN\"`.",
      "remove": "\n\nThe **`DocumentType.remove()`** method removes a document's `doctype`.",
      "replacewith": "\n\nThe **`DocumentType.replaceWith()`** method replaces the document type with a set of given nodes.",
      "systemid": "\n\nThe read-only **`systemId`** property of the [DocumentType] returns the URL of the associated DTD.\n\nFor synthetic `DocumentType`, this property reflects the value given in parameter to [DOMImplementation.createDocumentType].\n\nFor HTML documents, browsers always set it up to `html`, whatever the actual `DOCTYPE` in the source code is. For SVG documents, for example, it can be `\"http://www.w3.org/2000/svg\"`."
    }
  },
  "domerror": {
    "docs": "\n\nThe **`DOMError`** interface describes an error object that contains an error name."
  },
  "domexception": {
    "docs": "\n\nThe **`DOMException`** interface represents an abnormal event (called an **exception**) that occurs as a result of calling a method or accessing a property of a web API. This is how error conditions are described in web APIs.\n\nEach exception has a **name**, which is a short \"PascalCase\"-style string identifying the error or abnormal condition.\n\n`DOMException` is a , so it can be cloned with [structuredClone] or copied between [Workers](/en-US/docs/Web/API/Worker) using [Worker.postMessage].",
    "properties": {
      "code": " \n\nThe **`code`** read-only property of the [DOMException] interface returns one of the legacy [error code constants](/en-US/docs/Web/API/DOMException#error_names), or `0` if none match.\n\nThis field is used for historical reasons. New DOM exceptions don't use this anymore: they put this info in the [DOMException.name] attribute.",
      "message": "\n\nThe **`message`** read-only property of the\n[DOMException] interface returns a string representing\na message or description associated with the given [error name](/en-US/docs/Web/API/DOMException#error_names).",
      "name": "\n\nThe **`name`** read-only property of the\n[DOMException] interface returns a string that contains\none of the strings associated with an [error name](/en-US/docs/Web/API/DOMException#error_names)."
    }
  },
  "domhighrestimestamp": {
    "docs": "\n\nThe **`DOMHighResTimeStamp`** type is a `double` and is used to store a time value in milliseconds.\n\nThis type can be used to describe a discrete point in time or a time interval (the difference in time between two discrete points in time). The starting time can be either a specific time determined by the script for a site or app, or the [time origin](/en-US/docs/Web/API/Performance/timeOrigin).\n\nThe time, given in milliseconds, should be accurate to 5 µs (microseconds), with the fractional part of the number indicating fractions of a millisecond. However, if the browser is unable to provide a time value accurate to 5 µs (due, for example, to hardware or software constraints), the browser can represent the value as a time in milliseconds accurate to a millisecond. Also note the section below on reduced time precision controlled by browser preferences to avoid timing attacks and [fingerprinting](/en-US/docs/Glossary/Fingerprinting).\n\nFurther, if the device or operating system the user agent is running on doesn't have a clock accurate to the microsecond level, they may only be accurate to the millisecond."
  },
  "domimplementation": {
    "docs": "\n\nThe **`DOMImplementation`** interface represents an object providing methods which are not dependent on any particular document. Such an object is returned by the [Document.implementation] property.",
    "properties": {
      "createdocument": "\n\nThe **`DOMImplementation.createDocument()`** method creates and\nreturns an [XMLDocument].",
      "createdocumenttype": "\n\nThe **`DOMImplementation.createDocumentType()`** method returns\na [DocumentType] object which can either be used with\n[DOMImplementation.createDocument] upon document creation or can be put\ninto the document via methods like [Node.insertBefore] or\n[Node.replaceChild].",
      "createhtmldocument": "\n\nThe\n**`DOMImplementation.createHTMLDocument()`** method creates a\nnew HTML [Document].",
      "hasfeature": "\n\nThe\n**`DOMImplementation.hasFeature()`** method returns a\nboolean flag indicating if a given feature is supported. It is\ndeprecated and modern browsers return `true` in all cases.\n\nThe different implementations fairly diverged in what kind of features were reported.\nThe latest version of the spec settled to force this method to always return\n`true`, where the functionality was accurate and in use."
    }
  },
  "dommatrix": {
    "docs": "\n\nThe **`DOMMatrix`** interface represents 4×4 matrices, suitable for 2D and 3D operations including rotation and translation. It is a mutable version of the [DOMMatrixReadOnly] interface.\n\n**`WebKitCSSMatrix`** and **`SVGMatrix`** are aliases to **`DOMMatrix`**.\n\nThis interface should be available inside [web workers](/en-US/docs/Web/API/Web_Workers_API), though some implementations don't allow it yet.\n\n"
  },
  "dommatrixreadonly": {
    "docs": "\n\nThe **`DOMMatrixReadOnly`** interface represents a read-only 4×4 matrix, suitable for 2D and 3D operations. The [DOMMatrix] interface — which is based upon `DOMMatrixReadOnly`—adds [mutability](https://en.wikipedia.org/wiki/Immutable_object), allowing you to alter the matrix after creating it.\n\nThis interface should be available inside [web workers](/en-US/docs/Web/API/Web_Workers_API), though some implementations doesn't allow it yet.",
    "properties": {
      "flipx": "\n\nThe `flipX()` method of the [DOMMatrixReadOnly] interface creates a new matrix being the result of the original matrix flipped about the x-axis.",
      "scale": "\n\nThe **`scale()`** method of the\n[DOMMatrixReadOnly] interface creates a new matrix being the result of the\noriginal matrix with a scale transform applied.",
      "translate": "\n\nThe `translate()` method of the [DOMMatrixReadOnly] interface\ncreates a new matrix being the result of the original matrix with a translation applied."
    }
  },
  "domparser": {
    "docs": "\n\nThe **`DOMParser`** interface provides\nthe ability to parse  or  source code from a\nstring into a DOM [Document].\n\nYou can perform the opposite operation—converting a DOM tree into XML or HTML\nsource—using the [XMLSerializer] interface.\n\nIn the case of an HTML document, you can also replace portions of the DOM with new DOM\ntrees built from HTML by setting the value of the [Element.innerHTML] and\n[Element.outerHTML] properties. These properties can also be\nread to fetch HTML fragments corresponding to the corresponding DOM subtree.\n\nNote that [XMLHttpRequest] can parse XML and HTML directly\nfrom a URL-addressable resource, returning a `Document` in its\n[XMLHttpRequest.response] property.\n\n> **Note:** Be aware that [block-level elements](/en-US/docs/Glossary/Block-level_content)\n> like `<p>` will be automatically closed if another\n> block-level element is nested inside and therefore parsed before the closing `</p>` tag.",
    "properties": {
      "parsefromstring": "\n\nThe **`parseFromString()`** method of the [DOMParser] interface parses a string containing either HTML or XML, returning an [HTMLDocument] or an [XMLDocument]."
    }
  },
  "dompoint": {
    "docs": "\n\nA **`DOMPoint`** object represents a 2D or 3D point in a coordinate system; it includes values for the coordinates in up to three dimensions, as well as an optional perspective value. `DOMPoint` is based on [DOMPointReadOnly] but allows its properties' values to be changed.\n\nIn general, a positive `x` component represents a position to the right of the origin, a positive `y` component is downward from the origin, and a positive `z` component extends outward from the screen (in other words, toward the user).\n\n",
    "properties": {
      "frompoint_static": "\n\nThe **[DOMPoint]** static method\n`fromPoint()` creates and returns a new mutable `DOMPoint`\nobject given a source point.\n\nYou can also create a new `DOMPoint` object using the\n[DOMPoint.DOMPoint] constructor.\n\nAlthough this interface is based on `DOMPointReadOnly`, it is not read-only;\nthe properties within may be changed at will.",
      "w": "\n\nThe **`DOMPoint`** interface's\n**`w`** property holds the point's perspective value, w, for a\npoint in space.",
      "x": "\n\nThe **`DOMPoint`** interface's\n**`x`** property holds the horizontal coordinate, x, for a\npoint in space.\n\nIn general, positive values `x` mean to the right,\nand negative values of `x` means to the left, barring any transforms that may\nhave altered the orientation of the axes.",
      "y": "\n\nThe **`DOMPoint`** interface's\n**`y`** property holds the vertical coordinate, _y_,\nfor a point in space.\n\nUnless transforms have been applied to alter the\norientation, the value of `y` increases downward and decreases upward.",
      "z": "\n\nThe **`DOMPoint`** interface's\n**`z`** property specifies the depth coordinate of a point in\nspace.\n\nUnless transforms have changed the orientation, a `z` of 0 is\nthe plane of the screen, with positive values extending outward toward the user from the\nscreen, and negative values receding into the distance behind the screen."
    }
  },
  "dompointreadonly": {
    "docs": "\n\nThe **`DOMPointReadOnly`** interface specifies the coordinate and perspective fields used by [DOMPoint] to define a 2D or 3D point in a coordinate system.\n\nThere are two ways to create a new `DOMPointReadOnly` instance. First, you can use its constructor, passing in the values of the parameters for each dimension and, optionally, the perspective:\n\n```js\n/* 2D */\nconst point2D = new DOMPointReadOnly(50, 50);\n\n/* 3D */\nconst point3D = new DOMPointReadOnly(50, 50, 25);\n\n/* 3D with perspective */\nconst point3DPerspective = new DOMPointReadOnly(100, 100, 100, 1.0);\n```\n\nThe other option is to use the static [DOMPointReadOnly.fromPoint_static] method:\n\n```js\nconst point = DOMPointReadOnly.fromPoint({ x: 100, y: 100, z: 50, w: 1.0 });\n```",
    "properties": {
      "frompoint_static": "\n\nThe static **[DOMPointReadOnly]**\nmethod `fromPoint()` creates and returns a new\n`DOMPointReadOnly` object given a source point.\n\nYou can also create a new `DOMPointReadOnly` object using the\n[DOMPointReadOnly.DOMPointReadOnly] constructor.",
      "tojson": "\n\nThe [DOMPointReadOnly] method\n`toJSON()` returns an object giving the\n form of the point object.",
      "w": "\n\nThe **`DOMPointReadOnly`** interface's\n**`w`** property holds the point's perspective value,\n`w`, for a read-only point in space.\n\nIf your script needs to be able\nto change the value of this property, you should instead use the [DOMPoint]\nobject.",
      "x": "\n\nThe **`DOMPointReadOnly`** interface's\n**`x`** property holds the horizontal coordinate, x, for a\nread-only point in space. This property cannot be changed by JavaScript code in this\nread-only version of the `DOMPoint` object.\n\nIn general, positive values `x` mean to the right, and negative values of\n`x` means to the left, assuming no transforms have resulted in a reversal.",
      "y": "\n\nThe **`DOMPointReadOnly`** interface's\n**`y`** property holds the vertical coordinate, y, for a\nread-only point in space.\n\nIf your script needs to be able to change the value\nof this property, you should instead use the [DOMPoint] object.\n\nIn general, positive values of `y` mean downward, and negative values of\n`y` mean upward, assuming no transforms have resulted in a reversal.",
      "z": "\n\nThe **`DOMPointReadOnly`** interface's\n**`z`** property holds the depth coordinate, z, for a\nread-only point in space.\n\nIf your script needs to be able to change the value\nof this property, you should instead use the [DOMPoint] object.\n\nIn general, positive values of `z` mean toward the user (out from the\nscreen), and negative values of `z` mean away from the user (into the\nscreen), assuming no transforms have resulted in a reversal."
    }
  },
  "domquad": {
    "docs": "\n\nA `DOMQuad` is a collection of four `DOMPoint`s defining the corners of an arbitrary quadrilateral. Returning `DOMQuad`s lets `getBoxQuads()` return accurate information even when arbitrary 2D or 3D transforms are present. It has a handy `bounds` attribute returning a `DOMRectReadOnly` for those cases where you just want an axis-aligned bounding rectangle."
  },
  "domrect": {
    "docs": "\n\nA **`DOMRect`** describes the size and position of a rectangle.\n\nThe type of box represented by the `DOMRect` is specified by the method or property that returned it. For example, [Range.getBoundingClientRect] specifies the rectangle that bounds the content of the range using such objects.\n\nIt inherits from its parent, [DOMRectReadOnly].\n\n",
    "properties": {
      "fromrect_static": "\n\nThe **`fromRect()`** static method of the\n[DOMRect] object creates a new `DOMRect`\nobject with a given location and dimensions."
    }
  },
  "domrectreadonly": {
    "docs": "\n\nThe **`DOMRectReadOnly`** interface specifies the standard properties (also used by [DOMRect]) to define a rectangle whose properties are immutable.",
    "properties": {
      "bottom": "\n\nThe **`bottom`** read-only property of the **`DOMRectReadOnly`** interface returns the bottom coordinate value of the `DOMRect`. (Has the same value as `y + height`, or `y` if `height` is negative.)",
      "fromrect_static": "\n\nThe **`fromRect()`** static method of the\n[DOMRectReadOnly] object creates a new `DOMRectReadOnly`\nobject with a given location and dimensions.",
      "height": "\n\nThe **`height`** read-only property of the **`DOMRectReadOnly`** interface represents the height of the `DOMRect`.",
      "left": "\n\nThe **`left`** read-only property of the **`DOMRectReadOnly`** interface returns the left coordinate value of the `DOMRect`. (Has the same value as `x`, or `x + width` if `width` is negative.)",
      "right": "\n\nThe **`right`** read-only property of the **`DOMRectReadOnly`** interface returns the right coordinate value of the `DOMRect`. (Has the same value as `x + width`, or `x` if `width` is negative.)",
      "top": "\n\nThe **`top`** read-only property of the **`DOMRectReadOnly`** interface returns the top coordinate value of the `DOMRect`. (Has the same value as `y`, or `y + height` if `height` is negative.)",
      "width": "\n\nThe **`width`** read-only property of the **`DOMRectReadOnly`** interface represents the width of the `DOMRect`.",
      "x": "\n\nThe **`x`** read-only property of the **`DOMRectReadOnly`** interface represents the x coordinate of the `DOMRect`'s origin.",
      "y": "\n\nThe **`y`** read-only property of the **`DOMRectReadOnly`** interface represents the y coordinate of the `DOMRect`'s origin."
    }
  },
  "domstringlist": {
    "docs": "\n\nThe **`DOMString`** interface is a legacy type returned by some APIs and represents a non-modifiable list of strings (`DOMString`). Modern APIs use `Array` objects (in WebIDL: `sequence<DOMString>`) instead.\n\nThis interface is used in [IndexedDB](/en-US/docs/Web/API/IndexedDB_API) and in the [Location] API:\n\n- [IDBDatabase.objectStoreNames]\n- [IDBObjectStore.indexNames]\n- [Location.ancestorOrigins]",
    "properties": {
      "contains": "\n\nThe **`contains()`** method returns a boolean indicating whether the given string is in the list.",
      "item": "\n\nThe **`item()`** method returns a string from a [`DOMStringList`](/en-US/docs/Web/API/DOMStringList) by index.",
      "length": "\n\nThe read-only **`length`** property indicates the number of strings in the [DOMStringList]."
    }
  },
  "domstringmap": {
    "docs": "\n\nThe **`DOMStringMap`** interface is used for the [HTMLElement.dataset] attribute, to represent data for custom attributes added to elements."
  },
  "domtokenlist": {
    "docs": "\n\nThe **`DOMTokenList`** interface represents a set of space-separated tokens. Such a set is returned by [Element.classList] or [HTMLLinkElement.relList], and many others.\n\nA `DOMTokenList` is indexed beginning with `0` as with JavaScript `Array` objects. `DOMTokenList` is always case-sensitive.",
    "properties": {
      "add": "\n\nThe **`add()`** method of the [DOMTokenList] interface adds the given tokens to the list, omitting any that are already present.",
      "contains": "\n\nThe **`contains()`** method of the [DOMTokenList] interface\nreturns a boolean value — `true` if the underlying list contains the given token,\notherwise `false`.",
      "entries": "\n\nThe **`entries()`** method of the [DOMTokenList] interface\nreturns an `iterator` allowing you\nto go through all key/value pairs contained in this object. The values are\n`Array`s which have [key, value] pairs, each representing a single token.",
      "foreach": "\n\nThe **`forEach()`** method of the [DOMTokenList] interface\ncalls the callback given in parameter once for each value pair in the list, in\ninsertion order.",
      "item": "\n\nThe **`item()`** method of the [DOMTokenList] interface returns an item in the list,\ndetermined by its position in the list, its index.\n\n> **Note:** This method is equivalent as the [bracket notation](/en-US/docs/Web/JavaScript/Reference/Operators/Property_accessors#bracket_notation).\n> So `aList.item(i)` is the same as `aList[i]`.",
      "keys": "\n\nThe **`keys()`** method of the [DOMTokenList] interface\nreturns an `1` allowing to go through all keys contained in this object.\nThe keys are unsigned integers.",
      "length": "\n\nThe read-only **`length`** property of the [DOMTokenList] interface is an `integer` representing the number\nof objects stored in the object.",
      "remove": "\n\nThe **`remove()`** method of the [DOMTokenList] interface\nremoves the specified _tokens_ from the list.",
      "replace": "\n\nThe **`replace()`** method of the [DOMTokenList] interface\nreplaces an existing token with a new token.\nIf the first token doesn't exist, `replace()` returns `false` immediately,\nwithout adding the new token to the token list.",
      "supports": "\n\nThe **`supports()`** method of the [DOMTokenList] interface\nreturns `true` if a given `token` is in the associated attribute's supported tokens.\nThis method is intended to support feature detection.",
      "toggle": "\n\nThe **`toggle()`** method of the [DOMTokenList] interface\nremoves an existing token from the list and returns `false`.\nIf the token doesn't exist it's added and the function returns `true`.",
      "value": "\n\nThe **`value`** property of the [DOMTokenList]\ninterface is a  that returns the value of the list serialized as a\nstring, or clears and sets the list to the given value.",
      "values": "\n\nThe **`values()`** method of the [DOMTokenList] interface\nreturns an `iterator`\nallowing the caller to go through all values contained in the `DOMTokenList`.\nThe individual values are strings."
    }
  },
  "dragevent": {
    "docs": "\n\nThe **`DragEvent`** interface is a [Event] that represents a drag and drop interaction. The user initiates a drag by placing a pointer device (such as a mouse) on the touch surface and then dragging the pointer to a new location (such as another DOM element). Applications are free to interpret a drag and drop interaction in an application-specific way.\n\nThis interface inherits properties from [MouseEvent] and [Event].\n\n",
    "properties": {
      "datatransfer": "\n\nThe **`DragEvent.dataTransfer`** read-only property holds the drag\noperation's data (as a [DataTransfer] object)."
    }
  },
  "dynamicscompressornode": {
    "docs": "\n\nThe `DynamicsCompressorNode` interface provides a compression effect, which lowers the volume of the loudest parts of the signal in order to help prevent clipping and distortion that can occur when multiple sounds are played and multiplexed together at once. This is often used in musical production and game audio. `DynamicsCompressorNode` is an [AudioNode] that has exactly one input and one output.\n\n<table class=\"properties\">\n  <tbody>\n    <tr>\n      <th scope=\"row\">Number of inputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Number of outputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count mode</th>\n      <td><code>\"clamped-max\"</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count</th>\n      <td><code>2</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel interpretation</th>\n      <td><code>\"speakers\"</code></td>\n    </tr>\n  </tbody>\n</table>",
    "properties": {
      "attack": "\n\nThe `attack` property of the [DynamicsCompressorNode] interface is a [k-rate](/en-US/docs/Web/API/AudioParam#k-rate) [AudioParam] representing the amount of time, in seconds, required to reduce the gain by 10 dB. It defines how quickly the signal is adapted when its volume is increased.\n\nThe `attack` property's default value is `0.003` and it can be set between `0` and `1`.",
      "knee": "\n\nThe `knee` property of the [DynamicsCompressorNode] interface is a [k-rate](/en-US/docs/Web/API/AudioParam#k-rate) [AudioParam] containing a decibel value representing the range above the threshold where the curve smoothly transitions to the compressed portion.\n\nThe `knee` property's default value is `30` and it can be set between `0` and `40`.\n\n![Describes the effect of a knee, showing two curves one for a hard knee, the other for a soft knee.](webaudioknee.png)",
      "ratio": "\n\nThe `ratio` property of the [DynamicsCompressorNode] interface Is a [k-rate](/en-US/docs/Web/API/AudioParam#k-rate) [AudioParam] representing the amount of change, in dB, needed in the input for a 1 dB change in the output.\n\nThe `ratio` property's default value is `12` and it can be set between `1` and `20`.\n\n![Describes the effect of different ratio on the output signal](webaudioratio.png)",
      "reduction": "\n\nThe **`reduction`** read-only property of the [DynamicsCompressorNode] interface is a float representing the amount of gain reduction currently applied by the compressor to the signal.\n\nIntended for metering purposes, it returns a value in dB, or `0` (no gain reduction) if no signal is fed into the `DynamicsCompressorNode`. The range of this value is between `-20` and `0` (in dB).",
      "release": "\n\nThe `release` property of the [DynamicsCompressorNode] interface Is a [k-rate](/en-US/docs/Web/API/AudioParam#k-rate) [AudioParam] representing the amount of time, in seconds, required to increase the gain by 10 dB. It defines how quick the signal is adapted when its volume is reduced.\n\nThe `release` property's default value is `0.25` and it can be set between `0` and `1`.",
      "threshold": "\n\nThe `threshold` property of the [DynamicsCompressorNode] interface is a [k-rate](/en-US/docs/Web/API/AudioParam#k-rate) [AudioParam] representing the decibel value above which the compression will start taking effect.\n\nThe `threshold` property's default value is `-24` and it can be set between `-100` and `0`.\n\n![The threshold attribute has no effect on signals lowers than its value, but induce volume reduction on signal stronger than its value.](webaudiothreshold.png)"
    }
  },
  "ecdhkeyderiveparams": {
    "docs": "\n\nThe **`EcdhKeyDeriveParams`** dictionary of the [Web Crypto API](/en-US/docs/Web/API/Web_Crypto_API) represents the object that should be passed as the `algorithm` parameter into [SubtleCrypto.deriveKey], when using the [ECDH](/en-US/docs/Web/API/SubtleCrypto/deriveKey#ecdh) algorithm.\n\nECDH enables two people who each have a key pair consisting of a public and a private key to derive a shared secret. They exchange public keys and use the combination of their private key and the other entity's public key to derive a secret key that they — and no one else — share.\n\nThe parameters for ECDH `deriveKey()` therefore include the other entity's public key, which is combined with this entity's private key to derive the shared secret."
  },
  "ecdsaparams": {
    "docs": "\n\nThe **`EcdsaParams`** dictionary of the [Web Crypto API](/en-US/docs/Web/API/Web_Crypto_API) represents the object that should be passed as the `algorithm` parameter into [SubtleCrypto.sign] or [SubtleCrypto.verify] when using the [ECDSA](/en-US/docs/Web/API/SubtleCrypto/sign#ecdsa) algorithm."
  },
  "eckeygenparams": {
    "docs": "\n\nThe **`EcKeyGenParams`** dictionary of the [Web Crypto API](/en-US/docs/Web/API/Web_Crypto_API) represents the object that should be passed as the `algorithm` parameter into [SubtleCrypto.generateKey], when generating any elliptic-curve-based key pair: that is, when the algorithm is identified as either of [ECDSA](/en-US/docs/Web/API/SubtleCrypto/sign#ecdsa) or [ECDH](/en-US/docs/Web/API/SubtleCrypto/deriveKey#ecdh)."
  },
  "eckeyimportparams": {
    "docs": "\n\nThe **`EcKeyImportParams`** dictionary of the [Web Crypto API](/en-US/docs/Web/API/Web_Crypto_API) represents the object that should be passed as the `algorithm` parameter into [SubtleCrypto.importKey] or [SubtleCrypto.unwrapKey], when generating any elliptic-curve-based key pair: that is, when the algorithm is identified as either of [ECDSA](/en-US/docs/Web/API/SubtleCrypto/sign#ecdsa) or [ECDH](/en-US/docs/Web/API/SubtleCrypto/deriveKey#ecdh)."
  },
  "element": {
    "docs": "\n\n**`Element`** is the most general base class from which all element objects (i.e. objects that represent elements) in a [Document] inherit. It only has methods and properties common to all kinds of elements. More specific classes inherit from `Element`.\n\nFor example, the [HTMLElement] interface is the base interface for HTML elements. Similarly, the [SVGElement] interface is the basis for all SVG elements, and the [MathMLElement] interface is the base interface for MathML elements. Most functionality is specified further down the class hierarchy.\n\nLanguages outside the realm of the Web platform, like XUL through the `XULElement` interface, also implement `Element`.\n\n",
    "properties": {
      "after": "\n\nThe **`Element.after()`** method inserts a set of\n[Node] or string objects in the children list of the\n`Element`'s parent, just after the `Element`.\nString objects are inserted as equivalent [Text] nodes.",
      "afterscriptexecute_event": "\n\n> **Warning:** This event was a proposal in an early version of the specification. Do not rely on it.\n\nThe **`afterscriptexecute`** event is fired after a script has been executed.\n\nIt is a proprietary event specific to Gecko (Firefox).\n\nThis event is not cancelable.",
      "animate": "\n\nThe [Element] interface's **`animate()`** method\nis a shortcut method which creates a new [Animation], applies it to the\nelement, then plays the animation. It returns the created [Animation]\nobject instance.\n\n> **Note:** Elements can have multiple animations applied to them. You can get a list of the\n> animations that affect an element by calling [Element.getAnimations].",
      "animationcancel_event": "\n\nThe **`animationcancel`** event is fired when a [CSS Animation](/en-US/docs/Web/CSS/CSS_animations) unexpectedly aborts. In other words, any time it stops running without sending an [Element/animationend_event] event. This might happen when the  is changed such that the animation is removed, or when the animating node is hidden using CSS. Therefore, either directly or because any of its containing nodes are hidden.\n\nAn event handler for this event can be added by setting the `onanimationcancel` property, or using [EventTarget.addEventListener].",
      "animationend_event": "\n\nThe **`animationend`** event is fired when a [CSS Animation](/en-US/docs/Web/CSS/CSS_animations) has completed. If the animation aborts before reaching completion, such as if the element is removed from the DOM or the animation is removed from the element, the `animationend` event is not fired.",
      "animationiteration_event": "\n\nThe **`animationiteration`** event is fired when an iteration of a [CSS Animation](/en-US/docs/Web/CSS/CSS_animations) ends, and another one begins. This event does not occur at the same time as the [Element/animationend_event] event, and therefore does not occur for animations with an `animation-iteration-count` of one.",
      "animationstart_event": "\n\nThe **`animationstart`** event is fired when a [CSS Animation](/en-US/docs/Web/CSS/CSS_animations) has started. If there is an , this event will fire once the delay period has expired. A negative delay will cause the event to fire with an [AnimationEvent/elapsedTime] equal to the absolute value of the delay (and, correspondingly, the animation will begin playing at that time index into the sequence).",
      "append": "\n\nThe **`Element.append()`** method\ninserts a set of [Node] objects or string objects after\nthe last child of the `Element`. String objects\nare inserted as equivalent [Text] nodes.\n\nDifferences from [Node.appendChild]:\n\n- `Element.append()` allows you to also append string\n  objects, whereas `Node.appendChild()` only accepts [Node]\n  objects.\n- `Element.append()` has no return value, whereas\n  `Node.appendChild()` returns the appended [Node] object.\n- `Element.append()` can append several nodes and strings, whereas\n  `Node.appendChild()` can only append one node.",
      "ariaatomic": "`DOM`\n\nThe **`ariaAtomic`** property of the [Element] interface reflects the value of the [`aria-atomic`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-atomic) attribute, which indicates whether assistive technologies will present all, or only parts of, the changed region based on the change notifications defined by the [`aria-relevant`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-relevant) attribute.",
      "ariaautocomplete": "`DOM`\n\nThe **`ariaAutoComplete`** property of the [Element] interface reflects the value of the [`aria-autocomplete`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-autocomplete) attribute, which indicates whether inputting text could trigger display of one or more predictions of the user's intended value for a combobox, searchbox, or textbox and specifies how predictions would be presented if they were made.",
      "ariabusy": "`DOM`\n\nThe **`ariaBusy`** property of the [Element] interface reflects the value of the [`aria-busy`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-busy) attribute, which indicates whether an element is being modified, as assistive technologies may want to wait until the modifications are complete before exposing them to the user.",
      "ariachecked": "`DOM`\n\nThe **`ariaChecked`** property of the [Element] interface reflects the value of the [`aria-checked`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-checked) attribute, which indicates the current \"checked\" state of checkboxes, radio buttons, and other widgets that have a checked state.\n\n> **Note:** Where possible use an HTML `input` element with `type=\"checkbox\"` as this element has built in semantics and does not require ARIA attributes.",
      "ariacolcount": "`DOM`\n\nThe **`ariaColCount`** property of the [Element] interface reflects the value of the [`aria-colcount`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-colcount) attribute, which defines the number of columns in a table, grid, or treegrid.",
      "ariacolindex": "`DOM`\n\nThe **`ariaColIndex`** property of the [Element] interface reflects the value of the [`aria-colindex`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-colindex) attribute, which defines an element's column index or position with respect to the total number of columns within a table, grid, or treegrid.",
      "ariacolindextext": "\n\nThe **`ariaColIndexText`** property of the [Element] interface reflects the value of the [`aria-colindextext`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-colindextext) attribute, which defines a human readable text alternative of aria-colindex.",
      "ariacolspan": "`DOM`\n\nThe **`ariaColSpan`** property of the [Element] interface reflects the value of the [`aria-colspan`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-colspan) attribute, which defines the number of columns spanned by a cell or gridcell within a table, grid, or treegrid.",
      "ariacurrent": "`DOM`\n\nThe **`ariaCurrent`** property of the [Element] interface reflects the value of the [`aria-current`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-current) attribute, which indicates the element that represents the current item within a container or set of related elements.",
      "ariadescription": "`DOM`\n\nThe **`ariaDescription`** property of the [Element] interface reflects the value of the [`aria-description`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-description) attribute, which defines a string value that describes or annotates the current element.",
      "ariadisabled": "`DOM`\n\nThe **`ariaDisabled`** property of the [Element] interface reflects the value of the [`aria-disabled`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-disabled) attribute, which indicates that the element is perceivable but disabled, so it is not editable or otherwise operable.\n\n> **Note:** Where possible, use the `input` element with `type=\"button\"` or the `button` element — because those elements have built in semantics and do not require ARIA attributes.",
      "ariaexpanded": "`DOM`\n\nThe **`ariaExpanded`** property of the [Element] interface reflects the value of the [`aria-expanded`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-expanded) attribute, which indicates whether a grouping element owned or controlled by this element is expanded or collapsed.",
      "ariahaspopup": "`DOM`\n\nThe **`ariaHasPopup`** property of the [Element] interface reflects the value of the [`aria-haspopup`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-haspopup) attribute, which indicates the availability and type of interactive popup element, such as menu or dialog, that can be triggered by an element.",
      "ariahidden": "`DOM`\n\nThe **`ariaHidden`** property of the [Element] interface reflects the value of the [`aria-hidden`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-hidden)) attribute, which indicates whether the element is exposed to an accessibility API.",
      "ariakeyshortcuts": "`DOM`\n\nThe **`ariaKeyShortcuts`** property of the [Element] interface reflects the value of the `aria-keyshortcuts` attribute, which indicates keyboard shortcuts that an author has implemented to activate or give focus to an element.",
      "arialabel": "`DOM`\n\nThe **`ariaLabel`** property of the [Element] interface reflects the value of the [`aria-label`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-label) attribute, which defines a string value that labels the current element.",
      "arialevel": "`DOM`\n\nThe **`ariaLevel`** property of the [Element] interface reflects the value of the `aria-level` attribute, which defines the hierarchical level of an element within a structure.\n\n> **Note:** Where possible use an HTML `h1` or other correct heading level as these have built in semantics and do not require ARIA attributes.",
      "arialive": "`DOM`\n\nThe **`ariaLive`** property of the [Element] interface reflects the value of the [`aria-live`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-live) attribute, which indicates that an element will be updated, and describes the types of updates the user agents, assistive technologies, and user can expect from the [live region](/en-US/docs/Web/Accessibility/ARIA/ARIA_Live_Regions).",
      "ariamodal": "`DOM`\n\nThe **`ariaModal`** property of the [Element] interface reflects the value of the `aria-modal` attribute, which indicates whether an element is modal when displayed. Applying the `aria-modal` property to an element with `role=\"dialog\"` replaces the technique of using aria-hidden on the background for informing assistive technologies that content outside a dialog is inert.",
      "ariamultiline": "`DOM`\n\nThe **`ariaMultiLine`** property of the [Element] interface reflects the value of the [`aria-multiline`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-multiline) attribute, which indicates whether a text box accepts multiple lines of input or only a single line.\n\n> **Note:** Where possible use an HTML `input` element with `type=\"text\"` or a `textarea` as these have built in semantics and do not require ARIA attributes.",
      "ariamultiselectable": "`DOM`\n\nThe **`ariaMultiSelectable`** property of the [Element] interface reflects the value of the [`aria-multiselectable`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-multiselectable) attribute, which indicates that the user may select more than one item from the current selectable descendants.\n\n> **Note:** Where possible use an HTML `select` element as this has built in semantics and does not require ARIA attributes.",
      "ariaorientation": "`DOM`\n\nThe **`ariaOrientation`** property of the [Element] interface reflects the value of the [`aria-orientation`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-orientation) attribute, which indicates whether the element's orientation is horizontal, vertical, or unknown/ambiguous.",
      "ariaplaceholder": "`DOM`\n\nThe **`ariaPlaceholder`** property of the [Element] interface reflects the value of the `aria-placeholder` attribute, which defines a short hint intended to aid the user with data entry when the control has no value.\n\n> **Note:** Where possible use an HTML `input` element with `type=\"text\"` or a `textarea` as these have built in semantics and do not require ARIA attributes.",
      "ariaposinset": "`DOM`\n\nThe **`ariaPosInSet`** property of the [Element] interface reflects the value of the [`aria-posinset`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-posinset) attribute, which defines an element's number or position in the current set of listitems or treeitems.",
      "ariapressed": "`DOM`\n\nThe **`ariaPressed`** property of the [Element] interface reflects the value of the [`aria-pressed`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-pressed) attribute, which indicates the current \"pressed\" state of toggle buttons.\n\n> **Note:** Where possible use an HTML `input` element with `type=\"button\"` or the `button` element as these have built in semantics and do not require ARIA attributes.",
      "ariareadonly": "`DOM`\n\nThe **`ariaReadOnly`** property of the [Element] interface reflects the value of the [`aria-readonly`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-readonly) attribute, which indicates that the element is not editable, but is otherwise operable.\n\n> **Note:** Where possible use an HTML `input` element with `type=\"text\"` or a `textarea` as these have built in semantics and do not require ARIA attributes.",
      "ariarelevant": "\n\nThe **`ariaRelevant`** property of the [Element] interface reflects the value of the [`aria-relevant`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-relevant) attribute, which indicates what notifications the user agent will trigger when the accessibility tree within a live region is modified. This is used to describe what changes in an `aria-live` region are relevant and should be announced.",
      "ariarequired": "`DOM`\n\nThe **`ariaRequired`** property of the [Element] interface reflects the value of the `aria-required` attribute, which indicates that user input is required on the element before a form may be submitted.\n\n> **Note:** Where possible use an HTML `input` element with `type=\"text\"` or a `textarea` as these have built in semantics and do not require ARIA attributes.",
      "ariaroledescription": "`DOM`\n\nThe **`ariaRoleDescription`** property of the [Element] interface reflects the value of the [`aria-roledescription`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-roledescription) attribute, which defines a human-readable, author-localized description for the role of an element.",
      "ariarowcount": "`DOM`\n\nThe **`ariaRowCount`** property of the [Element] interface reflects the value of the [`aria-rowcount`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-rowcount) attribute, which defines the total number of rows in a table, grid, or treegrid.",
      "ariarowindex": "`DOM`\n\nThe **`ariaRowIndex`** property of the [Element] interface reflects the value of the [`aria-rowindex`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-rowindex) attribute, which defines an element's row index or position with respect to the total number of rows within a table, grid, or treegrid.",
      "ariarowindextext": "\n\nThe **`ariaRowIndexText`** property of the [Element] interface reflects the value of the [`aria-rowindextext`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-rowindextext) attribute, which defines a human readable text alternative of aria-rowindex.",
      "ariarowspan": "`DOM`\n\nThe **`ariaRowSpan`** property of the [Element] interface reflects the value of the [`aria-rowspan`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-rowspan) attribute, which defines the number of rows spanned by a cell or gridcell within a table, grid, or treegrid.",
      "ariaselected": "`DOM`\n\nThe **`ariaSelected`** property of the [Element] interface reflects the value of the [`aria-selected`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-selected) attribute, which indicates the current \"selected\" state of elements that have a selected state.",
      "ariasetsize": "`DOM`\n\nThe **`ariaSetSize`** property of the [Element] interface reflects the value of the [`aria-setsize`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-setsize) attribute, which defines the number of items in the current set of listitems or treeitems.",
      "ariasort": "`DOM`\n\nThe **`ariaSort`** property of the [Element] interface reflects the value of the [`aria-sort`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-sort) attribute, which indicates if items in a table or grid are sorted in ascending or descending order.",
      "ariavaluemax": "`DOM`\n\nThe **`ariaValueMax`** property of the [Element] interface reflects the value of the [`aria-valuemax`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-valuemax) attribute, which defines the maximum allowed value for a range widget.",
      "ariavaluemin": "`DOM`\n\nThe **`ariaValueMin`** property of the [Element] interface reflects the value of the [`aria-valuemin`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-valuemin) attribute, which defines the minimum allowed value for a range widget.",
      "ariavaluenow": "`DOM`\n\nThe **`ariaValueNow`** property of the [Element] interface reflects the value of the [`aria-valuenow`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-valuenow) attribute, which defines the current value for a range widget.",
      "ariavaluetext": "`DOM`\n\nThe **`ariaValueText`** property of the [Element] interface reflects the value of the [`aria-valuetext`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-valuetext) attribute, which defines the human-readable text alternative of aria-valuenow for a range widget.",
      "assignedslot": "\n\nThe **`assignedSlot`** read-only\nproperty of the [Element] interface returns an\n[HTMLSlotElement] representing the `slot` element the\nnode is inserted in.",
      "attachshadow": "\n\nThe **`Element.attachShadow()`** method attaches a shadow DOM tree to the specified element and returns a reference to its [ShadowRoot].",
      "attributes": "\n\nThe **`Element.attributes`** property returns a live collection\nof all attribute nodes registered to the specified node. It is a\n[NamedNodeMap], not an `Array`, so it has no `Array`\nmethods and the [Attr] nodes' indexes may differ among browsers. To be more\nspecific, `attributes` is a key/value pair of strings that represents any\ninformation regarding that attribute.",
      "auxclick_event": "\n\nThe **`auxclick`** event is fired at an [Element] when a non-primary pointing device button (any mouse button other than the primary—usually leftmost—button) has been pressed and released both within the same element.\n\n`auxclick` is fired after the [Element/mousedown_event] and [Element/mouseup_event] events have been fired, in that order.",
      "before": "\n\nThe **`Element.before()`** method inserts a set of\n[Node] or string objects in the children list of this\n`Element`'s parent, just before this `Element`.\nString objects are inserted as equivalent [Text] nodes.",
      "beforeinput_event": "\n\nThe DOM **`beforeinput`** event fires when the value of an `input` or `textarea` element is about to be modified. But in contrast to the [Element/input_event] event, it does not fire on the `select` element. The event also applies to elements with [HTMLElement.contentEditable] enabled, and to any element when [Document.designMode] is turned on.\n\nThis allows web apps to override text edit behavior before the browser modifies the DOM tree, and provides more control over input events to improve performance.\n\nIn the case of `contenteditable` and `designMode`, the event target is the **editing host**. If these properties apply to multiple elements, the editing host is the nearest ancestor element whose parent isn't editable.\n\n> **Note:** Not every user modification results in `beforeinput` firing. Also the event may fire but be non-cancelable. This may happen when the modification is done by autocomplete, by accepting a correction from a spell checker, by password manager autofill, by , or in other ways. The details vary by browser and OS. To override the edit behavior in all situations, the code needs to handle the `input` event and possibly revert any modifications that were not handled by the `beforeinput` handler. See bugs [1673558](https://bugzil.la/1673558) and [1763669](https://bugzil.la/1763669).",
      "beforematch_event": "\n\nAn element receives a **`beforematch`** event when it is in the _hidden until found_ state and the browser is about to reveal its content because the user has found the content through the \"find in page\" feature or through fragment navigation.",
      "beforescriptexecute_event": "\n\n> **Warning:** This event was a proposal in an early version of the specification. Do not rely on it.\n\nThe **`beforescriptexecute`** event is fired when a script is about to be executed. Cancelling the event prevents the script from executing.\n\nIt is a proprietary event specific to Gecko (Firefox).",
      "beforexrselect_event": "\n\nThe **`beforexrselect`** event is fired before WebXR select events ([XRSession/select_event], [XRSession/selectstart_event], [XRSession/selectend_event]) are dispatched. It can be used to suppress XR world input events while the user is interacting with a DOM overlay UI.\n\nThis event [bubbles](/en-US/docs/Learn/JavaScript/Building_blocks/Events#event_bubbling_and_capture), is [cancelable](/en-US/docs/Web/API/Event/cancelable) and is [composed](/en-US/docs/Web/API/Event/composed).",
      "blur_event": "\n\nThe **`blur`** event fires when an element has lost focus. The event does not bubble, but the related [Element/focusout_event] event that follows does bubble.\n\nAn element will lose focus if another element is selected.\nAn element will also lose focus if a style that does not allow focus is applied, such as `hidden`, or if the element is removed from the document — in both of these cases focus moves to the `body` element (viewport).\nNote however that `blur` is not fired when a focused element is removed from the document.\n\n<!-- Prior to FF110 elements did not lose focus if the style changed to hidden (say) -->\n\nThe opposite of `blur` is the [Element/focus_event] event, which fires when the element has _received_ focus.\n\nThe `blur` event is not cancelable.",
      "childelementcount": "\n\nThe **`Element.childElementCount`** read-only property\nreturns the number of child elements of this element.",
      "children": "\n\nThe read-only **`children`** property returns a live [HTMLCollection]\nwhich contains all of the child [Element] of the element upon which it was called.\n\n`Element.children` includes only element nodes. To get all child nodes, including non-element nodes like text and comment nodes, use [Node.childNodes].",
      "classlist": "\n\nThe **`Element.classList`** is a read-only property that\nreturns a live [DOMTokenList] collection of the `class`\nattributes of the element. This can then be used to manipulate the class list.\n\nUsing `classList` is a convenient alternative to accessing an element's list\nof classes as a space-delimited string via [element.className].",
      "classname": "\n\nThe **`className`** property of the\n[Element] interface gets and sets the value of the [`class` attribute](/en-US/docs/Web/HTML/Global_attributes/class)\nof the specified element.",
      "click_event": "\n\nAn element receives a **`click`** event when any of the following occurs:\n\n- a pointing-device button (such as a mouse's primary button) is both pressed and released while the pointer is located inside the element.\n- a touch gesture is performed on the element\n- the <kbd>Space</kbd> key or <kbd>Enter</kbd> key is pressed while the element is focused\n\nIf the button is pressed on one element and the pointer is moved outside the element before the button is released, the event is fired on the most specific ancestor element that contained both elements.\n\n`click` fires after both the [Element/mousedown_event] and [Element/mouseup_event] events have fired, in that order.\n\nThe event is a device-independent event — meaning it can be activated by touch, keyboard, mouse, and any other mechanism provided by assistive technology.",
      "clientheight": "\n\nThe **`Element.clientHeight`** read-only property is zero for\nelements with no CSS or inline layout boxes; otherwise, it's the inner height of an\nelement in pixels. It includes padding but excludes borders, margins, and horizontal\nscrollbars (if present).\n\n`clientHeight` can be calculated as: CSS `height` + CSS\n`padding` - height of horizontal scrollbar (if present).\n\nWhen `clientHeight` is used on the root element (the\n`<html>` element), (or on `<body>` if the document is\nin quirks mode), the viewport's height (excluding any scrollbar) is returned. [This is a special case of `clientHeight`](https://www.w3.org/TR/2016/WD-cssom-view-1-20160317/#dom-element-clientheight).\n\n> **Note:** This property will round the value to an integer. If you need\n> a fractional value, use [element.getBoundingClientRect].",
      "clientleft": "\n\nThe width of the left border of an element in pixels. It includes the width of the\nvertical scrollbar if the text direction of the element is right-to-left and if there\nis an overflow causing a left vertical scrollbar to be rendered.\n`clientLeft` does not include the left margin or the left padding.\n`clientLeft` is read-only.\n\n> **Note:** This property will round the value to an integer. If you\n> need a fractional value, use [element.getBoundingClientRect].\n\n> **Note:** When an element has\n> `display: inline`, `clientLeft` returns `0`\n> regardless of the element's border.",
      "clienttop": "\n\nThe width of the top border of an element in pixels. It is a read-only, integer\nproperty of element.\n\nAs it happens, all that lies between the two locations (`offsetTop` and\nclient area top) is the element's border. This is because the `offsetTop`\nindicates the location of the top of the border (not the margin) while the client area\nstarts immediately below the border, (client area includes padding.) Therefore, the\n**clientTop** value will always equal the integer portion of the\n`.getComputedStyle()` value for \"border-top-width\". (Actually might be\nMath.round(parseFloat()).) For example, if the computed \"border-top-width\" is zero,\nthen **`clientTop`** is also zero.\n\n> **Note:** This property will round the value to an integer. If you\n> need a fractional value, use [element.getBoundingClientRect].",
      "clientwidth": "\n\nThe **`Element.clientWidth`** property is zero for inline\nelements and elements with no CSS; otherwise, it's the inner width of an element in\npixels. It includes padding but excludes borders, margins, and vertical scrollbars (if\npresent).\n\nWhen `clientWidth` is used on the root element (the\n`<html>` element), (or on `<body>` if the document is\nin quirks mode), the viewport's width (excluding any scrollbar) is returned. [This is a special case of `clientWidth`](https://www.w3.org/TR/2016/WD-cssom-view-1-20160317/#dom-element-clientwidth).\n\n> **Note:** This property will round the value to an integer. If you need\n> a fractional value, use [element.getBoundingClientRect].",
      "closest": "\n\nThe **`closest()`** method of the [Element] interface traverses the element and its parents (heading toward the document root) until it finds a node that matches the specified [CSS selector](/en-US/docs/Learn/CSS/Building_blocks/Selectors).",
      "compositionend_event": "\n\nThe **`compositionend`** event is fired when a text composition system such as an  completes or cancels the current composition session.\n\nFor example, this event could be fired after a user finishes entering a Chinese character using a [Pinyin](https://en.wikipedia.org/wiki/Pinyin) IME.",
      "compositionstart_event": "\n\nThe **`compositionstart`** event is fired when a text composition system such as an  starts a new composition session.\n\nFor example, this event could be fired after a user starts entering a Chinese character using a [Pinyin](https://en.wikipedia.org/wiki/Pinyin) IME.",
      "compositionupdate_event": "\n\nThe **`compositionupdate`** event is fired when a new character is received in the context of a text composition session controlled by a text composition system such as an .\n\nFor example, this event could be fired while a user enters a Chinese character using a [Pinyin](https://en.wikipedia.org/wiki/Pinyin) IME.",
      "computedstylemap": "\n\nThe **`computedStyleMap()`** method of\nthe [Element] interface returns a [StylePropertyMapReadOnly]\ninterface which provides a read-only representation of a CSS declaration block that is\nan alternative to [CSSStyleDeclaration].",
      "contentvisibilityautostatechange_event": "\n\nThe **`contentvisibilityautostatechange`** event fires on any element with  set on it when it starts or stops being [relevant to the user](/en-US/docs/Web/CSS/CSS_containment#relevant_to_the_user) and [skipping its contents](/en-US/docs/Web/CSS/CSS_containment#skips_its_contents).\n\nWhile the element is not relevant (between the start and end events), the user agent skips an element's rendering, including layout and painting, which can significantly improve page rendering speed.\nThe [element/contentvisibilityautostatechange_event] event provides a way for an app's code to also start or stop rendering processes (e.g. drawing on a `canvas`) when they are not needed, thereby conserving processing power.\n\nNote that even when hidden from view, element contents will remain semantically relevant (e.g. to assistive technology users), so this signal should not be used to skip significant semantic DOM updates.",
      "contextmenu_event": "\n\nThe **`contextmenu`** event fires when the user attempts to open a context menu. This event is typically triggered by clicking the right mouse button, or by pressing the context menu key.\n\nIn the latter case, the context menu is displayed at the bottom left of the focused element, unless the element is a tree, in which case the context menu is displayed at the bottom left of the current row.\n\nAny right-click event that is not disabled (by calling the click event's [Event.preventDefault] method) will result in a `contextmenu` event being fired at the targeted element.\n\n> **Note:** An exception to this in Firefox: if the user holds down the <kbd>Shift</kbd> key while right-clicking, then the context menu will be shown without a `contextmenu` event being fired.",
      "copy_event": "\n\nThe **`copy`** event fires when the user initiates a copy action through the browser's user interface.\n\nThe event's default action is to copy the selection (if any) to the clipboard.\n\nA handler for this event can _modify_ the clipboard contents by calling [DataTransfer.setData] on the event's [ClipboardEvent.clipboardData] property, and cancelling the event's default action using [Event/preventDefault].\n\nHowever, the handler cannot _read_ the clipboard data.\n\nIt's possible to construct and dispatch a [synthetic](/en-US/docs/Web/Events/Creating_and_triggering_events) `copy` event, but this will not affect the system clipboard.",
      "cut_event": "\n\nThe **`cut`** event is fired when the user has initiated a \"cut\" action through the browser's user interface.\n\nIf the user attempts a cut action on uneditable content, the `cut` event still fires but the event object contains no data.\n\nThe event's default action is to copy the current selection (if any) to the system clipboard and remove it from the document.\n\nA handler for this event can _modify_ the clipboard contents by calling [DataTransfer.setData] on the event's [ClipboardEvent.clipboardData] property, and cancelling the default action using [Event/preventDefault].\n\nNote though that cancelling the default action will also prevent the document from being updated. So an event handler which wants to emulate the default action for \"cut\" while modifying the clipboard must also manually remove the selection from the document.\n\nThe handler cannot _read_ the clipboard data.\n\nIt's possible to construct and dispatch a [synthetic](/en-US/docs/Web/Events/Creating_and_triggering_events) `cut` event, but this will not affect the system clipboard or the document's contents.",
      "dblclick_event": "\n\nThe **`dblclick`** event fires when a pointing device button (such as a mouse's primary button) is double-clicked; that is, when it's rapidly clicked twice on a single element within a very short span of time.\n\n`dblclick` fires after two [Element/click_event] events (and by extension, after two pairs of [Element.mousedown_event] and [Element.mouseup_event] events).",
      "domactivate_event": "\n\nThe **`DOMActivate`** event is fired at an element when it becomes active, such as when it is clicked on using the mouse or a keypress is used to navigate to it.",
      "dommousescroll_event": "\n\nThe DOM `DOMMouseScroll` event is fired asynchronously when mouse wheel or similar device is operated and the accumulated scroll amount is over 1 line or 1 page since last event. It's represented by the [MouseScrollEvent] interface. This event was only implemented by Firefox. You should instead use the standard [Element.wheel_event] event.\n\nIf you want to prevent the default action of mouse wheel events, it's not enough to handle only this event on Gecko because If scroll amount by a native mouse wheel event is less than 1 line (or less than 1 page when the system setting is by page scroll), other mouse wheel events may be fired without this event.\n\nOn Gecko 17 (Firefox 17) or later, you need to call `preventDefault()` of `wheel` events which must be fired for every native event.\n\nUse the standardized [Element/wheel_event] event if available.",
      "elementtiming": "\n\nThe **`elementTiming`** property of the [Element] interface identifies elements for observation in the [PerformanceElementTiming] API. The `elementTiming` property reflects the value of the [`elementtiming`](/en-US/docs/Web/HTML/Attributes/elementtiming) attribute.",
      "firstelementchild": "\n\nThe **`Element.firstElementChild`** read-only property\nreturns an element's first child [Element], or `null` if there\nare no child elements.\n\n`Element.firstElementChild` includes only element nodes.\nTo get all child nodes, including non-element nodes like text and comment nodes, use [Node.firstChild].",
      "focus_event": "\n\nThe **`focus`** event fires when an element has received focus. The event does not bubble, but the related [Element/focusin_event] event that follows does bubble.\n\nThe opposite of `focus` is the [Element/blur_event] event, which fires when the element has _lost_ focus.\n\nThe `focus` event is not cancelable.",
      "focusin_event": "\n\nThe **`focusin`** event fires when an element has received focus, after the [Element/focus_event] event. The two events differ in that `focusin` bubbles, while `focus` does not.\n\nThe opposite of `focusin` is the [Element/focusout_event] event, which fires when the element has lost focus.\n\nThe `focusin` event is not cancelable.",
      "focusout_event": "\n\nThe **`focusout`** event fires when an element has lost focus, after the [Element/blur_event] event. The two events differ in that `focusout` bubbles, while `blur` does not.\n\nThe opposite of `focusout` is the [Element/focusin_event] event, which fires when the element has received focus.\n\nThe `focusout` event is not cancelable.",
      "fullscreenchange_event": "\n\nThe `fullscreenchange` event is fired immediately after an [Element] switches into or out of fullscreen mode.\n\nThis event is sent to the `Element` which is transitioning into or out of fullscreen mode.\n\nTo find out whether the `Element` is entering or exiting fullscreen mode, check the value of [Document.fullscreenElement]: if this value is `null` then the element is exiting fullscreen mode, otherwise it is entering fullscreen mode.\n\nThis event is not cancelable.",
      "fullscreenerror_event": "\n\nThe `fullscreenerror` event is fired when the browser cannot switch to fullscreen mode.\n\nAs with the [`fullscreenchange` event](/en-US/docs/Web/API/Element/fullscreenchange_event), two `fullscreenerror` events are fired; the first is sent to the [Element] which failed to change modes, and the second is sent to the [Document] which owns that element.\n\nFor some reasons that switching into fullscreen mode might fail, see [the guide to the Fullscreen API](/en-US/docs/Web/API/Fullscreen_API/Guide).\n\nThis event is not cancelable.",
      "gesturechange_event": "\n\nThe **`gesturechange`** event is fired when digits move during a touch gesture.\n\nIt is a proprietary event specific to WebKit.",
      "gestureend_event": "\n\nThe **`gestureend`** event is fired when there are no longer multiple fingers contacting the touch surface, thus ending the gesture.\n\nIt is a proprietary event specific to WebKit.",
      "gesturestart_event": "\n\nThe **`gesturestart`** event is fired when multiple fingers contact the touch surface, thus starting a new gesture. During the gesture, [Element/gesturechange_event] events will be fired. When the gesture has ended, a [Element/gestureend_event] event will be fired.\n\nIt is a proprietary event specific to WebKit.",
      "getanimations": "\n\nThe `getAnimations()` method of the [Element] interface\n(specified on the `Animatable` mixin) returns an array of all\n[Animation] objects affecting this element or which are scheduled to do so\nin future. It can optionally return [Animation] objects for descendant\nelements too.\n\n> **Note:** This array includes [CSS Animations](/en-US/docs/Web/CSS/CSS_animations), [CSS Transitions](/en-US/docs/Web/CSS/CSS_transitions), and [Web Animations](/en-US/docs/Web/API/Web_Animations_API).",
      "getattribute": "\n\nThe **`getAttribute()`** method of the\n[Element] interface returns the value of a specified attribute on the\nelement.\n\nIf the given attribute does not exist, the value returned will\neither be `null` or `\"\"` (the empty string); see [Non-existing attributes](#non-existing_attributes) for details.",
      "getattributenames": "\n\nThe **`getAttributeNames()`** method of the\n[Element] interface returns the attribute names of the element as an\n`Array` of strings. If the element has no attributes it returns an empty\narray.\n\nUsing `getAttributeNames()` along with\n[Element.getAttribute], is a memory-efficient and\nperformant alternative to accessing [Element.attributes].\n\nThe names returned by **`getAttributeNames()`** are _qualified_ attribute names, meaning that attributes with a namespace prefix have their names returned with that namespace prefix (_not_ the actual namespace), followed by a colon, followed by the attribute name (for example, **`xlink:href`**), while any attributes which have no namespace prefix have their names returned as-is (for example, **`href`**).",
      "getattributenode": "\n\nReturns the specified attribute of the specified element, as an `Attr` node.",
      "getattributenodens": "\n\nReturns the `Attr` node for the attribute with the given namespace and name.",
      "getattributens": "\n\nThe **`getAttributeNS()`** method of the [Element]\ninterface returns the string value of the attribute with the specified namespace and\nname. If the named attribute does not exist, the value returned will either be\n`null` or `\"\"` (the empty string); see [Notes](#notes) for\ndetails.",
      "getboundingclientrect": "\n\nThe **`Element.getBoundingClientRect()`** method returns a\n[DOMRect] object providing information about the size of an element and its\nposition relative to the [viewport](/en-US/docs/Glossary/Viewport).",
      "getclientrects": "\n\nThe **`getClientRects()`** method of the [Element]\ninterface returns a collection of [DOMRect] objects that indicate the\nbounding rectangles for each [CSS border box](/en-US/docs/Web/CSS/CSS_box_model/Introduction_to_the_CSS_box_model) in a client.\n\nMost elements only have one border box each, but a multiline [inline-level element](/en-US/docs/Glossary/Inline-level_content) (such as a multiline\n`span` element, by default) has a border box around each line.",
      "getelementsbyclassname": "\n\nThe [Element] method\n**`getElementsByClassName()`** returns a live\n[HTMLCollection] which contains every descendant element which has the\nspecified class name or names.\n\nThe method [Document.getElementsByClassName]\non the [Document] interface works essentially the same way, except it acts\non the entire document, starting at the document root.",
      "getelementsbytagname": "\n\nThe\n**`Element.getElementsByTagName()`** method returns a live\n[HTMLCollection] of elements with the given [tag name](/en-US/docs/Web/API/Element/tagName).\n\nAll descendants of the\nspecified element are searched, but not the element itself. The returned list is\n_live_, which means it updates itself with the DOM tree automatically.\nTherefore, there is no need to call `Element.getElementsByTagName()` with\nthe same element and arguments repeatedly if the DOM changes in between calls.\n\nWhen called on an HTML element in an HTML document, `getElementsByTagName`\nlower-cases the argument before searching for it. This is undesirable when trying to\nmatch  SVG elements (such as\n[`<linearGradient>`](/en-US/docs/Web/SVG/Element/linearGradient))\nin an HTML document. Instead, use [Element.getElementsByTagNameNS],\nwhich preserves the capitalization of the tag name.\n\n`Element.getElementsByTagName` is similar to\n[Document.getElementsByTagName], except that it only searches for\nelements that are descendants of the specified element.",
      "getelementsbytagnamens": "\n\nThe **`Element.getElementsByTagNameNS()`** method returns a\nlive [HTMLCollection] of elements with the given tag name belonging to the\ngiven namespace. It is similar to [Document.getElementsByTagNameNS], except\nthat its search is restricted to descendants of the specified element.",
      "gotpointercapture_event": "\n\nThe **`gotpointercapture`** event is fired when an element captures a pointer using [`setPointerCapture()`](/en-US/docs/Web/API/Element/setPointerCapture).",
      "hasattribute": "\n\nThe **`Element.hasAttribute()`** method returns a\n**Boolean** value indicating whether the specified element has the\nspecified attribute or not.",
      "hasattributens": "\n\n`hasAttributeNS` returns a boolean value indicating whether the current element has the specified attribute.",
      "hasattributes": "\n\nThe **`hasAttributes()`** method of the [Element]\ninterface returns a boolean value indicating whether the current element has any\nattributes or not.",
      "haspointercapture": "\n\nThe **`hasPointerCapture()`** method of the\n[Element] interface checks whether the element on which it is invoked has\npointer capture for the pointer identified by the given pointer ID.",
      "id": "\n\nThe **`id`** property of the [Element] interface\nrepresents the element's identifier, reflecting the\n[**`id`**](/en-US/docs/Web/HTML/Global_attributes/id)\nglobal attribute.\n\nIf the `id` value is not the empty string, it must be unique in a document.\n\nThe `id` is often used with [Document.getElementById] to retrieve a particular element. Another common case is to use an\nelement's [ID as a selector](/en-US/docs/Web/CSS/ID_selectors) when styling\nthe document with [CSS](/en-US/docs/Web/CSS).\n\n> **Note:** Identifiers are case-sensitive, but you should avoid creating\n> IDs that differ only in the capitalization.",
      "innerhtml": "\n\nThe [Element] property\n**`innerHTML`** gets or sets the HTML or XML markup contained\nwithin the element.\n\nTo insert the HTML into the document rather than replace the contents of an element,\nuse the method [Element.insertAdjacentHTML].",
      "input_event": "\n\nThe **`input`** event fires when the `value` of an `input`, `select`, or `textarea` element has been changed as a direct result of a user action (such as typing in a textbox or checking a checkbox).\n\nThe event also applies to elements with [HTMLElement.contentEditable] enabled, and to any element when [Document.designMode] is turned on. In the case of `contenteditable` and `designMode`, the event target is the _editing host_. If these properties apply to multiple elements, the editing host is the nearest ancestor element whose parent isn't editable.\n\nFor `<input>` elements with `type=checkbox` or `type=radio`, the `input` event should fire whenever a user toggles the control, per the [HTML Living Standard specification](https://html.spec.whatwg.org/multipage/input.html#the-input-element:event-input-2). However, historically this has not always been the case. Check compatibility, or use the [HTMLElement/change_event] event instead for elements of these types.\n\nFor `textarea` and `input` elements that accept text input (`type=text`, `type=tel`, etc.), the interface is [InputEvent]; for others, the interface is [Event].\n\nThe `input` event is fired every time the `value` of the element changes. This is unlike the [HTMLElement/change_event] event, which only fires when the value is committed, such as by pressing the enter key or selecting a value from a list of options. Note that the `input` event is not fired when JavaScript changes an element's `value` programmatically.",
      "insertadjacentelement": "\n\nThe **`insertAdjacentElement()`** method of the\n[Element] interface inserts a given element node at a given position\nrelative to the element it is invoked upon.",
      "insertadjacenthtml": "\n\nThe **`insertAdjacentHTML()`** method of the\n[Element] interface parses the specified text as HTML or XML and inserts\nthe resulting nodes into the DOM tree at a specified position.",
      "insertadjacenttext": "\n\nThe **`insertAdjacentText()`** method of the [Element] interface, given a relative position and a string, inserts a new text node at the given position relative to the element it is called from.",
      "keydown_event": "\n\nThe **`keydown`** event is fired when a key is pressed.\n\nUnlike the deprecated [Element/keypress_event] event, the `keydown` event is fired for all keys, regardless of whether they produce a character value.\n\nThe `keydown` and [`keyup`](/en-US/docs/Web/API/Element/keyup_event) events provide a code indicating which key is pressed, while `keypress` indicates which character was entered. For example, a lowercase \"a\" will be reported as 65 by `keydown` and `keyup`, but as 97 by `keypress`. An uppercase \"A\" is reported as 65 by all events.\n\nKeyboard events are only generated by `<input>`, `<textarea>`, `<summary>` and anything with the `contentEditable` or `tabindex` attribute. If not caught, they [bubble](/en-US/docs/Learn/JavaScript/Building_blocks/Events#event_bubbling) up the [DOM tree](/en-US/docs/Web/API/Document_object_model/Using_the_Document_Object_Model#what_is_a_dom_tree) until they reach [Document].\n\nSince Firefox 65, the `keydown` and [`keyup`](/en-US/docs/Web/API/Element/keyup_event) events are now fired during IME composition, to improve cross-browser compatibility for CJKT users ([Firefox bug 354358](https://bugzil.la/354358)). To ignore all `keydown` events that are part of composition, do something like this (229 is a special value set for a `keyCode` relating to an event that has been processed by an IME):\n\n```js\neventTarget.addEventListener(\"keydown\", (event) => {\n  if (event.isComposing || event.keyCode === 229) {\n    return;\n  }\n  // do something\n});\n```",
      "keypress_event": " \n\nThe **`keypress`** event is fired when a key that produces a character value is pressed down.\n\nExamples of keys that produce a character value are alphabetic, numeric, and punctuation keys. Examples of keys that don't produce a character value are modifier keys such as <kbd>Alt</kbd>, <kbd>Shift</kbd>, <kbd>Ctrl</kbd>, or <kbd>Meta</kbd>.\n\n> **Warning:** Since this event has been deprecated, you should use [`beforeinput`](/en-US/docs/Web/API/Element/beforeinput_event) or [`keydown`](/en-US/docs/Web/API/Element/keydown_event) instead.",
      "keyup_event": "\n\nThe **`keyup`** event is fired when a key is released.\n\nThe [`keydown`](/en-US/docs/Web/API/Element/keydown_event) and `keyup` events provide a code indicating which key is pressed, while `keypress` indicates which character was entered. For example, a lowercase \"a\" will be reported as 65 by `keydown` and `keyup`, but as 97 by `keypress`. An uppercase \"A\" is reported as 65 by all events.\n\nKeyboard events are only generated by `<input>`, `<textarea>`, `<summary>` and anything with the `contentEditable` or `tabindex` attribute.\n\nSince Firefox 65, the `keyup` and [`keydown`](/en-US/docs/Web/API/Element/keydown_event) events are now fired during IME composition, to improve cross-browser compatibility for CJKT users ([Firefox bug 354358](https://bugzil.la/354358). To ignore all `keyup` events that are part of composition, do something like this (229 is a special value set for a `keyCode` relating to an event that has been processed by an input-method editor ([IME](https://www.w3.org/TR/ime-api/#IME))):\n\n```js\neventTarget.addEventListener(\"keyup\", (event) => {\n  if (event.isComposing || event.keyCode === 229) {\n    return;\n  }\n  // do something\n});\n```",
      "lastelementchild": "\n\nThe **`Element.lastElementChild`** read-only property\nreturns an element's last child [Element], or `null` if there\nare no child elements.\n\n`Element.lastElementChild` includes only element nodes.\nTo get all child nodes, including non-element nodes like text and comment nodes, use [Node.lastChild].",
      "localname": "\n\nThe **`Element.localName`** read-only property returns the\nlocal part of the qualified name of an element.",
      "lostpointercapture_event": "\n\nThe **`lostpointercapture`** event is fired when a [captured pointer](/en-US/docs/Web/API/Pointer_events#pointer_capture) is released.",
      "matches": "\n\nThe **`matches()`** method of the [Element] interface tests whether the element would be selected by the specified [CSS selector](/en-US/docs/Learn/CSS/Building_blocks/Selectors).",
      "mousedown_event": "\n\nThe **`mousedown`** event is fired at an [Element] when a pointing device button is pressed while the pointer is inside the element.\n\n> **Note:** This differs from the [Element/click_event] event in that `click` is fired after a full click action occurs; that is, the mouse button is pressed and released while the pointer remains inside the same element. `mousedown` is fired the moment the button is initially pressed.",
      "mouseenter_event": "\n\nThe **`mouseenter`** event is fired at an [Element] when a pointing device (usually a mouse) is initially moved so that its hotspot is within the element at which the event was fired.",
      "mouseleave_event": "\n\nThe **`mouseleave`** event is fired at an [Element] when the cursor of a pointing device (usually a mouse) is moved out of it.\n\n`mouseleave` and [Element/mouseout_event] are similar but differ in that `mouseleave` does not bubble and `mouseout` does. This means that `mouseleave` is fired when the pointer has exited the element _and_ all of its descendants, whereas `mouseout` is fired when the pointer leaves the element _or_ leaves one of the element's descendants (even if the pointer is still within the element).",
      "mousemove_event": "\n\nThe `mousemove` event is fired at an element when a pointing device (usually a mouse) is moved while the cursor's hotspot is inside it.",
      "mouseout_event": "\n\nThe **`mouseout`** event is fired at an [Element] when a pointing device (usually a mouse) is used to move the cursor so that it is no longer contained within the element or one of its children.\n\n`mouseout` is also delivered to an element if the cursor enters a child element, because the child element obscures the visible area of the element.",
      "mouseover_event": "\n\nThe **`mouseover`** event is fired at an [Element] when a pointing device (such as a mouse or trackpad) is used to move the cursor onto the element or one of its child elements.",
      "mouseup_event": "\n\nThe **`mouseup`** event is fired at an [Element] when a button on a pointing device (such as a mouse or trackpad) is released while the pointer is located inside it.\n\n`mouseup` events are the counterpoint to [Element.mousedown_event] events.",
      "mousewheel_event": "\n\nThe _obsolete_ and _non-standard_ **`mousewheel`** event is fired asynchronously at an [Element] to provide updates while a mouse wheel or similar device is operated. The `mousewheel` event was never part of any standard, and while it was implemented by several browsers, it was never implemented by Firefox.\n\n> **Note:** Instead of this obsolete event, use the standard [Element.wheel_event] event.",
      "mozmousepixelscroll_event": "\n\nThe Firefox-only, _non-standard_, and _obsolete_ **`MozMousePixelScroll`** event is fired at an [Element] asynchronously when a mouse wheel or similar device is operated. It's represented by the [MouseScrollEvent] interface.\n\n> **Note:** Do not use this non-standard and obsolete event. Instead, you should always use the standard [Element.wheel_event] event.",
      "namespaceuri": "\n\nThe **`Element.namespaceURI`** read-only property returns the namespace URI of the element, or `null` if the element is not in a namespace.",
      "nextelementsibling": "\n\nThe **`Element.nextElementSibling`** read-only\nproperty returns the element immediately following the specified one in its parent's\nchildren list, or `null` if the specified element is the last one in the list.",
      "outerhtml": "\n\nThe **`outerHTML`** attribute of the [Element]\nDOM interface gets the serialized HTML fragment describing the element including its\ndescendants. It can also be set to replace the element with nodes parsed from the given\nstring.\n\nTo only obtain the HTML representation of the contents of an element, or to replace the\ncontents of an element, use the [Element.innerHTML] property\ninstead.",
      "part": "\n\nThe **`part`** property of the [Element] interface\nrepresents the part identifier(s) of the element (i.e. set using the `part`\nattribute), returned as a [DOMTokenList]. These can be used to style parts\nof a shadow DOM, via the  pseudo-element.",
      "paste_event": "\n\nThe **`paste`** event is fired when the user has initiated a \"paste\" action through the browser's user interface.\n\nIf the cursor is in an editable context (for example, in a `textarea` or an element with [`contenteditable`](/en-US/docs/Web/HTML/Global_attributes/contenteditable) attribute set to `true`) then the default action is to insert the contents of the clipboard into the document at the cursor position.\n\nA handler for this event can access the clipboard contents by calling [DataTransfer/getData] on the event's `clipboardData` property.\n\nTo override the default behavior (for example to insert some different data or a transformation of the clipboard contents) an event handler must cancel the default action using [Event/preventDefault], and then insert its desired data manually.\n\nIt's possible to construct and dispatch a [synthetic](/en-US/docs/Web/Events/Creating_and_triggering_events) `paste` event, but this will not affect the document's contents.",
      "pointercancel_event": "\n\nThe **`pointercancel`** event is fired when the browser determines that there are unlikely to be any more pointer events, or if after the [Element/pointerdown_event] event is fired, the pointer is then used to manipulate the viewport by panning, zooming, or scrolling.\n\nSome examples of situations that will trigger a `pointercancel` event:\n\n- A hardware event occurs that cancels the pointer activities. This may include, for example, the user switching applications using an application switcher interface or the \"home\" button on a mobile device.\n- The device's screen orientation is changed while the pointer is active.\n- The browser decides that the user started pointer input accidentally. This can happen if, for example, the hardware supports palm rejection to prevent a hand resting on the display while using a stylus from accidentally triggering events.\n- The  CSS property prevents the input from continuing.\n- When the user interacts with too many simultaneous pointers, the browser can fire this event for all existing pointers (even if the user is still touching the screen).\n\n> **Note:** After the `pointercancel` event is fired, the browser will also send [Element/pointerout_event] followed by [Element/pointerleave_event].",
      "pointerdown_event": "\n\nThe `pointerdown` event is fired when a pointer becomes active. For mouse, it is fired when the device transitions from no buttons pressed to at least one button pressed. For touch, it is fired when physical contact is made with the digitizer. For pen, it is fired when the stylus makes physical contact with the digitizer.\n\n> **Note:** For touchscreen browsers that allow [direct manipulation](https://w3c.github.io/pointerevents/#dfn-direct-manipulation), a `pointerdown` event triggers [implicit pointer capture](https://w3c.github.io/pointerevents/#dfn-implicit-pointer-capture), which causes the target to capture all subsequent pointer events as if they were occurring over the capturing target. Accordingly, `pointerover`, `pointerenter`, `pointerleave`, and `pointerout` **will not fire** as long as this capture is set. The capture can be released manually by calling [element.releasePointerCapture] on the target element, or it will be implicitly released after a `pointerup` or `pointercancel` event.",
      "pointerenter_event": "\n\nThe `pointerenter` event fires when a pointing device is moved into the hit test boundaries of an element or one of its descendants, including as a result of a [Element/pointerdown_event] event from a device that does not support hover (see [Element/pointerdown_event]).",
      "pointerleave_event": "\n\nThe `pointerleave` event is fired when a pointing device is moved out of the hit test boundaries of an element. For pen devices, this event is fired when the stylus leaves the hover range detectable by the digitizer.",
      "pointermove_event": "\n\nThe `pointermove` event is fired when a pointer changes coordinates, and the pointer has not been [canceled](/en-US/docs/Web/API/Element/pointercancel_event) by a browser [touch-action](/en-US/docs/Web/CSS/touch-action).",
      "pointerout_event": "\n\nThe `pointerout` event is fired for several reasons including: pointing device is moved out of the _hit test_ boundaries of an element; firing the [Element/pointerup_event] event for a device that does not support hover (see [Element/pointerup_event]); after firing the [Element/pointercancel_event] event (see [Element/pointercancel_event]); when a pen stylus leaves the hover range detectable by the digitizer.",
      "pointerover_event": "\n\nThe `pointerover` event is fired when a pointing device is moved into an element's hit test boundaries.",
      "pointerrawupdate_event": "\n\nThe **`pointerrawupdate`** [PointerEvent] is fired when a pointer changes any properties that don't fire [Element/pointerdown_event] or [Element/pointerup_event] events.\nSee [Element/pointermove_event] for a list of these properties.\n\nThe `pointerrawupdate` event may have coalesced events if there is already another `pointerrawupdate` event with the same pointer ID that hasn't been dispatched in the event loop.\nFor information on coalesced events, see the [PointerEvent.getCoalescedEvents] documentation.\n\nListeners for `pointerrawupdate` events should only be added if your JavaScript needs high-frequency events and can handle them as quickly as they are dispatched.\nFor most use cases, other pointer event types should suffice as there may be performance implications to adding listeners for `pointerrawupdate` events.",
      "pointerup_event": "\n\nThe `pointerup` event is fired when a pointer is no longer active. Remember that it is possible to get a [`pointercancel`](/en-US/docs/Web/API/Element/pointercancel_event) event instead.",
      "prefix": "\n\nThe **`Element.prefix`** read-only property returns the\nnamespace prefix of the specified element, or `null` if no prefix is\nspecified.",
      "prepend": "\n\nThe **`Element.prepend()`** method inserts a set of\n[Node] objects or string objects before the first child\nof the [Element]. String objects are inserted as\nequivalent [Text] nodes.",
      "previouselementsibling": "\n\nThe **`Element.previousElementSibling`**\nread-only property returns the [Element] immediately prior to the specified\none in its parent's children list, or `null` if the specified element is the first one in the list.",
      "queryselector": "\n\nThe **`querySelector()`** method of the [Element]\ninterface returns the first element that is a descendant of the element on which it is\ninvoked that matches the specified group of selectors.",
      "queryselectorall": "\n\nThe [Element] method **`querySelectorAll()`**\nreturns a static (not live) [NodeList] representing a list of elements\nmatching the specified group of selectors which are descendants of the element on which\nthe method was called.",
      "releasepointercapture": "\n\nThe **`releasePointerCapture()`** method of the\n[Element] interface releases (stops) _pointer capture_ that was\npreviously set for a specific ([PointerEvent]) _pointer_.\n\nSee the [Element.setPointerCapture] method\nfor a description of _pointer capture_ and how to set it for a particular\nelement.",
      "remove": "\n\nThe **`Element.remove()`** method removes the element from the DOM.",
      "removeattribute": "\n\nThe [Element] method\n**`removeAttribute()`** removes the attribute with the\nspecified name from the element.",
      "removeattributenode": "\n\nThe **`removeAttributeNode()`** method of the\n[Element] interface removes the specified attribute from the element.",
      "removeattributens": "\n\nThe **`removeAttributeNS()`** method of the\n[Element] interface removes the specified attribute from an element.",
      "replacechildren": "\n\nThe **`Element.replaceChildren()`** method replaces the\nexisting children of a [Node] with a specified new set of children. These\ncan be string or [Node] objects.",
      "replacewith": "\n\nThe **`Element.replaceWith()`** method replaces this\n`Element` in the children list of its parent with a set of\n[Node] or string objects. String\nobjects are inserted as equivalent [Text] nodes.",
      "requestfullscreen": "\n\nThe **`Element.requestFullscreen()`**\nmethod issues an asynchronous request to make the element be displayed in fullscreen\nmode.\n\nIt's not guaranteed that the element will be put into full screen mode. If permission\nto enter full screen mode is granted, the returned `Promise` will resolve\nand the element will receive a [Element/fullscreenchange_event] event to let it know that\nit's now in full screen mode. If permission is denied, the promise is rejected and the\nelement receives a [Element/fullscreenerror_event] event instead. If the element has been\ndetached from the original document, then the document receives these events instead.",
      "requestpointerlock": "\n\nThe **`requestPointerLock()`** method of the [Element] interface lets you asynchronously ask for the pointer to be locked on the given element.\n\nTo track the success or failure of the request, it is necessary to listen for the [Document/pointerlockchange_event] and [Document/pointerlockerror_event] events at the [Document] level.\n\n> **Note:** In the current specification, `requestPointerLock()` only communicates the success or failure of the request by firing [Document/pointerlockchange_event] or [Document/pointerlockerror_event] events. [A proposed update to the specification](https://github.com/w3c/pointerlock/pull/49) updates `requestPointerLock()` to return a `Promise` which communicates success or failure. This page documents the version that returns a `Promise`. However, note that this version is not yet a standard and is not implemented by all browsers. See [Browser compatibility](#browser_compatibility) for more information.",
      "scroll": "\n\nThe **`scroll()`** method of the [Element]\ninterface scrolls the element to a particular set of coordinates inside a given\nelement.",
      "scroll_event": "\n\nThe **`scroll`** event fires when an element has been scrolled.\nTo detect when scrolling has completed, see the .",
      "scrollby": "\n\nThe **`scrollBy()`** method of the [Element]\ninterface scrolls an element by the given amount.",
      "scrollend_event": "\n\nThe **`scrollend`** event fires when element scrolling has completed.\nScrolling is considered completed when the scroll position has no more pending updates and the user has completed their gesture.\n\nScroll position updates include smooth or instant mouse wheel scrolling, keyboard scrolling, scroll-snap events, or other APIs and gestures which cause the scroll position to update.\nUser gestures like touch panning or trackpad scrolling aren't complete until pointers or keys have released.\nIf the scroll position did not change, then no scrollend event fires.\n\nFor detecting when scrolling inside a Document is complete, see the .",
      "scrollheight": "\n\nThe **`Element.scrollHeight`** read-only property is a\nmeasurement of the height of an element's content, including content not visible on the\nscreen due to overflow.\n\n![The user's viewport is an element with four regions labeled padding-top, border-top, border-bottom, padding-bottom. The scroll height goes from the container's padding top to the end of the padding bottom, well beyond the top and bottom of the viewport.](scrollheight.png)\n\nThe `scrollHeight` value is equal to the minimum height the element would\nrequire in order to fit all the content in the viewport without using a vertical\nscrollbar. The height is measured in the same way as [Element.clientHeight]: it includes the element's padding, but not its border, margin or\nhorizontal scrollbar (if present). It can also include the height of pseudo-elements\nsuch as  or . If the element's content can\nfit without a need for vertical scrollbar, its `scrollHeight` is equal to\n[Element.clientHeight]\n\n> **Note:** This property will round the value to an integer. If you need a fractional value, use\n> [Element.getBoundingClientRect].",
      "scrollintoview": "\n\nThe [Element] interface's\n**`scrollIntoView()`** method scrolls the element's ancestor\ncontainers such that the element on which `scrollIntoView()` is called is\nvisible to the user.",
      "scrollintoviewifneeded": "\n\nThe **`Element.scrollIntoViewIfNeeded()`** method scrolls the current element into the visible area of the browser window if it's not already within the visible area of the browser window. If the element is already within the visible area of the browser window, then no scrolling takes place. This method is a proprietary variation of the standard [`Element.scrollIntoView()`](/en-US/docs/Web/API/Element/scrollIntoView) method.",
      "scrollleft": "\n\nThe **`Element.scrollLeft`** property gets or sets the number\nof pixels that an element's content is scrolled from its left edge.\n\nIf the element's `direction` is `rtl` (right-to-left), then\n`scrollLeft` is `0` when the scrollbar is at its rightmost\nposition (at the start of the scrolled content), and then increasingly negative as you\nscroll towards the end of the content.\n\nIt can be specified as any integer value. However:\n\n- If the element can't be scrolled (e.g., it has no overflow), `scrollLeft`\n  is set to `0`.\n- If specified as a value less than `0` (greater than `0` for\n  right-to-left elements), `scrollLeft` is set to `0`.\n- If specified as a value greater than the maximum that the content can be scrolled,\n  `scrollLeft` is set to the maximum.\n\n> **Warning:** On systems using display scaling, `scrollLeft` may give you a decimal\n> value.",
      "scrollleftmax": "\n\nThe **`Element.scrollLeftMax`** read-only property returns a\nnumber representing the maximum left scroll offset possible for the\nelement.",
      "scrollto": "\n\nThe **`scrollTo()`** method of the [Element]\ninterface scrolls to a particular set of coordinates inside a given element.",
      "scrolltop": "\n\nThe **`Element.scrollTop`** property gets or sets the number of pixels that an element's content is scrolled vertically.\n\nAn element's `scrollTop` value is a measurement of the distance from the element's top to its topmost _visible_ content. When an element's content does not generate a vertical scrollbar, then its `scrollTop` value is `0`.\n\n`scrollTop` can be set to any integer value, with certain caveats:\n\n- If the element can't be scrolled (e.g. it has no overflow or if the element has a property of \"**non-scrollable**\"), `scrollTop` is `0`.\n- `scrollTop` doesn't respond to negative values; instead, it sets itself back to `0`.\n- If set to a value greater than the maximum available for the element, `scrollTop` settles itself to the maximum value.\n\nWhen `scrollTop` is used on the root element (the `<html>` element), the `scrollY` of the window is returned. [This is a special case of `scrollTop`](https://www.w3.org/TR/2016/WD-cssom-view-1-20160317/#dom-element-scrolltop).\n\n> **Warning:** On systems using display scaling, `scrollTop` may give you a decimal value.",
      "scrolltopmax": "\n\nThe **`Element.scrollTopMax`** read-only property returns a\nnumber representing the maximum top scroll offset possible for the\nelement.",
      "scrollwidth": "\n\nThe **`Element.scrollWidth`** read-only property is a\nmeasurement of the width of an element's content, including content not visible on the\nscreen due to overflow.\n\nThe `scrollWidth` value is equal to the minimum width the element would\nrequire in order to fit all the content in the viewport without using a horizontal\nscrollbar. The width is measured in the same way as [Element.clientWidth]: it includes the element's padding, but not its border, margin or\nvertical scrollbar (if present). It can also include the width of pseudo-elements such\nas  or . If the element's content can fit\nwithout a need for horizontal scrollbar, its `scrollWidth` is equal to\n[Element.clientWidth]\n\n> **Note:** This property will round the value to an integer. If you need a fractional value,\n> use [element.getBoundingClientRect].",
      "securitypolicyviolation_event": "\n\nThe **`securitypolicyviolation`** event is fired when a [Content Security Policy](/en-US/docs/Web/HTTP/CSP) is violated.\n\nThe event is fired on the element that violates the policy and bubbles.\nIt is normally handled by an event handler on the [Window] or [Document] object.\n\nThe handler can be assigned using the `onsecuritypolicyviolation` property or using [EventTarget.addEventListener].\n\n> **Note:** You must add the handler for this event to a top level object (i.e. [Window] or [Document]).\n> While the property exists in HTML elements, you can't assign a handler to the property until the elements have been loaded, by which time this event will already have fired.",
      "setattribute": "\n\nSets the value of an attribute on the specified element. If\nthe attribute already exists, the value is updated; otherwise a new attribute is added\nwith the specified name and value.\n\nTo get the current value of an attribute, use [Element.getAttribute]; to remove an attribute, call [Element.removeAttribute].",
      "setattributenode": "\n\nThe **`setAttributeNode()`** method adds a new\n`Attr` node to the specified element.",
      "setattributenodens": "\n\n`setAttributeNodeNS` adds a new namespaced attribute node to an element.",
      "setattributens": "\n\n`setAttributeNS` adds a new attribute or changes the value of an attribute\nwith the given namespace and name.",
      "setcapture": "\n\nCall this method during the handling of a mousedown event to retarget all mouse events\nto this element until the mouse button is released or [document.releaseCapture] is called.\n\n> **Warning:** This interface never had much cross-browser\n> support and you probably looking for [element.setPointerCapture] instead,\n> from the Pointer Events API.",
      "sethtml": "\n\nThe **`setHTML()`** method of the [Element] interface is used to parse and sanitize a string of HTML and then insert it into the DOM as a subtree of the element.\nIt should be used instead of [Element.innerHTML] for inserting untrusted strings of HTML into an element.\n\nThe parsing process drops any elements in the HTML string that are invalid in the context of the current element, while sanitizing removes any unsafe or otherwise unwanted elements, attributes or comments.\nThe default `Sanitizer()` configuration strips out XSS-relevant input by default, including `script` tags, custom elements, and comments.\nThe sanitizer configuration may be customized using [Sanitizer.Sanitizer] constructor options.",
      "setpointercapture": "\n\nThe **`setPointerCapture()`** method of the\n[Element] interface is used to designate a specific element as the\n_capture target_ of future pointer events. Subsequent events for the pointer will\nbe targeted at the capture element until capture is released (via\n[Element.releasePointerCapture] or the\n[Element/pointerup_event] event is fired).\n\n> **Note:** Pointer capture will cause the target to capture all subsequent pointer events as if they were occurring over the capturing target. Accordingly, `pointerover`, `pointerenter`, `pointerleave`, and `pointerout` **will not fire** as long as this capture is set.\n> For touchscreen browsers that allow [direct manipulation](https://w3c.github.io/pointerevents/#dfn-direct-manipulation), an [implicit pointer capture](https://w3c.github.io/pointerevents/#dfn-implicit-pointer-capture) will be called on the element when a `pointerdown` event triggers. The capture can be released manually by calling [element.releasePointerCapture] on the target element, or it will be implicitly released after a `pointerup` or `pointercancel` event.\n\n### Overview of pointer capture\n\n_Pointer capture_ allows events for a particular _pointer event_\n([PointerEvent]) to be re-targeted to a particular element instead of the\nnormal (or _hit test_) target at a pointer's location. This can be used to ensure\nthat an element continues to receive pointer events even if the pointer device's contact\nmoves off the element (such as by scrolling or panning).",
      "shadowroot": "\n\nThe `Element.shadowRoot` read-only property\nrepresents the shadow root hosted by the element.\n\nUse [Element.attachShadow] to add a shadow root to an existing element.",
      "slot": "\n\nThe **`slot`** property of the [Element] interface\nreturns the name of the shadow DOM slot the element is inserted in.\n\nA slot is a placeholder inside a [web component](/en-US/docs/Web/API/Web_components) that users can fill with their own markup (see [Using templates and slots](/en-US/docs/Web/API/Web_components/Using_templates_and_slots) for more information).",
      "tagname": "\n\nThe **`tagName`** read-only property\nof the [Element] interface returns the tag name of the element on which\nit's called.\n\nFor example, if the element is an `img`, its\n`tagName` property is `\"IMG\"` (for HTML documents; it may be cased\ndifferently for XML/XHTML documents).",
      "toggleattribute": "\n\nThe **`toggleAttribute()`** method of the\n[Element] interface toggles a Boolean attribute (removing it if it is\npresent and adding it if it is not present) on the given element.",
      "touchcancel_event": "\n\nThe `touchcancel` event is fired when one or more touch points have been disrupted in an implementation-specific manner.\n\nSome examples of situations that will trigger a `touchcancel` event:\n\n- A hardware event occurs that cancels the touch activities. This may include, for example, the user switching applications using an application switcher interface or the \"home\" button on a mobile device.\n- The device's screen orientation is changed while the touch is active.\n- The browser decides that the user started touch input accidentally. This can happen if, for example, the hardware supports palm rejection to prevent a hand resting on the display while using a stylus from accidentally triggering events.\n- The  CSS property prevents the input from continuing.\n- When the user interacts with too many fingers simultaneously, the browser can fire this event for all existing pointers (even if the user is still touching the screen).",
      "touchend_event": "\n\nThe `touchend` event fires when one or more touch points are removed from the touch surface. Remember that it is possible to get a [`touchcancel`](/en-US/docs/Web/API/Element/touchcancel_event) event instead.",
      "touchmove_event": "\n\nThe `touchmove` event is fired when one or more touch points are moved along the touch surface.",
      "touchstart_event": "\n\nThe `touchstart` event is fired when one or more touch points are placed on the touch surface.",
      "transitioncancel_event": "\n\nThe **`transitioncancel`** event is fired when a [CSS transition](/en-US/docs/Web/CSS/CSS_transitions/Using_CSS_transitions) is canceled.",
      "transitionend_event": "\n\nThe **`transitionend`** event is fired when a [CSS transition](/en-US/docs/Web/CSS/CSS_transitions/Using_CSS_transitions) has completed. In the case where a transition is removed before completion, such as if the  is removed or `display` is set to `none`, then the event will not be generated.\n\nThe `transitionend` event is fired in both directions - as it finishes transitioning to the transitioned state, and when it fully reverts to the default or non-transitioned state. If there is no transition delay or duration, if both are 0s or neither is declared, there is no transition, and none of the transition events are fired. If the `transitioncancel` event is fired, the `transitionend` event will not fire.\n\nThis event is not cancelable.",
      "transitionrun_event": "\n\nThe **`transitionrun`** event is fired when a [CSS transition](/en-US/docs/Web/CSS/CSS_transitions/Using_CSS_transitions) is first created, i.e. before any  has begun.\n\nThis event is not cancelable.",
      "transitionstart_event": "\n\nThe **`transitionstart`** event is fired when a [CSS transition](/en-US/docs/Web/CSS/CSS_transitions/Using_CSS_transitions) has actually started, i.e., after any  has ended.\n\nThis event is not cancelable.",
      "webkitmouseforcechanged_event": "\n\nThe non-standard **`webkitmouseforcechanged`** event is fired by Safari each time the amount of pressure changes on the trackpad/touchscreen.\n\n**`webkitmouseforcechanged`** is a proprietary, WebKit-specific event introduced by Apple to support their [Force Touch Events] feature.\n\nThis event first fires after the [Element/mousedown_event] event and stops firing before the [Element/mouseup_event] event.",
      "webkitmouseforcedown_event": "\n\nAfter a [Element.mousedown_event] event has been fired at the element, if and when sufficient pressure has been applied to the mouse or trackpad button to qualify as a \"force click,\" Safari begins sending **`webkitmouseforcedown`** events to the element.\n\n**`webkitmouseforcedown`** is a proprietary, WebKit-specific event. It is part of the [Force Touch Events] feature.",
      "webkitmouseforceup_event": "\n\nThe non-standard **`webkitmouseforceup`** event is fired by Safari at an [Element] some time after the [Element/webkitmouseforcedown_event] event, when pressure on the button has been reduced sufficiently to end the \"force click\".\n\n**`webkitmouseforceup`** is a proprietary, WebKit-specific event. It is part of the [Force Touch Events] feature.",
      "webkitmouseforcewillbegin_event": "\n\nSafari for macOS fires the non-standard **`webkitmouseforcewillbegin`** event at an [Element] before firing the initial [Element/mousedown_event] event.\n\nThis offers the opportunity to tell the system not to trigger any default Force Touch actions if and when the click turns into a [Force Touch Events].\n\nTo instruct macOS not to engage any default Force Touch actions if the user apply enough pressure to activate a Force Touch event, call [Event.preventDefault] on the `webkitmouseforcewillbegin` event object.\n\n**`webkitmouseforcewillbegin`** is a proprietary, WebKit-specific event. It is part of the [Force Touch Events] feature.",
      "wheel_event": "\n\nThe **`wheel`** event fires when the user rotates a wheel button on a pointing device (typically a mouse).\n\nThis event replaces the non-standard deprecated [Element/mousewheel_event] event.\n\n> **Note:** Don't confuse the `wheel` event with the [Element/scroll_event] event. The default action of a `wheel` event is implementation-specific, and doesn't necessarily dispatch a `scroll` event. Even when it does, the `delta*` values in the `wheel` event don't necessarily reflect the content's scrolling direction. Therefore, do not rely on the `wheel` event's `delta*` properties to get the scrolling direction. Instead, detect value changes of [Element.scrollLeft] and [Element.scrollTop] of the target in the `scroll` event."
    }
  },
  "elementinternals": {
    "docs": "\n\nThe **`ElementInternals`** interface of the [Document Object Model](/en-US/docs/Web/API/Document_Object_Model) gives web developers a way to allow custom elements to fully participate in HTML forms. It provides utilities for working with these elements in the same way you would work with any standard HTML form element, and also exposes the [Accessibility Object Model](https://wicg.github.io/aom/explainer.html) to the element.",
    "properties": {
      "ariaatomic": "\n\nThe **`ariaAtomic`** property of the [ElementInternals] interface reflects the value of the [`aria-atomic`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-atomic) attribute, which indicates whether assistive technologies will present all, or only parts of, the changed region based on the change notifications defined by the `aria-relevant` attribute.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariaautocomplete": "\n\nThe **`ariaAutoComplete`** property of the [ElementInternals] interface reflects the value of the [`aria-autocomplete`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-autocomplete) attribute, which indicates whether inputting text could trigger display of one or more predictions of the user's intended value for a combobox, searchbox, or textbox and specifies how predictions would be presented if they were made.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariabusy": "\n\nThe **`ariaBusy`** property of the [ElementInternals] interface reflects the value of the [`aria-busy`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-busy) attribute, which indicates whether an element is being modified, as assistive technologies may want to wait until the modifications are complete before exposing them to the user.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariachecked": "\n\nThe **`ariaChecked`** property of the [ElementInternals] interface reflects the value of the [`aria-checked`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-checked) attribute, which indicates the current \"checked\" state of checkboxes, radio buttons, and other widgets that have a checked state.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariacolcount": "\n\nThe **`ariaColCount`** property of the [ElementInternals] interface reflects the value of the [`aria-colcount`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-colcount) attribute, which defines the number of columns in a table, grid, or treegrid.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariacolindex": "\n\nThe **`ariaColIndex`** property of the [ElementInternals] interface reflects the value of the [`aria-colindex`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-colindex) attribute, which defines an element's column index or position with respect to the total number of columns within a table, grid, or treegrid.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariacolindextext": "\n\nThe **`ariaColIndexText`** property of the [ElementInternals] interface reflects the value of the [`aria-colindextext`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-colindextext) attribute, which defines a human readable text alternative of aria-colindex.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariacolspan": "\n\nThe **`ariaColSpan`** property of the [ElementInternals] interface reflects the value of the [`aria-colspan`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-colspan) attribute, which defines the number of columns spanned by a cell or gridcell within a table, grid, or treegrid.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariacurrent": "\n\nThe **`ariaCurrent`** property of the [ElementInternals] interface reflects the value of the [`aria-current`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-current) attribute, which indicates the element that represents the current item within a container or set of related elements.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariadescription": "\n\nThe **`ariaDescription`** property of the [ElementInternals] interface reflects the value of the [`aria-description`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-description) attribute, which defines a string value that describes or annotates the current element.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariadisabled": "\n\nThe **`ariaDisabled`** property of the [ElementInternals] interface reflects the value of the [`aria-disabled`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-disabled) attribute, which indicates that the element is perceivable but disabled, so it is not editable or otherwise operable.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariaexpanded": "\n\nThe **`ariaExpanded`** property of the [ElementInternals] interface reflects the value of the [`aria-expanded`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-expanded) attribute, which indicates whether a grouping element owned or controlled by this element is expanded or collapsed.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariahaspopup": "\n\nThe **`ariaHasPopup`** property of the [ElementInternals] interface reflects the value of the [`aria-haspopup`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-haspopup) attribute, which indicates the availability and type of interactive popup element, such as menu or dialog, that can be triggered by an element.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariahidden": "\n\nThe **`ariaHidden`** property of the [ElementInternals] interface reflects the value of the [`aria-hidden`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-hidden) attribute, which indicates whether the element is exposed to an accessibility API.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariakeyshortcuts": "\n\nThe **`ariaKeyShortcuts`** property of the [ElementInternals] interface reflects the value of the [`aria-keyshortcuts`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-keyshortcuts) attribute, which indicates keyboard shortcuts that an author has implemented to activate or give focus to an element.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "arialabel": "}\n\nThe **`ariaLabel`** property of the [ElementInternals] interface reflects the value of the [`aria-label`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-label) attribute, which defines a string value that labels the current Element.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "arialevel": "\n\nThe **`ariaLevel`** property of the [ElementInternals] interface reflects the value of the [`aria-level`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-level) attribute, which defines the hierarchical level of an element within a structure.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "arialive": "\n\nThe **`ariaLive`** property of the [ElementInternals] interface reflects the value of the [`aria-live`](/en-US/docs/Web/Accessibility/ARIA/ARIA_Live_Regions) attribute, which indicates that an element will be updated, and describes the types of updates the user agents, assistive technologies, and user can expect from the live region.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariamodal": "\n\nThe **`ariaModal`** property of the [ElementInternals] interface reflects the value of the [`aria-modal`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-modal) attribute, which indicates whether an element is modal when displayed.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariamultiline": "\n\nThe **`ariaMultiLine`** property of the [ElementInternals] interface reflects the value of the [`aria-multiline`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-multiline) attribute, which indicates whether a text box accepts multiple lines of input or only a single line.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariamultiselectable": "\n\nThe **`ariaMultiSelectable`** property of the [ElementInternals] interface reflects the value of the [`aria-multiselectable`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-multiselectable) attribute, which indicates that the user may select more than one item from the current selectable descendants.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariaorientation": "\n\nThe **`ariaOrientation`** property of the [ElementInternals] interface reflects the value of the [`aria-orientation`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-orientation) attribute, which indicates whether the element's orientation is horizontal, vertical, or unknown/ambiguous.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariaplaceholder": "\n\nThe **`ariaPlaceholder`** property of the [ElementInternals] interface reflects the value of the [`aria-placeholder`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-placeholder) attribute, which defines a short hint intended to aid the user with data entry when the control has no value.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariaposinset": "\n\nThe **`ariaPosInSet`** property of the [ElementInternals] interface reflects the value of the [`aria-posinset`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-posinset) attribute, which defines an element's number or position in the current set of listitems or treeitems.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariapressed": "\n\nThe **`ariaPressed`** property of the [ElementInternals] interface reflects the value of the [`aria-pressed`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-pressed) attribute, which indicates the current \"pressed\" state of toggle buttons.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariareadonly": "\n\nThe **`ariaReadOnly`** property of the [ElementInternals] interface reflects the value of the [`aria-readonly`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-readonly) attribute, which indicates that the element is not editable, but is otherwise operable.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariarelevant": "\n\nThe **`ariaRelevant`** property of the [ElementInternals] interface reflects the value of the [`aria-relevant`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-relevant) attribute, which indicates what notifications the user agent will trigger when the accessibility tree within a live region is modified. This is used to describe what changes in an `aria-live` region are relevant and should be announced.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariarequired": "\n\nThe **`ariaRequired`** property of the [Element] interface reflects the value of the [`aria-required`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-required) attribute, which indicates that user input is required on the element before a form may be submitted.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariaroledescription": "\n\nThe **`ariaRoleDescription`** property of the [Element] interface reflects the value of the [`aria-roledescription`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-roledescription) attribute, which defines a human-readable, author-localized description for the role of an element.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariarowcount": "\n\nThe **`ariaRowCount`** property of the [ElementInternals] interface reflects the value of the [`aria-rowcount`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-rowcount) attribute, which defines the total number of rows in a table, grid, or treegrid.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariarowindex": "\n\nThe **`ariaRowIndex`** property of the [ElementInternals] interface reflects the value of the [`aria-rowindex`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-rowindex) attribute, which defines an element's row index or position with respect to the total number of rows within a table, grid, or treegrid.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariarowindextext": "\n\nThe **`ariaRowIndexText`** property of the [ElementInternals] interface reflects the value of the [`aria-rowindextext`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-rowindextext) attribute, which defines a human readable text alternative of aria-rowindex.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariarowspan": "\n\nThe **`ariaRowSpan`** property of the [ElementInternals] interface reflects the value of the [`aria-rowspan`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-rowspan) attribute, which defines the number of rows spanned by a cell or gridcell within a table, grid, or treegrid.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariaselected": "\n\nThe **`ariaSelected`** property of the [ElementInternals] interface reflects the value of the [`aria-selected`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-selected) attribute, which indicates the current \"selected\" state of elements that have a selected state.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariasetsize": "\n\nThe **`ariaSetSize`** property of the [ElementInternals] interface reflects the value of the [`aria-setsize`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-setsize) attribute, which defines the number of items in the current set of listitems or treeitems.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariasort": "\n\nThe **`ariaSort`** property of the [ElementInternals] interface reflects the value of the [`aria-sort`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-sort) attribute, which indicates if items in a table or grid are sorted in ascending or descending order.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariavaluemax": "\n\nThe **`ariaValueMax`** property of the [ElementInternals] interface reflects the value of the [`aria-valuemax`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-valuemax) attribute, which defines the maximum allowed value for a range widget.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariavaluemin": "\n\nThe **`ariaValueMin`** property of the [ElementInternals] interface reflects the value of the [`aria-valuemin`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-valuemin) attribute, which defines the minimum allowed value for a range widget.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariavaluenow": "\n\nThe **`ariaValueNow`** property of the [ElementInternals] interface reflects the value of the [`aria-valuenow`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-valuenow) attribute, which defines the current value for a range widget.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "ariavaluetext": "\n\nThe **`ariaValueText`** property of the [ElementInternals] interface reflects the value of the [`aria-valuetext`](/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-valuetext) attribute, which defines the human-readable text alternative of aria-valuenow for a range widget.\n\n> **Note:** Setting aria attributes on `ElementInternals` allows default semantics to be defined on a custom element. These may be overwritten by author-defined attributes, but ensure that default semantics are retained should the author delete those attributes, or fail to add them at all. For more information see the [Accessibility Object Model explainer](https://wicg.github.io/aom/explainer.html#default-semantics-for-custom-elements-via-the-elementinternals-object).",
      "checkvalidity": "\n\nThe **`checkValidity()`** method of the [ElementInternals] interface checks if the element meets any [constraint validation](/en-US/docs/Web/HTML/Constraint_validation) rules applied to it.\n\nIf `checkValidity` returns `false` then a cancelable [invalid event](/en-US/docs/Web/API/HTMLInputElement/invalid_event) is fired on the element.",
      "form": "\n\nThe **`form`** read-only property of the [ElementInternals] interface returns the [HTMLFormElement] associated with this element.",
      "labels": "\n\nThe **`labels`** read-only property of the [ElementInternals] interface returns the labels associated with the element.",
      "reportvalidity": "\n\nThe **`reportValidity()`** method of the [ElementInternals] interface checks if the element meets any [constraint validation](/en-US/docs/Web/HTML/Constraint_validation) rules applied to it.\n\nIf `reportValidity` returns `false` then a cancelable [invalid event](/en-US/docs/Web/API/HTMLInputElement/invalid_event) is fired on the element.\n\nThis method behaves in a similar way to [ElementInternals.checkValidity], however it additionally sends the value of [ElementInternals.validationMessage] to the user agent for display.",
      "role": "\n\nThe **`role`** read-only property of the [ElementInternals] interface returns the [WAI-ARIA role](/en-US/docs/Web/Accessibility/ARIA/Roles) for the element. For example, a checkbox might have [`role=\"checkbox\"`](/en-US/docs/Web/Accessibility/ARIA/Roles/checkbox_role).",
      "setformvalue": "\n\nThe **`setFormValue()`** method of the [ElementInternals] interface sets the element's submission value and state, communicating these to the user agent.",
      "setvalidity": "\n\nThe **`setValidity()`** method of the [ElementInternals] interface sets the validity of the element.",
      "shadowroot": "\n\nThe **`shadowRoot`** read-only property of the [ElementInternals] interface returns the [ShadowRoot] for this element.",
      "states": "\n\nThe **`states`** read-only property of the [ElementInternals] interface returns a [CustomStateSet] representing the possible states of the custom element.",
      "validationmessage": "\n\nThe **`validationMessage`** read-only property of the [ElementInternals] interface returns the validation message for the element.",
      "validity": "\n\nThe **`validity`** read-only property of the [ElementInternals] interface returns a [ValidityState] object which represents the different validity states the element can be in, with respect to constraint validation.",
      "willvalidate": "\n\nThe **`willValidate`** read-only property of the [ElementInternals] interface returns `true` if the element is a submittable element that is a candidate for [constraint validation](/en-US/docs/Web/HTML/Constraint_validation).\n\nElements that are barred from being candidates for constraint validation include those that have the attributes: `disabled`, `hidden` or `readonly`, input elements of `type=button` or `type=reset`, or any element that is a `datalist` element or has a `<datalist>` element ancestor."
    }
  },
  "encodedaudiochunk": {
    "docs": "\n\nThe **`EncodedAudioChunk`** interface of the [WebCodecs API] represents a chunk of encoded audio data.",
    "properties": {
      "bytelength": "\n\nThe **`byteLength`** read-only property of the [EncodedAudioChunk] interface returns the length in bytes of the encoded audio data.",
      "copyto": "\n\nThe **`copyTo()`** method of the [EncodedAudioChunk] interface copies the encoded chunk of audio data.",
      "duration": "\n\nThe **`duration`** read-only property of the [EncodedAudioChunk] interface returns an integer indicating the duration of the audio in microseconds.",
      "timestamp": "\n\nThe **`timestamp`** read-only property of the [EncodedAudioChunk] interface returns an integer indicating the timestamp of the audio in microseconds.",
      "type": "\n\nThe **`type`** read-only property of the [EncodedAudioChunk] interface returns a value indicating whether the audio chunk is a key chunk, which does not relying on other frames for decoding."
    }
  },
  "encodedvideochunk": {
    "docs": "\n\nThe **`EncodedVideoChunk`** interface of the [WebCodecs API] represents a chunk of encoded video data.",
    "properties": {
      "bytelength": "\n\nThe **`byteLength`** read-only property of the [EncodedVideoChunk] interface returns the length in bytes of the encoded video data.",
      "copyto": "\n\nThe **`copyTo()`** method of the [EncodedVideoChunk] interface copies the encoded chunk of video data.",
      "duration": "\n\nThe **`duration`** read-only property of the [EncodedVideoChunk] interface returns an integer indicating the duration of the video in microseconds.",
      "timestamp": "\n\nThe **`timestamp`** read-only property of the [EncodedVideoChunk] interface returns an integer indicating the timestamp of the video in microseconds.",
      "type": "\n\nThe **`type`** read-only property of the [EncodedVideoChunk] interface returns a value indicating whether the video chunk is a key chunk, which does not rely on other frames for decoding."
    }
  },
  "errorevent": {
    "docs": "\n\nThe **`ErrorEvent`** interface represents events providing information related to errors in scripts or in files.\n\n"
  },
  "event": {
    "docs": "\n\nThe **`Event`** interface represents an event which takes place in the DOM.\n\nAn event can be triggered by the user action e.g. clicking the mouse button or tapping keyboard, or generated by APIs to represent the progress of an asynchronous task. It can also be triggered programmatically, such as by calling the [`HTMLElement.click()`](/en-US/docs/Web/API/HTMLElement/click) method of an element, or by defining the event, then sending it to a specified target using [`EventTarget.dispatchEvent()`](/en-US/docs/Web/API/EventTarget/dispatchEvent).\n\nThere are many types of events, some of which use other interfaces based on the main `Event` interface. `Event` itself contains the properties and methods which are common to all events.\n\nMany DOM elements can be set up to accept (or \"listen\" for) these events, and execute code in response to process (or \"handle\") them. Event-handlers are usually connected (or \"attached\") to various [HTML elements](/en-US/docs/Web/HTML/Element) (such as `<button>`, `<div>`, `<span>`, etc.) using [`EventTarget.addEventListener()`](/en-US/docs/Web/API/EventTarget/addEventListener), and this generally replaces using the old HTML [event handler attributes](/en-US/docs/Web/HTML/Global_attributes). Further, when properly added, such handlers can also be disconnected if needed using [`removeEventListener()`](/en-US/docs/Web/API/EventTarget/removeEventListener).\n\n> **Note:** One element can have several such handlers, even for the exact same event—particularly if separate, independent code modules attach them, each for its own independent purposes. (For example, a webpage with an advertising-module and statistics-module both monitoring video-watching.)\n\nWhen there are many nested elements, each with its own handler(s), event processing can become very complicated—especially where a parent element receives the very same event as its child elements because \"spatially\" they overlap so the event technically occurs in both, and the processing order of such events depends on the [Event bubbling and capture](/en-US/docs/Learn/JavaScript/Building_blocks/Events#event_bubbling_and_capture) settings of each handler triggered.",
    "properties": {
      "bubbles": "\n\nThe **`bubbles`** read-only property of the [Event] interface indicates whether the event bubbles up through the DOM tree or not.\n\n> **Note:** See [Event bubbling and capture](/en-US/docs/Learn/JavaScript/Building_blocks/Events#event_bubbling) for more information on bubbling.",
      "cancelable": "\n\nThe **`cancelable`** read-only property of the [Event] interface indicates whether the event\ncan be canceled, and therefore prevented as if the event never happened.\n\nIf the event is _not_ cancelable, then its `cancelable` property will be\n`false` and the event listener cannot stop the event from occurring.\n\nMost browser-native events that can be canceled are the ones that result from the user\ninteracting with the page. Canceling the [Element/click_event],\n[Element/wheel_event], or\n[Window/beforeunload_event] events would prevent the user\nfrom clicking on something, scrolling the page with the mouse wheel, or\nnavigating away from the page, respectively.\n\n[Synthetic events](/en-US/docs/Web/API/Event/Event) created by other JavaScript\ncode define if they can be canceled when they are created.\n\nTo cancel an event, call the [event.preventDefault]\nmethod on the event. This keeps the implementation from executing the default action\nthat is associated with the event.\n\nEvent listeners that handle multiple kinds of events may want to check\n`cancelable` before invoking their [event.preventDefault] methods.",
      "cancelbubble": " \n\nThe **`cancelBubble`** property of the [Event]\ninterface is deprecated. Use [Event.stopPropagation] instead.\nSetting its value to `true` before returning from an event handler prevents propagation\nof the event. In later implementations, setting this to `false` does nothing.\nSee [Browser compatibility](#browser_compatibility) for details.",
      "comparison_of_event_targets": "\n\nIt's easy to get confused about which event target to examine when writing an event handler. This article should clarify the use of the target properties.\n\nThere are five targets to consider:\n\n<table class=\"no-markdown\">\n  <thead>\n    <tr>\n      <th>Property</th>\n      <th>Defined in</th>\n      <th>Purpose</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>\n        <code><a href=\"/en-US/docs/Web/API/Event/target\">event.target</a></code>\n      </td>\n      <td>\n        <a href=\"https://www.w3.org/TR/DOM-Level-2/events.html#Events-interface\"\n          >DOM Event Interface</a\n        >\n      </td>\n      <td>\n        The DOM element on the left-hand side of the call that triggered this\n        event.\n      </td>\n    </tr>\n    <tr>\n      <td>\n        <code\n          ><a href=\"/en-US/docs/Web/API/Event/currentTarget\"\n            >event.currentTarget</a\n          ></code\n        >\n      </td>\n      <td>\n        <a href=\"https://www.w3.org/TR/DOM-Level-2/events.html#Events-interface\"\n          >DOM Event Interface</a\n        >\n      </td>\n      <td>\n        The\n        <a\n          href=\"https://www.w3.org/TR/DOM-Level-2/events.html#Events-EventTarget\"\n          ><code>EventTarget</code></a\n        >\n        whose\n        <a\n          href=\"https://www.w3.org/TR/DOM-Level-2/events.html#Events-EventListener\"\n          ><code>EventListeners</code></a\n        >\n        are currently being processed. As the event capturing and bubbling\n        occurs, this value changes.\n      </td>\n    </tr>\n    <tr>\n      <td>\n        <code\n          ><a href=\"/en-US/docs/Web/API/MouseEvent/relatedTarget\"\n            >event.relatedTarget</a\n          ></code\n        >\n      </td>\n      <td>\n        <a\n          href=\"https://www.w3.org/TR/DOM-Level-2/events.html#Events-MouseEvent\"\n          >DOM MouseEvent Interface</a\n        >\n      </td>\n      <td>Identifies a secondary target for the event.</td>\n    </tr>\n    <tr>\n      <td>\n        <code\n          ><a href=\"/en-US/docs/Web/API/Event/explicitOriginalTarget\"\n            >event.explicitOriginalTarget</a\n          ></code\n        >\n      </td>\n      <td><a href=\"https://dxr.mozilla.org/mozilla-central/source/dom/webidl/Event.webidl\">Event.webidl</a>\n      </td>\n      <td>\n         If the event was retargeted for\n        some reason other than an anonymous boundary crossing, this will be set\n        to the target before the retargeting occurs. For example, mouse events\n        are retargeted to their parent node when they happen over text nodes\n        ([Firefox bug 185889](https://bugzil.la/185889)), and in that case <code>.target</code> will\n        show the parent and <code>.explicitOriginalTarget</code> will show the\n        text node.<br />Unlike <code>.originalTarget</code>,\n        <code>.explicitOriginalTarget</code> will never contain anonymous\n        content.\n      </td>\n    </tr>\n    <tr>\n      <td>\n        <code\n          ><a href=\"/en-US/docs/Web/API/Event/originalTarget\"\n            >event.originalTarget</a\n          ></code\n        >\n      </td>\n      <td>\n        <a href=\"https://dxr.mozilla.org/mozilla-central/source/dom/webidl/Event.webidl\">Event.webidl</a>\n      </td>\n      <td>\n         The original target of the event,\n        before any retargetings. See\n        <a\n          href=\"/en-US/docs/XBL/XBL_1.0_Reference/Anonymous_Content#Event_Flow_and_Targeting\"\n          >Anonymous Content#Event_Flow_and_Targeting</a\n        >\n        for details.\n      </td>\n    </tr>\n    <tr>\n      <td>event.composedTarget</td>\n      <td>\n        <a href=\"https://dxr.mozilla.org/mozilla-central/source/dom/webidl/Event.webidl\">Event.webidl</a>\n      </td>\n      <td>\n         The original non-native target of\n        the event before composition from Shadow DOM.\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n### Use of `explicitOriginalTarget` and `originalTarget`\n\n> **Note:** These properties are only available in Mozilla-based browsers.\n\n### Examples\n\n```html\n<!doctype html>\n<html lang=\"en-US\">\n  <head>\n    <meta charset=\"utf-8\" />\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\" />\n    <title>Comparison of Event Targets</title>\n    <style>\n      table {\n        border-collapse: collapse;\n        height: 150px;\n        width: 100%;\n      }\n      td {\n        border: 1px solid #ccc;\n        font-weight: bold;\n        padding: 5px;\n        min-height: 30px;\n      }\n      .standard {\n        background-color: #99ff99;\n      }\n      .non-standard {\n        background-color: #902d37;\n      }\n    </style>\n  </head>\n  <body>\n    <table>\n      <thead>\n        <tr>\n          <td class=\"standard\">\n            Original target dispatching the event <small>event.target</small>\n          </td>\n          <td class=\"standard\">\n            Target who's event listener is being processed\n            <small>event.currentTarget</small>\n          </td>\n          <td class=\"standard\">\n            Identify other element (if any) involved in the event\n            <small>event.relatedTarget</small>\n          </td>\n          <td class=\"non-standard\">\n            If there was a retargeting of the event for some reason\n            <small> event.explicitOriginalTarget</small> contains the target\n            before retargeting (never contains anonymous targets)\n          </td>\n          <td class=\"non-standard\">\n            If there was a retargeting of the event for some reason\n            <small> event.originalTarget</small> contains the target before\n            retargeting (may contain anonymous targets)\n          </td>\n        </tr>\n      </thead>\n      <tr>\n        <td id=\"target\"></td>\n        <td id=\"currentTarget\"></td>\n        <td id=\"relatedTarget\"></td>\n        <td id=\"explicitOriginalTarget\"></td>\n        <td id=\"originalTarget\"></td>\n      </tr>\n    </table>\n    <p>\n      Clicking on the text will show the difference between\n      explicitOriginalTarget, originalTarget, and target\n    </p>\n    <script>\n      function handleClicks(e) {\n        document.getElementById(\"target\").innerHTML = e.target;\n        document.getElementById(\"currentTarget\").innerHTML = e.currentTarget;\n        document.getElementById(\"relatedTarget\").innerHTML = e.relatedTarget;\n        document.getElementById(\"explicitOriginalTarget\").innerHTML =\n          e.explicitOriginalTarget;\n        document.getElementById(\"originalTarget\").innerHTML = e.originalTarget;\n      }\n\n      function handleMouseover(e) {\n        document.getElementById(\"target\").innerHTML = e.target;\n        document.getElementById(\"relatedTarget\").innerHTML = e.relatedTarget;\n      }\n\n      document.addEventListener(\"click\", handleClicks, false);\n      document.addEventListener(\"mouseover\", handleMouseover, false);\n    </script>\n  </body>\n</html>\n```\n\n### Use of `target` and `relatedTarget`\n\nThe `relatedTarget` property for the `mouseover` event holds the node that the mouse was previously over. For the `mouseout` event, it holds the node that the mouse moved to.\n\n| Event type  | [event.target](/en-US/docs/Web/API/Event/target)  | [event.relatedTarget](/en-US/docs/Web/API/MouseEvent/relatedTarget) |\n| ----------- | ------------------------------------------------- | ------------------------------------------------------------------- |\n| `mouseover` | the EventTarget which the pointing device entered | the EventTarget which the pointing device exited                    |\n| `mouseout`  | the EventTarget which the pointing device exited  | the EventTarget which the pointing device entered                   |\n\n#### Example\n\n```xml\n<hbox id=\"outer\">\n  <hbox id=\"inner\"\n        onmouseover=\"dump('mouseover ' + event.relatedTarget.id + ' > ' + event.target.id + '\\n');\"\n        onmouseout=\"dump('mouseout  ' + event.target.id + ' > ' + event.relatedTarget.id + '\\n');\"\n        style=\"margin: 100px; border: 10px solid black; width: 100px; height: 100px;\" />\n</hbox>\n```",
      "composed": "\n\nThe read-only **`composed`** property of the\n[Event] interface returns a boolean value which indicates whether\nor not the event will propagate across the shadow DOM boundary into the standard DOM.\n\nAll UA-dispatched UI events are composed (click/touch/mouseover/copy/paste, etc.). Most\nother types of events are not composed, and so will return `false`. For\nexample, this includes synthetic events that are created without their\n`composed` option set to `true`.\n\nPropagation only occurs if the [Event.bubbles] property is also\n`true`. However, capturing only composed events are also handled at host as\nif they were in `AT_TARGET` phase. You can determine the path the event will\nfollow through the shadow root to the DOM root by calling\n[Event.composedPath].",
      "composedpath": "\n\nThe **`composedPath()`** method of the [Event]\ninterface returns the event's path which is an array of the objects on which listeners\nwill be invoked. This does not include nodes in shadow trees if the shadow root was\ncreated with its [ShadowRoot.mode] closed.",
      "currenttarget": "\n\nThe **`currentTarget`** read-only property of the [Event] interface identifies the element to which the event handler has been attached.\n\nThis will not always be the same as the element on which the event was fired, because the event may have fired on a descendant of the element with the handler, and then [bubbled](/en-US/docs/Learn/JavaScript/Building_blocks/Events#event_bubbling) up to the element with the handler. The element on which the event was fired is given by [Event.target].",
      "defaultprevented": "\n\nThe **`defaultPrevented`** read-only property of the [Event] interface returns a boolean value indicating whether or not the call to [Event.preventDefault] canceled the event.",
      "eventphase": "\n\nThe **`eventPhase`** read-only property of the\n[Event] interface indicates which phase of the event flow is currently\nbeing evaluated.",
      "explicitoriginaltarget": "\n\nThe read-only **`explicitOriginalTarget`** property of the [Event] interface returns the non-anonymous original target of the event.\n\nIf the event was retargeted for some reason other than an anonymous boundary crossing, this will be set to the target before the retargeting occurs.\n\nFor example, mouse events are retargeted to their parent node when they happen over text nodes (see [Firefox bug 185889](https://bugzil.la/185889)), and in that case [`currentTarget`](/en-US/docs/Web/API/Event/currentTarget) will show the parent while this property will show the text node.\n\nThis property also differs from [`originalTarget`](/en-US/docs/Web/API/Event/originalTarget) in that it will never contain anonymous content.",
      "initevent": "\n\nThe **`Event.initEvent()`** method is used to initialize the\nvalue of an [event] created using [Document.createEvent].\n\nEvents initialized in this way must have been created with the\n[Document.createEvent] method.\nThis method must be called to set the event\nbefore it is dispatched, using [EventTarget.dispatchEvent].\nOnce dispatched, it doesn't do anything anymore.\n\n> **Note:** _Do not use this method anymore as it is deprecated._\n> Instead use specific event constructors, like [Event.Event].\n> The page on [Creating and triggering events](/en-US/docs/Web/Events/Creating_and_triggering_events) gives more information about the way to use these.",
      "istrusted": "\n\nThe **`isTrusted`** read-only property of the\n[Event] interface is a boolean value that is `true`\nwhen the event was generated by a user action, and `false` when the event was\ncreated or modified by a script or dispatched via\n[EventTarget.dispatchEvent].",
      "originaltarget": " \n\nThe read-only **`originalTarget`** property of the [Event] interface returns the original target of the event before any retargetings. Unlike [Event.explicitOriginalTarget] it can also be native anonymous content.\n\nSee also [Comparison of Event Targets](/en-US/docs/Web/API/Event/Comparison_of_Event_Targets).",
      "preventdefault": "\n\nThe **`preventDefault()`** method of the [Event] interface tells the  that if the event does not get explicitly handled, its default action should not be taken as it normally would be.\n\nThe event continues to propagate as usual,\nunless one of its event listeners calls\n[Event.stopPropagation]\nor [Event.stopImmediatePropagation],\neither of which terminates propagation at once.\n\nAs noted below, calling **`preventDefault()`** for a\nnon-cancelable event, such as one dispatched via\n[EventTarget.dispatchEvent], without specifying\n`cancelable: true` has no effect.",
      "returnvalue": "\n\nThe [Event] property\n**`returnValue`** indicates whether the default action for\nthis event has been prevented or not.\n\nIt is set to `true` by\ndefault, allowing the default action to occur. Setting this property to\n`false` prevents the default action.\n\n> **Note:** While `returnValue` has been adopted into the DOM\n> standard, it is present primarily to support existing code. Use\n> [Event.preventDefault], and\n> [Event.defaultPrevented] instead of this historical\n> property.",
      "srcelement": "\n\nThe deprecated **`Event.srcElement`** is an alias for the [Event.target] property. Use [Event.target] instead.",
      "stopimmediatepropagation": "\n\nThe **`stopImmediatePropagation()`** method of the\n[Event] interface prevents other listeners of the same event from being called.\n\nIf several listeners are attached to the same element for the same event type, they are called in the order in which they were added. If `stopImmediatePropagation()` is invoked during one such call, no remaining listeners will be called, either on that element or any other element.",
      "stoppropagation": "\n\nThe **`stopPropagation()`** method of the [Event]\ninterface prevents further propagation of the current event in the capturing and\nbubbling phases. It does not, however, prevent any default behaviors from occurring; for\ninstance, clicks on links are still processed. If you want to stop those behaviors, see\nthe [Event.preventDefault] method. It also does not\nprevent propagation to other event-handlers of the current element. If you want to stop those,\nsee [Event.stopImmediatePropagation].",
      "target": "\n\nThe read-only **`target`** property of the\n[Event] interface is a reference to the object onto which the event was\ndispatched. It is different from [Event.currentTarget] when the event\nhandler is called during the bubbling or capturing phase of the event.",
      "timestamp": "\n\nThe **`timeStamp`** read-only property of the [Event] interface returns the time (in milliseconds) at which the event was created.",
      "type": "\n\nThe **`type`** read-only property of the [Event]\ninterface returns a string containing the event's type. It is set when the event is\nconstructed and is the name commonly used to refer to the specific event, such as\n`click`, `load`, or `error`."
    }
  },
  "eventcounts": {
    "docs": "\n\nThe **`EventCounts`** interface of the [Performance API](/en-US/docs/Web/API/Performance_API) provides the number of events that have been dispatched for each event type.\n\nAn `EventCounts` instance is a read-only [`Map`-like object](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map#map-like_browser_apis), in which each key is the name string for an event type, and the corresponding value is an integer indicating the number of events that have been dispatched for that event type."
  },
  "eventsource": {
    "docs": "\n\nThe **`EventSource`** interface is web content's interface to [server-sent events](/en-US/docs/Web/API/Server-sent_events).\n\nAn `EventSource` instance opens a persistent connection to an [HTTP](/en-US/docs/Web/HTTP) server, which sends [events](/en-US/docs/Learn/JavaScript/Building_blocks/Events) in `text/event-stream` format. The connection remains open until closed by calling [EventSource.close].\n\nOnce the connection is opened, incoming messages from the server are delivered to your code in the form of events. If there is an event field in the incoming message, the triggered event is the same as the event field value. If no event field is present, then a generic [EventSource/message_event] event is fired.\n\nUnlike [WebSockets](/en-US/docs/Web/API/WebSockets_API), server-sent events are unidirectional; that is, data messages are delivered in one direction, from the server to the client (such as a user's web browser). That makes them an excellent choice when there's no need to send data from the client to the server in message form. For example, `EventSource` is a useful approach for handling things like social media status updates, news feeds, or delivering data into a [client-side storage](/en-US/docs/Learn/JavaScript/Client-side_web_APIs/Client-side_storage) mechanism like [IndexedDB](/en-US/docs/Web/API/IndexedDB_API) or [web storage](/en-US/docs/Web/API/Web_Storage_API).\n\n> **Warning:** When **not used over HTTP/2**, SSE suffers from a limitation to the maximum number of open connections, which can be specially painful when opening various tabs as the limit is _per browser_ and set to a very low number (6). The issue has been marked as \"Won't fix\" in [Chrome](https://crbug.com/275955) and [Firefox](https://bugzil.la/906896). This limit is per browser + domain, so that means that you can open 6 SSE connections across all of the tabs to `www.example1.com` and another 6 SSE connections to `www.example2.com`. (from [Stackoverflow](https://stackoverflow.com/questions/5195452/websockets-vs-server-sent-events-eventsource/5326159)). When using HTTP/2, the maximum number of simultaneous _HTTP streams_ is negotiated between the server and the client (defaults to 100).",
    "properties": {
      "close": "\n\nThe **`close()`** method of the [EventSource]\ninterface closes the connection, if one is made, and sets the\n[EventSource.readyState] attribute to `2` (closed).\n\n> **Note:** If the connection is already closed, the method does nothing.",
      "error_event": "\n\nThe `error` event of the [EventSource] API is fired when a connection with an event source fails to be opened.\n\nThis event is not cancelable and does not bubble.",
      "message_event": "\n\nThe `message` event of the [EventSource] API is fired when data is received through an event source.\n\nThis event is not cancelable and does not bubble.",
      "open_event": "\n\nThe `open` event of the [EventSource] API is fired when a connection with an event source is opened.\n\nThis event is not cancelable and does not bubble.",
      "readystate": "\n\nThe **`readyState`** read-only property of the\n[EventSource] interface returns a number representing the state of the\nconnection.",
      "url": "\n\nThe **`url`** read-only property of the\n[EventSource] interface returns a string representing the\nURL of the source.",
      "withcredentials": "\n\nThe **`withCredentials`** read-only property of the\n[EventSource] interface returns a boolean value indicating whether\nthe `EventSource` object was instantiated with CORS credentials set."
    }
  },
  "eventtarget": {
    "docs": "\n\nThe **`EventTarget`** interface is implemented by objects that can receive events and may have listeners for them.\nIn other words, any target of events implements the three methods associated with this interface.\n\n[Element], and its children, as well as [Document] and [Window], are the most common event targets,\nbut other objects can be event targets, too.\nFor example [IDBRequest], [AudioNode], and [AudioContext] are also event targets.\n\nMany event targets (including elements, documents, and windows) also support setting [event handlers](/en-US/docs/Web/Events/Event_handlers) via `onevent` properties and attributes.\n\n",
    "properties": {
      "addeventlistener": "\n\nThe **`addEventListener()`** method of the [EventTarget] interface\nsets up a function that will be called whenever the specified event is delivered to the target.\n\nCommon targets are [Element], or its children, [Document], and [Window],\nbut the target may be any object that supports events (such as [IDBRequest]).\n\n> **Note:** The `addEventListener()` method is the _recommended_ way to register an event listener. The benefits are as follows:\n>\n> - It allows adding more than one handler for an event. This is particularly\n>   useful for libraries, JavaScript modules, or any other kind of\n>   code that needs to work well with other libraries or extensions.\n> - In contrast to using an `onXYZ` property, it gives you finer-grained control of the phase when the listener is activated (capturing vs. bubbling).\n> - It works on any event target, not just HTML or SVG elements.\n\nThe method `addEventListener()` works by adding a function, or an object that implements\n[EventTarget.addEventListener], to the list of event listeners for the specified event type\non the [EventTarget] on which it's called. If the function or object is already in the list of event listeners for this target, the function or object is not added a second time.\n\n> **Note:** If a particular anonymous function is in the list of event listeners registered for a certain target, and then later in the code, an identical anonymous function is given in an `addEventListener` call, the second function will _also_ be added to the list of event listeners for that target.\n>\n> Indeed, anonymous functions are not identical even if defined using\n> the _same_ unchanging source-code called repeatedly, **even if in a loop**.\n>\n> Repeatedly defining the same unnamed function in such cases can be\n> problematic. (See [Memory issues](#memory_issues), below.)\n\nIf an event listener is added to an [EventTarget] from inside another listener —\nthat is, during the processing of the event —\nthat event will not trigger the new listener.\nHowever, the new listener may be triggered during a later stage of event flow,\nsuch as during the bubbling phase.",
      "dispatchevent": "\n\nThe **`dispatchEvent()`** method of the [EventTarget] sends an [Event] to the object, (synchronously) invoking the affected\nevent listeners in the appropriate order. The normal event processing\nrules (including the capturing and optional bubbling phase) also apply to events\ndispatched manually with `dispatchEvent()`.\n\nCalling `dispatchEvent()` is the last step to _firing an event_. The event\nshould have already been created and initialized using an [Event/Event] constructor.\n\n> **Note:** When calling this method, the [Event.target] property is initialized to the current `EventTarget`.\n\nUnlike \"native\" events, which are fired by the browser and invoke event handlers\nasynchronously via the [event loop](/en-US/docs/Web/JavaScript/Event_loop),\n`dispatchEvent()` invokes event handlers _synchronously_. All applicable event\nhandlers are called and return before `dispatchEvent()` returns.",
      "removeeventlistener": "\n\nThe **`removeEventListener()`** method of the [EventTarget] interface\nremoves an event listener previously registered with [EventTarget.addEventListener] from the target.\nThe event listener to be removed is identified using a combination of the event type,\nthe event listener function itself, and various optional options that may affect the matching process;\nsee [Matching event listeners for removal](#matching_event_listeners_for_removal).\n\nCalling `removeEventListener()` with arguments that do not identify any\ncurrently registered [event listener](/en-US/docs/Web/API/EventTarget/addEventListener#the_event_listener_callback) on the `EventTarget` has no\neffect.\n\nIf an [event listener](/en-US/docs/Web/API/EventTarget/addEventListener#the_event_listener_callback) is removed from an [EventTarget] while another listener of the target is processing an event, it will not be triggered by the event. However, it can be reattached.\n\n> **Warning:** If a listener is registered twice, one with the _capture_ flag set and one without, you must remove each one separately. Removal of a capturing listener does not affect a non-capturing version of the same listener, and vice versa.\n\nEvent listeners can also be removed by passing an [AbortSignal] to an [EventTarget/addEventListener] and then later calling [AbortController/abort] on the controller owning the signal."
    }
  },
  "extendablecookiechangeevent": {
    "docs": "\n\nThe **`ExtendableCookieChangeEvent`** interface of the [Cookie Store API] is the event type passed to [ServiceWorkerGlobalScope/cookiechange_event] event fired at the [ServiceWorkerGlobalScope] when any cookie changes occur which match the service worker's cookie change subscription list. A cookie change event consists of a cookie and a type. (either \"changed\" or \"deleted\")\n\nCookie changes that cause the `ExtendableCookieChangeEvent` to be dispatched are:\n\n- A cookie is newly created and not immediately removed. In this case `type` is \"changed\".\n- A cookie is newly created and immediately removed. In this case `type` is \"deleted\"\n- A cookie is removed. In this case `type` is \"deleted\".\n\n> **Note:** A cookie that is replaced due to the insertion of another cookie with the same name, domain, and path, is ignored and does not trigger a change event.\n\n",
    "properties": {
      "changed": "\n\nThe **`changed`** read-only property of the [ExtendableCookieChangeEvent] interface returns any cookies that have been changed by the given `ExtendableCookieChangeEvent` instance.\n\n",
      "deleted": "\n\nThe **`deleted`** read-only property of the [ExtendableCookieChangeEvent] interface returns any cookies that have been deleted by the given `ExtendableCookieChangeEvent` instance.\n\n"
    }
  },
  "extendableevent": {
    "docs": "\n\nThe **`ExtendableEvent`** interface extends the lifetime of the [`install`](/en-US/docs/Web/API/ServiceWorkerGlobalScope/install_event) and [`activate`](/en-US/docs/Web/API/ServiceWorkerGlobalScope/activate_event) events dispatched on the global scope as part of the service worker lifecycle. This ensures that any functional events (like [FetchEvent]) are not dispatched until it upgrades database schemas and deletes the outdated cache entries.\n\nIf [ExtendableEvent.waitUntil] is called outside of the `ExtendableEvent` handler, the browser should throw an `InvalidStateError`; note also that multiple calls will stack up, and the resulting promises will be added to the list of [extend lifetime promises](https://w3c.github.io/ServiceWorker/#extendableevent-extend-lifetime-promises).\n\n> **Note:** The behavior described in the above paragraph was fixed in Firefox 43 (see [Firefox bug 1180274](https://bugzil.la/1180274).)\n\nThis interface inherits from the [Event] interface.\n\n> **Note:** This interface is only available when the global scope is a [ServiceWorkerGlobalScope]. It is not available when it is a [Window], or the scope of another kind of worker.",
    "properties": {
      "waituntil": "\n\nThe **`ExtendableEvent.waitUntil()`**\nmethod tells the event dispatcher that work is ongoing. It can also be used to detect\nwhether that work was successful. In service workers, `waitUntil()` tells\nthe browser that work is ongoing until the promise settles, and it shouldn't terminate\nthe service worker if it wants that work to complete.\n\nThe [ServiceWorkerGlobalScope/install_event] events in [service workers](/en-US/docs/Web/API/ServiceWorkerGlobalScope) use\n`waitUntil()` to hold the service worker in\nthe [ServiceWorkerRegistration.installing] phase until tasks\ncomplete. If the promise passed to `waitUntil()` rejects, the install is\nconsidered a failure, and the installing service worker is discarded. This is primarily\nused to ensure that a service worker is not considered installed until all of the core\ncaches it depends on are successfully populated.\n\nThe [ServiceWorkerGlobalScope/activate_event] events in [service workers](/en-US/docs/Web/API/ServiceWorkerGlobalScope) use\n`waitUntil()` to buffer functional events such as `fetch` and\n`push` until the promise passed to `waitUntil()` settles. This\ngives the service worker time to update database schemas and delete outdated\n[Cache], so other events can rely on a completely upgraded state.\n\nThe `waitUntil()` method must be initially called within the event callback,\nbut after that it can be called multiple times, until all the promises passed to it\nsettle.\n\n> **Note:** The behavior described in the above paragraph was fixed in\n> Firefox 43 (see [Firefox bug 1180274](https://bugzil.la/1180274))."
    }
  },
  "extendablemessageevent": {
    "docs": "\n\nThe **`ExtendableMessageEvent`** interface of the [Service Worker API](/en-US/docs/Web/API/Service_Worker_API) represents the event object of a [ServiceWorkerGlobalScope/message_event] event fired on a service worker (when a message is received on the [ServiceWorkerGlobalScope] from another context) — extends the lifetime of such events.\n\nThis interface inherits from the [ExtendableEvent] interface.\n\n",
    "properties": {
      "data": "\n\nThe **`data`** read-only property of the\n[ExtendableMessageEvent] interface returns the event's data. It can be any\ndata type.",
      "lasteventid": "\n\nThe **`lastEventID`** read-only property of the\n[ExtendableMessageEvent] interface represents, in [server-sent events](/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events), the last event ID of the event source. This is an empty string.",
      "origin": "\n\nThe **`origin`** read-only property of the\n[ExtendableMessageEvent] interface returns the origin of the\n[Client] that sent the message.",
      "ports": "\n\nThe **`ports`** read-only property of the\n[ExtendableMessageEvent] interface returns the array containing the\n[MessagePort] objects representing the ports of the associated message\nchannel (the channel the message is being sent through.)",
      "source": "\n\nThe **`source`** read-only property of the\n[ExtendableMessageEvent] interface returns a reference to the\n[Client] object from which the message was sent."
    }
  },
  "eyedropper": {
    "docs": "\n\nThe **`EyeDropper`** interface represents an instance of an eyedropper tool that can be opened and used by the user to select colors from the screen.",
    "properties": {
      "open": "\n\nThe **`EyeDropper.open()`** method starts the eyedropper mode, returning a promise which is fulfilled once the user has selected a color and exited the eyedropper mode."
    }
  },
  "featurepolicy": {
    "docs": "\n\nThe `FeaturePolicy` interface represents the set of [Permissions Policies](/en-US/docs/Web/HTTP/Permissions_Policy) applied to the current execution context.",
    "properties": {
      "allowedfeatures": "\n\nThe **`allowedFeatures()`** method of\nthe [FeaturePolicy] interface returns a list of directive names of all\nfeatures allowed by the [Permissions Policy](/en-US/docs/Web/HTTP/Permissions_Policy). This enables introspection of individual directives\nof the Permissions Policy it is run on. As such, `allowedFeatures()` method\nreturns a subset of directives returned by [FeaturePolicy.features].",
      "allowsfeature": "\n\nThe **`allowsFeature()`** method of\nthe [FeaturePolicy] interface enables introspection of individual\ndirectives of the [Permissions Policy](/en-US/docs/Web/HTTP/Permissions_Policy) it is run on. It returns a `Boolean`\nthat is `true` if and only if the specified feature is allowed in the\nspecified context (or the default context if no context is specified).",
      "features": "\n\nThe **`features()`** method of the\n[FeaturePolicy] interface returns a list of names of all features\nsupported by the User Agent. Feature whose name appears on the list might not be\nallowed by the [Permissions Policy](/en-US/docs/Web/HTTP/Permissions_Policy) of the current execution context and/or might not be\naccessible because of user's permissions.",
      "getallowlistforfeature": "\n\nThe **`getAllowlistForFeature()`**\nmethod of the [FeaturePolicy] interface enables querying of the allowlist for a specific feature for the current Permissions Policy."
    }
  },
  "federatedcredential": {
    "docs": "\n\nThe **`FederatedCredential`** interface of the [Credential Management API](/en-US/docs/Web/API/Credential_Management_API) provides information about credentials from a federated identity provider. A federated identity provider is an entity that a website trusts to correctly authenticate a user, and that provides an API for that purpose. [OpenID Connect](https://openid.net/developers/specs/) is an example of a federated identity provider framework.\n\n> **Note:** The [Federated Credential Management API (FedCM)](/en-US/docs/Web/API/FedCM_API) provides a more complete solution for handling identity federation in the browser, and uses the [IdentityCredential] type.\n\nIn browsers that support it, an instance of this interface may be passed in the `credential` member of the `init` object for global [fetch].\n\n",
    "properties": {
      "protocol": "\n\nThe **`protocol`** property of the\n[FederatedCredential] interface returns a read-only\nstring containing a credential's federated identity protocol. If this\nproperty is [`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null), the protocol may be inferred from the\n[FederatedCredential.provider] property.",
      "provider": "\n\nThe **`provider`** property of the\n[FederatedCredential] interface returns a string\ncontaining a credential's federated identity provider."
    }
  },
  "fetchevent": {
    "docs": "\n\nThis is the event type for `fetch` events dispatched on the [ServiceWorkerGlobalScope]. It contains information about the fetch, including the request and how the receiver will treat the response. It provides the [FetchEvent.respondWith] method, which allows us to provide a response to this fetch.\n\n",
    "properties": {
      "clientid": "\n\nThe **`clientId`** read-only property of the\n[FetchEvent] interface returns the id of the [Client] that the\ncurrent service worker is controlling.\n\nThe [Clients.get] method could then be passed this ID to retrieve the\nassociated client.",
      "handled": "\n\nThe **`handled`** property of the [FetchEvent] interface returns a promise indicating if the event has been handled by the fetch algorithm or not. This property allows executing code after the browser has consumed a response, and is usually used together with the [ExtendableEvent.waitUntil] method.",
      "isreload": "\n\nThe **`isReload`** read-only property of the\n[FetchEvent] interface returns `true` if the event was\ndispatched by the user attempting to reload the page, and `false` otherwise.\nPressing the refresh button is a reload while clicking a link and pressing the back\nbutton is not.",
      "preloadresponse": "\n\nThe **`preloadResponse`** read-only property of the [FetchEvent] interface returns a `Promise` that resolves to the navigation preload [Response] if [navigation preload](/en-US/docs/Web/API/NavigationPreloadManager) was triggered, or `undefined` otherwise.\n\nNavigation preload is triggered if [navigation preload is enabled](/en-US/docs/Web/API/NavigationPreloadManager/enable), the request is a `GET` request, and the request is a navigation request (generated by the browser when loading pages and iframes).\n\nA service worker can wait on this promise in its fetch event handler in order to track completion of a fetch request made during service-worker boot.",
      "replacesclientid": "\n\nThe **`replacesClientId`** read-only property of the\n[FetchEvent] interface is the [Client.id] of the\n[Client] that is being replaced during a page navigation.\n\nFor example, when navigating from page A to page B `replacesClientId` is the\nID of the client associated with page A. It can be an empty string when navigating from\n`about:blank` to another page, as `about:blank`'s client will be\nreused, rather than be replaced.\n\nAdditionally, if the fetch isn't a navigation, `replacesClientId` will be an\nempty string. This could be used to access/communicate with a client that will\nimminently be replaced, right before a navigation.",
      "request": "\n\nThe **`request`** read-only property of the\n[FetchEvent] interface returns the [Request] that triggered\nthe event handler.\n\nThis property is non-nullable (since version 46, in the case of Firefox.) If a request\nis not provided by some other means, the constructor `options` object must\ncontain a request (see [FetchEvent.FetchEvent].)",
      "respondwith": "\n\nThe **`respondWith()`** method of\n[FetchEvent] prevents the browser's default fetch handling, and\nallows you to provide a promise for a [Response] yourself.\n\nIn most cases you can provide any response that the receiver understands. For example,\nif an `img` initiates the request, the response body needs to be\nimage data. For security reasons, there are a few global rules:\n\n- You can only return [Response] objects of [Response.type] \"`opaque`\" if the [fetchEvent.request] object's\n  [request.mode] is \"`no-cors`\". This prevents the\n  leaking of private data.\n- You can only return [Response] objects of [Response.type] \"`opaqueredirect`\" if the [fetchEvent.request]\n  object's [request.mode] is \"`manual`\".\n- You cannot return [Response] objects of [Response.type] \"`cors`\" if the [fetchEvent.request] object's\n  [request.mode] is \"`same-origin`\".\n\n### Specifying the final URL of a resource\n\nFrom Firefox 59 onwards, when a service worker provides a [Response] to\n[FetchEvent.respondWith], the [Response.url] value will be\npropagated to the intercepted network request as the final resolved URL. If the\n[Response.url] value is the empty string, then the\n[Request.url] is used as the final URL.\n\nIn the past the [Request.url] was used as the\nfinal URL in all cases. The provided [Response.url] was effectively\nignored.\n\nThis means, for example, if a service worker intercepts a stylesheet or worker script,\nthen the provided [Response.url] will be used to resolve any relative\n or\n[WorkerGlobalScope.importScripts] subresource loads\n([Firefox bug 1222008](https://bugzil.la/1222008)).\n\nFor most types of network request this change has no impact because you can't observe\nthe final URL. There are a few, though, where it does matter:\n\n- If a [fetch] is intercepted,\n  then you can observe the final URL on the result's [Response.url].\n- If a [worker](/en-US/docs/Web/API/Web_Workers_API) script is\n  intercepted, then the final URL is used to set\n  [`self.location`](/en-US/docs/Web/API/WorkerGlobalScope/location)\n  and used as the base URL for relative URLs in the worker script.\n- If a stylesheet is intercepted, then the final URL is used as the base URL for\n  resolving relative  loads.\n\nNote that navigation requests for [Window] and\n[HTMLIFrameElement] do NOT use the final URL. The way the HTML\nspecification handles redirects for navigations ends up using the request URL for the\nresulting [Window.location]. This means sites can still provide an\n\"alternate\" view of a web page when offline without changing the user-visible URL.",
      "resultingclientid": "\n\nThe **`resultingClientId`** read-only property of the\n[FetchEvent] interface is the [Client.id] of the\n[Client] that replaces the previous client during a page\nnavigation.\n\nFor example, when navigating from page A to page B `resultingClientId` is\nthe ID of the client associated with page B.\n\nIf the fetch request is a subresource request or the request's\n[`destination`](/en-US/docs/Web/API/Request/destination) is\n`report`, `resultingClientId` will be an empty string."
    }
  },
  "file": {
    "docs": "\n\nThe **`File`** interface provides information about files and allows JavaScript in a web page to access their content.\n\n`File` objects are generally retrieved from a [FileList] object returned as a result of a user selecting files using the `input` element, or from a drag and drop operation's [DataTransfer] object.\n\nA `File` object is a specific kind of [Blob], and can be used in any context that a Blob can. In particular, [FileReader], [URL.createObjectURL_static], [createImageBitmap], the [`body`](/en-US/docs/Web/API/fetch#body) option to [fetch], and [XMLHttpRequest] accept both `Blob`s and `File`s.\n\nSee [Using files from web applications](/en-US/docs/Web/API/File_API/Using_files_from_web_applications) for more information and examples.\n\n",
    "properties": {
      "lastmodified": "\n\nThe **`lastModified`** read-only property of the [File] interface provides the\nlast modified date of the file as the number of milliseconds since the Unix\nepoch (January 1, 1970 at midnight). Files without a known last modified date return the\ncurrent date.",
      "lastmodifieddate": "\n\nThe **`lastModifiedDate`** read-only property of the [File] interface returns the last modified date of the file. Files without a known last modified date return the current date.",
      "name": "\n\nThe **`name`** read-only property of the [File] interface returns the name of the file represented by a [File] object. For security\nreasons, the path is excluded from this property.",
      "webkitrelativepath": "\n\nThe **`webkitRelativePath`** read-only property of the [File] interface\ncontains a string which specifies the file's path relative to the\ndirectory selected by the user in an `input` element with its\n[`webkitdirectory`](/en-US/docs/Web/HTML/Element/input#webkitdirectory) attribute set."
    }
  },
  "fileentrysync": {
    "docs": " \n\nThe `FileEntrySync` interface represents a file in a file system. It lets you write content to a file.\n\n> **Warning:** This interface is deprecated and is no more on the standard track.\n> _Do not use it anymore._ Use the [File and Directory Entries API](/en-US/docs/Web/API/File_and_Directory_Entries_API) instead."
  },
  "filelist": {
    "docs": "\n\nThe **`FileList`** interface represents an object of this type returned by the `files` property of the HTML `input` element; this lets you access the list of files selected with the `<input type=\"file\">` element. It's also used for a list of files dropped into web content when using the drag and drop API; see the [DataTransfer] object for details on this usage.\n\nAll `<input>` element nodes have a `files` attribute of type `FileList` on them which allows access to the items in this list. For example, if the HTML includes the following file input:\n\n```html\n<input id=\"fileItem\" type=\"file\" />\n```\n\nThe following line of code fetches the first file in the node's file list as a [File] object:\n\n```js\nconst file = document.getElementById(\"fileItem\").files[0];\n```\n\n> **Note:** This interface was an [attempt to create an unmodifiable list](https://stackoverflow.com/questions/74630989/why-use-domstringlist-rather-than-an-array/74641156#74641156) and only continues to be supported to not break code that's already using it. Modern APIs use types that wrap around ECMAScript array types instead, so you can treat them like ECMAScript arrays, and at the same time impose additional semantics on their usage (such as making their items read-only).",
    "properties": {
      "item": "\n\nThe **`item()`** method of the [FileList] interface returns a [File] object representing the file at the specified index in the file list.",
      "length": "\n\nThe **`length`** read-only property of the [FileList] interface returns the number of files in the `FileList`."
    }
  },
  "filereader": {
    "docs": "\n\nThe **`FileReader`** object lets web applications asynchronously read the contents of files (or raw data buffers) stored on the user's computer, using [File] or [Blob] objects to specify the file or data to read.\n\nFile objects may be obtained from a [FileList] object returned as a result of a user selecting files using the `input` element, or from a drag and drop operation's [DataTransfer] object.\n\n`FileReader` can only access the contents of files that the user has explicitly selected, either using an HTML `<input type=\"file\">` element or by drag and drop. It cannot be used to read a file by pathname from the user's file system. To read files on the client's file system by pathname, use the [File System Access API](/en-US/docs/Web/API/File_System_API). To read server-side files, use [fetch], with [CORS](/en-US/docs/Web/HTTP/CORS) permission if reading cross-domain.\n\n",
    "properties": {
      "abort": "\n\nThe **`abort`** method of the [FileReader] interface aborts the read operation. Upon return,\nthe [FileReader.readyState] will be `DONE`.",
      "abort_event": "\n\nThe **`abort`** event is fired when a read has been aborted: for instance because the program called [FileReader.abort].\n\nThis event is not cancelable and does not bubble.",
      "error": "\n\nThe **`error`** read-only property of the [FileReader] interface returns the\nerror that occurred while reading the file.",
      "error_event": "\n\nThe **`error`** event is fired when the read failed due to an error (for example, because the file was not found or not readable).\n\nThis event is not cancelable and does not bubble.",
      "load_event": "\n\nThe **`load`** event is fired when a file has been read successfully.\n\nThis event is not cancelable and does not bubble.",
      "loadend_event": "\n\nThe **`loadend`** event is fired when a file read has completed, successfully or not.\n\nThis event is not cancelable and does not bubble.",
      "loadstart_event": "\n\nThe **`loadstart`** event is fired when a file read operation has begun.\n\nThis event is not cancelable and does not bubble.",
      "progress_event": "\n\nThe **`progress`** event is fired periodically as the `FileReader` reads data.\n\nThis event is not cancelable and does not bubble.",
      "readasarraybuffer": "\n\nThe **`readAsArrayBuffer()`** method of the [FileReader] interface is used to start reading the\ncontents of a specified [Blob] or [File]. When the read\noperation is finished, the [FileReader.readyState] becomes\n`DONE`, and the [FileReader/loadend_event] is\ntriggered. At that time, the [FileReader.result] attribute\ncontains an `ArrayBuffer` representing the file's data.\n\n> **Note:** The [Blob.arrayBuffer] method is a newer promise-based API to read a\n> file as an array buffer.",
      "readasbinarystring": "\n\n> **Note:** This method is deprecated in favor of [FileReader.readAsArrayBuffer].\n\nThe **`readAsBinaryString`** method of the [FileReader] interface is used to start reading the contents of the\nspecified [Blob] or [File]. When the read operation is\nfinished, the [FileReader.readyState] becomes\n`DONE`, and the [FileReader.loadend_event] is triggered. At that time, the\n[FileReader.result] attribute contains the raw binary data from\nthe file.\n\nNote that this method was once removed from the File API specification, but\nre-introduced for backward compatibility.\nUsing [FileReader.readAsArrayBuffer] is recommended.",
      "readasdataurl": "\n\nThe **`readAsDataURL`** method of the [FileReader] interface is used to read the contents of the specified\n[Blob] or [File]. When the read operation is finished, the\n[FileReader.readyState] becomes `DONE`, and the\n[FileReader/loadend_event] is triggered. At that time, the\n[FileReader.result] attribute contains the data as a [data: URL](/en-US/docs/Web/HTTP/Basics_of_HTTP/Data_URLs) representing the\nfile's data as a base64 encoded string.\n\n> **Note:** The blob's [FileReader.result] cannot be\n> directly decoded as Base64 without first removing the Data-URL declaration preceding\n> the Base64-encoded data. To retrieve only the Base64 encoded string, first\n> remove `data:*/*;base64,` from the result.",
      "readastext": "\n\nThe **`readAsText()`** method of the [FileReader] interface is used to read the contents of the specified [Blob] or [File].\nWhen the read operation is complete, the [FileReader.readyState] is changed to `DONE`,\nthe [FileReader/loadend_event] event is triggered, and the [FileReader.result] property contains the contents of the file as a text string.\n\n> **Note:** The [Blob.text] method is a newer promise-based API to read a file as text.\n\n> **Note:** This method loads the entire file's content into memory and is not suitable for large files. Prefer [`readAsArrayBuffer()`](/en-US/docs/Web/API/FileReader/readAsArrayBuffer) for large files.",
      "readystate": "\n\nThe **`readyState`** read-only property of the [FileReader] interface provides the current state of the reading operation a `FileReader` is in. A `FileReader` exists in one of the following states:\n\n| Value | State     | Description                                                   |\n| ----- | --------- | ------------------------------------------------------------- |\n| `0`   | `EMPTY`   | Reader has been created. None of the read methods called yet. |\n| `1`   | `LOADING` | A read method has been called.                                |\n| `2`   | `DONE`    | The operation is complete.                                    |\n\n- `EMPTY`\n  - : The `FileReader` has been created, but no readAs method was called yet.\n- `LOADING`\n  - : A readAs method was invoked. A [File] or [Blob] is being read, and no error has occurred yet.\n- `DONE`\n  - : The read operation is complete. This could mean that: the entire [File] or [Blob] has been read into memory, a file read error occurred, or [FileReader.abort] was called and the read was cancelled.",
      "result": "\n\nThe **`result`** read-only property of the [FileReader] interface returns the\nfile's contents. This property is only valid after the read operation is complete, and\nthe format of the data depends on which of the methods was used to initiate the read\noperation."
    }
  },
  "filereadersync": {
    "docs": "\n\nThe **`FileReaderSync`** interface allows to read [File] or [Blob] objects synchronously. This interface is [only available](/en-US/docs/Web/API/Web_Workers_API/Functions_and_classes_available_to_workers) in [workers](/en-US/docs/Web/API/Worker) as it enables synchronous I/O that could potentially block.\n\n",
    "properties": {
      "readasarraybuffer": "\n\nThe **`readAsArrayBuffer()`** method of the [FileReaderSync] interface allows to read [File] or [Blob] objects in a synchronous way into an `ArrayBuffer`. This interface is [only available](/en-US/docs/Web/API/Web_Workers_API/Functions_and_classes_available_to_workers) in [workers](/en-US/docs/Web/API/Worker) as it enables synchronous I/O that could potentially block.\n\n",
      "readasbinarystring": "\n\n> **Note:** This method is deprecated in favor of [FileReaderSync.readAsArrayBuffer].\n\nThe **`readAsBinaryString()`** method of the [FileReaderSync] interface allows to read [File] or [Blob] objects in a synchronous way into a string. This interface is [only available](/en-US/docs/Web/API/Web_Workers_API/Functions_and_classes_available_to_workers) in [workers](/en-US/docs/Web/API/Worker) as it enables synchronous I/O that could potentially block.\n\n",
      "readasdataurl": "\n\nThe **`readAsDataURL()`** method of the [FileReaderSync] interface allows to read [File] or [Blob] objects in a synchronous way into a string representing a data URL. This interface is [only available](/en-US/docs/Web/API/Web_Workers_API/Functions_and_classes_available_to_workers) in [workers](/en-US/docs/Web/API/Worker) as it enables synchronous I/O that could potentially block.\n\n",
      "readastext": "\n\nThe **`readAsText()`** method of the [FileReaderSync] interface allows to read [File] or [Blob] objects in a synchronous way into a string. This interface is [only available](/en-US/docs/Web/API/Web_Workers_API/Functions_and_classes_available_to_workers) in [workers](/en-US/docs/Web/API/Worker) as it enables synchronous I/O that could potentially block.\n\n"
    }
  },
  "filesystem": {
    "docs": "\n\nThe File and Directory Entries API interface **`FileSystem`** is used to represent a file system. These objects can be obtained from the [FileSystemEntry.filesystem] property on any file system entry. Some browsers offer additional APIs to create and manage file systems, such as Chrome's [Window.requestFileSystem] method.\n\nThis interface will not grant you access to the users' filesystem. Instead, you will have a \"virtual drive\" within the browser sandbox if you want to gain access to the users' file system, you need to invoke the user, for example by installing a Chrome extension. The relevant Chrome API can be found [here](https://developer.chrome.com/docs/extensions/reference/fileSystem/).",
    "properties": {
      "name": "\n\nThe read-only **`name`** property of the\n[FileSystem] interface indicates the file system's name. This\nstring is unique among all file systems currently exposed by the [File and Directory Entries API](/en-US/docs/Web/API/File_and_Directory_Entries_API).",
      "root": "\n\nThe read-only **`root`** property of the\n[FileSystem] interface specifies a [FileSystemDirectoryEntry]\nobject representing the root directory of the file system, for use with the [File and Directory Entries API](/en-US/docs/Web/API/File_and_Directory_Entries_API)."
    }
  },
  "filesystemdirectoryentry": {
    "docs": "\n\nThe **`FileSystemDirectoryEntry`** interface of the [File and Directory Entries API](/en-US/docs/Web/API/File_and_Directory_Entries_API) represents a directory in a file system. It provides methods which make it possible to access and manipulate the files in a directory, as well as to access the entries within the directory.\n\n",
    "properties": {
      "createreader": "\n\nThe [FileSystemDirectoryEntry] interface's method\n**`createReader()`** returns a\n[FileSystemDirectoryReader] object which can be used to read the entries in\nthe directory.",
      "getdirectory": "\n\nThe [FileSystemDirectoryEntry] interface's method\n**`getDirectory()`** returns a\n[FileSystemDirectoryEntry] object corresponding to a directory contained\nsomewhere within the directory subtree rooted at the directory on which it's called.",
      "getfile": "\n\nThe [FileSystemDirectoryEntry] interface's method\n**`getFile()`** returns a\n[FileSystemFileEntry] object corresponding to a file contained somewhere\nwithin the directory subtree rooted at the directory on which it's called.",
      "removerecursively": "\n\nThe [FileSystemDirectoryEntry] interface's method\n**`removeRecursively()`** removes\nthe directory as well as all of its content, hierarchically iterating over its entire\nsubtree of descendant files and directories.\n\nTo remove a single file, or an empty directory, you can also use\n[FileSystemEntry.remove]."
    }
  },
  "filesystemdirectoryhandle": {
    "docs": "\n\nThe **`FileSystemDirectoryHandle`** interface of the [File System API] provides a handle to a file system directory.\n\nThe interface can be accessed via the [window.showDirectoryPicker], [StorageManager.getDirectory], [DataTransferItem.getAsFileSystemHandle], and [FileSystemDirectoryHandle.getDirectoryHandle] methods.\n\n",
    "properties": {
      "entries": "\n\nThe **`entries()`** method of the\n[FileSystemDirectoryHandle] interface returns a new asynchronous iterator\nfor the iteration of the key-value pairs of the entries within the `FileSystemDirectoryHandle`\non which this method is called. The key-value pairs are\nin the form of an array like `[key, value]`.",
      "getdirectoryhandle": "\n\nThe **`getDirectoryHandle()`** method of the\n[FileSystemDirectoryHandle] interface returns a\n[FileSystemDirectoryHandle] for a subdirectory with the specified name\nwithin the directory handle on which the method is called.",
      "getfilehandle": "\n\nThe **`getFileHandle()`** method of the\n[FileSystemDirectoryHandle] interface returns a\n[FileSystemFileHandle] for a file with the specified name, within the\ndirectory the method is called.",
      "keys": "\n\nThe **`keys()`** method of the\n[FileSystemDirectoryHandle] interface returns a new asynchronous iterator\nfor the iteration of the key of the entries within the `FileSystemDirectoryHandle`\non which this method is called.",
      "removeentry": "\n\nThe **`removeEntry()`** method of the\n[FileSystemDirectoryHandle] interface attempts to remove an entry if the\ndirectory handle contains a file or directory called the name specified.",
      "resolve": "\n\nThe **`resolve()`** method of the\n[FileSystemDirectoryHandle] interface returns an `Array` of\ndirectory names from the parent handle to the specified child entry, with the name of\nthe child entry as the last array item.",
      "values": "\n\nThe **`values()`** method of the\n[FileSystemDirectoryHandle] interface returns a new asynchronous iterator\nfor the iteration of the value of the entries within the `FileSystemDirectoryHandle`\non which this method is called."
    }
  },
  "filesystemdirectoryreader": {
    "docs": "\n\nThe `FileSystemDirectoryReader` interface of the [File and Directory Entries API](/en-US/docs/Web/API/File_and_Directory_Entries_API) lets you access the [FileSystemFileEntry]-based objects (generally [FileSystemFileEntry] or [FileSystemDirectoryEntry]) representing each entry in a directory.",
    "properties": {
      "readentries": "\n\nThe [FileSystemDirectoryReader] interface's **`readEntries()`** method retrieves the directory entries\nwithin the directory being read and delivers them in an array to a provided callback function.\n\nThe objects in the array are all based upon [FileSystemEntry].\nGenerally, they are either [FileSystemFileEntry] objects, which represent standard files, or [FileSystemDirectoryEntry] objects, which represent directories."
    }
  },
  "filesystementry": {
    "docs": "\n\nThe **`FileSystemEntry`** interface of the File and Directory Entries API represents a single entry in a file system. The entry can be a file or a directory (directories are represented by the [FileSystemDirectoryEntry] interface). It includes methods for working with files—including copying, moving, removing, and reading files—as well as information about a file it points to—including the file name and its path from the root to the entry.",
    "properties": {
      "copyto": "\n\nThe [FileSystemEntry] interface's method\n**`copyTo()`** copies the file\nspecified by the entry to a new location on the file system.\n\nThere are some\ntypical restrictions on what you can do:\n\n- A directory can't be copied into itself.\n- An entry can't be copied into its parent directory unless you specify a new name.\n- When copying a directory, the copy is always recursive; you can't leave out\n  subfolders.",
      "filesystem": "\n\nThe read-only **`filesystem`**\nproperty of the [FileSystemEntry] interface contains a\n[FileSystem] object that represents the file system on which the entry\nresides.",
      "fullpath": "\n\nThe read-only **`fullPath`** property\nof the [FileSystemEntry] interface returns a string\nspecifying the full, absolute path from the file system's root to the file represented\nby the entry.\n\nThis can also be thought of as a path which is relative to the root directory, with a\n\"/\" prepended to it to make it absolute.",
      "getmetadata": "\n\nThe [FileSystemEntry] interface's method\n**`getMetadata()`** obtains a\n[Metadata] object with information about the file system entry, such as\nits modification date and time and its size.",
      "getparent": "\n\nThe [FileSystemEntry] interface's method\n**`getParent()`** obtains a\n[FileSystemDirectoryEntry].",
      "isdirectory": "\n\nThe read-only **`isDirectory`**\nproperty of the [FileSystemEntry] interface is `true` if the\nentry represents a directory (meaning it's a [FileSystemDirectoryEntry])\nand `false` if it's not.\n\nYou can also use [FileSystemEntry.isFile] to determine if the\nentry is a file.\n\n> **Warning:** You should not assume that any entry which isn't a directory is a file or vice versa.\n> There are other types of file descriptors on many operating systems. Be sure to use\n> both `isDirectory` and `isFile` as needed to ensure that the\n> entry is something you know how to work with.",
      "isfile": "\n\nThe read-only **`isFile`** property of\nthe [FileSystemEntry] interface is `true` if the entry\nrepresents a file (meaning it's a [FileSystemFileEntry]) and\n`false` if it's not.\n\nYou can also use [FileSystemEntry.isDirectory] to determine\nif the entry is a directory.\n\n> **Warning:** You should not assume that any entry which isn't a file is a directory or vice versa.\n> There are other types of file descriptors on many operating systems. Be sure to use\n> both `isDirectory` and `isFile` as needed to ensure that the\n> entry is something you know how to work with.",
      "moveto": "\n\nThe [FileSystemEntry] interface's method\n**`moveTo()`** moves the file\nspecified by the entry to a new location on the file system, or renames the file if\nthe destination directory is the same as the source.\n\nThere are some typical\nrestrictions on what you can do:\n\n- A directory can't be moved into itself.\n- An entry can't be moved into its parent directory unless you specify a new name.\n  Specifying a new name lets `moveTo()` double as a rename operation.\n- When moving a directory, the move is always recursive; you can't leave out\n  subfolders.\n- You can't move a file such that it replaces an existing directory, and you can't\n  move a directory such that it replaces an existing file. However, a file can replace a\n  file and a directory can replace a directory.\n- You can only overwrite a directory if it's empty.",
      "name": "\n\nThe read-only **`name`** property of\nthe [FileSystemEntry] interface returns a string\nspecifying the entry's name; this is the entry within its parent directory (the last\ncomponent of the path as indicated by the [FileSystemEntry.fullPath] property).",
      "remove": "\n\nThe [FileSystemEntry] interface's method\n**`remove()`** deletes the file\nor directory from the file system. Directories must be empty before they can be\nremoved.\n\nTo recursively remove a directory as well as all of its contents and its\nsubdirectories, call [FileSystemDirectoryEntry.removeRecursively]\ninstead.",
      "tourl": "\n\nThe [FileSystemEntry] interface's method\n**`toURL()`** creates and\nreturns a string containing a URL which can be used to identify the file system entry.\nThis is done by exposing a new URL scheme—`filesystem:`—that can be used as\nthe value of `src` and `href` attributes."
    }
  },
  "filesystemfileentry": {
    "docs": "\n\nThe **`FileSystemFileEntry`** interface of the [File and Directory Entries API](/en-US/docs/Web/API/File_and_Directory_Entries_API/Introduction) represents a file in a file system. It offers properties describing the file's attributes, as well as the [FileSystemFileEntry.file] method, which creates a [File] object that can be used to read the file.\n\n",
    "properties": {
      "createwriter": "\n\nThe [FileSystemFileEntry] interface's method\n**`createWriter()`** returns a [FileWriter] object\nwhich can be used to write data into the file represented by the directory entry.",
      "file": "\n\nThe [FileSystemFileEntry] interface's method\n**`file()`** returns a\n[File] object which can be used to read data from the file represented by\nthe directory entry."
    }
  },
  "filesystemfilehandle": {
    "docs": "\n\nThe **`FileSystemFileHandle`** interface of the [File System API] represents a handle to a file system entry. The interface is accessed through the [window.showOpenFilePicker] method.\n\nNote that read and write operations depend on file-access permissions that do not persist after a page refresh if no other tabs for that origin remain open. The [FileSystemHandle.queryPermission] method of the [FileSystemHandle] interface can be used to verify permission state before accessing a file.\n\n",
    "properties": {
      "createsyncaccesshandle": "\n\nThe **`createSyncAccessHandle()`** method of the\n[FileSystemFileHandle] interface returns a `Promise` which resolves to a [FileSystemSyncAccessHandle] object\nthat can be used to synchronously read from and write to a file. The synchronous nature of this method brings performance advantages,\nbut it is only usable inside dedicated [Web Workers](/en-US/docs/Web/API/Web_Workers_API) for files within the [origin private file system](/en-US/docs/Web/API/File_System_API/Origin_private_file_system).\n\nCreating a [FileSystemSyncAccessHandle] takes an exclusive lock on the file associated with the file handle. This prevents the creation of further [FileSystemSyncAccessHandle]s or [FileSystemWritableFileStream]s for the file until the existing access handle is closed.",
      "createwritable": "\n\nThe **`createWritable()`** method of the [FileSystemFileHandle] interface creates a [FileSystemWritableFileStream] that can be used to write to a file.\nThe method returns a `Promise` which resolves to this created stream.\n\nAny changes made through the stream won't be reflected in the file represented by the file handle until the stream has been closed.\nThis is typically implemented by writing data to a temporary file, and only replacing the file represented by file handle with the temporary file when the writable filestream is closed.",
      "getfile": "\n\nThe **`getFile()`** method of the\n[FileSystemFileHandle] interface returns a `Promise` which resolves to a\n[File] object representing the state on disk of the entry represented by the handle.\n\nIf the file on disk changes or is removed after this method is called, the returned\n[File] object will likely be no longer readable."
    }
  },
  "filesystemhandle": {
    "docs": "\n\nThe **`FileSystemHandle`** interface of the [File System API] is an object which represents a file or directory entry. Multiple handles can represent the same entry. For the most part you do not work with `FileSystemHandle` directly but rather its child interfaces [FileSystemFileHandle] and [FileSystemDirectoryHandle].",
    "properties": {
      "issameentry": "\n\nThe **`isSameEntry()`** method of the\n[FileSystemHandle] interface compares two [FileSystemHandle] to see if the associated entries (either a file or directory) match.",
      "kind": "\n\nThe **`kind`** read-only property of the\n[FileSystemHandle] interface returns the type of entry. This is\n`'file'` if the associated entry is a file or `'directory'`. It is\nused to distinguish files from directories when iterating over the contents of a\ndirectory.",
      "name": "\n\nThe **`name`** read-only property of the\n[FileSystemHandle] interface returns the name of the entry represented by\nhandle.",
      "querypermission": "\n\nThe **`queryPermission()`** method of the\n[FileSystemHandle] interface queries the current permission state of the\ncurrent handle.",
      "remove": "\n\nThe **`remove()`** method of the [FileSystemHandle] interface requests removal of the entry represented by the handle from the underlying file system.\n\nThe `remove()` method allows you to remove a file or directory directly from its handle. Without this method, you would have to obtain the handle of the parent directory, then call [FileSystemDirectoryHandle.removeEntry] on that to remove it.\n\nYou can also call `remove()` on the root directory of the [Origin Private File System](/en-US/docs/Web/API/File_System_API/Origin_private_file_system) to clear its contents, after which a new empty OPFS is created.",
      "requestpermission": "\n\nThe **`requestPermission()`** method of the\n[FileSystemHandle] interface requests read or readwrite permissions for the\nfile handle."
    }
  },
  "filesystemsync": {
    "docs": "\n\nIn the [File and Directory Entries API](/en-US/docs/Web/API/File_and_Directory_Entries_API/Introduction), a `FileSystemSync` object represents a file system. It has two properties.\n\n> **Warning:** This interface is deprecated and is no more on the standard track.\n> _Do not use it anymore._ Use the [File and Directory Entries API](/en-US/docs/Web/API/File_and_Directory_Entries_API) instead."
  },
  "filesystemsyncaccesshandle": {
    "docs": "\n\nThe **`FileSystemSyncAccessHandle`** interface of the [File System API] represents a synchronous handle to a file system entry.\n\nThis class is only accessible inside dedicated [Web Workers](/en-US/docs/Web/API/Web_Workers_API) (so that its methods do not block execution on the main thread) for files within the [origin private file system](/en-US/docs/Web/API/File_System_API/Origin_private_file_system), which is not visible to end-users.\n\nAs a result, its methods are not subject to the same security checks as methods running on files within the user-visible file system, and so are much more performant. This makes them suitable for significant, large-scale file updates such as [SQLite](https://www.sqlite.org/wasm) database modifications.\n\nThe interface is accessed through the [FileSystemFileHandle.createSyncAccessHandle] method.\n\n> **Note:** In earlier versions of the spec, [FileSystemSyncAccessHandle.close], [FileSystemSyncAccessHandle.flush], [FileSystemSyncAccessHandle.getSize], and [FileSystemSyncAccessHandle.truncate] were wrongly specified as asynchronous methods, and older versions of some browsers implement them in this way. However, all current browsers that support these methods implement them as synchronous methods.",
    "properties": {
      "close": "\n\nThe **`close()`** method of the\n[FileSystemSyncAccessHandle] interface closes an open synchronous file handle, disabling any further operations on it and releasing the exclusive lock previously put on the file associated with the file handle.\n\n> **Note:** In earlier versions of the spec, `close()`, [FileSystemSyncAccessHandle.flush], [FileSystemSyncAccessHandle.getSize], and [FileSystemSyncAccessHandle.truncate] were wrongly specified as asynchronous methods, and older versions of some browsers implement them in this way. However, all current browsers that support these methods implement them as synchronous methods.",
      "flush": "\n\nThe **`flush()`** method of the\n[FileSystemSyncAccessHandle] interface persists any changes made to the file associated with the handle via the [FileSystemSyncAccessHandle.write] method to disk.\n\nBear in mind that you only need to call this method if you need the changes committed to disk at a specific time, otherwise you can leave the underlying operating system to handle this when it sees fit, which should be OK in most cases.\n\n> **Note:** In earlier versions of the spec, [FileSystemSyncAccessHandle.close], `flush()`, [FileSystemSyncAccessHandle.getSize], and [FileSystemSyncAccessHandle.truncate] were wrongly specified as asynchronous methods, and older versions of some browsers implement them in this way. However, all current browsers that support these methods implement them as synchronous methods.",
      "getsize": "\n\nThe **`getSize()`** method of the\n[FileSystemSyncAccessHandle] interface returns the size of the file associated with the handle in bytes.\n\n> **Note:** In earlier versions of the spec, [FileSystemSyncAccessHandle.close], [FileSystemSyncAccessHandle.flush], `getSize()`, and [FileSystemSyncAccessHandle.truncate] were wrongly specified as asynchronous methods, and older versions of some browsers implement them in this way. However, all current browsers that support these methods implement them as synchronous methods.",
      "read": "\n\nThe **`read()`** method of the\n[FileSystemSyncAccessHandle] interface reads the content of the file associated with the handle into a specified buffer, optionally at a given offset.",
      "truncate": "\n\nThe **`truncate()`** method of the\n[FileSystemSyncAccessHandle] interface resizes the file associated with the handle to a specified number of bytes.\n\n> **Note:** In earlier versions of the spec, [FileSystemSyncAccessHandle.close], [FileSystemSyncAccessHandle.flush], [FileSystemSyncAccessHandle.getSize], and `truncate()` were wrongly specified as asynchronous methods, and older versions of some browsers implement them in this way. However, all current browsers that support these methods implement them as synchronous methods.",
      "write": "\n\nThe **`write()`** method of the\n[FileSystemSyncAccessHandle] interface writes the content of a specified buffer to the file associated with the handle, optionally at a given offset.\n\nFiles within the [origin private file system](/en-US/docs/Web/API/File_System_API/Origin_private_file_system) are not visible to end-users, therefore are not subject to the same security checks as methods running on files within the user-visible file system. As a result, writes performed using `FileSystemSyncAccessHandle.write()` are much more performant. This makes them suitable for significant, large-scale file updates such as [SQLite](https://www.sqlite.org/wasm) database modifications."
    }
  },
  "filesystemwritablefilestream": {
    "docs": "\n\nThe **`FileSystemWritableFileStream`** interface of the [File System API] is a [WritableStream] object with additional convenience methods, which operates on a single file on disk. The interface is accessed through the [FileSystemFileHandle.createWritable] method.\n\n",
    "properties": {
      "seek": "\n\nThe **`seek()`** method of the [FileSystemWritableFileStream] interface updates the current file cursor offset to the position (in bytes) specified when calling the method.",
      "truncate": "\n\nThe **`truncate()`** method of the [FileSystemWritableFileStream] interface resizes the file associated with the stream to the specified size in bytes.\n\nIf the size specified is larger than the current file size the file is padded with `0x00` bytes.\n\nThe file cursor is also updated when `truncate()` is called.\nIf the offset is smaller than the size, it remains unchanged.\nIf the offset is larger than size, the offset is set to that size.\nThis ensures that subsequent writes do not error.\n\nNo changes are written to the actual file on disk until the stream has been closed.\nChanges are typically written to a temporary file instead.",
      "write": "\n\nThe **`write()`** method of the [FileSystemWritableFileStream] interface writes content into the file the method is called on, at the current file cursor offset.\n\nNo changes are written to the actual file on disk until the stream has been closed.\nChanges are typically written to a temporary file instead. This method can also be used to seek to a byte point within the stream and truncate to modify the total bytes the file contains."
    }
  },
  "focusevent": {
    "docs": "\n\nThe **`FocusEvent`** interface represents focus-related events, including [Element/focus_event], [Element/blur_event], [Element/focusin_event], and [Element/focusout_event].\n\n",
    "properties": {
      "relatedtarget": "\n\nThe **`FocusEvent.relatedTarget`** read-only property is the\nsecondary target, depending on the type of event:\n\n<table class=\"no-markdown\">\n  <thead>\n    <tr>\n      <th scope=\"col\">Event name</th>\n      <th scope=\"col\"><code>target</code></th>\n      <th scope=\"col\"><code>relatedTarget</code></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>[Element/blur_event]</td>\n      <td>The [EventTarget] losing focus</td>\n      <td>\n        The [EventTarget] receiving focus (if any).\n      </td>\n    </tr>\n    <tr>\n      <td>[Element/focus_event]</td>\n      <td>The [EventTarget] receiving focus</td>\n      <td>The [EventTarget] losing focus (if any)</td>\n    </tr>\n    <tr>\n      <td>[Element/focusin_event]</td>\n      <td>The [EventTarget] receiving focus</td>\n      <td>The [EventTarget] losing focus (if any)</td>\n    </tr>\n    <tr>\n      <td>[Element/focusout_event]</td>\n      <td>The [EventTarget] losing focus</td>\n      <td>The [EventTarget] receiving focus (if any)</td>\n    </tr>\n  </tbody>\n</table>\n\nNote that [many elements can't have focus](https://stackoverflow.com/questions/42764494/blur-event-relatedtarget-returns-null/42764495), which is a common reason for `relatedTarget` to be\n`null`. `relatedTarget` may also be set to `null` for\nsecurity reasons, like when tabbing in or out of a page.\n\n[MouseEvent.relatedTarget] is a similar property for mouse events."
    }
  },
  "fontdata": {
    "docs": "\n\nThe **`FontData`** interface of the [Local Font Access API] represents a single local font face.",
    "properties": {
      "blob": "\n\nThe **`blob()`** method of the [FontData] interface returns a `Promise` that fulfills with a [Blob] containing the raw bytes of the underlying font file.",
      "family": "\n\nThe **`family`** read-only property of the [FontData] interface returns the family of the font face.\n\nThis is the name used when referring to the font family from code, for example, in the  property or in places within the  at-rule such as the `local()` function.\n\nExamples include:\n\n- Apple SD Gothic Neo\n- Arial Black\n- Avenir Next\n- Katari\n- YuMincho +36p Kana",
      "fullname": "\n\nThe **`fullName`** read-only property of the [FontData] interface returns the full name of the font face. This is usually a human-readable name used to identify the font, e.g., \"Optima Bold\".\n\nExamples include:\n\n- Apple SD Gothic Neo UltraLight\n- Arial Black\n- Avenir Next Heavy\n- Katari Medium Italic\n- YuMincho +36p Kana Extrabold",
      "postscriptname": "\n\nThe **`postscriptName`** read-only property of the [FontData] interface returns the PostScript name of the font face.\n\nThis is the name used to uniquely identify the PostScript font, and is generally an unbroken sequence of characters that includes the font's name and style.\n\nExamples include:\n\n- AppleSDGothicNeo-UltraLight\n- Arial-Black\n- AvenirNext-Heavy\n- Katari-MediumItalic\n- YuMin_36pKn-Extrabold",
      "style": "\n\nThe **`style`** read-only property of the [FontData] interface returns the style of the font face.\n\nThis is the value used to select the style of the font you want to use, for example inside the  property.\n\nExamples include:\n\n- UltraLight\n- Regular\n- Heavy\n- Medium Italic\n- Extrabold"
    }
  },
  "fontface": {
    "docs": "\n\nThe **`FontFace`** interface of the [CSS Font Loading API](/en-US/docs/Web/API/CSS_Font_Loading_API) represents a single usable font face.\n\nThis interface defines the source of a font face, either a URL to an external resource or a buffer, and font properties such as `style`, `weight`, and so on.\nFor URL font sources it allows authors to trigger when the remote font is fetched and loaded, and to track loading status.",
    "properties": {
      "ascentoverride": "\n\nThe **`ascentOverride`** property of the [FontFace] interface returns and sets the ascent metric for the font, the height above the baseline that CSS uses to lay out line boxes in an inline formatting context.\n\nThis property is equivalent to the  descriptor of .",
      "descentoverride": "\n\nThe **`descentOverride`** property of the [FontFace] interface returns and sets the value of the  descriptor.\nThe possible values are `normal`, indicating that the metric used should be obtained from the font file, or a percentage.",
      "display": "\n\nThe **`display`** property of the [FontFace] interface determines how a font face is displayed based on whether and when it is downloaded and ready to use.\nThis property is equivalent to the CSS `font-display` descriptor.\n\nWhen this property is used, font loading has a timeline with three periods.\nThe lengths of the first two periods depend on the value of the property and the user agent.\n(See below.)\n\n- block period\n  - : The browser invisibly prepares a fallback font. If the font face loads during this time, it's used to display the text and display is complete.\n- swap period\n  - : If the font face is still not loaded, the fallback font will be shown.\n    When the font face loads, the fallback will be swapped for the downloaded font.\n- failure period\n  - : If the font face still is not loaded, the fallback font will be shown and no swap will occur.",
      "family": "\n\nThe **`FontFace.family`** property allows the author to get or set the font family of a [FontFace] object.\n\nThe value is used for name matching against a particular font face when styling elements using the [`font-family`](/en-US/docs/Web/CSS/font-family) property.\nAny name may be used, and this overrides any name specified in the underlying font data.\n\nThis property is equivalent to the  descriptor of .",
      "featuresettings": "\n\nThe **`featureSettings`** property of the [FontFace] interface retrieves or sets infrequently used font features that are not available from a font's variant properties.\n\nThis property is equivalent to the  descriptor.",
      "linegapoverride": "\n\nThe **`lineGapOverride`** property of the [FontFace] interface returns and sets the value of the  descriptor.\nThe possible values are `normal`, indicating that the metric used should be obtained from the font file, or a percentage.",
      "load": "\n\nThe **`load()`** method of the [FontFace] interface requests and loads a font whose `source` was specified as a URL. It returns a `Promise` that resolves with the current `FontFace` object.\n\nIf the `source` for the font face was specified as binary data, or the font [FontFace/status] property of the font face is anything other than `unloaded`, then this method does nothing.",
      "loaded": "\n\nThe **`loaded`** read-only property of the [FontFace] interface returns a `Promise` that resolves with the current `FontFace` object when the font specified in the object's constructor is done loading or rejects with a `SyntaxError`.",
      "status": "\n\nThe **`status`** read-only property of the [FontFace] interface returns an enumerated value indicating the status of the font, one of `\"unloaded\"`, `\"loading\"`, `\"loaded\"`, or `\"error\"`.",
      "stretch": "\n\nThe **`stretch`** property of the [FontFace] interface retrieves or sets how the font stretches.\n\nThis property is equivalent to the  descriptor.",
      "style": "\n\nThe **`style`** property of the [FontFace] interface retrieves or sets the font's style.\n\nThis property is equivalent to the  descriptor.",
      "unicoderange": "\n\nThe **`unicodeRange`** property of the [FontFace] interface retrieves or sets the range of unicode code points encompassing the font.\n\nThis property is equivalent to the  descriptor.",
      "variant": "\n\nThe **`variant`** property of the\n[FontFace] interface programmatically retrieves or sets font variant\nvalues.",
      "variationsettings": "\n\nThe **`variationSettings`** property of the [FontFace] interface retrieves or sets low-level OpenType or TrueType font variations.\n\nThis property is equivalent to the  descriptor.",
      "weight": "\n\nThe **`weight`** property of the [FontFace] interface retrieves or sets the weight of the font.\n\nThis property is equivalent to the  descriptor."
    }
  },
  "fontfaceset": {
    "docs": "\n\nThe **`FontFaceSet`** interface of the [CSS Font Loading API](/en-US/docs/Web/API/CSS_Font_Loading_API) manages the loading of font-faces and querying of their download status.\n\nA `FontFaceSet` instance is a [`Set`-like object](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Set#set-like_browser_apis) that can hold an ordered set of [FontFace] objects.\n\nThis property is available as [Document.fonts], or `self.fonts` in [web workers](/en-US/docs/Web/API/Web_Workers_API).\n\n",
    "properties": {
      "add": "\n\nThe **`add()`** method of the [FontFaceSet] interface adds a new font to the set.",
      "check": "\n\nThe `check()` method of the [FontFaceSet] returns `true` if you can render some text using the given font specification without attempting to use any fonts in this `FontFaceSet` that are not yet fully loaded. This means you can use the font specification without causing a [font swap](/en-US/docs/Web/CSS/@font-face/font-display#the_font_display_timeline).",
      "clear": "\n\nThe **`clear()`** method of the [FontFaceSet] interface removes all fonts added via this interface. Fonts added with the  rule are not removed.",
      "delete": "\n\nThe **`delete()`** method of the [FontFaceSet] interface removes a font from the set.\n\nFont faces that were added to the set using the CSS  rule remain connected to the corresponding CSS, and cannot be deleted.",
      "entries": "\n\nThe **`entries()`** method of the [FontFaceSet] interface returns a new `Iterator` object, containing an array of `[value,value]` for each element in the `FontFaceSet`.",
      "foreach": "\n\nThe **`forEach()`** method of the [FontFaceSet] interface executes a provided function for each value in the `FontFaceSet` object.",
      "has": "\n\nThe **`has()`** method of the [FontFaceSet] interface returns a `Boolean` asserting whether an element is present with the given value.",
      "keys": "\n\nThe **`keys()`** method of the [FontFaceSet] interface is an alias for [FontFaceSet.values].",
      "load": "\n\nThe `load()` method of the [FontFaceSet] forces all the fonts given in parameters to be loaded.",
      "loading_event": "\n\nThe `loading` event fires when the document begins loading fonts.",
      "loadingdone_event": "\n\nThe `loadingdone` event fires when the document has loaded all fonts.",
      "loadingerror_event": "\n\nThe `loadingerror` event fires when fonts have finished loading, but some or all fonts have failed to load.",
      "ready": "\n\nThe `ready` read-only property of the [FontFaceSet] interface returns a `Promise` that resolves to the given [FontFaceSet].\n\nThe promise will only resolve once the document has completed loading fonts, layout operations are completed, and no further font loads are needed.",
      "size": "\n\nThe **`size`** property of the [FontFaceSet] interface returns the number of items in the `FontFaceSet`.",
      "status": "\n\nThe **`status`** read-only property of the [FontFaceSet] interface returns the loading state of the fonts in the set.",
      "values": "\n\nThe **`values()`** method of the [FontFaceSet] interface returns a new iterator object that yields the values for each element in the `FontFaceSet` object in insertion order."
    }
  },
  "fontfacesetloadevent": {
    "docs": "\n\nThe **`FontFaceSetLoadEvent`** interface of the [CSS Font Loading API](/en-US/docs/Web/API/CSS_Font_Loading_API) represents events fired at a [FontFaceSet] after it starts loading font faces.\n\nEvents are fired when font loading starts ([`loading`](/en-US/docs/Web/API/FontFaceSet/loading_event)), loading completes ([`loadingdone`](/en-US/docs/Web/API/FontFaceSet/loadingdone_event)) or there is an error loading one of the fonts ([`loadingerror`](/en-US/docs/Web/API/FontFaceSet/loadingerror_event)).\n\n",
    "properties": {
      "fontfaces": "\n\nThe **`fontfaces`** read-only property of the\n[FontFaceSetLoadEvent] interface returns an array of\n[FontFace] instances, each of which represents a single usable font."
    }
  },
  "formdata": {
    "docs": "\n\nThe **`FormData`** interface provides a way to construct a set of key/value pairs representing form fields and their values, which can be sent using the [fetch], [XMLHttpRequest.send] or [navigator.sendBeacon] methods. It uses the same format a form would use if the encoding type were set to `\"multipart/form-data\"`.\n\nYou can also pass it directly to the [URLSearchParams] constructor if you want to generate query parameters in the way a `form` would do if it were using simple `GET` submission.\n\nAn object implementing `FormData` can directly be used in a `for...of` structure, instead of [FormData.entries]: `for (const p of myFormData)` is equivalent to `for (const p of myFormData.entries())`.\n\n> **Note:** This feature is available in [Web Workers](/en-US/docs/Web/API/Web_Workers_API).",
    "properties": {
      "append": "\n\nThe **`append()`** method of the [FormData] interface appends a new value onto an existing key inside a `FormData` object, or adds the key if it does not already exist.\n\nThe difference between [FormData.set] and `append()` is that if the specified key already exists, `set()` will overwrite all existing values with the new one, whereas `append()` will append the new value onto the end of the existing set of values.\n\n> **Note:** This method is available in [Web Workers](/en-US/docs/Web/API/Web_Workers_API).",
      "delete": "\n\nThe **`delete()`** method of the [FormData] interface deletes a key and its value(s) from a `FormData` object.\n\n> **Note:** This method is available in [Web Workers](/en-US/docs/Web/API/Web_Workers_API).",
      "entries": "\n\nThe **`FormData.entries()`** method returns an [iterator](/en-US/docs/Web/JavaScript/Reference/Iteration_protocols) which iterates through all key/value pairs contained in the [FormData]. The key of each pair is a string object, and the value is either a string or a [Blob].\n\n> **Note:** This method is available in [Web Workers](/en-US/docs/Web/API/Web_Workers_API).",
      "get": "\n\nThe **`get()`** method of the [FormData] interface\nreturns the first value associated with a given key from within a `FormData`\nobject. If you expect multiple values and want all of them, use the\n[FormData.getAll] method instead.\n\n> **Note:** This method is available in [Web Workers](/en-US/docs/Web/API/Web_Workers_API).",
      "getall": "\n\nThe **`getAll()`** method of the [FormData] interface returns all the values associated with a given key from within a `FormData` object.\n\n> **Note:** This method is available in [Web Workers](/en-US/docs/Web/API/Web_Workers_API).",
      "has": "\n\nThe **`has()`** method of the [FormData] interface returns whether a `FormData` object contains a certain key.\n\n> **Note:** This method is available in [Web Workers](/en-US/docs/Web/API/Web_Workers_API).",
      "keys": "\n\nThe **`FormData.keys()`** method returns an [iterator](/en-US/docs/Web/JavaScript/Reference/Iteration_protocols) which iterates through all keys contained in the [FormData]. The keys are strings.\n\n> **Note:** This method is available in [Web Workers](/en-US/docs/Web/API/Web_Workers_API).",
      "set": "\n\nThe **`set()`** method of the [FormData] interface sets a new value for an existing key inside a `FormData` object, or adds the key/value if it does not already exist.\n\nThe difference between `set()` and [FormData.append] is that if the specified key does already exist, `set()` will overwrite all existing values with the new one, whereas `append()` will append the new value onto the end of the existing set of values.\n\n> **Note:** This method is available in [Web Workers](/en-US/docs/Web/API/Web_Workers_API).",
      "values": "\n\nThe **`FormData.values()`** method returns an [iterator](/en-US/docs/Web/JavaScript/Reference/Iteration_protocols) which iterates through all values contained in the [FormData]. The values are strings or [Blob] objects.\n\n> **Note:** This method is available in [Web Workers](/en-US/docs/Web/API/Web_Workers_API)."
    }
  },
  "formdataevent": {
    "docs": "\n\nThe **`FormDataEvent`** interface represents a [`formdata` event](/en-US/docs/Web/API/HTMLFormElement/formdata_event) — such an event is fired on an [HTMLFormElement] object after the entry list representing the form's data is constructed. This happens when the form is submitted, but can also be triggered by the invocation of a [FormData.FormData] constructor.\n\nThis allows a [FormData] object to be quickly obtained in response to a `formdata` event firing, rather than needing to put it together yourself when you wish to submit form data via a method like [fetch] (see [Using FormData objects](/en-US/docs/Web/API/XMLHttpRequest_API/Using_FormData_Objects)).\n\n",
    "properties": {
      "formdata": "\n\nThe `formData` read-only property of the [FormDataEvent]\ninterface contains the [FormData] object representing the data contained in\nthe form when the event was fired."
    }
  },
  "fragmentdirective": {
    "docs": "\n\nThe **`FragmentDirective`** interface is an object exposed for feature detectability, that is, whether or not a browser supports text fragments.\n\nIt is accessed via the [Document.fragmentDirective] property."
  },
  "gainnode": {
    "docs": "\n\nThe `GainNode` interface represents a change in volume. It is an [AudioNode] audio-processing module that causes a given gain to be applied to the input data before its propagation to the output. A `GainNode` always has exactly one input and one output, both with the same number of channels.\n\nThe gain is a unitless value, changing with time, that is multiplied to each corresponding sample of all input channels. If modified, the new gain is instantly applied, causing unaesthetic 'clicks' in the resulting audio. To prevent this from happening, never change the value directly but use the exponential interpolation methods on the [AudioParam] interface.\n\n![The GainNode is increasing the gain of the output.](webaudiogainnode.png)\n\n<table class=\"properties\">\n  <tbody>\n    <tr>\n      <th scope=\"row\">Number of inputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Number of outputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count mode</th>\n      <td><code>\"max\"</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count</th>\n      <td><code>2</code> (not used in the default count mode)</td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel interpretation</th>\n      <td><code>\"speakers\"</code></td>\n    </tr>\n  </tbody>\n</table>",
    "properties": {
      "gain": "\n\nThe `gain` property of the [GainNode] interface is an [a-rate](/en-US/docs/Web/API/AudioParam#a-rate) [AudioParam] representing the amount of gain to apply."
    }
  },
  "gamepad": {
    "docs": "\n\nThe **`Gamepad`** interface of the [Gamepad API](/en-US/docs/Web/API/Gamepad_API) defines an individual gamepad or other controller, allowing access to information such as button presses, axis positions, and id.\n\nA Gamepad object can be returned in one of two ways: via the `gamepad` property of the [Window.gamepadconnected_event] and [Window.gamepaddisconnected_event] events, or by grabbing any position in the array returned by the [Navigator.getGamepads] method.",
    "properties": {
      "axes": "\n\nThe **`Gamepad.axes`** property of the [Gamepad]\ninterface returns an array representing the controls with axes present on the device\n(e.g. analog thumb sticks).\n\nEach entry in the array is a floating point value in the range -1.0 – 1.0, representing\nthe axis position from the lowest value (-1.0) to the highest value (1.0).",
      "buttons": "\n\nThe **`Gamepad.buttons`** property of the [Gamepad] interface returns an array of [gamepadButton] objects representing the\nbuttons present on the device.\n\nEach entry in the array is 0 if the button is not pressed, and non-zero (typically 1.0)\nif the button is pressed. Each [gamepadButton] object has two properties:\n`pressed` and `value`:\n\n- The `pressed` property is a boolean indicating whether the button is\n  currently pressed (`true`) or unpressed (`false`).\n- The `value` property is a floating point value used to enable\n  representing analog buttons, such as the triggers on many modern gamepads. The values\n  are normalized to the range 0.0 – 1.0, with 0.0 representing a button that is not\n  pressed, and 1.0 representing a button that is fully pressed.",
      "connected": "\n\nThe **`Gamepad.connected`** property of the\n[Gamepad] interface returns a boolean indicating whether the gamepad is\nstill connected to the system.\n\nIf the gamepad is connected, the value is `true`; if not, it is\n`false`.",
      "displayid": "\n\nThe **`displayId`** read-only property of the [Gamepad] interface _returns the [VRDisplay.displayId] of the associated [VRDisplay] — the `VRDisplay` that the gamepad is controlling the displayed scene of._\n\nA Gamepad is considered to be associated with a [VRDisplay] if it reports a pose that is in the same space as the display's pose, see [VRDisplay.getPose].\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/#gamepad-getvrdisplays-attribute). It has been superseded by the [WebXR Gamepads Module](https://immersive-web.github.io/webxr-gamepads-module/).\n>\n> There is no direct replacement for this property. The [Gamepad] object associated with an [XRInputSource] can be obtained using the [XRInputSource.gamepad] property.",
      "hand": "\n\nThe **`hand`** read-only property of the [Gamepad] interface returns an enum defining what hand the controller is being held in, or is most likely to be held in.",
      "hapticactuators": "\n\nThe **`hapticActuators`** read-only property of the [Gamepad] interface returns an array containing [GamepadHapticActuator] objects, each of which represents haptic feedback hardware available on the controller.",
      "id": "\n\nThe **`Gamepad.id`** property of the [Gamepad]\ninterface returns a string containing some information about the controller.\n\nThe exact syntax is not strictly specified, but in Firefox it will contain three pieces\nof information separated by dashes (`-`):\n\n- Two 4-digit hexadecimal strings containing the USB vendor and product id of the\n  controller\n- The name of the controller as provided by the driver.\n\nFor example, a PS2 controller returned **810-3-USB Gamepad**.\n\nThis information is intended to allow you to find a mapping for the controls on the\ndevice as well as display useful feedback to the user.",
      "index": "\n\nThe **`Gamepad.index`** property of the [Gamepad]\ninterface returns an integer that is auto-incremented to be unique for each device\ncurrently connected to the system.\n\nThis can be used to distinguish multiple controllers; a gamepad that is disconnected\nand reconnected will retain the same index.",
      "mapping": "\n\nThe **`Gamepad.mapping`** property of the\n[Gamepad] interface returns a string indicating whether the browser has\nremapped the controls on the device to a known layout.\n\nThe currently supported known layouts are:\n\n- \"standard\" for the [standard gamepad](https://w3c.github.io/gamepad/#remapping).\n- \"xr-standard for the [standard XR gamepad](https://immersive-web.github.io/webxr-gamepads-module/#xr-standard-heading). See also [XRInputSource.gamepad].",
      "pose": "\n\nThe **`pose`** read-only property of the [Gamepad] interface returns a [GamepadPose] object representing the pose information associated with a WebVR controller (e.g. its position and orientation in 3D space).",
      "timestamp": "\n\nThe **`Gamepad.timestamp`** property of the\n[Gamepad] interface returns a [DOMHighResTimeStamp]\nrepresenting the last time the data for this gamepad was updated.\n\nThe idea behind this is to allow developers to determine if the `axes` and\n`button` data have been updated from the hardware. The value must be\nrelative to the `navigationStart` attribute of the\n[PerformanceTiming] interface. Values are monotonically\nincreasing, meaning that they can be compared to determine the ordering of updates, as\nnewer values will always be greater than or equal to older values.\n\n> **Note:** This property is not currently supported anywhere.",
      "vibrationactuator": "\n\nThe **`vibrationActuator`** read-only property of the [Gamepad] interface returns a [GamepadHapticActuator] object, which represents haptic feedback hardware available on the controller."
    }
  },
  "gamepadbutton": {
    "docs": "\n\nThe **`GamepadButton`** interface defines an individual button of a gamepad or other controller, allowing access to the current state of different types of buttons available on the control device.\n\nA `GamepadButton` object is returned by querying any value of the array returned by the `buttons` property of the [Gamepad] interface.",
    "properties": {
      "pressed": "\n\nThe **`GamepadButton.pressed`** property of the\n[GamepadButton] interface returns a `boolean` indicating whether\nthe button is currently pressed (`true`) or unpressed (`false`).",
      "touched": "\n\nThe **`touched`** property of the\n[GamepadButton] interface returns a `boolean` indicating whether\na button capable of detecting touch is currently touched (`true`) or not touched (`false`).\n\nIf the button is not capable of detecting touch but can return an analog value, the property will be `true` if the value is greater than `0`, and `false` otherwise. If the button is not capable of detecting touch and can only report a digital value, then it should mirror the [GamepadButton.pressed] property.",
      "value": "\n\nThe **`GamepadButton.value`** property of the\n[GamepadButton] interface returns a double value used to represent the\ncurrent state of analog buttons on many modern gamepads, such as the triggers.\n\nThe values are normalized to the range `0.0` — `1.0`, with\n`0.0` representing a button that is not pressed, and 1.0 representing a\nbutton that is fully pressed."
    }
  },
  "gamepadevent": {
    "docs": "\n\nThe GamepadEvent interface of the Gamepad API contains references to gamepads connected to the system, which is what the gamepad events [Window.gamepadconnected_event] and [Window.gamepaddisconnected_event] are fired in response to.\n\n",
    "properties": {
      "gamepad": "\n\nThe **`GamepadEvent.gamepad`** property of the\n**[GamepadEvent] interface** returns a [Gamepad]\nobject, providing access to the associated gamepad data for fired\n[Window.gamepadconnected_event] and [Window.gamepaddisconnected_event] events."
    }
  },
  "gamepadhapticactuator": {
    "docs": "\n\nThe **`GamepadHapticActuator`** interface of the [Gamepad API](/en-US/docs/Web/API/Gamepad_API) represents hardware in the controller designed to provide haptic feedback to the user (if available), most commonly vibration hardware.\n\nThis interface is accessible through the [Gamepad.hapticActuators] property.",
    "properties": {
      "playeffect": "\n\nThe **`playEffect()`** method of the [GamepadHapticActuator] interface makes the hardware play a specific vibration pattern.",
      "pulse": "\n\nThe **`pulse()`** method of the [GamepadHapticActuator] interface makes the hardware pulse at a certain intensity for a specified duration.",
      "type": "\n\nThe **`type`** read-only property of the [GamepadHapticActuator] interface returns an enum representing the type of the haptic hardware."
    }
  },
  "gamepadpose": {
    "docs": "\n\nThe **`GamepadPose`** interface of the [Gamepad API](/en-US/docs/Web/API/Gamepad_API) represents the pose of a [WebVR](/en-US/docs/Web/API/WebVR_API) controller at a given timestamp (which includes orientation, position, velocity, and acceleration information).\n\nThis interface is accessible through the [Gamepad.pose] property.",
    "properties": {
      "angularacceleration": "\n\nThe **`angularAcceleration`** read-only property of the [GamepadPose] interface returns an array representing the angular acceleration vector of the [Gamepad], in meters per second per second.\n\nIn other words, the current acceleration of the sensor's rotation around the `x`, `y`, and `z` axes.",
      "angularvelocity": "\n\nThe **`angularVelocity`** read-only property of the [GamepadPose] interface returns an array representing the angular velocity vector of the [Gamepad], in radians per second.\n\nIn other words, the current velocity at which the sensor is rotating around the `x`, `y`, and `z` axes.",
      "hasorientation": "\n\nThe **`hasOrientation`** read-only property of the [GamepadPose] interface returns a boolean value stating whether the [Gamepad] can track and return orientation information.",
      "hasposition": "\n\nThe **`hasPosition`** read-only property of the [GamepadPose] interface returns a boolean value stating whether the [Gamepad] can track and return position information.",
      "linearacceleration": "\n\nThe **`linearAcceleration`** read-only property of the [GamepadPose] interface returns an array representing the linear acceleration vector of the [Gamepad], in meters per second per second.\n\nIn other words, the current acceleration of the sensor, along the `x`, `y`, and `z` axes.",
      "linearvelocity": "\n\nThe **`linearVelocity`** read-only property of the [GamepadPose] interface returns an array representing the linear velocity vector of the [Gamepad], in meters per second.\n\nIn other words, the current velocity at which the sensor is moving along the `x`, `y`, and `z` axes.",
      "orientation": "\n\nThe **`orientation`** read-only property of the [GamepadPose] interface returns the orientation of the [Gamepad], as a quarternion value.\n\nThe value is a `Float32Array`, made up of the following values:\n\n- pitch — rotation around the X axis.\n- yaw — rotation around the Y axis.\n- roll — rotation around the Z axis.\n- w — the fourth dimension (usually 1).\n\nThe orientation yaw (rotation around the y axis) is relative to the initial yaw of the sensor when it was first read.",
      "position": "\n\nThe **`position`** read-only property of the [GamepadPose] interface returns the position of the [Gamepad] as a 3D vector.\n\nThe coordinate system is as follows:\n\n- Positive X is to the user's right.\n- Positive Y is up.\n- Positive Z is behind the user.\n\nPositions are measured in meters from an origin point — this point is the position the sensor was first read at."
    }
  },
  "geolocation": {
    "docs": "\n\nThe **`Geolocation`** interface represents an object able to obtain the position of the device programmatically. It gives Web content access to the location of the device. This allows a website or app to offer customized results based on the user's location.\n\nAn object with this interface is obtained using the [navigator.geolocation] property implemented by the [Navigator] object.\n\n> **Note:** For security reasons, when a web page tries to access location information, the user is notified and asked to grant permission. Be aware that each browser has its own policies and methods for requesting this permission.",
    "properties": {
      "clearwatch": "\n\nThe **`clearWatch()`** method of the [Geolocation] interface is used to unregister location/error monitoring handlers previously installed using [Geolocation.watchPosition].",
      "getcurrentposition": "\n\nThe **`getCurrentPosition()`** method of the [Geolocation] interface is used to get the current position of the device.",
      "watchposition": "\n\nThe **`watchPosition()`** method of the [Geolocation] interface is used to register a handler function that will be called automatically each time the position of the device changes.\nYou can also, optionally, specify an error handling callback function."
    }
  },
  "geolocationcoordinates": {
    "docs": "\n\nThe **`GeolocationCoordinates`** interface represents the position and altitude of the device on Earth, as well as the accuracy with which these properties are calculated.",
    "properties": {
      "accuracy": "\n\nThe **`accuracy`** read-only property of the [GeolocationCoordinates] interface is a strictly positive `double` representing the accuracy, with a 95% confidence level, of the [GeolocationCoordinates.latitude] and [GeolocationCoordinates.longitude] properties expressed in meters.",
      "altitude": "\n\nThe **`altitude`** read-only property of the [GeolocationCoordinates] interface is a `double` representing the altitude of the position in meters above the [WGS84](https://gis-lab.info/docs/nima-tr8350.2-wgs84fin.pdf) ellipsoid (which defines the nominal sea level surface). This value is `null` if the implementation cannot provide this data.",
      "altitudeaccuracy": "\n\nThe **`altitudeAccuracy`** read-only property of the [GeolocationCoordinates] interface is a strictly positive `double` representing the accuracy, with a 95% confidence level, of the `altitude` expressed in meters. This value is `null` if the implementation doesn't support measuring altitude.",
      "heading": "\n\nThe **`heading`** read-only property of the [GeolocationCoordinates] interface is a `double` representing the direction in which the device is traveling. This value, specified in degrees, indicates how far off from heading due north the device is. `0` degrees represents true north, and the direction is determined clockwise (which means that east is `90` degrees and west is `270` degrees). If [GeolocationCoordinates.speed] is `0`, `heading` is `NaN`. If the device is not able to provide heading information, this value is `null`.",
      "latitude": "\n\nThe **`latitude`** read-only property of the [GeolocationCoordinates] interface is a `double` representing the latitude of the position in decimal degrees.",
      "longitude": "\n\nThe **`longitude`** read-only property of the [GeolocationCoordinates] interface is a number which represents the longitude of a geographical position, specified in decimal degrees.\nTogether with a timestamp, given as  in milliseconds, indicating a time of measurement, the `GeolocationCoordinates` object is part of the [GeolocationPosition] interface, which is the object type returned by Geolocation API functions that obtain and return a geographical position.",
      "speed": "\n\nThe **`speed`** read-only property of the [GeolocationCoordinates] interface is a `double` representing the velocity of the device in meters per second. This value is `null` if the implementation is not able to measure it."
    }
  },
  "geolocationposition": {
    "docs": "\n\nThe **`GeolocationPosition`** interface represents the position of the concerned device at a given time. The position, represented by a [GeolocationCoordinates] object, comprehends the 2D position of the device, on a spheroid representing the Earth, but also its altitude and its speed.",
    "properties": {
      "coords": "\n\nThe **`coords`** read-only property of the [GeolocationPosition] interface returns a [GeolocationCoordinates] object representing a geographic position. It contains the location, that is longitude and latitude on the Earth, the altitude, and the speed of the object concerned, regrouped inside the returned value. It also contains accuracy information about these values.",
      "timestamp": "\n\nThe **`timestamp`** read-only property of the [GeolocationPosition] interface represents the date and time that the position was acquired by the device."
    }
  },
  "geolocationpositionerror": {
    "docs": "\n\nThe **`GeolocationPositionError`** interface represents the reason of an error occurring when using the geolocating device.",
    "properties": {
      "code": "\n\nThe **`code`** read-only property of the [GeolocationPositionError] interface is an `unsigned short` representing the error code.\n\nThe following values are possible:\n\n<table class=\"no-markdown\">\n  <thead>\n    <tr>\n      <th scope=\"col\">Value</th>\n      <th scope=\"col\">Associated constant</th>\n      <th scope=\"col\">Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td><code>1</code></td>\n      <td><code>PERMISSION_DENIED</code></td>\n      <td>\n        The acquisition of the geolocation information failed because the page\n        didn't have the permission to do it.\n      </td>\n    </tr>\n    <tr>\n      <td><code>2</code></td>\n      <td><code>POSITION_UNAVAILABLE</code></td>\n      <td>\n        The acquisition of the geolocation failed because one or several internal sources of position returned an internal error.\n      </td>\n    </tr>\n    <tr>\n      <td><code>3</code></td>\n      <td><code>TIMEOUT</code></td>\n      <td>Geolocation information was not obtained in the allowed time.</td>\n    </tr>\n  </tbody>\n</table>",
      "message": "\n\nThe **`message`** read-only property of the [GeolocationPositionError] interface returns a human-readable string describing the details of the error."
    }
  },
  "gestureevent": {
    "docs": "\n\nThe **`GestureEvent`** is a proprietary interface specific to WebKit which gives information regarding multi-touch gestures. Events using this interface include [Element/gesturestart_event], [Element/gesturechange_event], and [Element/gestureend_event].\n\n"
  },
  "gpu": {
    "docs": "\n\nThe **`GPU`** interface of the [WebGPU API] is the starting point for using WebGPU. It can be used to return a [GPUAdapter] from which you can request devices, configure features and limits, and more.\n\nThe `GPU` object for the current context is accessed via the [Navigator.gpu] or [WorkerNavigator.gpu] properties.\n\n",
    "properties": {
      "getpreferredcanvasformat": "\n\nThe **`getPreferredCanvasFormat()`** method of the\n[GPU] interface returns the optimal canvas texture format for displaying 8-bit depth, standard dynamic range content on the current system.\n\nThis is commonly used to provide a [GPUCanvasContext.configure] call with the optimal `format` value for the current system. This is recommended — if you don't use the preferred format when configuring the canvas context, you may incur additional overhead, such as additional texture copies, depending on the platform.",
      "requestadapter": "\n\nThe **`requestAdapter()`** method of the\n[GPU] interface returns a `Promise` that fulfills with a [GPUAdapter] object instance. From this you can request a [GPUDevice], adapter info, features, and limits.\n\nNote that the user agent chooses whether to return an adapter. If so, it chooses according to the provided options. If no options are provided, the device will provide access to the default adapter, which is usually good enough for most purposes.",
      "wgsllanguagefeatures": "\n\nThe **`wgslLanguageFeatures`** read-only property of the\n[GPU] interface returns a [WGSLLanguageFeatures] object that reports the [WGSL language extensions](https://gpuweb.github.io/gpuweb/wgsl/#language-extension) supported by the WebGPU implementation.\n\n> **Note:** Not all WGSL language extensions are available to WebGPU in all browsers that support the API. We recommend you thoroughly test any extensions you choose to use."
    }
  },
  "gpuadapter": {
    "docs": "\n\nThe **`GPUAdapter`** interface of the [WebGPU API] represents a GPU adapter. From this you can request a [GPUDevice], adapter info, features, and limits.\n\nA `GPUAdapter` object is requested using the [GPU.requestAdapter] method.\n\n",
    "properties": {
      "features": "\n\nThe **`features`** read-only property of the\n[GPUAdapter] interface returns a [GPUSupportedFeatures] object that describes additional functionality supported by the adapter.\n\nYou should note that not all features will be available to WebGPU in all browsers that support it, even if the features are supported by the underlying hardware. This could be due to constraints in the underlying system, browser, or adapter. For example:\n\n- The underlying system might not be able to guarantee exposure of a feature in a way that is compatible with a certain browser.\n- The browser vendor might not have found a secure way to implement support for that feature, or might just not have gotten round to it yet.\n\nIf you are hoping to take advantage of a specific additional feature in a WebGPU app, thorough testing is advised.",
      "isfallbackadapter": "\n\nThe **`isFallbackAdapter`** read-only property of the\n[GPUAdapter] interface returns `true` if the adapter is a [fallback adapter](/en-US/docs/Web/API/GPU/requestAdapter#fallback_adapters), and `false` if not.",
      "limits": "\n\nThe **`limits`** read-only property of the\n[GPUAdapter] interface returns a [GPUSupportedLimits] object that describes the limits supported by the adapter.\n\nYou should note that, rather than reporting the exact limits of each GPU, browsers will likely report different tier values of different limits to reduce the unique information available to drive-by fingerprinting. For example, the tiers of a certain limit might be 2048, 8192, and 32768. If your GPU's actual limit is 16384, the browser will still report 8192.\n\nGiven that different browsers will handle this differently and the tier values may change over time, it is hard to provide an accurate account of what limit values to expect — thorough testing is advised.",
      "requestadapterinfo": "\n\nThe **`requestAdapterInfo()`** method of the\n[GPUAdapter] interface returns a `Promise` that fulfills with a [GPUAdapterInfo] object containing identifying information about an adapter.\n\nThe intention behind this method is to allow developers to request specific details about the user's GPU so that they can preemptively apply workarounds for GPU-specific bugs, or provide different codepaths to better suit different GPU architectures. Providing such information does present a security risk — it could be used for fingerprinting — therefore the information shared is to be kept at a minimum, and different browser vendors are likely to share different information types and granularities.\n\n> **Note:** The specification includes an `unmaskHints` parameter for `requestAdapterInfo()`, which is intended to mitigate the security risk mentioned above. Once it is supported, developers will be able to specify the values they really need to know, and users will be given a permission prompt asking them if they are OK to share this information when the method is invoked. Browser vendors are likely to share more useful information if it is guarded by a permissions prompt, as it makes the method a less viable target for fingerprinting.",
      "requestdevice": "\n\nThe **`requestDevice()`** method of the\n[GPUAdapter] interface returns a `Promise` that fulfills with a [GPUDevice] object, which is the primary interface for communicating with the GPU."
    }
  },
  "gpuadapterinfo": {
    "docs": "\n\nThe **`GPUAdapterInfo`** interface of the [WebGPU API] contains identifying information about a [GPUAdapter].\n\nA `GPUAdapterInfo` object instance is requested using the [GPUAdapter.requestAdapterInfo] method.\n\n",
    "properties": {
      "architecture": "\n\nThe **`architecture`** read-only property of the\n[GPUAdapterInfo] interface returns the name of the family or class of GPUs the adapter belongs to, or an empty string if it is not available.",
      "description": "\n\nThe **`description`** read-only property of the\n[GPUAdapterInfo] interface returns a human-readable string describing the adapter, or an empty string if it is not available.",
      "device": "\n\nThe **`device`** read-only property of the\n[GPUAdapterInfo] interface returns a vendor-specific identifier for the adapter, or an empty string if it is not available.",
      "vendor": "\n\nThe **`vendor`** read-only property of the\n[GPUAdapterInfo] interface returns the name of the adapter vendor, or an empty string if it is not available."
    }
  },
  "gpubindgroup": {
    "docs": "\n\nThe **`GPUBindGroup`** interface of the [WebGPU API] is based on a [GPUBindGroupLayout] and defines a set of resources to be bound together in a group and how those resources are used in shader stages.\n\nA `GPUBindGroup` object instance is created using the [GPUDevice.createBindGroup] method.\n\n",
    "properties": {
      "label": "\n\nThe **`label`** property of the\n[GPUBindGroup] interface provides a label that can be used to identify the object, for example in [GPUError] messages or console warnings.\n\nThis can be set by providing a `label` property in the descriptor object passed into the originating [GPUDevice.createBindGroup] call, or you can get and set it directly on the `GPUBindGroup` object."
    }
  },
  "gpubindgrouplayout": {
    "docs": "\n\nThe **`GPUBindGroupLayout`** interface of the [WebGPU API] defines the structure and purpose of related GPU resources such as buffers that will be used in a pipeline, and is used as a template when creating [GPUBindGroup]s.\n\nA `GPUBindGroupLayout` object instance is created using the [GPUDevice.createBindGroupLayout] method.\n\n",
    "properties": {
      "label": "\n\nThe **`label`** property of the\n[GPUBindGroupLayout] interface provides a label that can be used to identify the object, for example in [GPUError] messages or console warnings.\n\nThis can be set by providing a `label` property in the descriptor object passed into the originating [GPUDevice.createBindGroupLayout] call, or you can get and set it directly on the `GPUBindGroupLayout` object."
    }
  },
  "gpubuffer": {
    "docs": "\n\nThe **`GPUBuffer`** interface of the [WebGPU API] represents a block of memory that can be used to store raw data to use in GPU operations.\n\nA `GPUBuffer` object instance is created using the [GPUDevice.createBuffer] method.\n\n",
    "properties": {
      "destroy": "\n\nThe **`destroy()`** method of the\n[GPUBuffer] interface destroys the `GPUBuffer`.",
      "getmappedrange": "\n\nThe **`getMappedRange()`** method of the\n[GPUBuffer] interface returns an `ArrayBuffer` containing the mapped contents of the `GPUBuffer` in the specified range.\n\nThis can only happen once the `GPUBuffer` has been successfully mapped with [GPUBuffer.mapAsync] (this can be checked via [GPUBuffer.mapState]). While the `GPUBuffer` is mapped it cannot be used in any GPU commands.\n\nWhen you have finished working with the `GPUBuffer` values, call [GPUBuffer.unmap] to unmap it, making it accessible to the GPU again.",
      "label": "\n\nThe **`label`** property of the\n[GPUBuffer] interface provides a label that can be used to identify the object, for example in [GPUError] messages or console warnings.\n\nThis can be set by providing a `label` property in the descriptor object passed into the originating [GPUDevice.createBuffer] call, or you can get and set it directly on the `GPUBuffer` object.",
      "mapasync": "\n\nThe **`mapAsync()`** method of the\n[GPUBuffer] interface maps the specified range of the `GPUBuffer`. It returns a `Promise` that resolves when the `GPUBuffer`'s content is ready to be accessed. While the `GPUBuffer` is mapped it cannot be used in any GPU commands.\n\nOnce the buffer is successfully mapped (which can be checked via [GPUBuffer.mapState]), calls to [GPUBuffer.getMappedRange] will return an `ArrayBuffer` containing the `GPUBuffer`'s current values, to be read and updated by JavaScript as required.\n\nWhen you have finished working with the `GPUBuffer` values, call [GPUBuffer.unmap] to unmap it, making it accessible to the GPU again.",
      "mapstate": "\n\nThe **`mapState`** read-only property of the\n[GPUBuffer] interface represents the mapped state of the `GPUBuffer`.",
      "size": "\n\nThe **`size`** read-only property of the\n[GPUBuffer] interface represents the length of the `GPUBuffer`'s memory allocation, in bytes.\n\n`size` is set via the `size` property in the descriptor object passed into the originating [GPUDevice.createBuffer] call.",
      "unmap": "\n\nThe **`unmap()`** method of the\n[GPUBuffer] interface unmaps the mapped range of the `GPUBuffer`, making its contents available for use by the GPU again after it has previously been mapped with [GPUBuffer.mapAsync] (the GPU cannot access a mapped `GPUBuffer`).\n\nWhen `unmap()` is called, any `ArrayBuffer`s created via [GPUBuffer.getMappedRange] are detached.",
      "usage": "\n\nThe **`usage`** read-only property of the\n[GPUBuffer] interface contains the  representing the allowed usages of the `GPUBuffer`.\n\n`usage` is set via the `usage` property in the descriptor object passed into the originating [GPUDevice.createBuffer] call."
    }
  },
  "gpucanvascontext": {
    "docs": "\n\nThe **`GPUCanvasContext`** interface of the [WebGPU API] represents the WebGPU rendering context of a `canvas` element, returned via an [HTMLCanvasElement.getContext] call with a `contextType` of `\"webgpu\"`.\n\n",
    "properties": {
      "canvas": "\n\nThe **`canvas`** read-only property of the\n[GPUCanvasContext] interface returns a reference to the canvas that the context was created from.",
      "configure": "\n\nThe **`configure()`** method of the\n[GPUCanvasContext] interface configures the context to use for rendering with a given [GPUDevice]. When called the canvas will initially be cleared to transparent black.",
      "getcurrenttexture": "\n\nThe **`getCurrentTexture()`** method of the\n[GPUCanvasContext] interface returns the next [GPUTexture] to be composited to the document by the canvas context.",
      "unconfigure": "\n\nThe **`unconfigure()`** method of the\n[GPUCanvasContext] interface removes any previously-set context configuration, and destroys any textures returned via [GPUCanvasContext.getCurrentTexture] while the canvas context was configured."
    }
  },
  "gpucommandbuffer": {
    "docs": "\n\nThe **`GPUCommandBuffer`** interface of the [WebGPU API] represents a pre-recorded list of GPU commands that can be submitted to a [GPUQueue] for execution.\n\nA `GPUCommandBuffer` is created via the [GPUCommandEncoder.finish] method; the GPU commands recorded within are submitted for execution by passing the `GPUCommandBuffer` into the parameter of a [GPUQueue.submit] call.\n\n> **Note:** Once a `GPUCommandBuffer` object has been submitted, it cannot be used again.\n\n",
    "properties": {
      "label": "\n\nThe **`label`** read-only property of the\n[GPUCommandBuffer] interface is a string providing a label that can be used to identify the object, for example in [GPUError] messages or console warnings.\n\nThis can be set by providing a `label` property in the descriptor object passed into the originating [GPUCommandEncoder.finish] call, or you can get and set it directly on the `GPUCommandBuffer` object."
    }
  },
  "gpucommandencoder": {
    "docs": "\n\nThe **`GPUCommandEncoder`** interface of the [WebGPU API] represents a command encoder, used to encode commands to be issued to the GPU.\n\nA `GPUCommandEncoder` object instance is created via the [GPUDevice.createCommandEncoder] property.\n\n",
    "properties": {
      "begincomputepass": "\n\nThe **`beginComputePass()`** method of the\n[GPUCommandEncoder] interface starts encoding a compute pass, returning a [GPUComputePassEncoder] that can be used to control computation.",
      "beginrenderpass": "\n\nThe **`beginRenderPass()`** method of the\n[GPUCommandEncoder] interface starts encoding a render pass, returning a [GPURenderPassEncoder] that can be used to control rendering.",
      "clearbuffer": "\n\nThe **`clearBuffer()`** method of the\n[GPUCommandEncoder] interface encodes a command that fills a region of a [GPUBuffer] with zeroes.",
      "copybuffertobuffer": "\n\nThe **`copyBufferToBuffer()`** method of the\n[GPUCommandEncoder] interface encodes a command that copies data from one [GPUBuffer] to another.",
      "copybuffertotexture": "\n\nThe **`copyBufferToTexture()`** method of the\n[GPUCommandEncoder] interface encodes a command that copies data from a [GPUBuffer] to a [GPUTexture].",
      "copytexturetobuffer": "\n\nThe **`copyTextureToBuffer()`** method of the\n[GPUCommandEncoder] interface encodes a command that copies data from a [GPUTexture] to a [GPUBuffer].",
      "copytexturetotexture": "\n\nThe **`copyTextureToTexture()`** method of the\n[GPUCommandEncoder] interface encodes a command that copies data from one [GPUTexture] to another.",
      "finish": "\n\nThe **`finish()`** method of the\n[GPUCommandEncoder] interface completes recording of the command sequence encoded on this `GPUCommandEncoder`, returning a corresponding [GPUCommandBuffer].",
      "insertdebugmarker": "\n\nThe **`insertDebugMarker()`** method of the\n[GPUCommandEncoder] interface marks a specific point in a series of encoded commands with a label.\n\nThis could be used for telemetry, or may be utilized in [GPUError] messages, browser dev tools, or other services in the future to help with debugging.",
      "label": "\n\nThe **`label`** read-only property of the\n[GPUCommandEncoder] interface is a string providing a label that can be used to identify the object, for example in [GPUError] messages or console warnings.\n\nThis can be set by providing a `label` property in the descriptor object passed into the originating [GPUDevice.createCommandEncoder] call, or you can get and set it directly on the `GPUCommandEncoder` object.",
      "popdebuggroup": "\n\nThe **`popDebugGroup()`** method of the\n[GPUCommandEncoder] interface ends a debug group, which is begun with a [GPUCommandEncoder.pushDebugGroup] call.\n\nThis could be used for telemetry, or may be utilized in [GPUError] messages, browser dev tools, or other services in the future to help with debugging.",
      "pushdebuggroup": "\n\nThe **`pushDebugGroup()`** method of the\n[GPUCommandEncoder] interface begins a debug group, which is marked with a specified label, and will contain all subsequent encoded commands up until a [GPUCommandEncoder.popDebugGroup] method is invoked.\n\nThis could be used for telemetry, or may be utilized in [GPUError] messages, browser dev tools, or other services in the future to help with debugging.",
      "resolvequeryset": "\n\nThe **`resolveQuerySet()`** method of the\n[GPUCommandEncoder] interface encodes a command that resolves a [GPUQuerySet], copying the results into a specified [GPUBuffer].",
      "writetimestamp": "\n\nThe **`writeTimestamp()`** method of the\n[GPUCommandEncoder] interface encodes a command that writes a timestamp into a [GPUQuerySet] once the previous commands recorded into the same queued [GPUCommandBuffer] have been executed by the GPU.\n\n> **Note:** To use timestamp queries, the `timestamp-query` [GPUSupportedFeatures] must be enabled in the [GPUDevice]."
    }
  },
  "gpucompilationinfo": {
    "docs": "\n\nThe **`GPUCompilationInfo`** interface of the [WebGPU API] represents an array of [GPUCompilationMessage] objects generated by the GPU shader module compiler to help diagnose problems with shader code.\n\n`GPUCompilationInfo` is accessed via [GPUShaderModule.getCompilationInfo].\n\n",
    "properties": {
      "messages": "\n\nThe **`messages`** read-only property of the\n[GPUCompilationInfo] interface is an array of [GPUCompilationMessage] objects, each one containing the details of an individual shader compilation message. Messages can be informational, warnings, or errors."
    }
  },
  "gpucompilationmessage": {
    "docs": "\n\nThe **`GPUCompilationMessage`** interface of the [WebGPU API] represents a single informational, warning, or error message generated by the GPU shader module compiler.\n\nAn array of `GPUCompilationMessage` objects is available in the `messages` property of the [GPUCompilationInfo] object accessed via [GPUShaderModule.getCompilationInfo].\n\n",
    "properties": {
      "length": "\n\nThe **`length`** read-only property of the\n[GPUCompilationMessage] interface is a number representing the length of the substring that the message corresponds to.",
      "linenum": "\n\nThe **`lineNum`** read-only property of the\n[GPUCompilationMessage] interface is a number representing the line number in the shader code that the message corresponds to.",
      "linepos": "\n\nThe **`linePos`** read-only property of the\n[GPUCompilationMessage] interface is a number representing the position in the code line that the message corresponds to. This could be an exact point, or the start of the relevant substring.",
      "message": "\n\nThe **`message`** read-only property of the\n[GPUCompilationMessage] interface is a string representing human-readable message text.",
      "offset": "\n\nThe **`offset`** read-only property of the\n[GPUCompilationMessage] interface is a number representing the offset from the start of the shader code to the exact point, or the start of the relevant substring, that the message corresponds to.",
      "type": "\n\nThe **`type`** read-only property of the\n[GPUCompilationMessage] interface is an enumerated value representing the type of the message. Each type represents a different severity level."
    }
  },
  "gpucomputepassencoder": {
    "docs": "\n\nThe **`GPUComputePassEncoder`** interface of the [WebGPU API] encodes commands related to controlling the compute shader stage, as issued by a [GPUComputePipeline]. It forms part of the overall encoding activity of a [GPUCommandEncoder].\n\nA compute pipeline contains a single compute stage in which a compute shader takes general data, processes it in parallel across a specified number of workgroups, then returns the result in one or more buffers.\n\nA `GPUComputePassEncoder` object instance is created via the [GPUCommandEncoder.beginComputePass] property.\n\n",
    "properties": {
      "dispatchworkgroups": "\n\nThe **`dispatchWorkgroups()`** method of the\n[GPUComputePassEncoder] interface dispatches a specific grid of workgroups to perform the work being done by the current [GPUComputePipeline] (i.e. set via [GPUComputePassEncoder.setPipeline]).",
      "dispatchworkgroupsindirect": "\n\nThe **`dispatchWorkgroupsIndirect()`** method of the\n[GPUComputePassEncoder] interface dispatches a grid of workgroups, defined by the parameters of a [GPUBuffer], to perform the work being done by the current [GPUComputePipeline] (i.e. set via [GPUComputePassEncoder.setPipeline]).",
      "end": "\n\nThe **`end()`** method of the\n[GPUComputePassEncoder] interface completes recording of the current compute pass command sequence.",
      "insertdebugmarker": "\n\nThe **`insertDebugMarker()`** method of the\n[GPUComputePassEncoder] interface marks a specific point in a series of encoded compute pass commands with a label.\n\nThis could be used for telemetry, or may be utilized in [GPUError] messages, browser dev tools, or other services in the future to help with debugging.",
      "label": "\n\nThe **`label`** read-only property of the\n[GPUComputePassEncoder] interface is a string providing a label that can be used to identify the object, for example in [GPUError] messages or console warnings.\n\nThis can be set by providing a `label` property in the descriptor object passed into the originating [GPUCommandEncoder.beginComputePass] call, or you can get and set it directly on the `GPUComputePassEncoder` object.",
      "popdebuggroup": "\n\nThe **`popDebugGroup()`** method of the\n[GPUComputePassEncoder] interface ends a compute pass debug group, which is begun with a [GPUComputePassEncoder.pushDebugGroup] call.\n\nThis could be used for telemetry, or may be utilized in [GPUError] messages, browser dev tools, or other services in the future to help with debugging.",
      "pushdebuggroup": "\n\nThe **`pushDebugGroup()`** method of the\n[GPUComputePassEncoder] interface begins a compute pass debug group, which is marked with a specified label, and will contain all subsequent encoded commands up until a [GPUComputePassEncoder.popDebugGroup] method is invoked.\n\nThis could be used for telemetry, or may be utilized in [GPUError] messages, browser dev tools, or other services in the future to help with debugging.",
      "setbindgroup": "\n\nThe **`setBindGroup()`** method of the\n[GPUComputePassEncoder] interface sets the [GPUBindGroup] to use for subsequent compute commands, for a given index.",
      "setpipeline": "\n\nThe **`setPipeline()`** method of the\n[GPUComputePassEncoder] interface sets the [GPUComputePipeline] to use for this compute pass."
    }
  },
  "gpucomputepipeline": {
    "docs": "\n\nThe **`GPUComputePipeline`** interface of the [WebGPU API] represents a pipeline that controls the compute shader stage and can be used in a [GPUComputePassEncoder].\n\nA `GPUComputePipeline` object instance can be created using the [GPUDevice.createComputePipeline] or [GPUDevice.createComputePipelineAsync] methods.\n\n",
    "properties": {
      "getbindgrouplayout": "\n\nThe **`getBindGroupLayout()`** method of the\n[GPUComputePipeline] interface returns the pipeline's [GPUBindGroupLayout] object with the given index (i.e. included in the originating [GPUDevice.createComputePipeline] or [GPUDevice.createComputePipelineAsync] call's pipeline layout).\n\nIf the [GPUComputePipeline] was created with `layout: \"auto\"`, this method is the only way to retrieve the [GPUBindGroupLayout]s generated by the pipeline.",
      "label": "\n\nThe **`label`** property of the\n[GPUComputePipeline] interface provides a label that can be used to identify the object, for example in [GPUError] messages or console warnings.\n\nThis can be set by providing a `label` property in the descriptor object passed into the originating [GPUDevice.createComputePipeline] or [GPUDevice.createComputePipelineAsync] call, or you can get and set it directly on the `GPUComputePipeline` object."
    }
  },
  "gpudevice": {
    "docs": "\n\nThe **`GPUDevice`** interface of the [WebGPU API] represents a logical GPU device. This is the main interface through which the majority of WebGPU functionality is accessed.\n\nA `GPUDevice` object is requested using the [GPUAdapter.requestDevice] method.\n\n",
    "properties": {
      "createbindgroup": "\n\nThe **`createBindGroup()`** method of the\n[GPUDevice] interface creates a [GPUBindGroup] based on a [GPUBindGroupLayout] that defines a set of resources to be bound together in a group and how those resources are used in shader stages.",
      "createbindgrouplayout": "\n\nThe **`createBindGroupLayout()`** method of the\n[GPUDevice] interface creates a [GPUBindGroupLayout] that defines the structure and purpose of related GPU resources such as buffers that will be used in a pipeline, and is used as a template when creating [GPUBindGroup]s.",
      "createbuffer": "\n\nThe **`createBuffer()`** method of the\n[GPUDevice] interface creates a [GPUBuffer] in which to store raw data to use in GPU operations.",
      "createcommandencoder": "\n\nThe **`createCommandEncoder()`** method of the\n[GPUDevice] interface creates a [GPUCommandEncoder], used to encode commands to be issued to the GPU.",
      "createcomputepipeline": "\n\nThe **`createComputePipeline()`** method of the\n[GPUDevice] interface creates a [GPUComputePipeline] that can control the compute shader stage and be used in a [GPUComputePassEncoder].",
      "createcomputepipelineasync": "\n\nThe **`createComputePipelineAsync()`** method of the\n[GPUDevice] interface returns a `Promise` that fulfills with a [GPUComputePipeline], which can control the compute shader stage and be used in a [GPUComputePassEncoder], once the pipeline can be used without any stalling.\n\n> **Note:** It is generally preferable to use this method over [GPUDevice.createComputePipeline] whenever possible, as it prevents blocking of GPU operation execution on pipeline compilation.",
      "createpipelinelayout": "\n\nThe **`createPipelineLayout()`** method of the\n[GPUDevice] interface creates a [GPUPipelineLayout] that defines the [GPUBindGroupLayout]s used by a pipeline. [GPUBindGroup]s used with the pipeline during command encoding must have compatible [GPUBindGroupLayout]s.",
      "createqueryset": "\n\nThe **`createQuerySet()`** method of the\n[GPUDevice] interface creates a [GPUQuerySet] that can be used to record the results of queries on passes, such as occlusion or timestamp queries.",
      "createrenderbundleencoder": "\n\nThe **`createRenderBundleEncoder()`** method of the\n[GPUDevice] interface creates a [GPURenderBundleEncoder] that can be used to pre-record bundles of commands. These can be reused in [GPURenderPassEncoder]s via the [GPURenderPassEncoder.executeBundles] method, as many times as required.",
      "createrenderpipeline": "\n\nThe **`createRenderPipeline()`** method of the\n[GPUDevice] interface creates a [GPURenderPipeline] that can control the vertex and fragment shader stages and be used in a [GPURenderPassEncoder] or [GPURenderBundleEncoder].",
      "createrenderpipelineasync": "\n\nThe **`createRenderPipelineAsync()`** method of the\n[GPUDevice] interface returns a `Promise` that fulfills with a [GPURenderPipeline], which can control the vertex and fragment shader stages and be used in a [GPURenderPassEncoder] or [GPURenderBundleEncoder], once the pipeline can be used without any stalling.\n\n> **Note:** It is generally preferable to use this method over [GPUDevice.createRenderPipeline] whenever possible, as it prevents blocking of GPU operation execution on pipeline compilation.",
      "createsampler": "\n\nThe **`createSampler()`** method of the\n[GPUDevice] interface creates a [GPUSampler], which controls how shaders transform and filter texture resource data.",
      "createshadermodule": "\n\nThe **`createShaderModule()`** method of the\n[GPUDevice] interface creates a [GPUShaderModule] from a string of [WGSL](https://gpuweb.github.io/gpuweb/wgsl/) source code.",
      "createtexture": "\n\nThe **`createTexture()`** method of the\n[GPUDevice] interface creates a [GPUTexture] in which to store 1D, 2D, or 3D arrays of data, such as images, to use in GPU rendering operations.",
      "destroy": "\n\nThe **`destroy()`** method of the\n[GPUDevice] interface destroys the device, preventing further operations on it.\n\nNote that:\n\n- Any commands currently enqueued on the device's [GPUQueue] will be executed before the device is destroyed.\n- Any WebGPU resources created using the device (buffers, textures, etc.) are also destroyed.\n- Any mapped buffers created using the device will be unmapped.",
      "features": "\n\nThe **`features`** read-only property of the\n[GPUDevice] interface returns a [GPUSupportedFeatures] object that describes additional functionality supported by the device. Only features requested during the creation of the device (i.e. when [GPUAdapter.requestDevice] is called) are included.\n\n> **Note:** Not all features will be available to WebGPU in all browsers that support it, even if the features are supported by the underlying hardware. See [GPUAdapter.features] for more details.",
      "importexternaltexture": "\n\nThe **`importExternalTexture()`** method of the\n[GPUDevice] interface takes an [HTMLVideoElement] or a [VideoFrame] object as an input and returns a [GPUExternalTexture] wrapper object containing a snapshot of the video that can be used as a frame in GPU rendering operations.",
      "label": "\n\nThe **`label`** read-only property of the\n[GPUDevice] interface is a string providing a label that can be used to identify the object, for example in [GPUError] messages or console warnings.",
      "limits": "\n\nThe **`limits`** read-only property of the\n[GPUDevice] interface returns a [GPUSupportedLimits] object that describes the limits supported by the device. All limit values will be included, and the limits requested during the creation of the device (i.e. when [GPUAdapter.requestDevice] is called) will be reflected in those values.\n\n> **Note:** Not all limits will be reported as expected, even if they are supported by the underlying hardware. See [GPUAdapter.limits] for more details.",
      "lost": "\n\nThe **`lost`** read-only property of the\n[GPUDevice] interface contains a `Promise` that remains pending throughout the device's lifetime and resolves with a [GPUDeviceLostInfo] object when the device is lost.\n\n[GPUAdapter.requestDevice] will never return `null`, and it will reject only if the request is invalid, i.e. it exceeds the capabilities of the [GPUAdapter]. If a valid device request can't be fulfilled for some reason however it may resolve to a device that has already been lost. Additionally, devices can be lost at any time after creation for a variety of reasons (such as browser resource management or driver updates), so it's a good idea to always handle lost devices gracefully.\n\nMany causes for lost devices are transient, so you should try getting a new device once a previous one has been lost unless the loss was caused by the application intentionally destroying the device (i.e. with [GPUDevice.destroy]). Note that any WebGPU resources created with a previous device (buffers, textures, etc.) will need to be re-created with the new one.\n\n> **Note:** Also bear in mind that a `GPUAdapter` may become unavailable, e.g. if the physical GPU is unplugged from the system or disabled to save power. From then on, the adapter can no longer return valid devices, and will always return already-lost devices.",
      "poperrorscope": "\n\nThe **`popErrorScope()`** method of the\n[GPUDevice] interface pops an existing GPU error scope from the error scope stack (originally pushed using [GPUDevice.pushErrorScope]) and returns a `Promise` that resolves to an object describing the first error captured in the scope, or `null` if no error occurred.",
      "pusherrorscope": "\n\nThe **`pushErrorScope()`** method of the\n[GPUDevice] interface pushes a new GPU error scope onto the device's error scope stack, allowing you to capture errors of a particular type.\n\nOnce you are done capturing errors, you can end capture by invoking [GPUDevice.popErrorScope]. This pops the scope from the stack and returns a `Promise` that resolves to an object describing the first error captured in the scope, or `null` if no errors were captured.",
      "queue": "\n\nThe **`queue`** read-only property of the\n[GPUDevice] interface returns the primary [GPUQueue] for the device.",
      "uncapturederror_event": "\n\nThe **`uncapturederror`** event of the [GPUDevice] interface is fired when an error is thrown that has not been observed by a GPU error scope, to provide a way to report unexpected errors.\n\nKnown error cases should be handled using [GPUDevice.pushErrorScope] and [GPUDevice.popErrorScope]."
    }
  },
  "gpudevicelostinfo": {
    "docs": "\n\nThe **`GPUDeviceLostInfo`** interface of the [WebGPU API] represents the object returned when the [GPUDevice.lost] `Promise` resolves. This provides information as to why a device has been lost.\n\nSee the [GPUDevice.lost] page for more information about \"lost\" state.\n\n",
    "properties": {
      "message": "\n\nThe **`message`** read-only property of the\n[GPUDeviceLostInfo] interface provides a human-readable message that explains why the device was lost.",
      "reason": "\n\nThe **`reason`** read-only property of the\n[GPUDeviceLostInfo] interface defines the reason the device was lost in a machine-readable way."
    }
  },
  "gpuerror": {
    "docs": "\n\nThe **`GPUError`** interface of the [WebGPU API] is the base interface for errors surfaced by [GPUDevice.popErrorScope] and the [GPUDevice.uncapturederror_event] event.\n\n",
    "properties": {
      "message": "\n\nThe **`message`** read-only property of the\n[GPUError] interface provides a human-readable message that explains why the error occurred."
    }
  },
  "gpuexternaltexture": {
    "docs": "\n\nThe **`GPUExternalTexture`** interface of the [WebGPU API] represents a wrapper object containing an [HTMLVideoElement] snapshot that can be used as a texture in GPU rendering operations.\n\nA `GPUExternalTexture` object instance is created using [GPUDevice.importExternalTexture].\n\n",
    "properties": {
      "label": "\n\nThe **`label`** property of the\n[GPUExternalTexture] interface provides a label that can be used to identify the object, for example in [GPUError] messages or console warnings.\n\nThis can be set by providing a `label` property in the descriptor object passed into the originating [GPUDevice.importExternalTexture] call, or you can get and set it directly on the `GPUExternalTexture` object."
    }
  },
  "gpuinternalerror": {
    "docs": "\n\nThe **`GPUInternalError`** interface of the [WebGPU API] describes an application error indicating that an operation did not pass the WebGPU API's validation constraints.\n\nIt represents one of the types of errors surfaced by [GPUDevice.popErrorScope] and the [GPUDevice.uncapturederror_event] event.\n\nInternal errors occur when something happens in the WebGPU implementation that wasn't caught by validation and wasn't clearly identifiable as an out-of-memory error. It generally means that an operation your code performed hit a system limit in a way that was difficult to express with WebGPU's [supported limits](/en-US/docs/Web/API/GPUSupportedLimits). The same operation might succeed on a different device. These can only be raised by pipeline creation, usually if the shader is too complex for the device.\n\n"
  },
  "gpuoutofmemoryerror": {
    "docs": "\n\nThe **`GPUOutOfMemoryError`** interface of the [WebGPU API] describes an out-of-memory (oom) error indicating that there was not enough free memory to complete the requested operation.\n\nIt represents one of the types of errors surfaced by [GPUDevice.popErrorScope] and the [GPUDevice.uncapturederror_event] event.\n\nOut-of-memory errors should be relatively rare in a well-behaved app but are less predictable than [GPUValidationError]s. This is because they are dependent on the device your app is running on as well as other apps that are using GPU resources at the time.\n\n"
  },
  "gpupipelineerror": {
    "docs": "\n\nThe **`GPUPipelineError`** interface of the [WebGPU API] describes a pipeline failure. This is the value received when a `Promise` returned by a [GPUDevice.createComputePipelineAsync] or [GPUDevice.createRenderPipelineAsync] call rejects.\n\n",
    "properties": {
      "reason": "\n\nThe **`reason`** read-only property of the\n[GPUPipelineError] interface defines the reason the pipeline creation failed in a machine-readable way."
    }
  },
  "gpupipelinelayout": {
    "docs": "\n\nThe **`GPUPipelineLayout`** interface of the [WebGPU API] defines the [GPUBindGroupLayout]s used by a pipeline. [GPUBindGroup]s used with the pipeline during command encoding must have compatible [GPUBindGroupLayout]s.\n\nA `GPUPipelineLayout` object instance is created using the [GPUDevice.createPipelineLayout] method.\n\n",
    "properties": {
      "label": "\n\nThe **`label`** property of the\n[GPUPipelineLayout] interface provides a label that can be used to identify the object, for example in [GPUError] messages or console warnings.\n\nThis can be set by providing a `label` property in the descriptor object passed into the originating [GPUDevice.createPipelineLayout] call, or you can get and set it directly on the `GPUPipelineLayout` object."
    }
  },
  "gpuqueryset": {
    "docs": "\n\nThe **`GPUQuerySet`** interface of the [WebGPU API] is used to record the results of queries on passes, such as occlusion or timestamp queries.\n\n- Occlusion queries are available on render passes to query whether any fragment samples pass all the per-fragment tests for a set of drawing commands (including scissor, sample mask, alpha to coverage, stencil, and depth tests). To run an occlusion query, an appropriate `GPUQuerySet` must be provided as the value of the `occlusionQuerySet` descriptor property when invoking [GPUCommandEncoder.beginRenderPass] to run a render pass.\n\n- Timestamp queries allow applications to write timestamps to a `GPUQuerySet`. To run a timestamp query, appropriate `GPUQuerySet`s must be provided inside the value of the `timestampWrites` descriptor property when invoking [GPUCommandEncoder.beginRenderPass] to run a render pass, or [GPUCommandEncoder.beginComputePass] to run a compute pass. Alternatively, you can run a single timestamp query at any time by invoking [GPUCommandEncoder.writeTimeStamp] with an appropriate `GPUQuerySet` as a parameter.\n\n> **Note:** To use timestamp queries, the `timestamp-query` [GPUSupportedFeatures] must be enabled in the [GPUDevice].\n\nA `GPUQuerySet` object instance is created using the [GPUDevice.createQuerySet] method.\n\n",
    "properties": {
      "count": "\n\nThe **`count`** read-only property of the\n[GPUQuerySet] interface is a number specifying the number of queries managed by the `GPUQuerySet`.",
      "destroy": "\n\nThe **`destroy()`** method of the\n[GPUQuerySet] interface destroys the `GPUQuerySet`.",
      "label": "\n\nThe **`label`** property of the\n[GPUQuerySet] interface is a string providing a label that can be used to identify the object, for example in [GPUError] messages or console warnings.\n\nThis can be set by providing a `label` property in the descriptor object passed into the originating [GPUDevice.createQuerySet] call, or you can get and set it directly on the `GPUQuerySet` object.",
      "type": "\n\nThe **`type`** read-only property of the\n[GPUQuerySet] interface is an enumerated value specifying the type of queries managed by the `GPUQuerySet`."
    }
  },
  "gpuqueue": {
    "docs": "\n\nThe **`GPUQueue`** interface of the [WebGPU API] controls execution of encoded commands on the GPU.\n\nA device's primary queue is accessed via the [GPUDevice.queue] property.\n\n",
    "properties": {
      "copyexternalimagetotexture": "\n\nThe **`copyExternalImageToTexture()`** method of the\n[GPUQueue] interface copies a snapshot taken from a source image, video, or canvas into a given [GPUTexture].\n\nUsing this function allows the user agent to determine the most efficient way to copy the data over for each source type.",
      "label": "\n\nThe **`label`** read-only property of the\n[GPUQueue] interface is a string providing a label that can be used to identify the object, for example in [GPUError] messages or console warnings.\n\nYou can get and set it directly on the `GPUQueue` object.",
      "onsubmittedworkdone": "\n\nThe **`onSubmittedWorkDone()`** method of the\n[GPUQueue] interface returns a `Promise` that resolves when all the work submitted to the GPU via this `GPUQueue` at the point the method is called has been processed.\n\nThis includes the completion of any [GPUBuffer.mapAsync] calls made on `GPUBuffer`s used in commands submitted to the queue, before `onSubmittedWorkDone()` is called.\n\nNote: In most cases, you do _not_ need to call `onSubmittedWorkDone()`. You do **_not_** need to call it for mapping a buffer. `mapAsync` guarantees work submitted\nto the queue before calling `mapAsync` happens before the `mapAsync` returns (see [WebGPU spec: section 5.2](https://www.w3.org/TR/webgpu/#buffer-mapping))\n\nThe two use cases for `onSubmittedWorkDone`\n\n1. Waiting for multiple buffer mapping (slow)\n\n   ```js\n   // good\n   await Promise.all([\n     buffer1.mapAsync(),\n     buffer2.mapAsync(),\n     buffer3.mapAsync(),\n   ]);\n   data1 = buffer1.getMappedRange();\n   data2 = buffer2.getMappedRange();\n   data3 = buffer3.getMappedRange();\n   ```\n\n   ```js\n   // works but slow\n   buffer1.mapAsync();\n   buffer2.mapAsync();\n   buffer3.mapAsync();\n   await device.queue.onSubmittedWorkDone();\n   data1 = buffer1.getMappedRange();\n   data2 = buffer2.getMappedRange();\n   data3 = buffer3.getMappedRange();\n   ```\n\n   The reason the second method is slow is, the implementation may be able to map the buffers before all the submitted work is done.\n   For example, if all the buffers are finished being used, but more work (unrelated to the buffers) is already submitted, then\n   you'll end up waiting longer using the second method than the first.\n\n2. Throttling work\n\n   If you are doing heavy compute work and you submit too much work at once, the browser may kill your work.\n   You can throttle the work by only submitting more work when the work you've already submitted is done.",
      "submit": "\n\nThe **`submit()`** method of the\n[GPUQueue] interface schedules the execution of command buffers represented by one or more [GPUCommandBuffer] objects by the GPU.",
      "writebuffer": "\n\nThe **`writeBuffer()`** method of the\n[GPUQueue] interface writes a provided data source into a given [GPUBuffer].\n\nThis is a convenience function, which provides an alternative to setting buffer data via buffer mapping and buffer-to-buffer copies. It lets the user agent determine the most efficient way to copy the data over.",
      "writetexture": "\n\nThe **`writeTexture()`** method of the\n[GPUQueue] interface writes a provided data source into a given [GPUTexture].\n\nThis is a convenience function, which provides an alternative to setting texture data via buffer mapping and buffer-to-texture copies. It lets the user agent determine the most efficient way to copy the data over."
    }
  },
  "gpurenderbundle": {
    "docs": "\n\nThe **`GPURenderBundle`** interface of the [WebGPU API] represents a container for pre-recorded bundles of commands.\n\nThe command bundles are encoded using a [GPURenderBundleEncoder]; once the desired commands have been encoded, they are recorded into a `GPURenderBundle` object instance using the [GPURenderBundleEncoder.finish] method.\n\nThese command bundles can then be reused across multiple render passes by passing the `GPURenderBundle` objects into [GPURenderPassEncoder.executeBundles] calls. Reusing pre-recoded commands can significantly improve app performance in situations where JavaScript draw call overhead is a bottleneck. Render bundles are most effective in situations where a batch of objects will be drawn the same way across multiple views or frames, with the only differences being the buffer content being used (such as updated matrix uniforms).\n\nA good example is VR rendering. Recording the rendering as a render bundle and then tweaking the view matrix and replaying it for each eye is a more efficient way to issue draw calls for both renderings of the scene.\n\n",
    "properties": {
      "label": "\n\nThe **`label`** read-only property of the\n[GPURenderBundle] interface is a string providing a label that can be used to identify the object, for example in [GPUError] messages or console warnings.\n\nThis can be set by providing a `label` property in the descriptor object passed into the originating [GPURenderBundleEncoder.finish] call, or you can get and set it directly on the `GPURenderBundle` object."
    }
  },
  "gpurenderbundleencoder": {
    "docs": "\n\nThe **`GPURenderBundleEncoder`** interface of the [WebGPU API] is used to pre-record bundles of commands.\n\nThe command bundles are encoded by calling the methods of `GPURenderBundleEncoder`; once the desired commands have been encoded, they are recorded into a [GPURenderBundle] object instance using the [GPURenderBundleEncoder.finish] method. These render bundles can then be reused across multiple render passes by passing the `GPURenderBundle` objects into [GPURenderPassEncoder.executeBundles] calls.\n\nIn effect, this is like a partial render pass — `GPURenderBundleEncoder`s have all the same functionality available as [GPURenderPassEncoder]s, except that they can't begin and end occlusion queries, and can't set the scissor rect, viewport, blend constant, and stencil reference. The `GPURenderBundle` will inherit all these values from the [GPURenderPassEncoder] that executes it.\n\n> **Note:** Currently set vertex buffers, index buffers, bind groups, and pipeline are all cleared prior to executing a render bundle, and once the render bundle has finished executing.\n\nReusing pre-recoded commands can significantly improve app performance in situations where JavaScript draw call overhead is a bottleneck. Render bundles are most effective in situations where a batch of objects will be drawn the same way across multiple views or frames, with the only differences being the buffer content being used (such as updated matrix uniforms). A good example is VR rendering. Recording the rendering as a render bundle and then tweaking the view matrix and replaying it for each eye is a more efficient way to issue draw calls for both renderings of the scene.\n\nA `GPURenderBundleEncoder` object instance is created via the [GPUDevice.createRenderBundleEncoder] property.\n\n> **Note:** The methods of `GPURenderBundleEncoder` are functionally identical to their equivalents available on [GPURenderPassEncoder], except for [GPURenderBundleEncoder.finish], which is similar in purpose to [GPUCommandEncoder.finish].\n\n",
    "properties": {
      "draw": "\n\nThe **`draw()`** method of the\n[GPURenderBundleEncoder] interface draws primitives based on the vertex buffers provided by [GPURenderBundleEncoder.setVertexBuffer].\n\n> **Note:** This method is functionally identical to its equivalent on [GPURenderPassEncoder] — [GPURenderPassEncoder.draw].",
      "drawindexed": "\n\nThe **`drawIndexed()`** method of the\n[GPURenderBundleEncoder] interface draws indexed primitives based on the vertex and index buffers provided by [GPURenderBundleEncoder.setVertexBuffer] and [GPURenderBundleEncoder.setIndexBuffer].\n\n> **Note:** This method is functionally identical to its equivalent on [GPURenderPassEncoder] — [GPURenderPassEncoder.drawIndexed].",
      "drawindexedindirect": "\n\nThe **`drawIndexedIndirect()`** method of the\n[GPURenderBundleEncoder] interface draws indexed primitives using parameters read from a [GPUBuffer].\n\n> **Note:** This method is functionally identical to its equivalent on [GPURenderPassEncoder] — [GPURenderPassEncoder.drawIndexedIndirect].",
      "drawindirect": "\n\nThe **`drawIndirect()`** method of the\n[GPURenderBundleEncoder] interface draws primitives using parameters read from a [GPUBuffer].\n\n> **Note:** This method is functionally identical to its equivalent on [GPURenderPassEncoder] — [GPURenderPassEncoder.drawIndirect].",
      "finish": "\n\nThe **`finish()`** method of the\n[GPURenderBundleEncoder] interface completes recording of the current render bundle command sequence, returning a [GPURenderBundle] object that can be passed into a [GPURenderPassEncoder.executeBundles] call to execute those commands in a specific render pass.",
      "insertdebugmarker": "\n\nThe **`insertDebugMarker()`** method of the\n[GPURenderBundleEncoder] interface marks a specific point in a series of encoded render bundle pass commands with a label.\n\nThis could be used for telemetry, or may be utilized in [GPUError] messages, browser dev tools, or other services in the future to help with debugging.\n\n> **Note:** This method is functionally identical to its equivalent on [GPURenderPassEncoder] — [GPURenderPassEncoder.InsertDebugMarker].",
      "label": "\n\nThe **`label`** read-only property of the\n[GPURenderBundleEncoder] interface is a string providing a label that can be used to identify the object, for example in [GPUError] messages or console warnings.\n\nThis can be set by providing a `label` property in the descriptor object passed into the originating [GPUDevice.createRenderBundleEncoder] call, or you can get and set it directly on the `GPURenderBundleEncoder` object.\n\n> **Note:** This property is functionally identical to its equivalent on [GPURenderPassEncoder] — [GPURenderPassEncoder.label].",
      "popdebuggroup": "\n\nThe **`popDebugGroup()`** method of the\n[GPURenderBundleEncoder] interface ends a render bundle debug group, which is begun with a [GPURenderBundleEncoder.pushDebugGroup] call.\n\nThis could be used for telemetry, or may be utilized in [GPUError] messages, browser dev tools, or other services in the future to help with debugging.\n\n> **Note:** This method is functionally identical to its equivalent on [GPURenderPassEncoder] — [GPURenderPassEncoder.popDebugGroup].",
      "pushdebuggroup": "\n\nThe **`pushDebugGroup()`** method of the\n[GPURenderBundleEncoder] interface begins a render bundle debug group, which is marked with a specified label, and will contain all subsequent encoded commands up until a [GPURenderBundleEncoder.popDebugGroup] method is invoked.\n\nThis could be used for telemetry, or may be utilized in [GPUError] messages, browser dev tools, or other services in the future to help with debugging.\n\n> **Note:** This method is functionally identical to its equivalent on [GPURenderPassEncoder] — [GPURenderPassEncoder.pushDebugGroup].",
      "setbindgroup": "\n\nThe **`setBindGroup()`** method of the\n[GPURenderBundleEncoder] interface sets the [GPUBindGroup] to use for subsequent render bundle commands, for a given index.\n\n> **Note:** This method is functionally identical to its equivalent on [GPURenderPassEncoder] — [GPURenderPassEncoder.setBindGroup].",
      "setindexbuffer": "\n\nThe **`setIndexBuffer()`** method of the\n[GPURenderBundleEncoder] interface sets the current [GPUBuffer] that will provide index data for subsequent drawing commands.\n\n> **Note:** This method is functionally identical to its equivalent on [GPURenderPassEncoder] — [GPURenderPassEncoder.setIndexBuffer].",
      "setpipeline": "\n\nThe **`setPipeline()`** method of the\n[GPURenderBundleEncoder] interface sets the [GPURenderPipeline] to use for subsequent render bundle commands.\n\n> **Note:** This method is functionally identical to its equivalent on [GPURenderPassEncoder] — [GPURenderPassEncoder.setPipeline].",
      "setvertexbuffer": "\n\nThe **`setVertexBuffer()`** method of the\n[GPURenderBundleEncoder] interface sets or unsets the current [GPUBuffer] for the given slot that will provide vertex data for subsequent drawing commands.\n\n> **Note:** This method is functionally identical to its equivalent on [GPURenderPassEncoder] — [GPURenderPassEncoder.setVertexBuffer]."
    }
  },
  "gpurenderpassencoder": {
    "docs": "\n\nThe **`GPURenderPassEncoder`** interface of the [WebGPU API] encodes commands related to controlling the vertex and fragment shader stages, as issued by a [GPURenderPipeline]. It forms part of the overall encoding activity of a [GPUCommandEncoder].\n\nA render pipeline renders graphics to [GPUTexture] attachments, typically intended for display in a `canvas` element, but it could also render to textures used for other purposes that never appear onscreen. It has two main stages:\n\n- A vertex stage, in which a vertex shader takes positioning data fed into the GPU and uses it to position a series of vertices in 3D space by applying specified effects like rotation, translation, or perspective. The vertices are then assembled into primitives such as triangles (the basic building block of rendered graphics) and rasterized by the GPU to figure out what pixels each one should cover on the drawing canvas.\n\n- A fragment stage, in which a fragment shader computes the color for each pixel covered by the primitives produced by the vertex shader. These computations frequently use inputs such as images (in the form of textures) that provide surface details and the position and color of virtual lights.\n\nA `GPURenderPassEncoder` object instance is created via the [GPUCommandEncoder.beginRenderPass] property.\n\n",
    "properties": {
      "beginocclusionquery": "\n\nThe **`beginOcclusionQuery()`** method of the\n[GPURenderPassEncoder] interface begins an occlusion query at the specified index of the relevant [GPUQuerySet] (provided as the value of the `occlusionQuerySet` descriptor property when invoking [GPUCommandEncoder.beginRenderPass] to run the render pass).",
      "draw": "\n\nThe **`draw()`** method of the\n[GPURenderPassEncoder] interface draws primitives based on the vertex buffers provided by [GPURenderPassEncoder.setVertexBuffer].",
      "drawindexed": "\n\nThe **`drawIndexed()`** method of the\n[GPURenderPassEncoder] interface draws indexed primitives based on the vertex and index buffers provided by [GPURenderPassEncoder.setVertexBuffer] and [GPURenderPassEncoder.setIndexBuffer].",
      "drawindexedindirect": "\n\nThe **`drawIndexedIndirect()`** method of the\n[GPURenderPassEncoder] interface draws indexed primitives using parameters read from a [GPUBuffer].",
      "drawindirect": "\n\nThe **`drawIndirect()`** method of the\n[GPURenderPassEncoder] interface draws primitives using parameters read from a [GPUBuffer].",
      "end": "\n\nThe **`end()`** method of the\n[GPURenderPassEncoder] interface completes recording of the current render pass command sequence.",
      "endocclusionquery": "\n\nThe **`endOcclusionQuery()`** method of the\n[GPURenderPassEncoder] interface ends an active occlusion query previously started with [GPURenderPassEncoder.beginOcclusionQuery].",
      "executebundles": "\n\nThe **`executeBundles()`** method of the\n[GPURenderPassEncoder] interface executes commands previously recorded into the referenced [GPURenderBundle]s, as part of this render pass.\n\n> **Note:** After calling `executeBundles()` the currently set vertex buffers, index buffers, bind groups, and pipeline are all cleared, even if no bundles are actually executed.",
      "insertdebugmarker": "\n\nThe **`insertDebugMarker()`** method of the\n[GPURenderPassEncoder] interface marks a specific point in a series of encoded render pass commands with a label.\n\nThis could be used for telemetry, or may be utilized in [GPUError] messages, browser dev tools, or other services in the future to help with debugging.",
      "label": "\n\nThe **`label`** read-only property of the\n[GPURenderPassEncoder] interface is a string providing a label that can be used to identify the object, for example in [GPUError] messages or console warnings.\n\nThis can be set by providing a `label` property in the descriptor object passed into the originating [GPUCommandEncoder.beginRenderPass] call, or you can get and set it directly on the `GPURenderPassEncoder` object.",
      "popdebuggroup": "\n\nThe **`popDebugGroup()`** method of the\n[GPURenderPassEncoder] interface ends a render pass debug group, which is begun with a [GPURenderPassEncoder.pushDebugGroup] call.\n\nThis could be used for telemetry, or may be utilized in [GPUError] messages, browser dev tools, or other services in the future to help with debugging.",
      "pushdebuggroup": "\n\nThe **`pushDebugGroup()`** method of the\n[GPURenderPassEncoder] interface begins a render pass debug group, which is marked with a specified label, and will contain all subsequent encoded commands up until a [GPURenderPassEncoder.popDebugGroup] method is invoked.\n\nThis could be used for telemetry, or may be utilized in [GPUError] messages, browser dev tools, or other services in the future to help with debugging.",
      "setbindgroup": "\n\nThe **`setBindGroup()`** method of the\n[GPURenderPassEncoder] interface sets the [GPUBindGroup] to use for subsequent render commands, for a given index.",
      "setblendconstant": "\n\nThe **`setBlendConstant()`** method of the\n[GPURenderPassEncoder] interface sets the constant blend color and alpha values used with `\"constant\"` and `\"one-minus-constant\"` blend factors (as set in the descriptor of the [GPUDevice.createRenderPipeline] method, in the `blend` property).",
      "setindexbuffer": "\n\nThe **`setIndexBuffer()`** method of the\n[GPURenderPassEncoder] interface sets the current [GPUBuffer] that will provide index data for subsequent drawing commands.",
      "setpipeline": "\n\nThe **`setPipeline()`** method of the\n[GPURenderPassEncoder] interface sets the [GPURenderPipeline] to use for subsequent render pass commands.",
      "setscissorrect": "\n\nThe **`setScissorRect()`** method of the\n[GPURenderPassEncoder] interface sets the scissor rectangle used during the rasterization stage. After transformation into viewport coordinates any fragments that fall outside the scissor rectangle will be discarded.",
      "setstencilreference": "\n\nThe **`setStencilReference()`** method of the\n[GPURenderPassEncoder] interface sets the stencil reference value using during stencil tests with the `\"replace\"` stencil operation (as set in the descriptor of the [GPUDevice.createRenderPipeline] method, in the properties defining the various stencil operations).",
      "setvertexbuffer": "\n\nThe **`setVertexBuffer()`** method of the\n[GPURenderPassEncoder] interface sets or unsets the current [GPUBuffer] for the given slot that will provide vertex data for subsequent drawing commands.",
      "setviewport": "\n\nThe **`setViewport()`** method of the\n[GPURenderPassEncoder] interface sets the viewport used during the rasterization stage to linearly map from normalized device coordinates to viewport coordinates."
    }
  },
  "gpurenderpipeline": {
    "docs": "\n\nThe **`GPURenderPipeline`** interface of the [WebGPU API] represents a pipeline that controls the vertex and fragment shader stages and can be used in a [GPURenderPassEncoder] or [GPURenderBundleEncoder].\n\nA `GPURenderPipeline` object instance can be created using the [GPUDevice.createRenderPipeline] or [GPUDevice.createRenderPipelineAsync] methods.\n\n",
    "properties": {
      "getbindgrouplayout": "\n\nThe **`getBindGroupLayout()`** method of the\n[GPURenderPipeline] interface returns the pipeline's [GPUBindGroupLayout] object with the given index (i.e. included in the originating [GPUDevice.createRenderPipeline] or [GPUDevice.createRenderPipelineAsync] call's pipeline layout).\n\nIf the [GPURenderPipeline] was created with `layout: \"auto\"`, this method is the only way to retrieve the [GPUBindGroupLayout]s generated by the pipeline.",
      "label": "\n\nThe **`label`** property of the\n[GPURenderPipeline] interface provides a label that can be used to identify the object, for example in [GPUError] messages or console warnings.\n\nThis can be set by providing a `label` property in the descriptor object passed into the originating [GPUDevice.createRenderPipeline] or [GPUDevice.createRenderPipelineAsync] call, or you can get and set it directly on the `GPURenderPipeline` object."
    }
  },
  "gpusampler": {
    "docs": "\n\nThe **`GPUSampler`** interface of the [WebGPU API] represents an object that can control how shaders transform and filter texture resource data.\n\nA `GPUSampler` object instance is created using the [GPUDevice.createSampler] method.\n\n",
    "properties": {
      "label": "\n\nThe **`label`** property of the\n[GPUSampler] interface provides a label that can be used to identify the object, for example in [GPUError] messages or console warnings.\n\nThis can be set by providing a `label` property in the descriptor object passed into the originating [GPUDevice.createSampler] call, or you can get and set it directly on the `GPUSampler` object."
    }
  },
  "gpushadermodule": {
    "docs": "\n\nThe **`GPUShaderModule`** interface of the [WebGPU API] represents an internal shader module object, a container for [WGSL](https://gpuweb.github.io/gpuweb/wgsl/) shader code that can be submitted to the GPU for execution by a pipeline.\n\nA `GPUShaderModule` object instance is created using [GPUDevice.createShaderModule].\n\n",
    "properties": {
      "getcompilationinfo": "\n\nThe **`getCompilationInfo()`** method of the\n[GPUShaderModule] interface returns a `Promise` that fulfills with a [GPUCompilationInfo] object containing messages generated during the `GPUShaderModule`'s compilation.",
      "label": "\n\nThe **`label`** property of the\n[GPUShaderModule] interface provides a label that can be used to identify the object, for example in [GPUError] messages or console warnings.\n\nThis can be set by providing a `label` property in the descriptor object passed into the originating [GPUDevice.createShaderModule] call, or you can get and set it directly on the `GPUShaderModule` object."
    }
  },
  "gpusupportedfeatures": {
    "docs": "\n\nThe **`GPUSupportedFeatures`** interface of the [WebGPU API] is a [`Set`-like object](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Set#set-like_browser_apis) that describes additional functionality supported by a [GPUAdapter].\n\nThe `GPUSupportedFeatures` object for the current adapter is accessed via the [GPUAdapter.features] property.\n\nYou should note that not all features will be available to WebGPU in all browsers that support it, even if the features are supported by the underlying hardware. This could be due to constraints in the underlying system, browser, or adapter. For example:\n\n- The underlying system might not be able to guarantee exposure of a feature in a way that is compatible with a certain browser.\n- The browser vendor might not have found a secure way to implement support for that feature, or might just not have gotten round to it yet.\n\nIf you are hoping to take advantage of a specific additional feature in a WebGPU app, thorough testing is advised.\n\n"
  },
  "gpusupportedlimits": {
    "docs": "\n\nThe **`GPUSupportedLimits`** interface of the [WebGPU API] describes the limits supported by a [GPUAdapter].\n\nThe `GPUSupportedLimits` object for the current adapter is accessed via the [GPUAdapter.limits] property.\n\nYou should note that, rather than reporting the exact limits of each GPU, browsers will likely report different tier values of different limits to reduce the unique information available to drive-by fingerprinting. For example, the tiers of a certain limit might be 2048, 8192, and 32768. If your GPU's actual limit is 16384, the browser will still report 8192.\n\nGiven that different browsers will handle this differently and the tier values may change over time, it is hard to provide an accurate account of what limit values to expect — thorough testing is advised.\n\n"
  },
  "gputexture": {
    "docs": "\n\nThe **`GPUTexture`** interface of the [WebGPU API] represents a container used to store 1D, 2D, or 3D arrays of data, such as images, to use in GPU rendering operations.\n\nA `GPUTexture` object instance is created using the [GPUDevice.createTexture] method.\n\n",
    "properties": {
      "createview": "\n\nThe **`createView()`** method of the\n[GPUTexture] interface creates a [GPUTextureView] representing a specific view of the `GPUTexture`.",
      "depthorarraylayers": "\n\nThe **`depthOrArrayLayers`** read-only property of the\n[GPUTexture] interface represents the depth or layer count of the `GPUTexture`.\n\nThis is set based on the `size` property in the descriptor object passed into the originating [GPUDevice.createTexture] call.",
      "destroy": "\n\nThe **`destroy()`** method of the\n[GPUTexture] interface destroys the `GPUTexture`.",
      "dimension": "\n\nThe **`dimension`** read-only property of the\n[GPUTexture] interface represents the dimension of the set of texels for each `GPUTexture` subresource.\n\nThis is set via the `dimension` property in the descriptor object passed into the originating [GPUDevice.createTexture] call, which defaults to `\"2d\"` if omitted.",
      "format": "\n\nThe **`format`** read-only property of the\n[GPUTexture] interface represents the format of the `GPUTexture`.\n\nThis is set via the `format` property in the descriptor object passed into the originating [GPUDevice.createTexture] call.",
      "height": "\n\nThe **`height`** read-only property of the\n[GPUTexture] interface represents the height of the `GPUTexture`.\n\nThis is set based on the value of the `size` property in the descriptor object passed into the originating [GPUDevice.createTexture] call.",
      "label": "\n\nThe **`label`** property of the\n[GPUTexture] interface provides a label that can be used to identify the object, for example in [GPUError] messages or console warnings.\n\nThis can be set by providing a `label` property in the descriptor object passed into the originating [GPUDevice.createTexture] call, or you can get and set it directly on the `GPUTexture` object.",
      "miplevelcount": "\n\nThe **`mipLevelCount`** read-only property of the\n[GPUTexture] interface represents the number of mip levels of the `GPUTexture`.\n\nThis is set via the `mipLevelCount` property in the descriptor object passed into the originating [GPUDevice.createTexture] call. If omitted, this defaults to 1.",
      "samplecount": "\n\nThe **`sampleCount`** read-only property of the\n[GPUTexture] interface represents the sample count of the `GPUTexture`.\n\nThis is set via the `sampleCount` property in the descriptor object passed into the originating [GPUDevice.createTexture] call. If omitted, this defaults to 1.",
      "usage": "\n\nThe **`usage`** read-only property of the\n[GPUTexture] interface is the  representing the allowed usages of the `GPUTexture`.\n\nThis is set via the `usage` property in the descriptor object passed into the originating [GPUDevice.createTexture] call.",
      "width": "\n\nThe **`width`** read-only property of the\n[GPUTexture] interface represents the width of the `GPUTexture`.\n\nThis is set based on the value of the `size` property in the descriptor object passed into the originating [GPUDevice.createTexture] call."
    }
  },
  "gputextureview": {
    "docs": "\n\nThe **`GPUTextureView`** interface of the [WebGPU API] represents a view into a subset of the texture resources defined by a particular [GPUTexture].\n\nA `GPUTextureView` object instance is created using the [GPUTexture.createView] method.\n\n",
    "properties": {
      "label": "\n\nThe **`label`** property of the\n[GPUTextureView] interface provides a label that can be used to identify the object, for example in [GPUError] messages or console warnings.\n\nThis can be set by providing a `label` property in the descriptor object passed into the originating [GPUTexture.createView] call, or you can get and set it directly on the `GPUTextureView` object."
    }
  },
  "gpuuncapturederrorevent": {
    "docs": "\n\nThe **`GPUUncapturedErrorEvent`** interface of the [WebGPU API] is the event object type for the [GPUDevice] [GPUDevice.uncapturederror_event] event, used for telemetry and to report unexpected errors.\n\nKnown error cases should be handled using [GPUDevice.pushErrorScope] and [GPUDevice.popErrorScope].\n\n",
    "properties": {
      "error": "\n\nThe **`error`** read-only property of the\n[GPUUncapturedErrorEvent] interface is a [GPUError] object instance providing access to the details of the error."
    }
  },
  "gpuvalidationerror": {
    "docs": "\n\nThe **`GPUValidationError`** interface of the [WebGPU API] describes an application error indicating that an operation did not pass the WebGPU API's validation constraints.\n\nIt represents one of the types of errors surfaced by [GPUDevice.popErrorScope] and the [GPUDevice.uncapturederror_event] event.\n\nValidation errors occur whenever invalid inputs are given to a WebGPU call. These are consistent, predictable, and should not occur provided your app is well-formed. They will occur in the same way on every device your code runs on, so once you've fixed any errors that show up during development you probably don't need to observe them directly most of the time. An exception to that rule is if you're consuming user-supplied assets, shaders, etc., in which case watching for validation errors while loading could be helpful.\n\n> **Note:** We have attempted to provide useful information to help you understand why validation errors are occurring in your WebGPU code in \"Validation\" sections where appropriate, which list criteria to meet to avoid validation errors. See for example the [`GPUDevice.createBindGroup()` Validation section](/en-US/docs/Web/API/GPUDevice/createBindGroup#validation).\n\n"
  },
  "gravitysensor": {
    "docs": "\n\nThe **`GravitySensor`** interface of the [Sensor APIs](/en-US/docs/Web/API/Sensor_APIs) provides on each reading the gravity applied to the device along all three axes.\n\nTo use this sensor, the user must grant permission to the `'accelerometer'` device sensor through the [Permissions API](/en-US/docs/Web/API/Permissions_API). In addition, this feature may be blocked by a [Permissions Policy](/en-US/docs/Web/HTTP/Permissions_Policy) set on your server.\n\n"
  },
  "gyroscope": {
    "docs": "\n\nThe **`Gyroscope`** interface of the [Sensor APIs](/en-US/docs/Web/API/Sensor_APIs) provides on each reading the angular velocity of the device along all three axes.\n\nTo use this sensor, the user must grant permission to the `'gyroscope'` device sensor through the [Permissions API](/en-US/docs/Web/API/Permissions_API). In addition, this feature may be blocked by a [Permissions Policy](/en-US/docs/Web/HTTP/Permissions_Policy) set on your server.\n\n",
    "properties": {
      "x": "\n\nThe **`x`** read-only property of the\n[Gyroscope] interface returns a number specifying the\nangular velocity of the device along its x-axis.",
      "y": "\n\nThe **`y`** read-only property of the [Gyroscope] interface returns a number specifying the angular velocity of the device along its y-axis.",
      "z": "\n\nThe **`z`** read-only property of the\n[Gyroscope] interface returns a number specifying the\nangular velocity of the device along its z-axis."
    }
  },
  "hashchangeevent": {
    "docs": "\n\nThe **`HashChangeEvent`** interface represents events that fire when the fragment identifier of the URL has changed.\n\nThe fragment identifier is the part of the URL that follows (and includes) the `#` symbol.\n\n",
    "properties": {
      "newurl": "\n\nThe **`newURL`** read-only property of the\n[HashChangeEvent] interface returns the new URL to which the window is\nnavigating.",
      "oldurl": "\n\nThe **`oldURL`** read-only property of the\n[HashChangeEvent] interface returns the previous URL from which the window\nwas navigated."
    }
  },
  "headers": {
    "docs": "\n\nThe **`Headers`** interface of the [Fetch API](/en-US/docs/Web/API/Fetch_API) allows you to perform various actions on [HTTP request and response headers](/en-US/docs/Web/HTTP/Headers). These actions include retrieving, setting, adding to, and removing headers from the list of the request's headers.\n\nA `Headers` object has an associated header list, which is initially empty and consists of zero or more name and value pairs. You can add to this using methods like [Headers.append] (see [Examples](#examples).) In all methods of this interface, header names are matched by case-insensitive byte sequence.\n\nFor security reasons, some headers can only be controlled by the user agent. These headers include the  and .\n\nA Headers object also has an associated guard, which takes a value of `immutable`, `request`, `request-no-cors`, `response`, or `none`. This affects whether the [Headers.set], [Headers.delete], and [Headers.append] methods will mutate the header. For more information see .\n\nYou can retrieve a `Headers` object via the [Request.headers] and [Response.headers] properties, and create a new `Headers` object using the [Headers.Headers] constructor.\n\nAn object implementing `Headers` can directly be used in a `for...of` structure, instead of [Headers.entries]: `for (const p of myHeaders)` is equivalent to `for (const p of myHeaders.entries())`.\n\n> **Note:** you can find out more about the available headers by reading our [HTTP headers](/en-US/docs/Web/HTTP/Headers) reference.",
    "properties": {
      "append": "\n\nThe **`append()`** method of the [Headers]\ninterface appends a new value onto an existing header inside a `Headers`\nobject, or adds the header if it does not already exist.\n\nThe difference between [Headers.set] and `append()` is\nthat if the specified header already exists and accepts multiple values,\n`set()` will overwrite the existing value with the new one, whereas\n`append()` will append the new value onto the end of the set of values.\n\nFor security reasons, some headers can only be controlled by the user agent. These\nheaders include the \nand .",
      "delete": "\n\nThe **`delete()`** method of the [Headers]\ninterface deletes a header from the current `Headers` object.\n\nThis method throws a `TypeError` for the following reasons:\n\n- The value of the name parameter is not the name of an HTTP header.\n- The value of  is `immutable`.\n\nFor security reasons, some headers can only be controlled by the user agent. These\nheaders include the \nand .",
      "entries": "\n\nThe **`Headers.entries()`** method returns an\n`iterator` allowing to go through all key/value pairs\ncontained in this object. Both the key and value of each pair are\n`String` objects.\n\n> **Note:** This method is available in [Web Workers](/en-US/docs/Web/API/Web_Workers_API).",
      "foreach": "\n\nThe **`Headers.forEach()`** method executes a callback function once per each key/value pair in the [`Headers`](/en-US/docs/Web/API/Headers) object.",
      "get": "\n\nThe **`get()`** method of the [Headers] interface\nreturns a byte string of all the values of a header within a `Headers` object\nwith a given name. If the requested header doesn't exist in the `Headers`\nobject, it returns `null`.\n\nFor security reasons, some headers can only be controlled by the user agent. These\nheaders include the \nand .",
      "getsetcookie": "\n\nThe **`getSetCookie()`** method of the [Headers] interface returns an array containing the values of all  headers associated with a response. This allows [Headers] objects to handle having multiple `Set-Cookie` headers, which wasn't possible prior to its implementation.\n\nThis method is intended for use on server environments (for example Node.js). Browsers block frontend JavaScript code from accessing the  header, as required by the Fetch spec, which defines `Set-Cookie` as a [forbidden response-header name](https://fetch.spec.whatwg.org/#forbidden-response-header-name) that [must be filtered out](https://fetch.spec.whatwg.org/#ref-for-forbidden-response-header-name%E2%91%A0) from any response exposed to frontend code.",
      "has": "\n\nThe **`has()`** method of the [Headers] interface\nreturns a boolean stating whether a `Headers` object contains a certain\nheader.\n\nFor security reasons, some headers can only be controlled by the user agent. These\nheaders include the \nand .",
      "keys": "\n\nThe **`Headers.keys()`** method returns an\n`iterator` allowing to go through all keys contained\nin this object. The keys are `String` objects.\n\n> **Note:** This method is available in [Web Workers](/en-US/docs/Web/API/Web_Workers_API).",
      "set": "\n\nThe **`set()`** method of the [Headers] interface\nsets a new value for an existing header inside a `Headers` object, or adds\nthe header if it does not already exist.\n\nThe difference between `set()` and [Headers.append] is that if\nthe specified header already exists and accepts multiple values, `set()`\noverwrites the existing value with the new one, whereas [Headers.append]\nappends the new value to the end of the set of values.\n\nFor security reasons, some headers can only be controlled by the user agent. These\nheaders include the \nand .",
      "values": "\n\nThe **`Headers.values()`** method returns an\n`iterator` allowing to go through all values contained\nin this object. The values are `String` objects.\n\n> **Note:** This method is available in [Web Workers](/en-US/docs/Web/API/Web_Workers_API)."
    }
  },
  "hid": {
    "docs": "\n\nThe **`HID`** interface provides methods for connecting to _HID devices_, listing attached HID devices and event handlers for connected HID devices.\n\n",
    "properties": {
      "connect_event": "\n\nThe **`connect`** event of the [HID] interface fires when the user agent connects to a HID device.",
      "disconnect_event": "\n\nThe **`disconnect`** event of the [HID] interface fires when the user agent disconnects a HID device.",
      "getdevices": "\n\nThe **`getDevices()`** method of the [HID] interface gets a list of the connected HID devices that the user has previously been granted access to in response to a [HID.requestDevice] call.",
      "requestdevice": "\n\nThe **`requestDevice()`** method of the [HID] interface requests access to a HID device.\n\nThe user agent will present a permission dialog including a list of connected devices, and ask the user to select and grant permission to one of these devices."
    }
  },
  "hidconnectionevent": {
    "docs": "\n\nThe **`HIDConnectionEvent`** interface of the [WebHID API] represents HID connection events, and is the event type passed to [HID/connect_event] and [HID/disconnect_event] event handlers when an input report is received.\n\n",
    "properties": {
      "device": "\n\nThe **`device`** read-only property of the [HIDConnectionEvent] interface returns the [HIDDevice] associated with this connection event."
    }
  },
  "hiddevice": {
    "docs": "\n\nThe **`HIDDevice`** interface of the [WebHID API] represents a HID Device. It provides properties for accessing information about the device, methods for opening and closing the connection, and the sending and receiving of reports.\n\n",
    "properties": {
      "close": "\n\nThe **`close()`** method of the [HIDDevice] interface closes the connection to the HID device.",
      "collections": "\n\nThe **`collections`** read-only property of the [HIDDevice] interface returns an array of report formats",
      "forget": "\n\nThe **`forget()`** method of the [HIDDevice] interface closes the connection to the HID device and forgets the device.",
      "inputreport_event": "\n\nThe **`inputreport`** event of the [HIDDevice] interface fires when a new report is received from the HID device.",
      "open": "\n\nThe **`open()`** method of the [HIDDevice] interface requests that the operating system opens the HID device.\n\n> **Note:** HID devices are not opened automatically. Therefore, a [HIDDevice] returned by [HID.requestDevice] must be opened with this method before it is available to transfer data.",
      "opened": "\n\nThe **`opened`** read-only property of the [HIDDevice] interface returns true if the connection to the [HIDDevice] is open and ready to transfer data.",
      "productid": "\n\nThe **`productId`** read-only property of the [HIDDevice] interface returns the product ID of the connected HID device.",
      "productname": "\n\nThe **`productName`** read-only property of the [HIDDevice] interface returns the product name of the connected HID device.",
      "receivefeaturereport": "\n\nThe **`receiveFeatureReport()`** method of the [HIDDevice] interface receives a feature report from the HID device. Feature reports are a way for HID devices and applications to exchange non-standardized HID data.\n\nThe `reportId` for each of the report formats that this device supports can be retrieved from [HIDDevice.collections].",
      "sendfeaturereport": "\n\nThe **`sendFeatureReport()`** method of the [HIDDevice] interface sends a feature report to the HID device. Feature reports are a way for HID devices and applications to exchange non-standardized HID data.\n\nThe `reportId` for each of the report formats that this device supports can be retrieved from [HIDDevice.collections].",
      "sendreport": "\n\nThe **`sendReport()`** method of the [HIDDevice] interface sends an output report to the HID device.\n\nThe `reportId` for each of the report formats that this device supports can be retrieved from [HIDDevice.collections].",
      "vendorid": "\n\nThe **`vendorId`** read-only property of the [HIDDevice] interface returns the vendor ID of the connected HID device. This identifies the vendor of the device."
    }
  },
  "hidinputreportevent": {
    "docs": "\n\nThe **`HIDInputReportEvent`** interface of the [WebHID API] is passed to [HIDDevice.inputreport_event] when an input report is received from any associated HID device.\n\n",
    "properties": {
      "data": "\n\nThe **`data`** property of the [HIDInputReportEvent] interface returns a `DataView` containing the data from the input report, excluding the `reportId` if the HID interface uses report IDs.",
      "device": "\n\nThe **`device`** property of the [HIDInputReportEvent] interface returns the [HIDDevice] instance that represents the HID interface that sent the input report.",
      "reportid": "\n\nThe **`reportId`** property of the [HIDInputReportEvent] interface returns the one-byte identification prefix for this report, or 0 if the HID interface does not use report IDs."
    }
  },
  "highlight": {
    "docs": "\n\nThe **`Highlight`** interface of the [CSS Custom Highlight API](/en-US/docs/Web/API/CSS_Custom_Highlight_API) is used to represent a collection of [Range] instances to be styled using the API.\n\nTo style arbitrary ranges in a page, instantiate a new `Highlight` object, add one or more `Range` objects to it, and register it using the [HighlightRegistry].\n\nA `Highlight` instance is a [`Set`-like object](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Set#set-like_browser_apis) that can hold one or more `Range` objects.\n\n",
    "properties": {
      "add": "\n\nThe **`add()`** method of the [Highlight] interface adds a new [Range] object to a highlight, to be styled using the [css_custom_highlight_api].\n\n`Highlight` is a `Set`-like object, so this is similar to using `Set.add()`.",
      "clear": "\n\nThe **`clear()`** method of the [Highlight] interface removes all the [Range] objects from a `Highlight` object.\n\n`Highlight` is a `Set`-like object, so this is similar to using `Set.clear()`.",
      "delete": "\n\nThe **`delete()`** method of the [Highlight] interface removes a specified [Range] object from a `Highlight` object.\n\n`Highlight` is a `Set`-like object, so this is similar to using `Set.delete()`.",
      "entries": "\n\nThe **`entries()`** method of the [Highlight] interface returns a new [Iterator](/en-US/docs/Web/JavaScript/Guide/Iterators_and_generators) object that contains an array of `[range, range]` for each [Range] object in the `Highlight` object, in insertion order.\n\n`Highlight` is a `Set`-like object, so this is similar to using `Set.entries()`.",
      "foreach": "\n\nThe **`forEach()`** method of the [Highlight] interface executes a provided function once for each [Range] object in the `Highlight` object, in insertion order.\n\n`Highlight` is a `Set`-like object, so this is similar to using `Set.forEach()`.",
      "has": "\n\nThe **`has()`** method of the [Highlight] interface returns a boolean indicating whether a [Range] object exists in a `Highlight` object or not.\n\n`Highlight` is a `Set`-like object, so this is similar to using `Set.has()`.",
      "keys": "\n\nThe **`keys()`** method of the [Highlight] interface is an alias for the [Highlight.values] method.\n\n`Highlight` is a `Set`-like object, so this is similar to using `Set.keys()`.",
      "priority": "\n\nIt is possible to create [Range] objects that overlap in a document.\n\nWhen overlapping ranges are used by multiple different [Highlight] objects, and when those highlights are styled using  pseudo-elements, this may lead to conflicting styles.\n\nIf two text ranges overlap and are both highlighted using the [css_custom_highlight_api], and if they're both styled using the `color` CSS property, the browser needs to decide which color should be used for styling the text in the overlapping part.\n\nBy default, all highlights have the same priority and the browser chooses the most recently registered highlight to style the overlapping parts.\n\nThe `priority` property of the [Highlight] interface is a `Number` used to change this default behavior and determine which highlight's styles should be used to resolve style conflicts in overlapping parts.\n\nNote that all the styles of a highlight are applied and the browser only needs to resolve conflicts when the same CSS properties are used by multiple overlapping highlights. The highlight style conflict resolution also does not depend on the order in which the  pseudo-elements rules appear in the source, or whether or not CSS properties are marked as `!important`.",
      "size": "\n\nThe **`size`** property returns the number of [Range] objects in a\n[Highlight] object.",
      "type": "\n\nThe `type` property of the [Highlight] interface is an enumerated `String` used to specify the meaning of the highlight. This allows assistive technologies, such as screen readers, to include this meaning when exposing the highlight to users.\n\nBy default, a highlight object will have its type set to `highlight`, but you can change it to `spelling-error` or `grammar-error`.",
      "values": "\n\nThe **`values()`** method of the [Highlight] interface returns a new [Iterator](/en-US/docs/Web/JavaScript/Guide/Iterators_and_generators) object that contains the values for each `Range` object in the `Highlight` object in insertion order.\n\n> **Note:** The **`keys()`** method is an alias for this method. It behaves exactly the same and returns **values** of `Highlight` elements.\n\n`Highlight` is a `Set`-like object, so this is similar to using `Set.values()`."
    }
  },
  "highlightregistry": {
    "docs": "\n\nThe **`HighlightRegistry`** interface of the [CSS Custom Highlight API](/en-US/docs/Web/API/CSS_Custom_Highlight_API) is used to register [Highlight] objects to be styled using the API.\nIt is accessed via [CSS.highlights_static].\n\nA `HighlightRegistry` instance is a [`Map`-like object](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map#map-like_browser_apis), in which each key is the name string for a custom highlight, and the corresponding value is the associated [Highlight] object.\n\n",
    "properties": {
      "clear": "\n\nThe **`clear()`** method of the [HighlightRegistry] interface removes all the [Highlight] objects registered in the `HighlightRegistry`.\n\n`HighlightRegistry` is a `Map`-like object, so this is similar to using `Map.clear()`.",
      "delete": "\n\nThe **`delete()`** method of the [HighlightRegistry] interface removes a the named [Highlight] object from the `HighlightRegistry`.\n\n`HighlightRegistry` is a `Map`-like object, so this is similar to using `Map.delete()`.",
      "entries": "\n\nThe **`entries()`** method of the [HighlightRegistry] interface returns a new [Iterator](/en-US/docs/Web/JavaScript/Guide/Iterators_and_generators) object that contains the `[name, highlight]` pairs for each element in the `HighlightRegistry` object, in insertion order.\n\n`HighlightRegistry` is a `Map`-like object, so this is similar to using `Map.entries()`.",
      "foreach": "\n\nThe **`forEach()`** method of the [HighlightRegistry] interface executes a provided function once for each [Highlight] object in the registry, in insertion order.\n\n`HighlightRegistry` is a `Map`-like object, so this is similar to using `Map.forEach()`.",
      "get": "\n\nThe **`get()`** method of the [HighlightRegistry] interface returns the named [Highlight] object from the registry.\n\n`HighlightRegistry` is a `Map`-like object, so this is similar to using `Map.get()`.",
      "has": "\n\nThe **`has()`** method of the [HighlightRegistry] interface returns a boolean indicating whether or not a [Highlight] object with the specified name exists in the registry.\n\n`HighlightRegistry` is a `Map`-like object, so this is similar to using `Map.has()`.",
      "keys": "\n\nThe **`keys()`** method of the [HighlightRegistry] interface returns a new [Iterator](/en-US/docs/Web/JavaScript/Guide/Iterators_and_generators) object that contains the keys for each `Highlight` object in the `HighlightRegistry` object in insertion order.\n\n`HighlightRegistry` is a `Map`-like object, so this is similar to using `Map.keys()`.",
      "set": "\n\nThe **`set()`** method of the [HighlightRegistry] interface adds or updates a [Highlight] object in the registry with the specified name.\n\n`HighlightRegistry` is a `Map`-like object, so this is similar to using `Map.set()`.",
      "size": "\n\nThe **`size`** property returns the number of [Highlight] objects in the [HighlightRegistry].",
      "values": "\n\nThe **`values()`** method of the [HighlightRegistry] interface returns a new [Iterator](/en-US/docs/Web/JavaScript/Guide/Iterators_and_generators) object that contains the values for each `Highlight` object in the `HighlightRegistry` object in insertion order.\n\n`HighlightRegistry` is a `Map`-like object, so this is similar to using `Map.values()`."
    }
  },
  "history": {
    "docs": "\n\nThe **`History`** interface allows manipulation of the browser _session history_, that is the pages visited in the tab or frame that the current page is loaded in.\n\nThere is only one instance of `history` (It is a _singleton_.) accessible via the global object [Window.history].\n\n> **Note:** This interface is only available on the main thread ([Window]). It cannot be accessed in [Worker] or [Worklet] contexts.",
    "properties": {
      "back": "\n\nThe **`History.back()`** method causes\nthe browser to move back one page in the session history.\n\nIt has the same\neffect as calling . If there is no previous\npage, this method call does nothing.\n\nThis method is . Add a listener for the\n[Window/popstate_event] event in order to determine when the navigation has completed.",
      "forward": "\n\nThe **`History.forward()`** method causes the browser to move\nforward one page in the session history. It has the same effect as calling\n[History.go].\n\nThis method is . Add a listener for the [Window/popstate_event] event in order to determine when the navigation has completed.",
      "go": "\n\nThe **`History.go()`** method loads a specific page from the\nsession history. You can use it to move forwards and backwards through the history\ndepending on the value of a parameter.\n\nThis method is . Add a listener for the\n[Window/popstate_event] event in order to determine when the navigation has completed.",
      "length": "\n\nThe **`History.length`** read-only\nproperty returns an integer representing the number of elements in the session\nhistory, including the currently loaded page.\n\nFor example, for a page loaded in a new tab this property returns `1`.",
      "pushstate": "\n\nIn an [HTML](/en-US/docs/Web/HTML) document, the\n**`history.pushState()`** method adds an entry to the browser's\nsession history stack.",
      "replacestate": "\n\nThe **`History.replaceState()`** method modifies the current\nhistory entry, replacing it with the state object and\nURL passed in the method parameters. This method is particularly useful\nwhen you want to update the state object or URL of the current history entry in response\nto some user action.",
      "scrollrestoration": "\n\nThe **`scrollRestoration`** property of [History]\ninterface allows web applications to explicitly set default scroll restoration behavior\non history navigation.",
      "state": "\n\nThe **`History.state`** read-only property\nreturns a value representing the state at the top of the history stack. This is\na way to look at the state without having to wait for a [Window/popstate_event] event."
    }
  },
  "hkdfparams": {
    "docs": "\n\nThe **`HkdfParams`** dictionary of the [Web Crypto API](/en-US/docs/Web/API/Web_Crypto_API) represents the object that should be passed as the `algorithm` parameter into [SubtleCrypto.deriveKey], when using the [HKDF](/en-US/docs/Web/API/SubtleCrypto/deriveKey#hkdf) algorithm."
  },
  "hmacimportparams": {
    "docs": "\n\nThe **`HmacImportParams`** dictionary of the [Web Crypto API](/en-US/docs/Web/API/Web_Crypto_API) represents the object that should be passed as the `algorithm` parameter into [SubtleCrypto.importKey] or [SubtleCrypto.unwrapKey], when generating a key for the [HMAC](/en-US/docs/Web/API/SubtleCrypto/sign#hmac) algorithm."
  },
  "hmackeygenparams": {
    "docs": "\n\nThe **`HmacKeyGenParams`** dictionary of the [Web Crypto API](/en-US/docs/Web/API/Web_Crypto_API) represents the object that should be passed as the `algorithm` parameter into [SubtleCrypto.generateKey], when generating a key for the [HMAC](/en-US/docs/Web/API/SubtleCrypto/sign#hmac) algorithm."
  },
  "hmdvrdevice": {
    "docs": "\n\nThe **`HMDVRDevice`** interface of the [WebVR API](/en-US/docs/Web/API/WebVR_API) represents a head mounted display, providing access to information about each eye, and allowing us to modify the current field of view.",
    "properties": {
      "geteyeparameters": "\n\nThe **`getEyeParameters()`** method of the [HMDVRDevice] interface returns current parameters for the eye specified as its argument (\"left\" or \"right\") — stored in a [VREyeParameters] object.\n\nThis includes field of view information, and more.",
      "setfieldofview": "\n\nThe **`setFieldOfView()`** method of the [HMDVRDevice] interface can be used to set the field of view for one eye, or both eyes simultaneously."
    }
  },
  "htmlallcollection": {
    "docs": "\n\nThe **`HTMLAllCollection`** interface represents a collection of _all_ of the document's elements, accessible by index (like an array) and by the element's [`id`](/en-US/docs/Web/HTML/Global_attributes/id). It is returned by the [document.all] property.\n\n`HTMLAllCollection` has a very similar shape to [HTMLCollection], but there are many subtle behavior differences — for example, `HTMLAllCollection` can be called as a function, and its `item()` method can be called with a string representing an element's `id` or `name` attribute.",
    "properties": {
      "item": "\n\nThe **`item()`** method of the [HTMLAllCollection] interface returns the element located at the specified offset into the collection, or the element with the specified value for its `id` or `name` attribute.",
      "length": "\n\nThe **`HTMLAllCollection.length`** property returns the number of items in this [HTMLAllCollection].",
      "nameditem": "\n\nThe **`namedItem()`** method of the [HTMLAllCollection] interface returns the first [Element] in the collection whose `id` or `name` attribute matches the specified name, or `null` if no element matches."
    }
  },
  "htmlanchorelement": {
    "docs": "\n\nThe **`HTMLAnchorElement`** interface represents hyperlink elements and provides special properties and methods (beyond those of the regular [HTMLElement] object interface that they inherit from) for manipulating the layout and presentation of such elements. This interface corresponds to [`<a>`](/en-US/docs/Web/HTML/Element/a) element; not to be confused with [`<link>`](/en-US/docs/Web/HTML/Element/link), which is represented by [`HTMLLinkElement`](/en-US/docs/Web/API/HTMLLinkElement).\n\n",
    "properties": {
      "download": "\n\nThe **`HTMLAnchorElement.download`** property is a\nstring indicating that the linked resource is intended to be\ndownloaded rather than displayed in the browser. The value, if any, specifies the\ndefault file name for use in labeling the resource in a local file system. If the name\nis not a valid file name in the underlying OS, the browser will adjust it.\n\n> **Note:** This value might not be used for download. This value cannot\n> be used to determine whether the download will occur.",
      "hash": "\n\nThe\n**`HTMLAnchorElement.hash`** property returns a\nstring containing a `'#'` followed by the fragment\nidentifier of the URL.\n\nThe fragment is [URL encoded](https://en.wikipedia.org/wiki/URL_encoding). If the URL does not\nhave a fragment identifier, this property contains an empty string, `\"\"`.",
      "host": "\n\nThe **`HTMLAnchorElement.host`** property is a\nstring containing the host, that is the _hostname_, and then,\nif the _port_ of the URL is nonempty, a `':'`, and the _port_\nof the URL.",
      "hostname": "\n\nThe **`HTMLAnchorElement.hostname`** property is a\nstring containing the domain of the URL.",
      "href": "\n\nThe **`HTMLAnchorElement.href`** property is a\n that returns a string containing the whole URL, and allows\nthe href to be updated.",
      "hreflang": "\n\nThe **`hreflang`** property of the [HTMLAnchorElement] interface is a string that is the language of the linked resource.\n\nIt reflects the `hreflang` attribute of the `a` element and is the empty string (`\"\"`) if there is no `hreflang` element.\n\nWeb browsers and search engines may use this information to understand the language of the linked content better, but they are not required to follow it. The value provided for the `hreflang` attribute adheres to the format defined in `5646, \"Tags for Identifying Languages (also known as BCP 47)\"`. If not, it is ignored.\n\nWeb browsers do not rely solely on the `hreflang` attribute after fetching the linked resource. Instead, they use language information directly associated with the resource (e.g., through HTTP headers) to determine its language.",
      "origin": "\n\nThe\n**`HTMLAnchorElement.origin`** read-only property is a\nstring containing the Unicode serialization of the origin of the\nrepresented URL.\n\nThat is:\n\n- for URL using the `http` or `https`, the scheme followed by\n  `'://'`, followed by the domain, followed by `':'`, followed by\n  the port (the default port, `80` and `443` respectively, if\n  explicitly specified);\n- for URL using `file:` scheme, the value is browser dependent;\n- for URL using the `blob:` scheme, the origin of the URL following\n  `blob:`. E.g `\"blob:https://mozilla.org\"` will have\n  `\"https://mozilla.org\".`",
      "password": "\n\nThe **`HTMLAnchorElement.password`** property is a\nstring containing the password specified before the domain name.\n\nIf it is set without first setting the\n[`username`](/en-US/docs/Web/API/HTMLAnchorElement/username)\nproperty, it silently fails.",
      "pathname": "\n\nThe **`HTMLAnchorElement.pathname`** property is a\nstring containing an initial `'/'` followed by the path of\nthe URL not including the query string or fragment (or the empty string if there is no\npath).",
      "port": "\n\nThe **`HTMLAnchorElement.port`** property is a\nstring containing the port number of the URL. If the URL does not\ncontain an explicit port number, it will be set to `''`.",
      "protocol": "\n\nThe\n**`HTMLAnchorElement.protocol`**\nproperty is a string representing the protocol scheme of the URL,\nincluding the final `':'`.",
      "referrerpolicy": "\n\nThe\n**`HTMLAnchorElement.referrerPolicy`**\nproperty reflect the HTML [`referrerpolicy`](/en-US/docs/Web/HTML/Element/a#referrerpolicy) attribute of the\n`a` element defining which referrer is sent when fetching the resource.",
      "rel": "\n\nThe **`HTMLAnchorElement.rel`** property reflects the [`rel`](/en-US/docs/Web/HTML/Attributes/rel) attribute. It is a string containing a space-separated list of link types indicating the relationship between the resource represented by the `a` element and the current document.",
      "rellist": "\n\nThe **`HTMLAnchorElement.relList`** read-only property reflects the [`rel`](/en-US/docs/Web/HTML/Attributes/rel) attribute. It is a live [DOMTokenList] containing the set of link types indicating the relationship between the resource represented by the `a` element and the current document.\n\nThe property itself is read-only, meaning you can't substitute the\n[DOMTokenList] with another one, but its contents can still be changed.",
      "search": "\n\nThe **`HTMLAnchorElement.search`** property is a search\nstring, also called a _query string_, that is a string containing\na `'?'` followed by the parameters of the URL.\n\nModern browsers provide\n[`URLSearchParams`](/en-US/docs/Web/API/URLSearchParams/get#examples)\nand\n[`URL.searchParams`](/en-US/docs/Web/API/URL/searchParams#examples)\nto make it easy to parse out the parameters from the querystring.",
      "tostring": "\n\nThe **`HTMLAnchorElement.toString()`** \nmethod returns a string containing the whole URL. It is a read-only\nversion of [HTMLAnchorElement.href].",
      "username": "\n\nThe **`HTMLAnchorElement.username`** property is a\nstring containing the username specified before the domain name."
    }
  },
  "htmlareaelement": {
    "docs": "\n\nThe **`HTMLAreaElement`** interface provides special properties and methods (beyond those of the regular object [HTMLElement] interface it also has available to it by inheritance) for manipulating the layout and presentation of `area` elements.\n\n",
    "properties": {
      "hash": "\n\nThe\n**`HTMLAreaElement.hash`** property returns a\nstring containing a `'#'` followed by the fragment\nidentifier of the URL.\n\nThe fragment is not [URL decoded](https://en.wikipedia.org/wiki/URL_encoding). If the URL does not\nhave a fragment identifier, this property contains an empty string, `\"\"`.",
      "host": "\n\nThe **`HTMLAreaElement.host`** property is a\nstring containing the host, that is the _hostname_, and then,\nif the _port_ of the URL is nonempty, a `':'`, and the _port_\nof the URL.",
      "hostname": "\n\nThe **`HTMLAreaElement.hostname`** property is a string containing the domain of the URL.",
      "href": "\n\nThe **`HTMLAreaElement.href`** property is a\n that returns a string containing the whole URL, and allows\nthe href to be updated.",
      "origin": "\n\nThe\n**`HTMLAreaElement.origin`** read-only property is a\nstring containing the Unicode serialization of the origin of the\nrepresented URL.\n\nThat is:\n\n- for URL using the `http` or `https`, the scheme followed by\n  `'://'`, followed by the domain, followed by `':'`, followed by\n  the port (the default port, `80` and `443` respectively, if\n  explicitly specified);\n- for URL using `file:` scheme, the value is browser dependent;\n- for URL using the `blob:` scheme, the origin of the URL following\n  `blob:`. E.g `\"blob:https://mozilla.org\"` will have\n  `\"https://mozilla.org\".`",
      "password": "\n\nThe **`HTMLAreaElement.password`** property is a\nstring containing the password specified before the domain name.\n\nIf it is set without first setting the\n[`username`](/en-US/docs/Web/API/HTMLAreaElement/username)\nproperty, it silently fails.",
      "pathname": "\n\nThe **`HTMLAreaElement.pathname`** property is a\nstring containing an initial `'/'` followed by the path of\nthe URL not including the query string or fragment (or the empty string if there is no\npath).",
      "port": "\n\nThe **`HTMLAreaElement.port`** property is a\nstring containing the port number of the URL. If the URL does not\ncontain an explicit port number, it will be set to `''`.",
      "protocol": "\n\nThe\n**`HTMLAreaElement.protocol`**\nproperty is a string representing the protocol scheme of the URL,\nincluding the final `':'`.",
      "referrerpolicy": "\n\nThe\n**`HTMLAreaElement.referrerPolicy`**\nproperty reflect the HTML [`referrerpolicy`](/en-US/docs/Web/HTML/Element/area#referrerpolicy) attribute of the\n`area` element defining which referrer is sent when fetching the\nresource.",
      "rel": "\n\nThe **`HTMLAreaElement.rel`** property reflects the [`rel`](/en-US/docs/Web/HTML/Attributes/rel) attribute. It is a string containing a space-separated list of link types indicating the relationship between the resource represented by the `area` element and the current document.",
      "rellist": "\n\nThe **`HTMLAreaElement.relList`** read-only property reflects the [`rel`](/en-US/docs/Web/HTML/Attributes/rel) attribute. It is a live [DOMTokenList] containing the set of link types indicating the relationship between the resource represented by the `area` element and the current document.\n\nThe property itself is read-only, meaning you can't substitute the\n[DOMTokenList] by another one, but the content of the returned list can be\nchanged.",
      "search": "\n\nThe **`HTMLAreaElement.search`** property is a search\nstring, also called a _query string_, that is a string containing\na `'?'` followed by the parameters of the URL.\n\nModern browsers provide\n[`URLSearchParams`](/en-US/docs/Web/API/URLSearchParams/get#examples)\nand\n[`URL.searchParams`](/en-US/docs/Web/API/URL/searchParams#examples)\nto make it easy to parse out the parameters from the querystring.",
      "tostring": "\n\nThe **`HTMLAreaElement.toString()`** \nmethod returns a string containing the whole URL. It is a read-only\nversion of [HTMLAreaElement.href].",
      "username": "\n\nThe **`HTMLAreaElement.username`** property is a\nstring containing the username specified before the domain name."
    }
  },
  "htmlaudioelement": {
    "docs": "\n\nThe **`HTMLAudioElement`** interface provides access to the properties of `audio` elements, as well as methods to manipulate them.\n\nThis element is based on, and inherits properties and methods from, the [HTMLMediaElement] interface.\n\n",
    "properties": {
      "audio": "\n\nThe **`Audio()`** constructor creates\nand returns a new [HTMLAudioElement] which can be either attached to\na document for the user to interact with and/or listen to, or can be used\noffscreen to manage and play audio."
    }
  },
  "htmlbaseelement": {
    "docs": "\n\nThe **`HTMLBaseElement`** interface contains the base URI for a document. This object inherits all of the properties and methods as described in the [HTMLElement] interface.\n\n"
  },
  "htmlbodyelement": {
    "docs": "\n\nThe **`HTMLBodyElement`** interface provides special properties (beyond those inherited from the regular [HTMLElement] interface) for manipulating `body` elements.\n\n"
  },
  "htmlbrelement": {
    "docs": "\n\nThe **`HTMLBRElement`** interface represents an HTML line break element (`br`). It inherits from [HTMLElement].\n\n"
  },
  "htmlbuttonelement": {
    "docs": "\n\nThe **`HTMLButtonElement`** interface provides properties and methods (beyond the regular [HTMLElement] interface it also has available to it by inheritance) for manipulating `button` elements.\n\n",
    "properties": {
      "disabled": "\n\nThe **`HTMLButtonElement.disabled`** property indicates whether the control is disabled, meaning that it does not accept any clicks.",
      "labels": "\n\nThe **`HTMLButtonElement.labels`** read-only property returns a\n[NodeList] of the `label` elements associated with the\n`button` element.",
      "popovertargetaction": "\n\nThe **`popoverTargetAction`** property of the [HTMLButtonElement] interface gets and sets the action to be performed (`\"hide\"`, `\"show\"`, or `\"toggle\"`) on a popover element being controlled by a button.\n\nIt reflects the value of the [`popovertargetaction`](/en-US/docs/Web/HTML/Element/button#popovertargetaction) HTML attribute.",
      "popovertargetelement": "\n\nThe **`popoverTargetElement`** property of the [HTMLButtonElement] interface gets and sets the popover element to control via a button.\n\nIt is the JavaScript equivalent of the [`popovertarget`](/en-US/docs/Web/HTML/Element/button#popovertarget) HTML attribute."
    }
  },
  "htmlcanvaselement": {
    "docs": "\n\nThe **`HTMLCanvasElement`** interface provides properties and methods for manipulating the layout and presentation of `canvas` elements. The `HTMLCanvasElement` interface also inherits the properties and methods of the [HTMLElement] interface.\n\n",
    "properties": {
      "capturestream": "\n\nThe **`captureStream()`** method of the [HTMLCanvasElement] interface returns a [MediaStream]\nwhich includes a [CanvasCaptureMediaStreamTrack] containing a real-time video capture of the canvas's contents.",
      "contextlost_event": "\n\nThe **`contextlost`** event of the [Canvas API](/en-US/docs/Web/API/Canvas_API) is fired if the user agent detects that the backing storage associated with a [`CanvasRenderingContext2D`](/en-US/docs/Web/API/CanvasRenderingContext2D) context is lost.\nContexts can be lost for several reasons like driver crashes or the application runs out of memory, etc.\n\nBy default the user agent will attempt to restore the context and then fire the [`contextrestored` event](/en-US/docs/Web/API/HTMLCanvasElement/contextrestored_event).\nUser code can prevent the context from being restored by calling [`Event.preventDefault()`](/en-US/docs/Web/API/Event/preventDefault) during event handling.",
      "contextrestored_event": "\n\nThe **`contextrestored`** event of the [Canvas API](/en-US/docs/Web/API/Canvas_API) is fired if the user agent restores the backing storage for a [`CanvasRenderingContext2D`](/en-US/docs/Web/API/CanvasRenderingContext2D).\n\nYou can redraw, re-retrieve resources, and reinitialize the state of your context after receiving this event.",
      "getcontext": "\n\nThe\n**`HTMLCanvasElement.getContext()`** method returns a drawing\ncontext on the canvas, or [`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null) if the context identifier is not\nsupported, or the canvas has already been set to a different context mode.\n\nLater calls to this method on the same canvas element, with the same\n`contextType` argument, will always return the same drawing context instance\nas was returned the first time the method was invoked. It is not possible to get a\ndifferent drawing context object on a given canvas element.",
      "height": "\n\nThe **`HTMLCanvasElement.height`** property is a\npositive `integer` reflecting the [`height`](/en-US/docs/Web/HTML/Element/canvas#height) HTML\nattribute of the `canvas` element interpreted in CSS pixels. When the\nattribute is not specified, or if it is set to an invalid value, like a negative, the\ndefault value of `150` is used.\n\nThis is one of the two properties, the other being\n[HTMLCanvasElement.width], that controls the size of the canvas.",
      "mozopaque": "\n\nThe non-standard **`HTMLCanvasElement.mozOpaque`** property is\na boolean value reflecting the [`moz-opaque`](/en-US/docs/Web/HTML/Element/canvas#moz-opaque) HTML\nattribute of the `canvas` element. It lets the canvas know whether or\nnot translucency will be a factor. If the canvas knows there's no translucency, painting\nperformance can be optimized.\n\n> **Note:** This has been standardized as setting the `alpha` option to\n> `false` when creating a drawing context with\n> [HTMLCanvasElement.getContext]. Use of `mozOpaque` should be\n> avoided. Firefox will stop supporting it in the future.",
      "toblob": "\n\nThe **`HTMLCanvasElement.toBlob()`** method creates a [Blob] object representing the image contained in the canvas.\nThis file may be cached on the disk or stored in memory at the discretion of the user agent.\n\nThe desired file format and image quality may be specified.\nIf the file format is not specified, or if the given format is not supported, then the data will be exported as `image/png`.\nBrowsers are required to support `image/png`; many will support additional formats including `image/jpeg` and `image/webp`.\n\nThe created image will have a resolution of 96dpi for file formats that support encoding resolution metadata.",
      "todataurl": "\n\nThe **`HTMLCanvasElement.toDataURL()`** method returns a [data URL](/en-US/docs/Web/HTTP/Basics_of_HTTP/Data_URLs) containing a representation of the image in the format specified by the `type` parameter.\n\nThe desired file format and image quality may be specified.\nIf the file format is not specified, or if the given format is not supported, then the data will be exported as `image/png`.\nIn other words, if the returned value starts with `data:image/png` for any other requested `type`, then that format is not supported.\n\nBrowsers are required to support `image/png`; many will support additional formats including `image/jpeg` and `image/webp`.\n\nThe created image data will have a resolution of 96dpi for file formats that support encoding resolution metadata.",
      "transfercontroltooffscreen": "\n\nThe **`HTMLCanvasElement.transferControlToOffscreen()`** method transfers control to an [OffscreenCanvas] object, either on the main thread or on a worker.",
      "webglcontextcreationerror_event": "\n\nThe **`webglcontextcreationerror`** event of the [WebGL API](/en-US/docs/Web/API/WebGL_API) is fired if the user agent is unable to create a [WebGLRenderingContext] context.\n\nThis event has a [WebGLContextEvent.statusMessage] property, which can contain a platform dependent string with more information about the failure.\n\nThis event does not bubble.",
      "webglcontextlost_event": "\n\nThe **`webglcontextlost`** event of the [WebGL API](/en-US/docs/Web/API/WebGL_API) is fired if the user agent detects that the drawing buffer associated with a [WebGLRenderingContext] object has been lost.\n\nThis event does not bubble.",
      "webglcontextrestored_event": "\n\nThe **`webglcontextrestored`** event of the [WebGL API](/en-US/docs/Web/API/WebGL_API) is fired if the user agent restores the drawing buffer for a [WebGLRenderingContext] object.\n\nOnce the context is restored, WebGL resources such as textures and buffers that were created before the context was lost are no longer valid. You need to reinitialize the state of your WebGL application and recreate resources.\n\nThis event does not bubble.",
      "width": "\n\nThe **`HTMLCanvasElement.width`** property is a\npositive `integer` reflecting the [`width`](/en-US/docs/Web/HTML/Element/canvas#width) HTML\nattribute of the `canvas` element interpreted in CSS pixels. When the\nattribute is not specified, or if it is set to an invalid value, like a negative, the\ndefault value of `300` is used.\n\nThis is one of the two properties, the other being\n[HTMLCanvasElement.height], that controls the size of the canvas."
    }
  },
  "htmlcollection": {
    "docs": "\n\nThe **`HTMLCollection`** interface represents a generic collection (array-like object similar to `arguments`) of elements (in document order) and offers methods and properties for selecting from the list.\n\n> **Note:** This interface is called `HTMLCollection` for historical reasons (before the modern DOM, collections implementing this interface could only have HTML elements as their items).\n\nAn `HTMLCollection` in the HTML DOM is live; it is automatically updated when the underlying document is changed. For this reason it is a good idea to make a copy (e.g., using `Array.from`) to iterate over if adding, moving, or removing nodes.\n\n> **Note:** This interface was an [attempt to create an unmodifiable list](https://stackoverflow.com/questions/74630989/why-use-domstringlist-rather-than-an-array/74641156#74641156) and only continues to be supported to not break code that's already using it. Modern APIs use types that wrap around ECMAScript array types instead, so you can treat them like ECMAScript arrays, and at the same time impose additional semantics on their usage (such as making their items read-only).",
    "properties": {
      "item": "\n\nThe [HTMLCollection] method `item()`\nreturns the element located at the specified offset into the collection.\n\n> **Note:** Because the contents of an `HTMLCollection` are\n> live, changes to the underlying DOM can and will cause the position of individual\n> elements in the collection to change, so the index value will not necessarily remain\n> constant for a given element.",
      "length": "\n\nThe **`HTMLCollection.length`** property returns the number of\nitems in a [HTMLCollection].",
      "nameditem": "\n\nThe **`namedItem()`** method of the [HTMLCollection] interface returns\nthe first [Element] in the collection whose `id` or `name` attribute match the specified name, or `null` if no element matches.\n\nIn JavaScript, using the array bracket syntax with a `String`, like `collection[\"value\"]` is equivalent to `collection.namedItem(\"value\")`."
    }
  },
  "htmldataelement": {
    "docs": "\n\nThe **`HTMLDataElement`** interface provides special properties (beyond the regular [HTMLElement] interface it also has available to it by inheritance) for manipulating `data` elements.\n\n",
    "properties": {
      "value": "\n\nThe **`value`** property of the [HTMLDataElement]\ninterface returns a string reflecting the [`value`](/en-US/docs/Web/HTML/Element/data#value) HTML attribute."
    }
  },
  "htmldatalistelement": {
    "docs": "\n\nThe **`HTMLDataListElement`** interface provides special properties (beyond the [HTMLElement] object interface it also has available to it by inheritance) to manipulate `datalist` elements and their content.\n\n"
  },
  "htmldetailselement": {
    "docs": "\n\nThe **`HTMLDetailsElement`** interface provides special properties (beyond the regular [HTMLElement] interface it also has available to it by inheritance) for manipulating `details` elements.\n\n",
    "properties": {
      "open": "\n\nThe **`open`** property of the\n[HTMLDetailsElement] interface is a boolean value reflecting the\n[`open`](/en-US/docs/Web/HTML/Element/details#open) HTML attribute, indicating whether the `details`'s contents (not counting the `summary`) is to be shown to the user.",
      "toggle_event": "\n\nThe **`toggle`** event fires when the `open`/`closed` state of a `details` element is toggled.\n\nThis event is not cancelable and does not bubble.\n\n> **Note:** The `toggle` event is also available in a different form on [HTMLElement]; this version fires on [popover elements](/en-US/docs/Web/API/Popover_API) just after they are shown or hidden. See the `HTMLElement` [HTMLElement.toggle_event] page for more information."
    }
  },
  "htmldialogelement": {
    "docs": "\n\nThe **`HTMLDialogElement`** interface provides methods to manipulate `dialog` elements. It inherits properties and methods from the [HTMLElement] interface.\n\n",
    "properties": {
      "close": "\n\nThe **`close()`** method of the [HTMLDialogElement] interface closes the `dialog`.\nAn optional string may be passed as an argument, updating the `returnValue` of the dialog.",
      "close_event": "\n\nThe `close` event is fired on an `HTMLDialogElement` object when the `dialog` it represents has been closed.\n\nThis event is not cancelable and does not bubble.",
      "open": "\n\nThe **`open`** property of the\n[HTMLDialogElement] interface is a boolean value reflecting the\n[`open`](/en-US/docs/Web/HTML/Element/dialog#open) HTML attribute, indicating whether the `dialog` is\navailable for interaction.",
      "returnvalue": "\n\nThe **`returnValue`** property of the [HTMLDialogElement] interface gets or sets the return value for the `dialog`, usually to indicate which button the user pressed to close it.",
      "show": "\n\nThe **`show()`** method of the [HTMLDialogElement]\ninterface displays the dialog modelessly, i.e. still allowing interaction with content\noutside of the dialog.",
      "showmodal": "\n\nThe **`showModal()`** method of the\n[HTMLDialogElement] interface displays the dialog as a modal, over the top\nof any other dialogs that might be present. It displays in the , along with a\n pseudo-element. Interaction outside the dialog is blocked and\nthe content outside it is rendered inert."
    }
  },
  "htmldivelement": {
    "docs": "\n\nThe **`HTMLDivElement`** interface provides special properties (beyond the regular [HTMLElement] interface it also has available to it by inheritance) for manipulating `div` elements.\n\n"
  },
  "htmldlistelement": {
    "docs": "\n\nThe **`HTMLDListElement`** interface provides special properties (beyond those of the regular [HTMLElement] interface it also has available to it by inheritance) for manipulating definition list (`dl`) elements.\n\n"
  },
  "htmldocument": {
    "docs": "\n\nFor historical reasons, [Window] objects have a `window.HTMLDocument` property whose value is the [Document] interface. So you can think of `HTMLDocument` as an alias for [Document], and you can find documentation for `HTMLDocument` members under the documentation for the [Document] interface."
  },
  "htmlelement": {
    "docs": "\n\nThe **`HTMLElement`** interface represents any [HTML](/en-US/docs/Web/HTML) element. Some elements directly implement this interface, while others implement it via an interface that inherits it.\n\n",
    "properties": {
      "accesskey": "\n\nThe **`HTMLElement.accessKey`** property sets the keystroke which a user can press to jump to a given element.\n\n> **Note:** The `HTMLElement.accessKey` property is seldom used because of its multiple conflicts with already present key bindings in browsers. To work around this, browsers implement accesskey behavior if the keys are pressed with other \"qualifying\" keys (such as <kbd>Alt</kbd> + accesskey).",
      "accesskeylabel": "\n\nThe **`HTMLElement.accessKeyLabel`**\nread-only property returns a string containing the element's\nbrowser-assigned access key (if any); otherwise it returns an empty string.",
      "attachinternals": "\n\nThe **`HTMLElement.attachInternals()`** method returns an [ElementInternals] object.\nThis method allows a [custom element](/en-US/docs/Web/API/Web_components/Using_custom_elements) to participate in HTML forms. The `ElementInternals` interface provides utilities for working with these elements in the same way you would work with any standard HTML form element, and also exposes the [Accessibility Object Model](https://wicg.github.io/aom/explainer.html) to the element.",
      "autofocus": "\n\nThe **`autofocus`** property of the [HTMLElement] interface represents a boolean value reflecting the [`autofocus`](/en-US/docs/Web/HTML/Element/select#autofocus) HTML global attribute, which indicates whether the control should be focused when the page loads, or when dialog or popover become shown if specified in an element inside `dialog` elements or elements whose popover attribute is set.\n\nOnly one form-associated element inside a document, or a `dialog` element, or an element whose `popover` attribute is set, can have this attribute specified. If there are several, the first element with the attribute set inserted, usually the first such element on the page, get the initial focus.\n\n> **Note:** Setting this property doesn't set the focus to the associated element: it merely tells the browser to focus to it when _the element is inserted_ in the document. Setting it after the insertion, that is most of the time after the document load, has no visible effect.",
      "beforetoggle_event": "\n\nThe **`beforetoggle`** event of the [HTMLElement] interface fires on a [Popover_API] element (i.e. one that has a valid [`popover`](/en-US/docs/Web/HTML/Global_attributes/popover) attribute) just before it is shown or hidden.\n\n- If the popover is transitioning from hidden to showing, the `event.oldState` property will be set to `closed` and the `event.newState` property will be set to `open`.\n- If the popover is transitioning from showing to hidden, then `event.oldState` will be `open` and `event.newState` will be `closed`.",
      "blur": "\n\nThe **`HTMLElement.blur()`** method removes keyboard focus from the current element.",
      "cancel_event": "\n\nThe **`cancel`** event is fired by `input` and `dialog` elements. The event is fired when the user cancels the currently open dialog by closing it with the <kbd>Esc</kbd> key. It is also fired by the [file input](/en-US/docs/Web/HTML/Element/input/file) when the user cancels the file picker dialog via the <kbd>Esc</kbd> key or the cancel button and when the user re-selects the same files that were previously selected.\n\nThis event does not bubble.\n\nWhen a `<dialog>` is dismissed with the <kbd>Esc</kbd> key, both the `cancel` and [HTMLDialogElement/close_event] events are fired.",
      "change_event": "\n\nThe `change` event is fired for `input`, `select`, and `textarea` elements when the user modifies the element's value. Unlike the [Element/input_event] event, the `change` event is not necessarily fired for each alteration to an element's `value`.\n\nDepending on the kind of element being changed and the way the user interacts with the element, the `change` event fires at a different moment:\n\n- When a `` element is checked or unchecked (by clicking or using the keyboard);\n- When a `` element is checked (but not when unchecked);\n- When the user commits the change explicitly (e.g., by selecting a value from a `select`'s dropdown with a mouse click, by selecting a date from a date picker for ``, by selecting a file in the file picker for ``, etc.);\n- When the element loses focus after its value was changed: for elements where the user's interaction is typing rather than selection, such as a `textarea` or the ``text``, ``search``, ``url``, ``tel``, ``email``, or ``password`` types of the `input` element.\n\nThe HTML specification lists [the `<input>` types that should fire the `change` event](https://html.spec.whatwg.org/multipage/forms.html#concept-input-apply).",
      "click": "\n\nThe **`HTMLElement.click()`** method simulates a mouse click on\nan element.\n\nWhen `click()` is used with supported elements (such as an\n`input`), it fires the element's click event. This event then bubbles\nup to elements higher in the document tree (or event chain) and fires their click\nevents.",
      "contenteditable": "\n\nThe **`contentEditable`** property of\nthe [HTMLElement] interface specifies whether or not the element is\neditable.\n\nThis enumerated attribute can have the following values:\n\n- '`true`' indicates that the element is `contenteditable`.\n- '`false`' indicates that the element cannot be edited.\n- '`plaintext-only`' indicates that the element's raw text is editable, but rich text formatting is disabled.\n- '`inherit`' indicates that the element inherits its parent's editable\n  status.\n\nYou can use the [HTMLElement.isContentEditable] property to test the\ncomputed boolean value of this property.",
      "copy_event": "\n\nThe **`copy`** event fires when the user initiates a copy action through the browser's user interface.",
      "cut_event": "\n\nThe **`cut`** event fires when the user initiates a cut action through the browser's user interface.",
      "dataset": "\n\nThe **`dataset`** read-only property\nof the [HTMLElement] interface provides read/write access to [custom data attributes](/en-US/docs/Web/HTML/Global_attributes/data-*)\n(`data-*`) on elements. It exposes a map of strings\n([DOMStringMap]) with an entry for each `data-*` attribute.\n\n> **Note:** The `dataset` property itself can be read, but not directly written.\n> Instead, all writes must be to the individual properties within the\n> `dataset`, which in turn represent the data attributes.\n\nAn HTML `data-*` attribute and its corresponding DOM\n`dataset.property` modify their shared name according to where\nthey are read or written:\n\n- In HTML\n  - : The attribute name begins with `data-`. It can contain only letters,\n    numbers, dashes (`-`), periods (`.`), colons (`:`),\n    and underscores (`_`). Any  capital letters (`A` to\n    `Z`) are converted to lowercase.\n- In JavaScript\n  - : The property name of a custom data attribute is the same as the HTML attribute\n    without the `data-` prefix, and removes single dashes (`-`) for\n    when to capitalize the property's \"\" name.\n\nIn addition to the information below, you'll find a how-to guide for using HTML data\nattributes in our article [_Using data attributes_](/en-US/docs/Learn/HTML/Howto/Use_data_attributes).\n\n### Name conversion\n\n- `dash-style` to `camelCase` conversion\n\n  - : A custom data attribute name is transformed to a key for the [DOMStringMap] entry by the following:\n\n    1. Lowercase all ASCII capital letters (`A` to\n       `Z`);\n    2. Remove the prefix `data-` (including the dash);\n    3. For any dash (`U+002D`) followed by an ASCII lowercase letter\n       `a` to `z`, remove the dash and uppercase the letter;\n    4. Other characters (including other dashes) are left unchanged.\n\n- `camelCase` to `dash-style` conversion\n\n  - : The opposite transformation, which maps a key to an attribute name, uses the\n    following:\n\n    1. **Restriction:** Before transformation, a dash _must not_ be\n       immediately followed by an ASCII lowercase letter `a` to\n       `z`;\n    2. Add the `data-` prefix;\n    3. Add a dash before any ASCII uppercase letter `A` to `Z`,\n       then lowercase the letter;\n    4. Other characters are left unchanged.\n\nFor example, a `data-abc-def` attribute corresponds to\n`dataset.abcDef`.\n\n### Accessing values\n\n- Attributes can be set and read by the camelCase name/key as an object property of\n  the dataset: `element.dataset.keyname`.\n- Attributes can also be set and read using bracket syntax:\n  `element.dataset['keyname']`.\n- The [`in` operator](/en-US/docs/Web/JavaScript/Reference/Operators/in) can check if a given attribute exists:\n  `'keyname' in element.dataset`.\n\n### Setting values\n\n- When the attribute is set, its value is always converted to a string.\n  For example: `element.dataset.example = null` is\n  converted into `data-example=\"null\"`.\n\n- To remove an attribute, you can use the [`delete` operator](/en-US/docs/Web/JavaScript/Reference/Operators/delete): `delete element.dataset.keyname`.",
      "dir": "\n\nThe **`HTMLElement.dir`** property gets or sets the text\nwriting directionality of the content of the current element.\n\nThe text writing directionality of an element is which direction that text goes (for\nsupport of different language systems). Arabic languages and Hebrew are typical\nlanguages using the RTL directionality.\n\nAn image can have its `dir` property set to \"`rtl`\" in which case\nthe HTML attributes `title` and `alt` will be formatted and\ndefined as \"`rtl`\".\n\nWhen a table has its `dir` set to \"`rtl`\", the column order is\narranged from right to left.\n\nWhen an element has its dir set to \"`auto`\", the direction of the element is\ndetermined based on its first strong directionality character, or default to the\ndirectionality of its parent element.\n\n> **Note:** Browsers might allow users to change the directionality of `input`\n> and `textarea`s in order to assist with authoring content. Chrome\n> and Safari provide a directionality option in the contextual menu of input fields\n> while pre-Chromium Edge uses the key combinations <kbd>Ctrl</kbd> + <kbd>Left Shift</kbd> and <kbd>Ctrl</kbd> + <kbd>Right Shift</kbd>. Firefox uses <kbd>Ctrl</kbd>/<kbd>Cmd</kbd> + <kbd>Shift</kbd> + <kbd>X</kbd> but does NOT update\n> the **`dir`** attribute value.",
      "drag_event": "\n\nThe `drag` event is fired every few hundred milliseconds as an element or text selection is being dragged by the user.\n\nThis event is cancelable and may bubble up to the [Document] and [Window] objects.",
      "dragend_event": "\n\nThe `dragend` event is fired when a drag operation ends (by releasing a mouse button or hitting the escape key).\n\nThis event is cancelable and may bubble up to the [Document] and [Window] objects.",
      "dragenter_event": "\n\nThe `dragenter` event is fired when a dragged element or text selection enters a valid drop target. The target object is the _immediate user selection_ (the element directly indicated by the user as the drop target), or the `body` element.\n\nThis event is cancelable and may bubble up to the [Document] and [Window] objects.",
      "draggable": "\n\nThe **`draggable`** property of the [HTMLElement] interface gets and sets a `Boolean` primitive indicating if the element is draggable.\n\nIt reflects the value of the [`draggable`](/en-US/docs/Web/HTML/Global_attributes/draggable) HTML global attribute.",
      "dragleave_event": "\n\nThe `dragleave` event is fired when a dragged element or text selection leaves a valid drop target.\n\nThis event is not cancelable and may bubble up to the [Document] and [Window] objects.",
      "dragover_event": "\n\nThe `dragover` event is fired when an element or text selection is being dragged over a valid drop target (every few hundred milliseconds).\n\nThis event is cancelable and may bubble up to the [Document] and [Window] objects.",
      "dragstart_event": "\n\nThe `dragstart` event is fired when the user starts dragging an element or text selection.\n\nThis event is cancelable and may bubble up to the [Document] and [Window] objects.",
      "drop_event": "\n\nThe **`drop`** event is fired when an element or text selection is dropped on a valid drop target. To ensure that the `drop` event always fires as expected, you should always include a [`preventDefault()`](/en-US/docs/Web/API/Event/preventDefault) call in the part of your code which handles the [`dragover`](/en-US/docs/Web/API/HTMLElement/dragover_event) event.\n\nThis event is cancelable and may bubble up to the [Document] and [Window] objects.",
      "enterkeyhint": "\n\nThe **`enterKeyHint`** property is an enumerated property defining\nwhat action label (or icon) to present for the enter key on virtual keyboards.\nIt reflects the [`enterkeyhint`](/en-US/docs/Web/HTML/Global_attributes/enterkeyhint)\nHTML global attribute and is an enumerated property, only accepting the following values\nas a string:\n\n- `'enter'` typically indicating inserting a new line.\n- `'done'` typically meaning there is nothing more to input and the input method editor (IME) will be closed.\n- `'go'` typically meaning to take the user to the target of the text they typed.\n- `'next'` typically taking the user to the next field that will accept text.\n- `'previous'` typically taking the user to the previous field that will accept text.\n- `'search'` typically taking the user to the results of searching for the text they have typed.\n- `'send'` typically delivering the text to its target.\n\nIf no `enterKeyHint` value has been specified or if it was set to a different value than the allowed ones, it will return an empty string.",
      "error_event": "\n\nThe `error` event is fired on an element when a resource failed to load, or can't be used. For example, if a script has an execution error or an image can't be found or is invalid.\n\nThis event is not cancelable and does not bubble.",
      "focus": "\n\nThe **`HTMLElement.focus()`** method sets focus on the specified element, if it can be focused.\nThe focused element is the element that will receive keyboard and similar events by default.\n\nBy default the browser will scroll the element into view after focusing it, and it may also provide visible indication of the focused element (typically by displaying a \"focus ring\" around the element).\nParameter options are provided to disable the default scrolling and force visible indication on elements.",
      "hidden": "\n\nThe [HTMLElement] property **`hidden`** reflects the value of the element's [`hidden`](/en-US/docs/Web/HTML/Global_attributes/hidden) attribute.",
      "hidepopover": "\n\nThe **`hidePopover()`** method of the [HTMLElement] interface hides a [popover](/en-US/docs/Web/API/Popover_API) element (i.e. one that has a valid [`popover`](/en-US/docs/Web/HTML/Global_attributes/popover) attribute) by removing it from the  and styling it with `display: none`.\n\nWhen `hidePopover()` is called on a showing element with the [`popover`](/en-US/docs/Web/HTML/Global_attributes/popover) attribute, a [HTMLElement/beforetoggle_event] event will be fired, followed by the popover being hidden, and then the [HTMLElement/toggle_event] event firing. If the element is already hidden, an error is thrown.",
      "inert": "\n\nThe [HTMLElement] property **`inert`** reflects the value of the element's [`inert`](/en-US/docs/Web/HTML/Global_attributes/inert) attribute. It is a boolean value that, when present, makes the browser \"ignore\" user input events for the element, including focus events and events from assistive technologies. The browser may also ignore page search and text selection in the element. This can be useful when building UIs such as modals where you would want to \"trap\" the focus inside the modal when it's visible.\n\n> **Note:** Do not nest interactive elements or important content within elements with the `inert` attribute as inert content and their descendants are neither focusable nor perceivable by all users.",
      "innertext": "\n\nThe **`innerText`** property of the [HTMLElement] interface represents the rendered text content of a node and its descendants.\n\nAs a getter, it approximates the text the user would get if they highlighted the contents of the element with the cursor and then copied it to the clipboard.\nAs a setter this will replace the element's children with the given value, converting any line breaks into `br` elements.\n\n> **Note:** `innerText` is easily confused with [Node.textContent], but there are important differences between the two.\n> Basically, `innerText` is aware of the rendered appearance of text, while `textContent` is not.",
      "inputmode": "\n\nThe [HTMLElement] property **`inputMode`** reflects the value of the element's [`inputmode`](/en-US/docs/Web/HTML/Global_attributes/inputmode) attribute.\n\nIt provides a hint about the type of data that might be entered by the user while editing the element or its contents. This allows the browser to display an appropriate virtual keyboard.\n\nIt is used primarily on `input` elements, but is usable on any element in [`contenteditable`](/en-US/docs/Web/HTML/Global_attributes#contenteditable) mode.",
      "iscontenteditable": "\n\nThe **`HTMLElement.isContentEditable`** read-only property\nreturns a boolean value that is `true` if the contents of the element\nare editable; otherwise it returns `false`.",
      "lang": "\n\nThe **`HTMLElement.lang`** property gets or sets the base\nlanguage of an element's attribute values and text content.\n\nThe language code returned by this property is defined in `5646, \"Tags for Identifying Languages (also known as BCP 47)\"`.\nCommon examples include \"en\" for English, \"ja\" for\nJapanese, \"es\" for Spanish and so on. The default value of this attribute is\n`unknown`. Note that this attribute, though valid at the individual element\nlevel described here, is most often specified for the root element of the document.\n\nThis also only works with the `lang` attribute and not with\n`xml:lang`.",
      "load_event": "\n\nThe **`load`** event fires for elements containing a resource when the resource has successfully loaded. Currently, the list of supported HTML elements are: `body`, `embed`, `iframe`, `img`, `link`, `object`, `script`, `style`, and`track`.\n\n> **Note:** The `load` event on  is actually an alias for the [Window/load_event] event. Therefore, the `load` event will only fire on the `<body>` element once all of the document's resources have loaded or errored. However, for the sake of clarity, it is recommended that the event handler is attached to the `window` object directly rather than on `HTMLBodyElement`.\n\nThis event is not cancelable and does not bubble.",
      "mscandidatewindowhide_event": "\n\nThe **`mscandidatewindowhide`** event is thrown after the Input Method Editor (IME) candidate window closes and is fully hidden.\n\nThis proprietary method is specific to Internet Explorer.\n\nThe handler of this event will see that the `isCandidateWindowVisible` method returns `false`, and no `ClientRect` object is returned from `getCandidateWindowClientRect()`.\n\nWeb applications need only register for this event once per element (the handler will remain valid for the lifetime of the element).",
      "mscandidatewindowshow_event": "\n\nThe **`mscandidatewindowshow`** event is thrown immediately after the Input Method Editor (IME) candidate window is set to appear, but before it renders.\n\nThis proprietary method is specific to Internet Explorer.\n\nThis event fires after the positioning information of the IME candidate window has been determined. You can obtain the positioning information using the [getCandidateWindowClientRect](/en-US/docs/Web/API/getCandidateWindowClientRect) method, and adjust your layout as needed to avoid any occlusions with the IME candidate window.\n\nWeb applications need only register for this event once per element (the handler will remain valid for the lifetime of the element).",
      "mscandidatewindowupdate_event": "\n\nThe **`mscandidatewindowupdate`** event is thrown after the Input Method Editor (IME) candidate window has been identified as needing to change size, but before any visual updates have rendered.\n\nThis proprietary method is specific to Internet Explorer.\n\nAn IME candidate window may be identified as needing to change size for any of the following reasons:\n\n- As a result of displaying new / changed alternatives or predictions\n\nWeb applications need only register for this event once per element (the handler will remain valid for the lifetime of the element).",
      "nonce": "\n\nThe **`nonce`** property of the [HTMLElement] interface returns the cryptographic number used once that is used by [Content Security Policy](/en-US/docs/Web/HTTP/CSP) to determine whether a given fetch will be allowed to proceed.\n\nIn later implementations, elements only expose their `nonce` attribute to scripts (and not to side-channels like CSS attribute selectors).",
      "offsetheight": "\n\nThe **`HTMLElement.offsetHeight`** read-only property returns\nthe height of an element, including vertical padding and borders, as an integer.\n\nTypically, `offsetHeight` is a measurement in pixels of the element's CSS\nheight, including any borders, padding, and horizontal scrollbars (if rendered). It does\nnot include the height of pseudo-elements such as `::before` or\n`::after`. For the document body object, the measurement includes total\nlinear content height instead of the element's CSS height. Floated elements extending\nbelow other linear content are ignored.\n\nIf the element is hidden (for example, by setting `style.display` on the\nelement or one of its ancestors to `\"none\"`), then `0` is\nreturned.\n\n> **Note:** This property will round the value to an integer. If you need a fractional value, use\n> [element.getBoundingClientRect].",
      "offsetleft": "\n\nThe **`HTMLElement.offsetLeft`** read-only property returns the number of pixels that the _upper left corner_ of the current element is offset to the left within the [HTMLElement.offsetParent] node.\n\nFor block-level elements, `offsetTop`, `offsetLeft`, `offsetWidth`, and `offsetHeight` describe the border box of an element relative to the `offsetParent`.\n\nHowever, for inline-level elements (such as **span**) that can wrap from one line to the next, `offsetTop` and `offsetLeft` describe the positions of the _first_ border box (use [Element.getClientRects] to get its width and height), while `offsetWidth` and `offsetHeight` describe the dimensions of the _bounding_ border box (use [Element.getBoundingClientRect] to get its position). Therefore, a box with the left, top, width and height of `offsetLeft`, `offsetTop`, `offsetWidth` and `offsetHeight` will not be a bounding box for a span with wrapped text.",
      "offsetparent": "\n\nThe **`HTMLElement.offsetParent`** read-only property returns a\nreference to the element which is the closest (nearest in the containment hierarchy)\npositioned ancestor element.\n\nA positioned ancestor is either:\n\n- an element with a non-static position, or\n- `td`, `th`, `table` in case the element itself is static positioned.\n\nIf there is no positioned ancestor element, the `body` is returned.\n\n> **Note:** `offsetParent` returns `null` in the following\n> situations:\n>\n> - The element or any ancestor has the `display` property set to\n>   `none`.\n> - The element has the `position` property set to `fixed`\n>   (Firefox returns `<body>`).\n> - The element is `<body>` or `<html>`.\n\n`offsetParent` is useful because\n[HTMLElement.offsetTop] and\n[HTMLElement.offsetLeft] are relative to its padding edge.",
      "offsettop": "\n\nThe **`HTMLElement.offsetTop`** read-only property returns the\ndistance from the outer border of the current element (including its margin) to the top padding edge of the [HTMLelement.offsetParent], the _closest positioned_\nancestor element.",
      "offsetwidth": "\n\nThe **`HTMLElement.offsetWidth`** read-only property returns\nthe layout width of an element as an integer.\n\nTypically, `offsetWidth` is a measurement in pixels of the element's CSS\nwidth, including any borders, padding, and vertical scrollbars (if rendered). It does\nnot include the width of pseudo-elements such as `::before` or\n`::after`.\n\nIf the element is hidden (for example, by setting `style.display` on the\nelement or one of its ancestors to `\"none\"`), then `0` is\nreturned.",
      "outertext": "\n\nThe **`outerText`** property of the [HTMLElement] interface returns the same value as [HTMLElement.innerText].\nWhen used as a setter it replaces the whole current node with the given text (this differs from `innerText`, which replaces the content _inside_ the current node).\n\nSee [HTMLElement.innerText] for more information and examples showing how both properties are used as getters.",
      "paste_event": "\n\nThe **`paste`** event fires when the user initiates a paste action through the browser's user interface.",
      "popover": "\n\nThe **`popover`** property of the [HTMLElement] interface gets and sets an element's popover state via JavaScript (`\"auto\"` or `\"manual\"`), and can be used for feature detection.\n\nIt reflects the value of the [`popover`](/en-US/docs/Web/HTML/Global_attributes/popover) global HTML attribute.",
      "showpopover": "\n\nThe **`showPopover()`** method of the [HTMLElement] interface shows a [Popover_API] element (i.e. one that has a valid [`popover`](/en-US/docs/Web/HTML/Global_attributes/popover) attribute) by adding it to the .\n\nWhen `showPopover()` is called on an element with the [`popover`](/en-US/docs/Web/HTML/Global_attributes/popover) attribute that is currently hidden, a [HTMLElement/beforetoggle_event] event will be fired, followed by the popover showing, and then the [HTMLElement/toggle_event] event firing. If the element is already showing, an error will be thrown.",
      "spellcheck": "\n\nThe **`spellcheck`** property of the [HTMLElement] interface represents a boolean value that controls the [spell-checking](/en-US/docs/Web/HTML/Global_attributes/spellcheck) hint. It is available on all HTML elements, though it doesn't affect all of them.\n\nIt reflects the value of the [`spellcheck`](/en-US/docs/Web/HTML/Global_attributes/spellcheck) HTML global attribute.",
      "style": "\n\nThe read-only **`style`** property of the [HTMLElement] returns the _inline_ style of an element in the form of a live [CSSStyleDeclaration] object that contains a list of all styles properties for that element with values assigned only for the attributes that are defined in the element's inline [`style`](/en-US/docs/Web/HTML/Global_attributes/style) attribute.\n\nShorthand properties are expanded. If you set `style=\"border-top: 1px solid black\"`, the longhand properties (, , and ) are set instead.\n\nThis property is read-only, meaning it is not possible to assign a [CSSStyleDeclaration] object to it. Nevertheless, it is possible to set an inline style by assigning a _string_ directly to the `style` property. In this case the string is forwarded to [CSSStyleDeclaration.cssText]. Using `style` in this manner will completely overwrite all inline styles on the element.\n\nTherefore, to add specific styles to an element without altering other style values, it is generally preferable to set individual properties on the [CSSStyleDeclaration] object. For example, you can write `element.style.backgroundColor = \"red\"`.\n\nA style declaration is reset by setting it to `null` or an empty string, e.g., `elt.style.color = null`.\n\n> **Note:** CSS property names are converted to JavaScript identifier with these rules:\n>\n> - If the property is made of one word, it remains as it is: `height` stays as is (in lowercase).\n> - If the property is made of several words, separated by dashes, the dashes are removed and it is converted to : `background-attachment` becomes `backgroundAttachment`.\n> - The property `float`, being a reserved JavaScript keyword, is converted to `cssFloat`.\n>\n> The `style` property has the same priority in the CSS cascade as an inline style declaration set via the `style` attribute.",
      "tabindex": "\n\nThe **`tabIndex`** property of the\n[HTMLElement] interface represents the tab order of the current element.\n\nTab order is as follows:\n\n1. Elements with a positive `tabIndex`. Elements that have identical\n   `tabIndex` values should be navigated in the order they appear. Navigation\n   proceeds from the lowest `tabIndex` to the highest `tabIndex`.\n2. Elements that do not support the `tabIndex` attribute or support it and\n   assign `tabIndex` to `0`, in the order they appear.\n\nElements that are disabled do not participate in the tabbing order.\n\nValues don't need to be sequential, nor must they begin with any particular value. They\nmay even be negative, though each browser trims very large values.",
      "title": "\n\nThe **`HTMLElement.title`** property\nrepresents the title of the element: the text usually displayed in a 'tooltip' popup\nwhen the mouse is over the node.",
      "toggle_event": "\n\nThe **`toggle`** event of the [HTMLElement] interface fires on a [Popover_API] element (i.e. one that has a valid [`popover`](/en-US/docs/Web/HTML/Global_attributes/popover) attribute) just after it is shown or hidden.\n\n- If the popover element is transitioning from hidden to showing, the `event.oldState` property will be set to `closed` and the `event.newState` property will be set to `open`.\n- If the popover element is transitioning from showing to hidden, then `event.oldState` will be `open` and `event.newState` will be `closed`.\n\n> **Note:** The `toggle` event behaves differently when fired on `details` elements. In this case, it does not relate to popovers, and instead fires when the `open`/`closed` state of a `<details>` element is toggled. See the `HTMLDetailsElement` [HTMLDetailsElement.toggle_event] page for more information.",
      "togglepopover": "\n\nThe **`togglePopover()`** method of the [HTMLElement] interface toggles a [Popover_API] element (i.e. one that has a valid [`popover`](/en-US/docs/Web/HTML/Global_attributes/popover) attribute) between the hidden and showing states.\n\nWhen `togglePopover()` is called on an element with the [`popover`](/en-US/docs/Web/HTML/Global_attributes/popover) attribute:\n\n1. A [HTMLElement/beforetoggle_event] event is fired.\n2. The popover toggles between hidden and showing:\n   1. If it was initially showing, it toggles to hidden.\n   2. If it was initially hidden, it toggles to showing.\n3. A [HTMLElement/toggle_event] event is fired.",
      "translate": "\n\nThe **`translate`** property of the [HTMLElement] interface indicates whether an element's attribute values and the values of its [Text] node children are to be translated when the page is localized, or whether to leave them unchanged.\n\nIt reflects the value of the [`translate`](/en-US/docs/Web/HTML/Global_attributes/translate) HTML global attribute.",
      "virtualkeyboardpolicy": "\n\nThe **`virtualKeyboardPolicy`** property of the [HTMLElement] interface gets and sets a string indicating the on-screen virtual keyboard behavior on devices such as tablets, mobile phones, or other devices where a hardware keyboard may not be available, if the element's content is editable (for example, it is an `input` or `textarea` element, or an element with the [`contenteditable`](/en-US/docs/Web/HTML/Global_attributes/contenteditable) attribute set).\n\nIt reflects the value of the [`virtualkeyboardpolicy`](/en-US/docs/Web/HTML/Global_attributes/virtualkeyboardpolicy) HTML global attribute."
    }
  },
  "htmlembedelement": {
    "docs": "\n\nThe **`HTMLEmbedElement`** interface provides special properties (beyond the regular [HTMLElement] interface it also has available to it by inheritance) for manipulating `embed` elements.\n\n> **Note:** This topic describes the `HTMLEmbedElement` interface as defined in the standard. It does not address earlier, non-standardized version of the interface.\n\n"
  },
  "htmlfieldsetelement": {
    "docs": "\n\nThe **`HTMLFieldSetElement`** interface provides special properties and methods (beyond the regular [HTMLElement] interface it also has available to it by inheritance) for manipulating the layout and presentation of `fieldset` elements.\n\n"
  },
  "htmlfontelement": {
    "docs": "\n\nImplements the document object model (DOM) representation of the font element. The HTML Font Element `font` defines the font size, font face and color of text.\n\n",
    "properties": {
      "color": "\n\nThe obsolete\n**`HTMLFontElement.color`**\nproperty is a string that reflects the [`color`](/en-US/docs/Web/HTML/Element/font#color) HTML attribute, containing either a named color or a color specified in the\nhexadecimal #RRGGBB format.\n\nThe format of the string must follow one of the following HTML microsyntaxes:\n\n| Microsyntax              | Description                                                      | Examples                  |\n| ------------------------ | ---------------------------------------------------------------- | ------------------------- |\n| Valid name color string  | _nameOfColor (case insensitive)_                                 | `Green`, `green`, `GREEN` |\n| Valid hex color string   | _in_ _: #RRGGBB_ | `#008000`                 |\n| RGB using decimal values | _rgb(x,x,x) (x in 0-255 range)_                                  | `rgb(0,128,0)`            |",
      "face": "\n\nThe obsolete\n**`HTMLFontElement.face`**\nproperty is a string that reflects the [`face`](/en-US/docs/Web/HTML/Element/font#face) HTML attribute, containing a comma-separated list of one or more font\nnames.\n\nThe document text, in the default style, is rendered as the first font face that the\nclient's browser supports. If no font listed is installed on the local system, the\nbrowser typically defaults to the proportional or fixed-width font for that system.\n\nThe format of the string must follow one of the following HTML microsyntax:\n\n| Microsyntax                                 | Description                                                         | Examples          |\n| ------------------------------------------- | ------------------------------------------------------------------- | ----------------- |\n| List of one or more valid font family names | _A list of font names, that have to be present on the local system_ | `courier,verdana` |",
      "size": "\n\nThe obsolete\n**`HTMLFontElement.size`** property is a\nstring that reflects the [`size`](/en-US/docs/Web/HTML/Element/font#size) HTML\nattribute. It contains either a font size ranging from 1 to 7 or a\nnumber relative to the default value 3, for example -2 or +1.\n\nThe format of the string must follow one of the following HTML microsyntaxes:\n\n<table class=\"no-markdown\">\n  <thead>\n    <tr>\n      <th scope=\"col\">Microsyntax</th>\n      <th scope=\"col\">Description</th>\n      <th scope=\"col\">Examples</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Valid size number string</td>\n      <td><em>integer number in the range of 1-7</em></td>\n      <td><code>6</code></td>\n    </tr>\n    <tr>\n      <td>Relative size string</td>\n      <td>\n        <em>+x or -x, where x is a number relative to 3 (the result should be in the range of 1-7)</em>\n      </td>\n      <td>\n        <code>+2<br />-1</code>\n      </td>\n    </tr>\n  </tbody>\n</table>"
    }
  },
  "htmlformcontrolscollection": {
    "docs": "\n\nThe **`HTMLFormControlsCollection`** interface represents a _collection_ of HTML _form control elements_, returned by the [HTMLFormElement] interface's [HTMLFormElement.elements] property.\n\nThis interface replaces one method from [HTMLCollection], on which it is based.\n\n",
    "properties": {
      "nameditem": "\n\nThe **`HTMLFormControlsCollection.namedItem()`** method returns\nthe [RadioNodeList] or the [Element] in the collection whose\n`name` or `id` match the specified name, or `null` if\nno node matches.\n\nNote that this version of `namedItem()` hides the one inherited from\n[HTMLCollection]. Like that one, in JavaScript, using the array bracket\nsyntax with a `String`, like `collection[\"value\"]` is\nequivalent to `collection.namedItem(\"value\")`."
    }
  },
  "htmlformelement": {
    "docs": "\n\nThe **`HTMLFormElement`** interface represents a `form` element in the DOM. It allows access to—and, in some cases, modification of—aspects of the form, as well as access to its component elements.\n\n",
    "properties": {
      "acceptcharset": "\n\nThe **`HTMLFormElement.acceptCharset`** property represents a\nlist of the supported [character encodings](/en-US/docs/Glossary/Character_encoding) for the given `form` element. This list can be\ncomma-separated or space-separated.",
      "action": "\n\nThe **`HTMLFormElement.action`** property represents the action\nof the `form` element.\n\nThe action of a form is the program that is executed on the server when the form is\nsubmitted. This property can be retrieved or set.",
      "elements": "\n\nThe [HTMLFormElement] property\n**`elements`** returns an\n[HTMLFormControlsCollection] listing all the form controls contained in\nthe `form` element.\n\nIndependently, you can obtain just the\nnumber of form controls using the [HTMLFormElement.length]\nproperty.\n\nYou can access a particular form control in the returned collection by using either an\nindex or the element's `name` or `id` attributes.\n\nPrior to HTML 5, the returned object was an [HTMLCollection], on which\n`HTMLFormControlsCollection` is based.\n\n> **Note:** Similarly, you can get a list of all of the forms contained within a given document using the document's [Document.forms] property.",
      "encoding": "\n\nThe **`HTMLFormElement.encoding`** property is an alternative name for the [HTMLFormElement.enctype] element on the DOM [HTMLFormElement] object.",
      "enctype": "\n\nThe **`HTMLFormElement.enctype`** property is the [MIME type](https://en.wikipedia.org/wiki/Mime_type) of content that is used\nto submit the form to the server. Possible values are:\n\n- `application/x-www-form-urlencoded`: The initial default type.\n- `multipart/form-data`: The type that allows file `input`\n  element(s) to upload file data.\n- `text/plain`: Ambiguous format, human-readable content not reliably interpretable by computer.\n\nThis value can be overridden by a [`formenctype`](/en-US/docs/Web/HTML/Element/button#formenctype) attribute\non a `button` or `input` element.",
      "formdata_event": "\n\nThe **`formdata`** event fires after the entry list representing the form's data is constructed. This happens when the form is submitted, but can also be triggered by the invocation of a [FormData.FormData] constructor.\n\nThis event is not cancelable and does not bubble.",
      "length": "\n\nThe **`HTMLFormElement.length`**\nread-only property returns the number of controls in the `form`\nelement.\n\nYou can access the list of the form's controls using the\n[HTMLFormElement.elements] property.\n\nThis includes both elements that are descendants of the `<form>`\nelement as well as elements that are made members of the form using their\n`form` property.\n\nElements that are considered for this property are: `button`,\n`fieldset`, `input` (with the exception\nthat any whose type is \"image\" are omitted for historical reasons),\n`object`, `output`, `select`,\nand `textarea`.",
      "method": "\n\nThe **`HTMLFormElement.method`** property represents the\n method used to submit the `form`.\n\nUnless explicitly specified, the default method is 'get'.",
      "name": "\n\nThe **`HTMLFormElement.name`** property represents the name of\nthe current `form` element as a string.\n\nIf your `Form` element contains an element named _name_ then\nthat element overrides the `form.name` property, so that you can't access it.",
      "reportvalidity": "\n\nThe **`HTMLFormElement.reportValidity()`** method returns\n`true` if the element's child controls satisfy their validation constraints.\nWhen `false` is returned, cancelable\n[`invalid`](/en-US/docs/Web/API/HTMLInputElement/invalid_event) events are fired for\neach invalid child and validation problems are reported to the user.",
      "requestsubmit": "\n\nThe [HTMLFormElement] method **`requestSubmit()`** requests\nthat the form be submitted using a specific submit button.",
      "reset": "\n\nThe **`HTMLFormElement.reset()`** method restores a form\nelement's default values. This method does the same thing as clicking the form's\n[`<input type=\"reset\">`](/en-US/docs/Web/HTML/Element/input/reset) control.\n\nIf a form control (such as a reset button) has a name or id of _reset_ it will\nmask the form's reset method. It does not reset other attributes in the input, such as\n`disabled`.\n\nNote that if [Element.setAttribute] is called to set\nthe value of a particular attribute, a subsequent call to `reset()` won't\nreset the attribute to its default value, but instead will keep the attribute at\nwhatever value the [Element.setAttribute] call set it to.",
      "reset_event": "\n\nThe **`reset`** event fires when a `form` is reset.",
      "submit": "\n\nThe **`HTMLFormElement.submit()`** method submits a given\n`form`.\n\nThis method is similar, but not identical to, activating a form's submit\n`button`. When invoking this method directly, however:\n\n- No [HTMLFormElement/submit_event] event is raised. In particular, the form's `onsubmit` event handler is not run.\n- [Constraint validation](/en-US/docs/Web/HTML/Constraint_validation) is not triggered.\n\nThe [HTMLFormElement.requestSubmit] method is identical to activating a\nform's submit `button` and does not have these differences.\n\nA form control (such as a submit button) with a `name` or `id` of `submit` will mask the form's `submit` method. Trying to call `myForm.submit();` throws an error \"submit is not a function\" because in this case `submit` refers to the form control which has a `name` or `id` of `submit`.\n\n`input` with attribute type=\"submit\" will not be submitted with the\nform when using **`HTMLFormElement.submit()`**, but it would be\nsubmitted when you do it with original HTML form submit.",
      "submit_event": "\n\nThe **`submit`** event fires when a `form` is submitted.\n\nNote that the `submit` event fires on the `<form>` element itself, and not on any `button` or `` inside it. However, the [SubmitEvent] which is sent to indicate the form's submit action has been triggered includes a [SubmitEvent.submitter] property, which is the button that was invoked to trigger the submit request.\n\nThe `submit` event fires when:\n\n- the user clicks a ,\n- the user presses <kbd>Enter</kbd> while editing a field (e.g. ) in a form,\n- a script calls the [HTMLFormElement.requestSubmit] method\n\nHowever, the event is _not_ sent to the form when a script calls the [HTMLFormElement.submit] method directly.\n\n> **Note:** Trying to submit a form that does not pass [validation](/en-US/docs/Learn/Forms/Form_validation) triggers an [HTMLInputElement/invalid_event] event. In this case, the validation prevents form submission, and thus there is no `submit` event.",
      "target": "\n\nThe **`target`** property of the [HTMLFormElement]\ninterface represents the target of the form's action (i.e., the frame in which to render\nits output)."
    }
  },
  "htmlframesetelement": {
    "docs": "\n\nThe **`HTMLFrameSetElement`** interface provides special properties (beyond those of the regular [HTMLElement] interface they also inherit) for manipulating `frameset` elements.\n\n"
  },
  "htmlheadelement": {
    "docs": "\n\nThe **`HTMLHeadElement`** interface contains the descriptive information, or metadata, for a document. This object inherits all of the properties and methods described in the [HTMLElement] interface.\n\n"
  },
  "htmlheadingelement": {
    "docs": "\n\nThe **`HTMLHeadingElement`** interface represents the different heading elements, [`<h1>` through `<h6>`](/en-US/docs/Web/HTML/Element/Heading_Elements). It inherits methods and properties from the [HTMLElement] interface.\n\n"
  },
  "htmlhrelement": {
    "docs": "\n\nThe **`HTMLHRElement`** interface provides special properties (beyond those of the [HTMLElement] interface it also has available to it by inheritance) for manipulating `hr` elements.\n\n"
  },
  "htmlhtmlelement": {
    "docs": "\n\nThe **`HTMLHtmlElement`** interface serves as the root node for a given HTML document. This object inherits the properties and methods described in the [HTMLElement] interface.\n\nYou can retrieve the `HTMLHtmlElement` object for a given document by reading the value of the [document.documentElement] property.\n\n",
    "properties": {
      "version": " \n\n> **Note:** This property has been declared as deprecated by the W3C technical recommendation for HTML 4.01 in favor of use of the DTD for obtaining version information for a document.\n\nReturns version information about the document type definition (DTD) of a document. While this property is recognized by Mozilla, the return value for this property is always an empty string."
    }
  },
  "htmliframeelement": {
    "docs": "\n\nThe **`HTMLIFrameElement`** interface provides special properties and methods (beyond those of the [HTMLElement] interface it also has available to it by inheritance) for manipulating the layout and presentation of inline frame elements.\n\n",
    "properties": {
      "allowpaymentrequest": "\n\nThe **`allowPaymentRequest`** property of the\n[HTMLIFrameElement] interface returns a boolean value indicating\nwhether the [Payment Request API](/en-US/docs/Web/API/Payment_Request_API) may be invoked on a cross-origin iframe.",
      "contentdocument": "\n\nIf the iframe and the iframe's parent document are [Same Origin](/en-US/docs/Web/Security/Same-origin_policy), returns a [`Document`](/en-US/docs/Web/API/Document) (that is, the active document in the inline frame's nested browsing context), else returns `null`.",
      "contentwindow": "\n\nThe **`contentWindow`** property returns the [Window](/en-US/docs/Web/API/Window) object of an [HTMLIFrameElement](/en-US/docs/Web/API/HTMLIFrameElement).\n\nThis attribute is read-only.",
      "credentialless": "\n\nThe **`credentialless`** property of the [HTMLIFrameElement] interface indicates whether the `iframe` is credentialless, meaning that documents inside will be loaded using new, ephemeral contexts.\n\nThose contexts do not have access to their network, cookies and storage data associated with their origin. Instead, they use new ones, local to the top-level document lifetime. It means any data stored won't be accessible anymore after the user navigates away from the page or reloads it.\n\nIn return, the  (COEP) embedding rules can be lifted, so documents with COEP set can embed third-party documents that do not. See [IFrame credentialless](/en-US/docs/Web/Security/IFrame_credentialless) for a deeper explanation.",
      "csp": "\n\nThe **`csp`** property of the [HTMLIFrameElement]\ninterface specifies the [Content Security Policy](/en-US/docs/Web/HTTP/CSP) that an\nembedded document must agree to enforce upon itself.",
      "featurepolicy": "\n\nThe **`featurePolicy`** read-only\nproperty of the [HTMLIFrameElement] interface returns the\n[FeaturePolicy] interface which provides a simple API for introspecting\nthe [Permissions Policies](/en-US/docs/Web/HTTP/Permissions_Policy) applied to a specific frame.",
      "loading": "\n\nThe **`loading`** property of the [HTMLIFrameElement] interface is a string that provides a hint to the  indicating whether the [iframe](/en-US/docs/Web/HTML/Element/iframe) should be loaded immediately on page load, or only when it is needed.\n\nThis can be used to optimize the loading of the document's contents.\nIframes that are visible when the page loads can be downloaded immediately (eagerly), while iframes that are likely to be offscreen on initial page load can be downloaded lazily — just before they will appear in the window's .",
      "referrerpolicy": "\n\nThe\n**`HTMLIFrameElement.referrerPolicy`**\nproperty reflects the HTML [`referrerpolicy`](/en-US/docs/Web/HTML/Element/iframe#referrerpolicy) attribute of the\n`iframe` element defining which referrer is sent when fetching the\nresource.",
      "src": "\n\nThe **`HTMLIFrameElement.src`**\nA string that reflects the [`src`](/en-US/docs/Web/HTML/Element/iframe#src) HTML attribute, containing the address of the content to be embedded.\n\nNote that programmatically removing an `<iframe>`'s src attribute (e.g. via [Element.removeAttribute]) causes `about:blank` to be loaded in the frame.",
      "srcdoc": "\n\nThe **`srcdoc`** property of the [HTMLIFrameElement] specifies the content of the page."
    }
  },
  "htmlimageelement": {
    "docs": "\n\nThe **`HTMLImageElement`** interface represents an HTML `img` element, providing the properties and methods used to manipulate image elements.\n\n",
    "properties": {
      "align": "\n\nThe _obsolete_ **`align`**\nproperty of the [HTMLImageElement] interface is a string which indicates\nhow to position the image relative to its container.\n\nYou should instead use the\nCSS property , which does in fact also work on images\ndespite its name. You can also use the `float` property to float the image\nto the left or right margin.\n\nThe `align` property reflects the HTML [`align`](/en-US/docs/Web/HTML/Element/img#align)\ncontent attribute.",
      "alt": "\n\nThe [HTMLImageElement] property **`alt`** provides fallback (alternate) text to display when the image specified by the `img` element is not loaded.\n\nThis may be the case because of an error, because the user has disabled the loading of images, or because the image hasn't finished loading yet.\n\nPerhaps the most important reason to use the `alt` property is to support [accessibility](/en-US/docs/Web/Accessibility), as the `alt` text may be used by screen readers and other assistive technologies to help people with a disability make full use of your content.\nIt will be read aloud or sent to a braille output device, for example, to support blind or visually impaired users.\n\n> **Think of it like this:** When choosing `alt` strings for your images, imagine what you would say when reading the page to someone over the phone without mentioning that there's an image on the page.\n\nThe alternate text is displayed in the space the image would occupy and should be able to take the place of the image _without altering the meaning of the page_.",
      "border": "\n\nThe obsolete [HTMLImageElement]\nproperty **`border`** specifies the number of pixels thick the\nborder surrounding the image should be. A value of 0, the default, indicates that no\nborder should be drawn.\n\nYou should _not_ use this property! Instead, you should use CSS to style the\nborder. The `border` property or its longhand properties to not only set\nthe thickness of the border but to potentially apply a wide variety of other styling\noptions to it.\n\nThe width, specifically, is controlled using the writing-mode aware\n, ,\n, and \nproperties.\n\nFor compatibility (or perhaps other) reasons, you can use the older properties instead\n(or in addition): , ,\n, and .",
      "complete": "\n\nThe read-only [HTMLImageElement] interface's\n**`complete`** attribute is a Boolean value which indicates\nwhether or not the image has completely loaded.",
      "crossorigin": "\n\nThe [HTMLImageElement]\ninterface's **`crossOrigin`** attribute is a string which\nspecifies the Cross-Origin Resource Sharing () setting to use when\nretrieving the image.",
      "currentsrc": "\n\nThe read-only [HTMLImageElement] property\n**`currentSrc`** indicates the URL of the image which is\ncurrently presented in the `img` element it represents.",
      "decode": "\n\nThe **`decode()`**\nmethod of the [HTMLImageElement] interface returns a\n`Promise` that resolves once the image is decoded and it is safe to append\nit to the DOM.\n\nThis can be used to initiate loading of the image prior\nto attaching it to an element in the DOM (or adding it to the DOM as a new element), so\nthat the image can be rendered immediately upon being added to the DOM. This, in turn,\nprevents the rendering of the next frame after adding the image to the DOM from causing\na delay while the image loads.",
      "decoding": "\n\nThe **`decoding`** property of the [HTMLImageElement] interface provides a hint to the browser as to how it should decode the image. More specifically, whether it should wait for the image to be decoded before presenting other content updates or not.",
      "fetchpriority": "\n\nThe **`fetchPriority`** property of the\n[HTMLImageElement] interface represents a hint given to the browser on how\nit should prioritize the fetch of the image relative to other images.",
      "height": "\n\nThe **`height`** property of the\n[HTMLImageElement] interface indicates the height at which the image is\ndrawn, in  if the image is being drawn or rendered to any\nvisual medium such as the screen or a printer; otherwise, it's the natural, pixel\ndensity corrected height of the image.",
      "hspace": "\n\nThe\n_obsolete_ **`hspace`** property of the\n[HTMLImageElement] interface specifies the number of pixels of empty\nspace to leave empty on the left and right sides of the `img` element\nwhen laying out the page.\n\nThis property reflects the  [`hspace`](/en-US/docs/Web/HTML/Element/img#hspace)\nattribute.",
      "image": "\n\nThe **`Image()`**\nconstructor creates a new [HTMLImageElement] instance. It is functionally\nequivalent to [Document.createElement].\n\n> **Note:** This function should not be confused with the CSS [`image()`](/en-US/docs/Web/CSS/image/image) function.",
      "ismap": "\n\nThe [HTMLImageElement] property **`isMap`** is a\nBoolean value which indicates that the image is to be used by a server-side image map.\nThis may only be used on images located within an `a` element.\n\n> **Note:** For accessibility reasons, you should generally avoid using\n> server-side image maps, as they require the use of a mouse. Use a [client-side image map](/en-US/docs/Learn/HTML/Howto/Add_a_hit_map_on_top_of_an_image) instead.",
      "loading": "\n\nThe [HTMLImageElement] property **`loading`** is a string whose value provides a hint to the  on how to handle the loading of the image which is currently outside the window's .\n\nThis helps to optimize the loading of the document's contents by postponing loading the image until it's expected to be needed, rather than immediately during the initial page load.",
      "longdesc": "\n\nThe _deprecated_ property **`longDesc`** on\nthe [HTMLImageElement] interface specifies the URL of a text or HTML file\nwhich contains a long-form description of the image. This can be used to\nprovide optional added details beyond the short description provided in the\n[`title`](/en-US/docs/Web/HTML/Global_attributes#title) attribute.",
      "name": "\n\nThe [HTMLImageElement]\ninterface's _deprecated_ **`name`** property specifies\na name for the element. This has been replaced by the [Element.id]\nproperty available on all elements.",
      "naturalheight": "\n\nThe [HTMLImageElement] interface's\n**`naturalHeight`** property is a read-only value which\nreturns the intrinsic (natural), density-corrected height of the image in\n.\n\nThis is the height the image is if\ndrawn with nothing constraining its height; if you don't specify a height for the image,\nor place the image inside a container that either limits or expressly specifies the\nimage height, it will be rendered this tall.\n\n> **Note:** Most of the time the natural height is the actual height of the image sent by the server.\n> Nevertheless, browsers can modify an image before pushing it to the renderer. For example, Chrome\n> [degrades the resolution of images on low-end devices](https://crbug.com/1187043#c7). In such cases, `naturalHeight` will consider the height of the image modified\n> by such browser interventions as the natural height, and returns this value.",
      "naturalwidth": "\n\nThe [HTMLImageElement] interface's read-only\n**`naturalWidth`** property returns the intrinsic (natural),\ndensity-corrected width of the image in .\n\nThis is the width the image is if drawn with nothing constraining\nits width; if you neither specify a width for the image nor place the image inside a\ncontainer that limits or expressly specifies the image width, this is the number of CSS\npixels wide the image will be.\n\nThe corresponding [HTMLImageElement.naturalHeight] method\nreturns the natural height of the image.\n\n> **Note:** Most of the time the natural width is the actual width of the image sent by the server.\n> Nevertheless, browsers can modify an image before pushing it to the renderer. For example, Chrome\n> [degrades the resolution of images on low-end devices](https://crbug.com/1187043#c7). In such cases, `naturalWidth` will consider the width of the image modified\n> by such browser interventions as the natural width, and returns this value.",
      "referrerpolicy": "\n\nThe\n**`HTMLImageElement.referrerPolicy`**\nproperty reflects the HTML [`referrerpolicy`](/en-US/docs/Web/HTML/Element/img#referrerpolicy) attribute of the\n`img` element defining which referrer is sent when fetching the\nresource.",
      "sizes": "\n\nThe [HTMLImageElement] property\n**`sizes`** allows you to specify the layout width of the\nimage for each of a list of media conditions. This provides the ability to\nautomatically select among different images—even images of different orientations or\naspect ratios—as the document state changes to match different media\nconditions.\n\nEach condition is specified using the same conditional format used\nby [media queries](/en-US/docs/Web/CSS/CSS_media_queries).",
      "src": "\n\nThe [HTMLImageElement] property\n**`src`**, which reflects the HTML [`src`](/en-US/docs/Web/HTML/Element/img#src) attribute, specifies the image to display in the `img`\nelement.",
      "srcset": "\n\nThe [HTMLImageElement] property\n**`srcset`** is a string which identifies one or more\n**image candidate strings**, separated using commas (`,`) each\nspecifying image resources to use under given circumstances.\n\nEach image\ncandidate string contains an image URL and an optional width or pixel density descriptor\nthat indicates the conditions under which that candidate should be used instead of the\nimage specified by the [HTMLImageElement.src] property.\n\nThe `srcset` property, along with the [HTMLImageElement.sizes] property, are a crucial component in designing responsive websites, as they\ncan be used together to make pages that use appropriate images for the rendering\nsituation.\n\n> **Note:** If the [`srcset`](/en-US/docs/Web/HTML/Element/img#srcset) attribute uses width descriptors, the `sizes` attribute must also be present, or the `srcset` itself will be ignored.",
      "usemap": "\n\nThe **`useMap`** property on the\n[HTMLImageElement] interface reflects the value of the\n [`usemap`](/en-US/docs/Web/HTML/Element/img#usemap) attribute, which is a string\nproviding the name of the client-side image map to apply to the image.",
      "vspace": "\n\nThe _obsolete_ **`vspace`** property of the\n[HTMLImageElement] interface specifies the number of pixels of empty space\nto leave empty on the top and bottom of the `img` element when laying\nout the page.",
      "width": "\n\nThe **`width`** property of the\n[HTMLImageElement] interface indicates the width at which an image is\ndrawn in  if it's being drawn or rendered to\nany visual medium such as a screen or printer. Otherwise, it's the natural, pixel\ndensity-corrected width of the image.",
      "x": "\n\nThe read-only [HTMLImageElement] property\n**`x`** indicates the x-coordinate of the\n`img` element's left border edge relative to the root element's\norigin.\n\nThe `x` and [HTMLImageElement.y] properties are only valid\nfor an image if its `display` property has the computed value\n`table-column` or `table-column-group`. In other words: it has\neither of those values set explicitly on it, or it has inherited it from a containing\nelement, or by being located within a column described by either `col`\nor `colgroup`.",
      "y": "\n\nThe read-only [HTMLImageElement] property\n**`y`** indicates the y-coordinate of the\n`img` element's top border edge relative to the root element's\norigin.\n\nThe [HTMLImageElement.x] and `y` properties are only valid\nfor an image if its `display` property has the computed value\n`table-column` or `table-column-group`. In other words: it has\neither of those values set explicitly on it, or it has inherited it from a containing\nelement, or by being located within a column described by either\n`col` or `colgroup`."
    }
  },
  "htmlinputelement": {
    "docs": "\n\nThe **`HTMLInputElement`** interface provides special properties and methods for manipulating the options, layout, and presentation of `input` elements.\n\n",
    "properties": {
      "checkvalidity": "\n\nThe **`HTMLInputElement.checkValidity()`** method returns a boolean value which indicates validity of the value of the element. If the value is invalid, this method also fires the [HTMLInputElement/invalid_event] event on the element.",
      "disabled": "\n\nThe **`HTMLInputElement.disabled`** property is a boolean value that reflects the [`disabled`](/en-US/docs/Web/HTML/Element/input#disabled) HTML attribute, which indicates whether the control is disabled. If it is disabled, it does not accept clicks. A disabled element is unusable and un-clickable.",
      "files": "\n\nThe **`HTMLInputElement.files`** property allows you to access the [FileList] selected with the [`<input type=\"file\">`](/en-US/docs/Web/HTML/Element/input/file) element.",
      "invalid_event": "\n\nThe **`invalid`** event fires when a submittable element has been checked for validity and doesn't satisfy its constraints.\n\nThis event can be useful for displaying a summary of the problems with a form on submission. When a form is submitted, `invalid` events are fired at each form control that is invalid. The validity of submittable elements is checked before submitting their owner `form`, or after the [`checkValidity()`](/en-US/docs/Web/API/HTMLInputElement/checkValidity) method of the element or its owner `<form>` is called.\n\nIt is not checked on [Element/blur_event].",
      "labels": "\n\nThe **`HTMLInputElement.labels`** read-only property returns a\n[NodeList] of the `label` elements associated with the\n`input` element, if the element is not hidden. If the element has the\ntype `hidden`, the property returns `null`.",
      "multiple": "\n\nThe **`HTMLInputElement.multiple`** property indicates if an input can have more than one value. Firefox currently only supports `multiple` for `<input type=\"file\">`.",
      "popovertargetaction": "\n\nThe **`popoverTargetAction`** property of the [HTMLInputElement] interface gets and sets the action to be performed (`\"hide\"`, `\"show\"`, or `\"toggle\"`) on a popover element being controlled by an `input` element of `type=\"button\"`.\n\nIt reflects the value of the [`popovertargetaction`](/en-US/docs/Web/HTML/Element/button#popovertargetaction) HTML attribute.",
      "popovertargetelement": "\n\nThe **`popoverTargetElement`** property of the [HTMLInputElement] interface gets and sets the popover element to control via an `input` element of `type=\"button\"`.\n\nIt is the JavaScript equivalent of the [`popovertarget`](/en-US/docs/Web/HTML/Element/button#popovertarget) HTML attribute.",
      "reportvalidity": "\n\nThe **`reportValidity()`** method of the [HTMLInputElement] interface performs the same validity checking steps as the [HTMLInputElement.checkValidity] method. If the value is invalid, this method also fires the [HTMLInputElement.invalid_event] event on the element, and (if the event isn't canceled) reports the problem to the user.",
      "search_event": "\n\nThe **`search`** event is fired when a search is initiated using an `input` element of `type=\"search\"`.\n\nThere are several ways a search can be initiated, such as by pressing <kbd>Enter</kbd> while the `input` is focused, or, if the [`incremental`](/en-US/docs/Web/HTML/Element/input#incremental) attribute is present, after a UA-defined timeout elapses since the most recent keystroke (with new keystrokes resetting the timeout so the firing of the event is debounced).\n\nCurrent UA implementations of `<input type=\"search\">` have an additional control to clear the field. Using this control also fires the `search` event. In that case the `value` of the `input` element will be the empty string.\n\nThis event is not cancelable.",
      "select": "\n\nThe **`HTMLInputElement.select()`** method selects all the text\nin a `textarea` element or in an `input` element\nthat includes a text field.",
      "select_event": "\n\nThe **`select`** event fires when some text has been selected.",
      "selectionchange_event": "\n\nThe **`selectionchange`** event of the [Selection API](/en-US/docs/Web/API/Selection) is fired when the text selection within an `input` element is changed.\nThis includes both changes in the selected range of characters, or if the caret moves.\n\nThis event is not cancelable.\n\nThe event is usually processed by adding an event listener on the `input`, and in the handler function read by the [HTMLInputElement] `selectionStart`, `selectionEnd` and `selectionDirection` properties.\n\nIt is also possible to add a listener on the `onselectionchange` event handler, and within the handler function use [Document.getSelection] to get the [Selection]. However this is not very useful for getting changes to _text_ selections.",
      "setcustomvalidity": "\n\nThe **`HTMLInputElement.setCustomValidity()`** method sets a custom validity message for the element.",
      "setrangetext": "\n\nThe **`HTMLInputElement.setRangeText()`** method replaces a\nrange of text in an `input` or `textarea` element with\na new string.",
      "setselectionrange": "\n\nThe **`HTMLInputElement.setSelectionRange()`** method sets the\nstart and end positions of the current text selection in an `input`\nor `textarea` element.\n\nOptionally, in newer browser versions, you can specify the direction in which selection\nshould be considered to have occurred. This lets you indicate, for example, that the\nselection was set by the user clicking and dragging from the end of the selected text\ntoward the beginning.\n\nThis method updates the `HTMLInputElement.selectionStart`,\n`selectionEnd`, and `selectionDirection` properties in one call.\n\nNote that according to the [WHATWG forms spec](https://html.spec.whatwg.org/multipage/forms.html#concept-input-apply) `selectionStart`, `selectionEnd` properties and\n`setSelectionRange` method apply only to inputs of types text, search, URL,\ntel and password. Chrome, starting from version 33, throws an exception while accessing\nthose properties and method on the rest of input types. For example, on input of type\nnumber: \"Failed to read the 'selectionStart' property from 'HTMLInputElement': The input\nelement's type ('number') does not support selection\".\n\nIf you wish to select **all** text of an input element, you can use the [HTMLInputElement.select()](/en-US/docs/Web/API/HTMLInputElement/select)\nmethod instead.",
      "showpicker": "\n\nThe **`HTMLInputElement.showPicker()`** method displays the browser picker for an `input` element.\n\nThis is the same picker that would normally be displayed when the element is selected, but can be triggered from a button press or other user interaction.\n\nCommonly browsers implement it for inputs of these types: `\"date\"`, `\"month\"`, `\"week\"`, `\"time\"`, `\"datetime-local\"`, `\"color\"`, or `\"file\"`.\nIt can also be prepopulated with items from a `datalist` element or [`autocomplete`](/en-US/docs/Web/HTML/Attributes/autocomplete) attribute.\n\nMore generally, this method should ideally display the picker for any input element on the platform that has a picker.",
      "stepdown": "\n\nThe\n**`HTMLInputElement.stepDown([n])`** method decrements the\nvalue of a numeric type of `input` element by the value of the\n[`step`](/en-US/docs/Web/HTML/Attributes/step) attribute or up\nto `n` multiples of the step attribute if a number is passed as the\nparameter.\n\nThe method, when invoked, decrements the\n[`value`](/en-US/docs/Web/HTML/Element/input#value) by ([`step`](/en-US/docs/Web/HTML/Element/input#step) \\* n), where n\ndefaults to 1 if not specified, and\n[`step`](/en-US/docs/Web/HTML/Attributes/step) defaults to the\ndefault value for `step` if not specified.\n\nValid on all numeric, date, and time input types that support the step attribute,\nincluding `date`, `month`,\n`week`, `time`,\n, `number`, and `range`.\n\nGiven `<input id=\"myTime\" type=\"time\" max=\"17:00\" step=\"900\" value=\"17:00\">`,\ninvoking `myTime.stepDown(3)` will change the value to 16:15, decrementing the\ntime by `3 * 900`, or 45 minutes. `myTime.stepDown()`, with no\nparameter, would have resulted in `16:45`, as `n` defaults to\n`1`.\n\n```html\n<!-- decrements by intervals of 900 seconds (15 minute) -->\n<input type=\"time\" max=\"17:00\" step=\"900\" />\n\n<!-- decrements by intervals of 7 days (one week) -->\n<input type=\"date\" max=\"2019-12-25\" step=\"7\" />\n\n<!-- decrements by intervals of 12 months (one year) -->\n<input type=\"month\" max=\"2019-12\" step=\"12\" />\n```\n\nHowever, calling `stepDown` on `<input type=\"time\" max=\"17:00\" step=\"900\">` would not set the value to `17:00`, as one would expect — and as it does for `stepUp` when the input is `<input type=\"time\" min=\"17:00\" step=\"900\">`. Instead, the first call to `stepDown` will set the initial value to `23:45` even though the `max` attribute is set. The second call will set the value to `17:00`. And the third call to will set the value to `16:45`.\n\n```js\nlet input1 = document.createElement(\"input\");\ninput1.setAttribute(\"type\", \"time\");\ninput1.setAttribute(\"min\", \"17:00\");\ninput1.setAttribute(\"step\", 900);\nconsole.log(input1.value); // \"\"\ninput1.stepUp();\nconsole.log(input1.value); // \"17:00\"\n// However\nlet input2 = document.createElement(\"input\");\ninput2.setAttribute(\"type\", \"time\");\ninput2.setAttribute(\"max\", \"17:00\");\ninput2.setAttribute(\"step\", 900);\nconsole.log(input2.value); // \"\"\ninput2.stepDown();\nconsole.log(input2.value); // \"23:45\"\ninput2.stepDown();\nconsole.log(input2.value); // \"17:00\"\ninput2.stepDown();\nconsole.log(input2.value); // \"16:45\"\n```\n\nThe method, when invoked, changes the form control's value by the value given in the\n`step` attribute, multiplied by the parameter, within the constraints set\nwithin the form control. The default value for the parameter, if not is passed, is 1.\nThe method will not cause the value to go below the\n[`min`](/en-US/docs/Web/HTML/Attributes/min) value set or defy the\nconstraints set by the\n[`step`](/en-US/docs/Web/HTML/Attributes/step) attribute. A\nnegative value for `n` will increment the value, but will not increment\nbeyond the [`max`](/en-US/docs/Web/HTML/Attributes/max) value.\n\nIf the value before invoking the `stepDown()` method is invalid, for\nexample, if it doesn't match the constraints set by the `step` attribute,\ninvoking the `stepDown()` method will return a value that does match the form\ncontrols constraints.\n\nIf the form control is non time, date, or numeric in nature, and therefore does not\nsupport the `step` attribute (see the list of supported input types above), or if the `step` value is set to `any`, an\n`InvalidStateError` exception is thrown.\n\n- [HTMLInputElement.stepDown]\n\n  - : Decrements the [`value`](/en-US/docs/Web/HTML/Element/input#value) by\n    ([`step`](/en-US/docs/Web/HTML/Element/input#step) \\* n), where n defaults to 1 if not specified. Throws\n    an `InvalidStateError` exception:\n\n    - if the method is not applicable to for the current\n      [`type`](/en-US/docs/Web/HTML/Element/input#type) value,\n    - if the element has no [`step`](/en-US/docs/Web/HTML/Element/input#step) value,\n    - if the [`value`](/en-US/docs/Web/HTML/Element/input#value) cannot be converted to a number,\n    - if the resulting value is above the [`max`](/en-US/docs/Web/HTML/Element/input#max) or below the\n      [`min`](/en-US/docs/Web/HTML/Element/input#min).",
      "stepup": "\n\nThe **`HTMLInputElement.stepUp()`** method increments the value\nof a numeric type of `input` element by the value of the\n[`step`](/en-US/docs/Web/HTML/Attributes/step) attribute, or the\ndefault `step` value if the step attribute is not explicitly set. The method,\nwhen invoked, increments the [`value`](/en-US/docs/Web/HTML/Element/input#value) by\n([`step`](/en-US/docs/Web/HTML/Element/input#step) \\* n), where `n` defaults to\n`1` if not specified, and\n[`step`](/en-US/docs/Web/HTML/Attributes/step) defaults to the\ndefault value for `step` if not specified.\n\n<table class=\"no-markdown\">\n  <thead>\n    <tr>\n      <th>Input type</th>\n      <th>Default step value</th>\n      <th>Example step declaration</th>\n    </tr>\n    <tr>\n      <td>`date`</td>\n      <td><code>1</code> (day)</td>\n      <td>\n        7 day (one week) increments:<br />\n        <code>&#x3C;input type=\"date\" min=\"2019-12-25\" step=\"7\"></code>\n      </td>\n    </tr>\n    <tr>\n      <td>`month`</td>\n      <td><code>1</code> (month)</td>\n      <td>\n        12 month (one year) increments:<br />\n        <code>&#x3C;input type=\"month\" min=\"2019-12\" step=\"12\"></code>\n      </td>\n    </tr>\n    <tr>\n      <td>`week`</td>\n      <td><code>1</code> (week)</td>\n      <td>\n        Two week increments:<br />\n        <code>&#x3C;input type=\"week\" min=\"2019-W23\" step=\"2\"></code>\n      </td>\n    </tr>\n    <tr>\n      <td>`time`</td>\n      <td><code>60</code> (seconds)</td>\n      <td>\n        900 second (15 minute) increments:<br />\n        <code>&#x3C;input type=\"time\" min=\"09:00\" step=\"900\"></code>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        \n      </td>\n      <td><code>1</code> (day)</td>\n      <td>\n        Same day of the week:<br />\n        <code>&#x3C;input type=\"datetime-local\" min=\"019-12-25T19:30\"\n          step=\"7\"></code>\n      </td>\n    </tr>\n    <tr>\n      <td>`number`</td>\n      <td><code>1</code></td>\n      <td>\n        0.1 increments<br />\n        <code>&#x3C;input type=\"number\" min=\"0\" step=\"0.1\" max=\"10\"></code>\n      </td>\n    </tr>\n    <tr>\n      <td>`range`</td>\n      <td><code>1</code></td>\n      <td>\n        Increments by 2:<br />\n        <code>&#x3C;input type=\"range\" min=\"0\" step=\"2\" max=\"10\"></code>\n      </td>\n    </tr>\n  </thead>\n</table>\n\nThe method, when invoked, changes the form control's value by the value given in the\n`step` attribute, multiplied by the parameter, within the constraints set on\nthe form control. The default value for the parameter, if no value is passed, is\n`1`. The method will not cause the value to exceed the\nset [`max`](/en-US/docs/Web/HTML/Attributes/max) value, or defy\nthe constraints set by the\n[`step`](/en-US/docs/Web/HTML/Attributes/step) attribute.\n\nIf the value before invoking the `stepUp()` method is invalid—for example,\nif it doesn't match the constraints set by the step attribute—invoking the\n`stepUp()` method will return a value that does match the form controls\nconstraints.\n\nIf the form control is non time, date, or numeric in nature, and therefore does not\nsupport the `step` attribute (see the list of supported input types in the\ntable above), or if the step value is set to `any`, an\n`InvalidStateError` exception is thrown.",
      "webkitdirectory": "\n\nThe **`HTMLInputElement.webkitdirectory`** is a property\nthat reflects the [`webkitdirectory`](/en-US/docs/Web/HTML/Element/input/file#webkitdirectory) HTML attribute\nand indicates that the `input` element should let the user select directories instead of files.\nWhen a directory is selected, the directory and its entire hierarchy of contents are included in the set of selected items.\nThe selected file system entries can be obtained using the [HTMLInputElement.webkitEntries] property.\n\n> **Note:** This property is called `webkitEntries` in the specification due to its\n> origins as a Google Chrome-specific API. It's likely to be renamed someday.",
      "webkitentries": "\n\nThe read-only **`webkitEntries`**\nproperty of the [HTMLInputElement] interface contains an array of file\nsystem entries (as objects based on [FileSystemEntry]) representing files\nand/or directories selected by the user using an `input` element of\ntype `file`, but only if that selection was made using drag-and-drop:\nselecting a file in the dialog will leave the property empty.\n\nThe array can only contain directories if the\n[HTMLInputElement.webkitdirectory] property is\n`true`. This means the `<input>` element was configured to\nlet the user choose directories.\n\n> **Note:** This property is called `webkitEntries` in the specification due to its\n> origins as a Google Chrome-specific API. It's likely to be renamed someday."
    }
  },
  "htmllabelelement": {
    "docs": "\n\nThe **`HTMLLabelElement`** interface gives access to properties specific to `label` elements. It inherits methods and properties from the base [HTMLElement] interface.\n\n",
    "properties": {
      "control": "\n\nThe read-only **`HTMLLabelElement.control`** property returns a\nreference to the control (in the form of an object of type [HTMLElement] or\none of its derivatives) with which the `label` element is associated,\nor `null` if the label isn't associated with a control.",
      "form": "\n\nThe read-only **`HTMLLabelElement.form`** property returns an\n[HTMLFormElement] object which represents the form of which the label's\nassociated control is a part, or null if there is either no associated control, or if\nthat control isn't in a form.\n\nThis property is just a shortcut for `HTMLLabelElement.control.form`.",
      "htmlfor": "\n\nThe **`HTMLLabelElement.htmlFor`** property reflects the value\nof the [`for`](/en-US/docs/Web/HTML/Element/label#for) content property. That means that this\nscript-accessible property is used to set and read the value of the content property\n`for`, which is the ID of the label's associated control element."
    }
  },
  "htmllegendelement": {
    "docs": "\n\nThe **`HTMLLegendElement`** is an interface allowing to access properties of the `legend` elements. It inherits properties and methods from the [HTMLElement] interface.\n\n"
  },
  "htmllielement": {
    "docs": "\n\nThe **`HTMLLIElement`** interface exposes specific properties and methods (beyond those defined by regular [HTMLElement] interface it also has available to it by inheritance) for manipulating list elements.\n\n"
  },
  "htmllinkelement": {
    "docs": "\n\nThe **`HTMLLinkElement`** interface represents reference information for external resources and the relationship of those resources to a document and vice versa (corresponds to [`<link>`](/en-US/docs/Web/HTML/Element/link) element; not to be confused with [`<a>`](/en-US/docs/Web/HTML/Element/a), which is represented by [`HTMLAnchorElement`](/en-US/docs/Web/API/HTMLAnchorElement)). This object inherits all of the properties and methods of the [HTMLElement] interface.\n\n",
    "properties": {
      "as": "\n\nThe **`as`** property of the [HTMLLinkElement] interface returns a string representing the type of content to be preloaded by a link element.\n\nThe `as` property must have a value for link elements when [`rel=\"preload\"`](/en-US/docs/Web/HTML/Attributes/rel/preload), or the resource will not be fetched.\nIt may also be applied to link elements where [`rel=\"modulepreload\"`](/en-US/docs/Web/HTML/Attributes/rel/preload), but if omitted, will default to `script`.\nThe property should not be set for other types of link elements, such as `rel=\"prefetch\"`.\n\nThis property reflects the value of the [`as` attribute](/en-US/docs/Web/HTML/Element/link#as) of the [`<link>`](/en-US/docs/Web/HTML/Element/link) HTML element.",
      "crossorigin": "\n\nThe **`crossOrigin`** property of the [HTMLLinkElement] interface specifies the Cross-Origin Resource Sharing () setting to use when retrieving the resource.",
      "fetchpriority": "\n\nThe **`fetchPriority`** property of the\n[HTMLLinkElement] interface represents a hint given to the browser\non how it should prioritize the preload of the given resource relative to other\nresources of the same type.",
      "referrerpolicy": "\n\nThe\n**`HTMLLinkElement.referrerPolicy`**\nproperty reflects the HTML [`referrerpolicy`](/en-US/docs/Web/HTML/Element/link#referrerpolicy) attribute of the\n`link` element defining which referrer is sent when fetching the\nresource.\n\nSee the HTTP  header for details.",
      "rel": "\n\nThe **`HTMLLinkElement.rel`** property reflects the [`rel`](/en-US/docs/Web/HTML/Attributes/rel) attribute. It is a string containing a space-separated list of link types indicating the relationship between the resource represented by the `link` element and the current document.\n\nThe most common use of this attribute is to specify a link to an external style sheet:\nthe property is set to `stylesheet`, and the [`href`](/en-US/docs/Web/HTML/Element/link#href)\nattribute is set to the URL of an external style sheet to format the page.",
      "rellist": "\n\nThe **`HTMLLinkElement.relList`** read-only property reflects the [`rel`](/en-US/docs/Web/HTML/Attributes/rel) attribute. It is a live [DOMTokenList] containing the set of link types indicating the relationship between the resource represented by the `link` element and the current document.\n\nThe property itself is read-only, meaning you can not substitute the\n[DOMTokenList] by another one, but the content of the returned list can be\nchanged.",
      "sheet": "\n\nThe read-only **`sheet`** property of the [HTMLLinkElement] interface\ncontains the stylesheet associated with that element.\n\nA stylesheet is associated to an `HTMLLinkElement` if `rel=\"stylesheet\"` is used with `<link>`."
    }
  },
  "htmlmapelement": {
    "docs": "\n\nThe **`HTMLMapElement`** interface provides special properties and methods (beyond those of the regular object [HTMLElement] interface it also has available to it by inheritance) for manipulating the layout and presentation of map elements.\n\n"
  },
  "htmlmarqueeelement": {
    "docs": "\n\nThe **`HTMLMarqueeElement`** interface provides methods to manipulate `marquee` elements.\n\nIt inherits properties and methods from the [HTMLElement] interface.\n\n"
  },
  "htmlmediaelement": {
    "docs": "\n\nThe **`HTMLMediaElement`** interface adds to [HTMLElement] the properties and methods needed to support basic media-related capabilities that are common to audio and video.\n\nThe [HTMLVideoElement] and [HTMLAudioElement] elements both inherit this interface.\n\n",
    "properties": {
      "abort_event": "\n\nThe **`abort`** event is fired when the resource was not fully loaded, but not as the result of an error.\n\nThis event is not cancelable and does not bubble.",
      "audiotracks": "\n\nThe read-only **`audioTracks`**\nproperty on [HTMLMediaElement] objects returns\nan [AudioTrackList] object listing all of the [AudioTrack]\nobjects representing the media element's audio tracks.\n\nThe media element may be\neither an `audio` element or a `video` element.\n\nThe returned list is _live_; that is, as tracks are added to and removed from\nthe media element, the list's contents change dynamically. Once you have a reference to\nthe list, you can monitor it for changes to detect when new audio tracks are added or\nexisting ones removed. See [AudioTrackList events](/en-US/docs/Web/API/AudioTrackList#events)\nto learn more about watching for changes to a media element's track list.",
      "autoplay": "\n\nThe **`HTMLMediaElement.autoplay`**\nproperty reflects the [`autoplay`](/en-US/docs/Web/HTML/Element/video#autoplay) HTML attribute, indicating\nwhether playback should automatically begin as soon as enough media is available to do\nso without interruption.\n\nA media element whose source is a [MediaStream] and whose\n`autoplay` property is `true` will begin playback when it becomes\nactive (that is, when [MediaStream.active] becomes `true`).\n\n> **Note:** Sites which automatically play audio (or videos with an audio\n> track) can be an unpleasant experience for users, so it should be avoided when\n> possible. If you must offer autoplay functionality, you should make it opt-in\n> (requiring a user to specifically enable it). However, autoplay can be useful when\n> creating media elements whose source will be set at a later time, under user control.\n\nFor a much more in-depth look at autoplay, autoplay blocking, and how to respond when\nautoplay is blocked by the user's browser, see our article [Autoplay guide for media and Web Audio APIs](/en-US/docs/Web/Media/Autoplay_guide).",
      "buffered": "\n\nThe **`buffered`** read-only property of [HTMLMediaElement] objects returns a new static [normalized `TimeRanges` object](/en-US/docs/Web/API/TimeRanges#normalized_timeranges_objects) that represents the ranges of the media resource, if any, that the user agent has buffered at the moment the `buffered` property is accessed.\n\n> **Note:** This feature is not available in [Web Workers](/en-US/docs/Web/API/Web_Workers_API).",
      "canplay_event": "\n\nThe `canplay` event is fired when the user agent can play the media, but estimates that not enough data has been loaded to play the media up to its end without having to stop for further buffering of content.\n\nThis event is not cancelable and does not bubble.",
      "canplaythrough_event": "\n\nThe `canplaythrough` event is fired when the user agent can play the media, and estimates that enough data has been loaded to play the media up to its end without having to stop for further buffering of content.\n\nThis event is not cancelable and does not bubble.",
      "canplaytype": "\n\nThe [HTMLMediaElement] method **`canPlayType()`** reports how likely it is that the current browser will be able to play media of a given MIME type.\n\n> **Note:** This feature is not available in [Web Workers](/en-US/docs/Web/API/Web_Workers_API).",
      "capturestream": "\n\nThe **`captureStream()`** method of the [HTMLMediaElement] interface returns a [MediaStream] object which is streaming a real-time capture of the content being rendered in the media element.\n\nThis can be used, for example, as a source for a [WebRTC](/en-US/docs/Web/API/WebRTC_API) [RTCPeerConnection].",
      "controller": "\n\nThe **`HTMLMediaElement.controller`** property represents the media controller assigned to the element.",
      "controls": "\n\nThe **`HTMLMediaElement.controls`** property reflects the\n[`controls`](/en-US/docs/Web/HTML/Element/video#controls) HTML attribute, which controls whether user\ninterface controls for playing the media item will be displayed.",
      "controlslist": "\n\nThe **`controlsList`** property of the\n[HTMLMediaElement] interface returns a DOMTokenList that helps the user\nagent select what controls to show on the media element whenever the user agent shows\nits own set of controls. The DOMTokenList takes one or more of three possible values:\n`nodownload`, `nofullscreen`, and `noremoteplayback`.",
      "crossorigin": "\n\nThe **`HTMLMediaElement.crossOrigin`** property is the CORS setting for this media element. See [CORS settings attributes](/en-US/docs/Web/HTML/Attributes/crossorigin) for details.",
      "currentsrc": "\n\nThe **`HTMLMediaElement.currentSrc`** property contains the\nabsolute URL of the chosen media resource. This could happen, for example, if the web\nserver selects a media file based on the resolution of the user's display. The value\nis an empty string if the `networkState` property is `EMPTY`.",
      "currenttime": "\n\nThe [HTMLMediaElement] interface's\n**`currentTime`** property specifies the current playback time\nin seconds.\n\nChanging the value of `currentTime` seeks the media to\nthe new time.",
      "defaultmuted": "\n\nThe **`HTMLMediaElement.defaultMuted`** property reflects the [`muted`](/en-US/docs/Web/HTML/Element/video#muted) HTML attribute, which indicates whether the media element's audio output should be muted by default. This property has no dynamic effect. To mute and unmute the audio output, use the [HTMLMediaElement.muted] property.",
      "defaultplaybackrate": "\n\nThe **`HTMLMediaElement.defaultPlaybackRate`** property indicates the default playback rate for the media.",
      "disableremoteplayback": "\n\nThe **`disableRemotePlayback`** property of the [HTMLMediaElement] interface determines whether the media element is allowed to have a remote playback UI.",
      "duration": "\n\nThe _read-only_ [HTMLMediaElement]\nproperty **`duration`** indicates the length of the element's\nmedia in seconds.",
      "durationchange_event": "\n\nThe `durationchange` event is fired when the `duration` attribute has been updated.",
      "emptied_event": "\n\nThe `emptied` event is fired when the media has become empty; for example, this event is sent if the media has already been loaded (or partially loaded), and the `load()` method is called to reload it.\n\nThis event is not cancelable and does not bubble.",
      "encrypted_event": "\n\nThe `encrypted` event is fired when the media encounters some initialization data indicating it is encrypted.\n\nThis event is not cancelable and does not bubble.",
      "ended": "\n\nThe **`HTMLMediaElement.ended`** property indicates whether the media\nelement has ended playback.",
      "ended_event": "\n\nThe `ended` event is fired when playback or streaming has stopped because the end of the media was reached or because no further data is available.\n\nThis event occurs based upon [HTMLMediaElement] (`audio` and `video`) fire `ended` when playback reaches the end of the media.\n\nThis event is not cancelable and does not bubble.",
      "error": "\n\nThe **`HTMLMediaElement.error`** property is the\n[MediaError] object for the most recent error, or `null` if\nthere has not been an error. When an [HTMLMediaElement/error_event] event is received by the\nelement, you can determine details about what happened by examining this object.",
      "error_event": "\n\nThe **`error`** event is fired when the resource could not be loaded due to an error (for example, a network connectivity problem).\n\nThis event is not cancelable and does not bubble.",
      "fastseek": "\n\nThe **`HTMLMediaElement.fastSeek()`** method quickly seeks the\nmedia to the new time with precision tradeoff.\n\n> **Note:** If you need to seek with precision, you should set [`HTMLMediaElement.currentTime`](/en-US/docs/Web/API/HTMLMediaElement/currentTime)\n> instead.",
      "load": "\n\nThe [HTMLMediaElement] method\n**`load()`** resets the media element to its initial state and\nbegins the process of selecting a media source and loading the media in preparation\nfor playback to begin at the beginning.\n\nThe amount of media data that is\nprefetched is determined by the value of the element's [`preload`](/en-US/docs/Web/HTML/Element/video#preload) attribute.\n\nThis method is generally only useful when you've made dynamic changes to the set of\nsources available for the media element, either by changing the element's\n[`src`](/en-US/docs/Web/HTML/Element/video#src) attribute or by adding or removing\n`source` elements nested within the media element itself.\n`load()` will reset the element and rescan the available sources, thereby\ncausing the changes to take effect.",
      "loadeddata_event": "\n\nThe **`loadeddata`** event is fired when the frame at the current playback position of the media has finished loading; often the first frame.\n\n> **Note:** This event will not fire in mobile/tablet devices if data-saver is on in browser settings.",
      "loadedmetadata_event": "\n\nThe `loadedmetadata` event is fired when the metadata has been loaded.",
      "loadstart_event": "\n\nThe **`loadstart`** event is fired when the browser has started to load a resource.",
      "loop": "\n\nThe **`HTMLMediaElement.loop`** property reflects the [`loop`](/en-US/docs/Web/HTML/Element/video#loop) HTML attribute, which controls whether the media element should start over when it reaches the end.",
      "mediagroup": "\n\nThe **`HTMLMediaElement.mediaGroup`** property reflects the [`mediaGroup`](/en-US/docs/Web/HTML/Element/video#mediagroup) HTML attribute, which indicates the name of the group of elements it belongs to. A group of media elements shares a common `controller`.",
      "mediakeys": "\n\nThe read-only **`HTMLMediaElement.mediaKeys`** property returns a [MediaKeys] object, that is a set of keys that the element can use for decryption of media data during playback.",
      "muted": "\n\nThe **`HTMLMediaElement.muted`** property indicates whether the media\nelement is muted.",
      "networkstate": "\n\nThe\n**`HTMLMediaElement.networkState`** property indicates the\ncurrent state of the fetching of media over the network.",
      "pause": "\n\nThe **`HTMLMediaElement.pause()`** method will pause playback\nof the media, if the media is already in a paused state this method will have no effect.",
      "pause_event": "\n\nThe `pause` event is sent when a request to pause an activity is handled and the activity has entered its paused state, most commonly after the media has been paused through a call to the element's [HTMLMediaElement.pause] method.\n\nThe event is sent once the `pause()` method returns and after the media element's [HTMLMediaElement.paused] property has been changed to `true`.\n\nThis event is not cancelable and does not bubble.",
      "paused": "\n\nThe read-only **`HTMLMediaElement.paused`** property\ntells whether the media element is paused.",
      "play": "\n\nThe [HTMLMediaElement]\n**`play()`** method attempts to begin playback of the media.\nIt returns a `Promise` which is resolved when playback has been\nsuccessfully started.\n\nFailure to begin playback for any reason, such as\npermission issues, result in the promise being rejected.",
      "play_event": "\n\nThe `play` event is fired when the `paused` property is changed from `true` to `false`, as a result of the `play` method, or the `autoplay` attribute.\n\nThis event is not cancelable and does not bubble.",
      "playbackrate": "\n\nThe **`HTMLMediaElement.playbackRate`** property sets the rate at which the media is being played back. This is used to implement user controls for fast forward, slow motion, and so forth. The normal playback rate is multiplied by this value to obtain the current rate, so a value of 1.0 indicates normal speed.\n\nIf `playbackRate` is negative, the media is played backwards.\n\nThe audio is muted when the fast forward or slow motion is outside a useful range (for example, Gecko mutes the sound outside the range `0.25` to `4.0`).\n\nThe pitch of the audio is corrected by default. You can disable pitch correction using the [HTMLMediaElement.preservesPitch] property.",
      "playing_event": "\n\nThe `playing` event is fired after playback is first started, and whenever it is restarted. For example it is fired when playback resumes after having been paused or delayed due to lack of data.\n\nThis event is not cancelable and does not bubble.",
      "preservespitch": "\n\nThe **`HTMLMediaElement.preservesPitch`** property determines whether or not the browser should adjust the pitch of the audio to compensate for changes to the playback rate made by setting [HTMLMediaElement.playbackRate].",
      "progress_event": "\n\nThe **`progress`** event is fired periodically as the browser loads a resource.\n\nThis event is not cancelable and does not bubble.",
      "ratechange_event": "\n\nThe `ratechange` event is fired when the playback rate has changed.\n\nThis event is not cancelable and does not bubble.",
      "readystate": "\n\nThe **`HTMLMediaElement.readyState`** property indicates the\nreadiness state of the media.",
      "remote": "\n\nThe **`remote`** read-only property of the [HTMLMediaElement] interface returns the [RemotePlayback] object associated with the media element. The `RemotePlayback` object allow the control of remote devices playing the media.",
      "seekable": "\n\nThe **`seekable`** read-only property of [HTMLMediaElement] objects returns a new static [normalized `TimeRanges` object](/en-US/docs/Web/API/TimeRanges#normalized_timeranges_objects) that represents the ranges of the media resource, if any, that the user agent is able to seek to at the time `seekable` property is accessed.",
      "seeked_event": "\n\nThe `seeked` event is fired when a seek operation completed, the current playback position has changed, and the Boolean `seeking` attribute is changed to `false`.\n\nThis event is not cancelable and does not bubble.",
      "seeking_event": "\n\nThe `seeking` event is fired when a seek operation starts, meaning the Boolean `seeking` attribute has changed to `true` and the media is seeking a new position.\n\nThis event is not cancelable and does not bubble.",
      "seektonextframe": "\n\nThe **`HTMLMediaElement.seekToNextFrame()`** method\nasynchronously advances the current play position to the next frame in the media.\n\n> **Warning:** This non-standard method is part of an experimentation process around support for\n> non-real-time access to media for tasks including filtering, editing, and so forth.\n> You should _not_ use this method in production code, because its implementation\n> may change—or be removed outright—without notice. You are, however, invited to\n> experiment with it.\n\nThis method lets you access frames of video media without the media being performed in\nreal time. This also lets you access media using frames as a seek unit rather than\ntimecodes (albeit only by seeking one frame at a time until you get to the frame you\nwant). Possible uses for this method include filtering and editing of video content.\n\nThis method returns immediately, returning a `Promise`, whose fulfillment\nhandler is called when the seek operation is complete. In addition, a\n[HTMLMediaElement/seeked_event] event is sent to let interested parties know that a seek has taken\nplace. If the seek fails because the media is already at the last frame, a\n[HTMLMediaElement/seeked_event] event occurs, followed immediately by an [HTMLMediaElement/ended_event] event.\n\nIf there is no video on the media element, or the media isn't seekable, nothing\nhappens.",
      "setmediakeys": "\n\nThe **`setMediaKeys()`** method of the\n[HTMLMediaElement] interface returns a `Promise` that resolves\nto the passed [MediaKeys], which are those used to decrypt media during\nplayback.",
      "setsinkid": "\n\nThe **`HTMLMediaElement.setSinkId()`** method of the [Audio Output Devices API](/en-US/docs/Web/API/Audio_Output_Devices_API) sets the ID of the audio device to use for output and returns a `Promise`.\n\nThis only works when the application is permitted to use the specified device.\nFor more information see the [security requirements](#security_requirements) below.",
      "sinkid": "\n\nThe **`HTMLMediaElement.sinkId`** read-only property of the [Audio Output Devices API](/en-US/docs/Web/API/Audio_Output_Devices_API) returns a string that is the unique ID of the device to be used for playing audio output.\n\nThis ID should be one of the [MediaDeviceInfo.deviceId] values returned from [MediaDevices.enumerateDevices], `id-multimedia`, or `id-communications`.\nIf the user agent default device is being used, it returns an empty string.",
      "src": "\n\nThe **`HTMLMediaElement.src`** property reflects the value of\nthe HTML media element's `src` attribute, which indicates the URL of a media\nresource to use in the element.\n\n> **Note:** The best way to know the URL of the media resource currently\n> in active use in this element is to look at the value of the\n> [HTMLMediaElement.currentSrc] attribute, which also takes\n> into account selection of a best or preferred media resource from a list provided in\n> an [HTMLSourceElement] (which represents a `source`\n> element).",
      "srcobject": "\n\nThe **`srcObject`** property of the\n[HTMLMediaElement] interface sets or returns the object which serves as\nthe source of the media associated with the [HTMLMediaElement].\n\nThe object can be a [MediaStream], a [MediaSource], a\n[Blob], or a [File] (which inherits from `Blob`).\n\n> **Note:** As of March 2020, only Safari has full support for `srcObject`, i.e. using `MediaSource`, `MediaStream`, `Blob`, and `File` objects as values. Other browsers support `MediaStream` objects; until they catch up, consider falling back to creating a URL with [URL.createObjectURL_static] and assigning it to [HTMLMediaElement.src] (see below for an example). In addition, as of version 108 Chromium supports attaching a dedicated worker `MediaSource` object by assigning that object's [MediaSourceHandle] instance (transferred from the worker) to `srcObject`.",
      "stalled_event": "\n\nThe `stalled` event is fired when the user agent is trying to fetch media data, but data is unexpectedly not forthcoming.\n\nThis event is not cancelable and does not bubble.",
      "suspend_event": "\n\nThe `suspend` event is fired when media data loading has been suspended.\n\nThis event is not cancelable and does not bubble.",
      "texttracks": "\n\nThe read-only **`textTracks`**\nproperty on [HTMLMediaElement] objects returns a\n[TextTrackList] object listing all of the [TextTrack]\nobjects representing the media element's text tracks, in the same order as in\nthe list of text tracks.\n\nYou can detect when tracks are added to and removed from an\n[`<audio>`](/en-US/docs/Web/HTML/Element/audio) or\n[`<video>`](/en-US/docs/Web/HTML/Element/video) element\nusing the `addtrack` and `removetrack` events. However, these\nevents aren't sent directly to the media element itself. Instead, they're sent to the\ntrack list object of the [`HTMLMediaElement`](/en-US/docs/Web/API/HTMLMediaElement)\nthat corresponds to the type of track that was added to the element\n\nThe returned list is _live_; that is, as tracks are added to and removed from\nthe media element, the list's contents change dynamically. Once you have a reference to\nthe list, you can monitor it for changes to detect when new text tracks are added or\nexisting ones removed.\n\nSee [TextTrackList events](/en-US/docs/Web/API/TextTrackList#events) to learn\nmore about watching for changes to a media element's track list.",
      "timeupdate_event": "\n\nThe `timeupdate` event is fired when the time indicated by the `currentTime` attribute has been updated.\n\nThe event frequency is dependent on the system load, but will be thrown between about 4Hz and 66Hz (assuming the event handlers don't take longer than 250ms to run). User agents are encouraged to vary the frequency of the event based on the system load and the average cost of processing the event each time, so that the UI updates are not any more frequent than the user agent can comfortably handle while decoding the video.\n\nThis event is not cancelable and does not bubble.",
      "videotracks": "\n\nThe read-only **`videoTracks`**\nproperty on [HTMLMediaElement] objects returns a\n[VideoTrackList] object listing all of the [VideoTrack]\nobjects representing the media element's video tracks.\n\nThe returned list is _live_; that is, as tracks are added to and removed from\nthe media element, the list's contents change dynamically. Once you have a reference to\nthe list, you can monitor it for changes to detect when new video tracks are added or\nexisting ones removed. See [VideoTrackList events](/en-US/docs/Web/API/VideoTrackList#events)\nto learn more about watching for changes to a media element's track list.",
      "volume": "\n\nThe **`HTMLMediaElement.volume`** property sets the volume at\nwhich the media will be played.",
      "volumechange_event": "\n\nThe `volumechange` event is fired when either the [HTMLMediaElement.volume] attribute or the [HTMLMediaElement.muted] attribute has changed.\n\nThis event is not cancelable and does not bubble.",
      "waiting_event": "\n\nThe `waiting` event is fired when playback has stopped because of a temporary lack of data.\n\nThis event is not cancelable and does not bubble."
    }
  },
  "htmlmenuelement": {
    "docs": "\n\nThe **`HTMLMenuElement`** interface provides additional properties (beyond those inherited from the [HTMLElement] interface) for manipulating a `menu` element.\n`<menu>` is a semantic alternative to the `ul` element.\n\n"
  },
  "htmlmenuitemelement": {
    "docs": "\n\nThe **`HTMLMenuItemElement`** interface provides special properties (beyond those defined on the regular [HTMLElement] interface it also has available to it by inheritance) for manipulating `menuitem` elements.\n\n"
  },
  "htmlmetaelement": {
    "docs": "\n\nThe **`HTMLMetaElement`** interface contains descriptive metadata about a document provided in HTML as [`<meta>`](/en-US/docs/Web/HTML/Element/meta) elements.\nThis interface inherits all of the properties and methods described in the [HTMLElement] interface.\n\n",
    "properties": {
      "content": "\n\nThe **`HTMLMetaElement.content`** property gets or sets the `content` attribute of pragma directives and named `meta` data in conjunction with [HTMLMetaElement.name] or [HTMLMetaElement.httpEquiv].\nFor more information, see the [content](/en-US/docs/Web/HTML/Element/meta#content) attribute.",
      "httpequiv": "\n\nThe **`HTMLMetaElement.httpEquiv`** property gets or sets the pragma directive or an HTTP response header name for the [HTMLMetaElement.content] attribute.\nFor more details on the possible values, see the [http-equiv](/en-US/docs/Web/HTML/Element/meta#http-equiv) attribute.",
      "media": "\n\nThe **`HTMLMetaElement.media`** property enables specifying the media for `theme-color` metadata.\n\nThe `theme-color` property enables setting the color of the browser's toolbar or UI in browsers and operating systems that support this property.\nThe `media` property enables setting different theme colors for different `media` values.",
      "name": "\n\nThe **`HTMLMetaElement.name`** property is used in combination with [HTMLMetaElement.content] to define the name-value pairs for the metadata of a document.\nThe `name` attribute defines the metadata name and the `content` attribute defines the value.",
      "scheme": "\n\nThe **`HTMLMetaElement.scheme`** property defines the scheme of the value in the [HTMLMetaElement.content] attribute.\nThe `scheme` property was created to enable providing additional information to be used to interpret the value of the `content` property. The `scheme` property takes as its value a scheme format (i.e. `YYYY-MM-DD`) or scheme format name (i.e. `ISBN`), or a URI providing more information regarding the scheme format. The scheme defines the format of the value of the `content` attribute.\nThe `scheme` content is interpreted as an extension of the element's [HTMLMetaElement.name] if a browser or user agent recognizes the scheme.\n\nThis property is deprecated and should not be used on new web pages."
    }
  },
  "htmlmeterelement": {
    "docs": "\n\nThe HTML `meter` elements expose the **`HTMLMeterElement`** interface, which provides special properties and methods (beyond the [HTMLElement] object interface they also have available to them by inheritance) for manipulating the layout and presentation of `meter` elements.\n\n",
    "properties": {
      "labels": "\n\nThe **`HTMLMeterElement.labels`** read-only property returns a\n[NodeList] of the `label` elements associated with the\n`meter` element."
    }
  },
  "htmlmodelement": {
    "docs": "\n\nThe **`HTMLModElement`** interface provides special properties (beyond the regular methods and properties available through the [HTMLElement] interface they also have available to them by inheritance) for manipulating modification elements, that is `del` and `ins`.\n\n"
  },
  "htmlobjectelement": {
    "docs": "\n\nThe **`HTMLObjectElement`** interface provides special properties and methods (beyond those on the [HTMLElement] interface it also has available to it by inheritance) for manipulating the layout and presentation of `object` element, representing external resources.\n\n",
    "properties": {
      "checkvalidity": "\n\nThe **`checkValidity()`** method of the\n[HTMLObjectElement] interface returns a boolean value that always\nis true, because object objects are never candidates for constraint validation.",
      "contentdocument": "\n\nThe **`contentDocument`** read-only property of\nthe [HTMLObjectElement] interface Returns a [Document]\nrepresenting the active document of the object element's nested browsing context, if\nany; otherwise null.",
      "contentwindow": "\n\nThe **`contentWindow`** read-only property of\nthe [HTMLObjectElement] interface returns a \nrepresenting the window proxy of the object element's nested browsing context, if any;\notherwise null.",
      "data": "\n\nThe **`data`** property of the\n[HTMLObjectElement] interface returns a string that\nreflects the [`data`](/en-US/docs/Web/HTML/Element/object#data) HTML attribute, specifying the address\nof a resource's data.",
      "form": "\n\nThe **`form`** read-only property of the\n[HTMLObjectElement] interface returns a [HTMLFormElement]\nrepresenting the object element's form owner, or null if there isn't one.",
      "height": "\n\nThe **`height`** property of the\n[HTMLObjectElement] interface Returns a string that\nreflects the [`height`](/en-US/docs/Web/HTML/Element/object#height) HTML attribute, specifying the\ndisplayed height of the resource in CSS pixels.",
      "name": "\n\nThe **`name`** property of the\n[HTMLObjectElement] interface returns a string that\nreflects the [`name`](/en-US/docs/Web/HTML/Element/object#name) HTML attribute, specifying the name of\nthe browsing context.",
      "setcustomvalidity": "\n\nThe **`setCustomValidity()`** method of the\n[HTMLObjectElement] interface sets a custom validity message for the\nelement.",
      "type": "\n\nThe **`type`** property of the\n[HTMLObjectElement] interface returns a string that\nreflects the [`type`](/en-US/docs/Web/HTML/Element/object#type) HTML attribute, specifying the MIME type\nof the resource.",
      "usemap": "\n\nThe **`useMap`** property of the\n[HTMLObjectElement] interface returns a string that\nreflects the [`usemap`](/en-US/docs/Web/HTML/Element/object#usemap) HTML attribute, specifying a\n`map` element to use.",
      "validationmessage": "\n\nThe **`validationMessage`** read-only property\nof the [HTMLObjectElement] interface returns a string\nrepresenting a localized message that describes the validation constraints that the\ncontrol does not satisfy (if any). This is the empty string if the control is not a\ncandidate for constraint validation (willValidate is false), or it satisfies its\nconstraints.",
      "validity": "\n\nThe **`validity`** read-only property of the\n[HTMLObjectElement] interface returns a [ValidityState] with\nthe validity states that this element is in.",
      "width": "\n\nThe **`width`** property of the\n[HTMLObjectElement] interface returns a string that\nreflects the [`width`](/en-US/docs/Web/HTML/Element/object#width) HTML attribute, specifying the\ndisplayed width of the resource in CSS pixels.",
      "willvalidate": "\n\nThe **`willValidate`** read-only property of\nthe [HTMLObjectElement] interface returns a boolean value that\nindicates whether the element is a candidate for constraint validation. Always false for\nHTMLObjectElement objects."
    }
  },
  "htmlolistelement": {
    "docs": "\n\nThe **`HTMLOListElement`** interface provides special properties (beyond those defined on the regular [HTMLElement] interface it also has available to it by inheritance) for manipulating ordered list elements.\n\n"
  },
  "htmloptgroupelement": {
    "docs": "\n\nThe **`HTMLOptGroupElement`** interface provides special properties and methods (beyond the regular [HTMLElement] object interface they also have available to them by inheritance) for manipulating the layout and presentation of `optgroup` elements.\n\n"
  },
  "htmloptionelement": {
    "docs": "\n\nThe **`HTMLOptionElement`** interface represents `option` elements and inherits all properties and methods of the [HTMLElement] interface.\n\n",
    "properties": {
      "option": "\n\nThe **`Option()`** constructor creates a new\n[HTMLOptionElement]."
    }
  },
  "htmloptionscollection": {
    "docs": "\n\nThe **`HTMLOptionsCollection`** interface represents a collection of [`<option>`](/en-US/docs/Web/HTML/Element/option) HTML elements (in document order) and offers methods and properties for selecting from the list as well as optionally altering its items. This object is returned only by the `options` property of [select](/en-US/docs/Web/API/HTMLSelectElement).\n\n"
  },
  "htmloutputelement": {
    "docs": "\n\nThe **`HTMLOutputElement`** interface provides properties and methods (beyond those inherited from [HTMLElement]) for manipulating the layout and presentation of `output` elements.\n\n",
    "properties": {
      "labels": "\n\nThe **`HTMLOutputElement.labels`** read-only property returns a\n[NodeList] of the `label` elements associated with the\n`output` element."
    }
  },
  "htmlparagraphelement": {
    "docs": "\n\nThe **`HTMLParagraphElement`** interface provides special properties (beyond those of the regular [HTMLElement] object interface it inherits) for manipulating `p` elements.\n\n"
  },
  "htmlparamelement": {
    "docs": "\n\nThe **`HTMLParamElement`** interface provides special properties (beyond those of the regular [HTMLElement] object interface it inherits) for manipulating `param` elements, representing a pair of a key and a value that acts as a parameter for an `object` element.\n\n"
  },
  "htmlpictureelement": {
    "docs": "\n\nThe **`HTMLPictureElement`** interface represents a `picture` HTML element. It doesn't implement specific properties or methods.\n\n"
  },
  "htmlpreelement": {
    "docs": "\n\nThe **`HTMLPreElement`** interface exposes specific properties and methods (beyond those of the [HTMLElement] interface it also has available to it by inheritance) for manipulating a block of preformatted text (`pre`).\n\n"
  },
  "htmlprogresselement": {
    "docs": "\n\nThe **`HTMLProgressElement`** interface provides special properties and methods (beyond the regular [HTMLElement] interface it also has available to it by inheritance) for manipulating the layout and presentation of `progress` elements.\n\n",
    "properties": {
      "labels": "\n\nThe **`HTMLProgressElement.labels`** read-only property returns\na [NodeList] of the `label` elements associated with the\n`progress` element."
    }
  },
  "htmlquoteelement": {
    "docs": "\n\nThe **`HTMLQuoteElement`** interface provides special properties and methods (beyond the regular [HTMLElement] interface it also has available to it by inheritance) for manipulating quoting elements, like `blockquote` and `q`, but not the `cite` element.\n\n"
  },
  "htmlscriptelement": {
    "docs": "\n\nHTML `script` elements expose the **`HTMLScriptElement`** interface, which provides special properties and methods for manipulating the behavior and execution of `<script>` elements (beyond the inherited [HTMLElement] interface).\n\nJavaScript files should be served with the `text/javascript` [MIME type](/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types), but browsers are lenient and block them only if the script is served with an image type (`image/*`), video type (`video/*`), audio type (`audio/*`), or `text/csv`. If the script is blocked, its element receives an [HTMLElement/error_event] event; otherwise, it receives a [Window/load_event] event.\n\n",
    "properties": {
      "crossorigin": "\n\nThe **`crossOrigin`** property of the [HTMLScriptElement] interface reflects the  settings for the script element. For classic scripts from other [origins](/en-US/docs/Glossary/Origin), this controls if full error information will be exposed. For module scripts, it controls the script itself and any script it imports. See [CORS settings attributes](/en-US/docs/Web/HTML/Attributes/crossorigin) for details.",
      "referrerpolicy": "\n\nThe **`referrerPolicy`** property of the\n[HTMLScriptElement] interface reflects the HTML\n[`referrerpolicy`](/en-US/docs/Web/HTML/Element/script#referrerpolicy) of the `script` element, which defines how the referrer is set when fetching the script and any scripts it imports.",
      "supports_static": "\n\nThe **`supports()`** static method of the [HTMLScriptElement] interface provides a simple and consistent method to feature-detect what types of scripts are supported by the user agent.\n\nThe method is expected to return `true` for classic and module scripts, which are supported by most modern browsers."
    }
  },
  "htmlselectelement": {
    "docs": "\n\nThe **`HTMLSelectElement`** interface represents a `select` HTML Element. These elements also share all of the properties and methods of other HTML elements via the [HTMLElement] interface.\n\n",
    "properties": {
      "add": "\n\nThe **`HTMLSelectElement.add()`** method adds an element to the\ncollection of `option` elements for this `select` element.",
      "checkvalidity": "\n\nThe **`HTMLSelectElement.checkValidity()`** method checks\nwhether the element has any constraints and whether it satisfies them. If the element\nfails its constraints, the browser fires a cancelable [HTMLSelectElement/invalid_event] event at the\nelement, and then returns `false`.",
      "disabled": "\n\nThe **`HTMLSelectElement.disabled`** property is a boolean value that reflects the\n[`disabled`](/en-US/docs/Web/HTML/Element/select#disabled)\nHTML attribute, which indicates whether the control is disabled. If it is disabled, it\ndoes not accept clicks. A disabled element is unusable and un-clickable.",
      "form": "\n\nThe **`HTMLSelectElement.form`** read-only property returns a\n[HTMLFormElement] representing the form that this element is associated\nwith. If the element is not associated with a `form` element, then\nit returns `null`.",
      "item": "\n\nThe **`HTMLSelectElement.item()`** method returns the\n[Element] corresponding to the [HTMLOptionElement] whose\nposition in the options list corresponds to the index given in the parameter, or\n`null` if there are none.\n\nIn JavaScript, using the array bracket syntax with an `unsigned long`, like\n`selectElt[index]` is equivalent to\n`selectElt.namedItem(index)`.",
      "labels": "\n\nThe **`HTMLSelectElement.labels`** read-only property returns a\n[NodeList] of the `label` elements associated with the\n`select` element.",
      "nameditem": "\n\nThe **`HTMLSelectElement.namedItem()`** method returns the\n[HTMLOptionElement] corresponding to the [HTMLOptionElement]\nwhose `name` or `id` match the specified name, or\n`null` if no option matches.\n\nIn JavaScript, using `selectElt.namedItem('value')` is equivalent to `selectElt.options.namedItem('value')`.",
      "options": "\n\nThe **`HTMLSelectElement.options`** read-only property returns\na [HTMLOptionsCollection] of the `option` elements\ncontained by the `select` element.",
      "remove": "\n\nThe **`HTMLSelectElement.remove()`** method removes the element\nat the specified index from the options collection for this select element.",
      "selectedindex": "\n\nThe **`HTMLSelectElement.selectedIndex`** property is a\n`long` that reflects the index of the first or last selected\n`option` element, depending on the value of `multiple`. The\nvalue `-1` indicates that no element is selected.",
      "selectedoptions": "\n\nThe **read-only** [HTMLSelectElement] property\n**`selectedOptions`** contains a list of the\n`option` elements contained within the `select`\nelement that are currently selected. The list of selected options is an\n[HTMLCollection] object with one entry per currently selected option.\n\nAn option is considered selected if it has an [HTMLOptionElement.selected]\nattribute.",
      "setcustomvalidity": "\n\nThe **`HTMLSelectElement.setCustomValidity()`** method sets the\ncustom validity message for the selection element to the specified message. Use the\nempty string to indicate that the element does _not_ have a custom validity\nerror.",
      "showpicker": "\n\nThe **`HTMLSelectElement.showPicker()`** method displays the browser picker for a `select` element.\n\nThis is the same picker that would normally be displayed when the element is selected, but can be triggered from a button press or other user interaction.",
      "type": "\n\nThe **`HTMLSelectElement.type`**\nread-only property returns the form control's `type`."
    }
  },
  "htmlslotelement": {
    "docs": "\n\nThe **`HTMLSlotElement`** interface of the [Shadow DOM API](/en-US/docs/Web/API/Web_components/Using_shadow_DOM) enables access to the name and assigned nodes of an HTML `slot` element.\n\n",
    "properties": {
      "assign": "\n\nThe **`assign()`** method of the [HTMLSlotElement] interface sets the slot's _manually assigned nodes_ to an ordered set of slottables. The manually assigned nodes set is initially empty until nodes are assigned using `assign()`.\n\n> **Note:** you cannot mix manually (imperative) and named (declarative, automatic) slot assignments. Therefore, for this method to work, the shadow tree needs to have been [created](/en-US/docs/Web/API/Element/attachShadow) with the `slotAssignment: \"manual\"` option.",
      "assignedelements": "\n\nThe **`assignedElements()`** method of the [HTMLSlotElement]\ninterface returns a sequence of the elements assigned to this slot (and no\nother nodes).\n\nIf the `flatten` option is set to `true`, it returns a sequence of both the elements assigned to this slot, as well as the elements assigned to any other slots that are descendants of this slot. If no assigned elements are found, it returns the slot's fallback content.",
      "assignednodes": "\n\nThe **`assignedNodes()`** method of the [HTMLSlotElement] interface returns a sequence of the nodes assigned to this slot.\n\nIf the `flatten` option is set to `true`, it returns a sequence of both the nodes assigned to this slot, as well as the nodes assigned to any other slots that are descendants of this slot. If no assigned nodes are found, it returns the slot's fallback content.",
      "name": "\n\nThe **`name`** property of the [HTMLSlotElement]\ninterface returns or sets the slot name. A slot is a placeholder inside a web component\nthat users can fill with their own markup.",
      "slotchange_event": "\n\nThe **`slotchange`** event is fired on an [HTMLSlotElement] instance (`slot` element) when the node(s) contained in that slot change.\n\n> **Note:** the `slotchange` event doesn't fire if the children of a slotted node change — only if you change (e.g. add or delete) the actual nodes themselves.\n\nIn order to trigger a **slotchange** event, one has to set or remove the `slot` attribute.\n\nThis event is not cancelable."
    }
  },
  "htmlsourceelement": {
    "docs": "\n\nThe **`HTMLSourceElement`** interface provides special properties (beyond the regular [HTMLElement] object interface it also has available to it by inheritance) for manipulating `source` elements.\n\n"
  },
  "htmlspanelement": {
    "docs": "\n\nThe **`HTMLSpanElement`** interface represents a `span` element and derives from the [HTMLElement] interface, but without implementing any additional properties or methods.\n\n"
  },
  "htmlstyleelement": {
    "docs": "\n\nThe **`HTMLStyleElement`** interface represents a `style` element. It inherits properties and methods from its parent, [HTMLElement].\n\nThis interface doesn't allow to manipulate the CSS it contains (in most case). To manipulate CSS, see [Using dynamic styling information](/en-US/docs/Web/API/CSS_Object_Model/Using_dynamic_styling_information) for an overview of the objects used to manipulate specified CSS properties using the DOM.\n\n",
    "properties": {
      "disabled": "\n\nThe **`HTMLStyleElement.disabled`** property can be used to get and set whether the stylesheet is disabled (`true`) or not (`false`).\n\nNote that there is no corresponding `disabled` attribute on the [HTML `<style>` element](/en-US/docs/Web/HTML/Element/style).",
      "media": "\n\nThe **`HTMLStyleElement.media`** property specifies the\nintended destination medium for style information.",
      "sheet": "\n\nThe read-only **`sheet`** property of the [HTMLStyleElement] interface\ncontains the stylesheet associated with that element.\n\nAn [StyleSheet] is always associated with a [HTMLStyleElement], unless its `type` attribute is not `text/css`.",
      "type": " \n\nThe **`HTMLStyleElement.type`** property returns the type of the current style.\nThe value mirrors the [HTML `<style>` element's `type` attribute](/en-US/docs/Web/HTML/Element/style#type).\n\nAuthors should not use this property or rely on the value."
    }
  },
  "htmltablecaptionelement": {
    "docs": "\n\nThe **`HTMLTableCaptionElement`** interface provides special properties (beyond the regular [HTMLElement] interface it also has available to it by inheritance) for manipulating table `caption` elements.\n\n"
  },
  "htmltablecellelement": {
    "docs": "\n\nThe **`HTMLTableCellElement`** interface provides special properties and methods (beyond the regular [HTMLElement] interface it also has available to it by inheritance) for manipulating the layout and presentation of table cells, either header cells (`th`)) or data cells (`td`), in an HTML document.\n\n"
  },
  "htmltablecolelement": {
    "docs": "\n\nThe **`HTMLTableColElement`** interface provides properties for manipulating single or grouped table column elements.\n\n"
  },
  "htmltableelement": {
    "docs": "\n\nThe **`HTMLTableElement`** interface provides special properties and methods (beyond the regular [HTMLElement] object interface it also has available to it by inheritance) for manipulating the layout and presentation of tables in an HTML document.\n\n",
    "properties": {
      "align": "\n\nThe **`HTMLTableElement.align`** property represents the\nalignment of the table.",
      "bgcolor": " \n\nThe **`bgcolor`** property of the [HTMLTableElement] represents the\nbackground color of the table.\n\n> **Note:** Do not use this attribute anymore. Instead, use the CSS  property by modifying the element's [`style`](/en-US/docs/Web/API/HTMLElement/style) attribute or using a style rule.",
      "border": "\n\nThe **`HTMLTableElement.border`** property represents the\nborder width of the `table` element.",
      "caption": "\n\nThe **`HTMLTableElement.caption`** property represents the\ntable caption. If no caption element is associated with the table, this property is\n`null`.",
      "cellpadding": " \n\nThe **`HTMLTableElement.cellPadding`** property represents the\npadding around the individual cells of the table.",
      "cellspacing": "\n\nWhile you should instead use the CSS\n property, the obsolete [HTMLTableElement]\ninterface's **`cellSpacing`** property represents the spacing\naround the individual `th` and `td` elements\nrepresenting a table's cells. Any two cells are separated by the sum of the\n`cellSpacing` of each of the two cells.",
      "createcaption": "\n\nThe **`HTMLTableElement.createCaption()`** method returns the\n`caption` element associated with a given `table`.\nIf no `<caption>` element exists on the table, this method creates\nit, and then returns it.\n\n> **Note:** If no caption exists, `createCaption()` inserts a\n> new caption directly into the table. The caption does not need to be added\n> separately as would be the case if [Document.createElement] had\n> been used to create the new `<caption>` element.",
      "createtbody": "\n\nThe **`createTBody()`** method of\n[HTMLTableElement] objects creates and returns a new\n`tbody` element associated with a given `table`.\n\n> **Note:** Unlike [HTMLTableElement.createTHead] and\n> [HTMLTableElement.createTFoot], `createTBody()`\n> systematically creates a new `<tbody>` element, even if the table\n> already contains one or more bodies. If so, the new one is inserted after the existing\n> ones.",
      "createtfoot": "\n\nThe **`createTFoot()`** method of\n[HTMLTableElement] objects returns the `tfoot` element\nassociated with a given `table`. If no footer exists in the table, this\nmethod creates it, and then returns it.\n\n> **Note:** If no footer exists, `createTFoot()` inserts a new\n> footer directly into the table. The footer does not need to be added separately as\n> would be the case if [Document.createElement] had been used to create\n> the new `<tfoot>` element.",
      "createthead": "\n\nThe **`createTHead()`** method of\n[HTMLTableElement] objects returns the `thead` element\nassociated with a given `table`. If no header exists in the table, this\nmethod creates it, and then returns it.\n\n> **Note:** If no header exists, `createTHead()` inserts a new\n> header directly into the table. The header does not need to be added separately as\n> would be the case if [Document.createElement] had been used to create\n> the new `<thead>` element.",
      "deletecaption": "\n\nThe **`HTMLTableElement.deleteCaption()`** method removes the\n`caption` element from a given `table`. If there is no\n`<caption>` element associated with the table, this method does\nnothing.",
      "deleterow": "\n\nThe **`HTMLTableElement.deleteRow()`** method removes a\nspecific row (`tr`) from a given `table`.",
      "deletetfoot": "\n\nThe **`HTMLTableElement.deleteTFoot()`** method removes the\n`tfoot` element from a given `table`.",
      "deletethead": "\n\nThe **`HTMLTableElement.deleteTHead()`** removes the\n`thead` element from a given `table`.",
      "frame": " \n\nThe [HTMLTableElement] interface's **`frame`**\nproperty is a string that indicates which of the table's exterior borders should be\ndrawn.",
      "insertrow": "\n\nThe **`HTMLTableElement.insertRow()`** method inserts a new row\n(`tr`) in a given `table`, and returns a reference to\nthe new row.\n\nIf a table has multiple `tbody` elements, by default, the new row is\ninserted into the last `<tbody>`. To insert the row into a specific\n`<tbody>`:\n\n```js\nlet specific_tbody = document.getElementById(tbody_id);\nlet row = specific_tbody.insertRow(index);\n```\n\n> **Note:** `insertRow()` inserts the row directly into the\n> table. The row does not need to be appended separately as would be the case if\n> [Document.createElement] had been used to create the new\n> `<tr>` element.",
      "rows": "\n\nThe read-only [HTMLTableElement]\nproperty **`rows`** returns a live\n[HTMLCollection] of all the rows in the table, including the rows\ncontained within any `thead`, `tfoot`, and\n`tbody` elements.\n\nAlthough the property itself is read-only, the returned object is live and allows the\nmodification of its content.",
      "rules": " \n\nThe **`HTMLTableElement.rules`** property indicates which cell\nborders to render in the table.",
      "summary": " \n\nThe **`HTMLTableElement.summary`** property represents the\ntable description.",
      "tbodies": "\n\nThe **`HTMLTableElement.tBodies`** read-only property returns a\nlive [HTMLCollection] of the bodies in a `table`.\n\nAlthough the property is read-only, the returned object is live and allows the\nmodification of its content.\n\nThe collection returned includes implicit `tbody` elements. For\nexample:\n\n```html\n<table>\n  <tr>\n    <td>cell one</td>\n  </tr>\n</table>\n```\n\nThe HTML DOM generated from the above HTML will have a `tbody` element\neven though the tags are not included in the source HTML.",
      "tfoot": "\n\nThe **`HTMLTableElement.tFoot`** property represents the\n`tfoot` element of a `table`. Its value will be\n`null` if there is no such element.",
      "thead": "\n\nThe **`HTMLTableElement.tHead`** represents the\n`thead` element of a `table`. Its value will be\n`null` if there is no such element.",
      "width": " \n\nThe **`HTMLTableElement.width`** property represents the\ndesired width of the table."
    }
  },
  "htmltablerowelement": {
    "docs": "\n\nThe **`HTMLTableRowElement`** interface provides special properties and methods (beyond the [HTMLElement] interface it also has available to it by inheritance) for manipulating the layout and presentation of rows in an HTML table.\n\n",
    "properties": {
      "insertcell": "\n\nThe **`HTMLTableRowElement.insertCell()`** method inserts a new\ncell (`td`) into a table row (`tr`) and returns a\nreference to the cell.\n\n> **Note:** `insertCell()` inserts the cell directly into the\n> row. The cell does not need to be appended separately\n> with [Node.appendChild] as would be the case if\n> [Document.createElement] had been used to create the new\n> `<td>` element.\n>\n> You can not use `insertCell()` to create a new `<th>`\n> element though.",
      "rowindex": "\n\nThe **`HTMLTableRowElement.rowIndex`** read-only property\nrepresents the position of a row in relation to the whole `table`.\n\nEven when the `thead`, `tbody`, and\n`tfoot` elements are out of order in the HTML, browsers render the\ntable in the right order. Therefore the rows count from `<thead>` to\n`<tbody>`, from `<tbody>` to\n`<tfoot>`."
    }
  },
  "htmltablesectionelement": {
    "docs": "\n\nThe **`HTMLTableSectionElement`** interface provides special properties and methods (beyond the [HTMLElement] interface it also has available to it by inheritance) for manipulating the layout and presentation of sections, that is headers, footers and bodies (`thead`, `tfoot`, and `tbody`, respectively) in an HTML table.\n\n"
  },
  "htmltemplateelement": {
    "docs": "\n\nThe **`HTMLTemplateElement`** interface enables access to the contents of an HTML `template` element.\n\n",
    "properties": {
      "content": "\n\nThe **`HTMLTemplateElement.content`** property returns a\n`<template>` element's template contents (a\n[DocumentFragment])."
    }
  },
  "htmltextareaelement": {
    "docs": "\n\nThe **`HTMLTextAreaElement`** interface provides special properties and methods for manipulating the layout and presentation of `textarea` elements.\n\n",
    "properties": {
      "labels": "\n\nThe **`HTMLTextAreaElement.labels`** read-only property returns\na [NodeList] of the `label` elements associated with the\n`textArea` element.",
      "select_event": "\n\nThe **`select`** event fires when some text has been selected.",
      "selectionchange_event": "\n\nThe **`selectionchange`** event of the [Selection API](/en-US/docs/Web/API/Selection) is fired when the text selection within an `textarea` element is changed.\nThis includes both changes in the selected range of characters, or if the caret moves.\n\nThis event is not cancelable.\n\nThe event is usually processed by adding an event listener on the `textarea`, and in the handler function read by the [HTMLTextAreaElement] `selectionStart`, `selectionEnd` and `selectionDirection` properties.\n\nIt is also possible to add a listener on the global `onselectionchange` event handler, and within the handler function use [Document.getSelection] to get the [Selection]. However this is not very useful for getting changes to _text_ selections."
    }
  },
  "htmltimeelement": {
    "docs": "\n\nThe **`HTMLTimeElement`** interface provides special properties (beyond the regular [HTMLElement] interface it also has available to it by inheritance) for manipulating `time` elements.\n\n",
    "properties": {
      "datetime": "\n\nThe\n**`HTMLTimeElement.dateTime`**\nproperty is a string that reflects the [`datetime`](/en-US/docs/Web/HTML/Element/time#datetime) HTML attribute, containing a machine-readable form of the element's date and\ntime value.\n\nThe format of the string must follow one of the following HTML microsyntaxes:\n\n<table class=\"no-markdown\">\n  <thead>\n    <tr>\n      <th scope=\"col\">Microsyntax</th>\n      <th scope=\"col\">Description</th>\n      <th scope=\"col\">Examples</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Valid month string</td>\n      <td><em>YYYY</em><code>-</code><em>MM</em></td>\n      <td><code>2011-11</code>, <code>2013-05</code></td>\n    </tr>\n    <tr>\n      <td>Valid date string</td>\n      <td><em>YYYY</em><code>-</code><em>MM</em><code>-</code><em>DD</em></td>\n      <td><code>1887-12-01</code></td>\n    </tr>\n    <tr>\n      <td>Valid yearless date string</td>\n      <td><em>MM</em><code>-</code><em>DD</em></td>\n      <td><code>11-12</code></td>\n    </tr>\n    <tr>\n      <td>Valid time string</td>\n      <td>\n        <em>HH</em><code>:</code><em>MM</em><br /><em>HH</em><code>:</code\n        ><em>MM</em><code>:</code><em>SS</em><br /><em>HH</em><code>:</code\n        ><em>MM</em><code>:</code><em>SS</em><code>.</code><em>mmm</em>\n      </td>\n      <td>\n        <code>23:59</code><br /><code>12:15:47</code><br /><code\n          >12:15:52.998</code\n        >\n      </td>\n    </tr>\n    <tr>\n      <td>Valid local date and time string</td>\n      <td>\n        <em>YYYY</em><code>-</code><em>MM</em><code>-</code><em>DD</em>\n        <em>HH</em><code>:</code><em>MM</em><br /><em>YYYY</em><code>-</code\n        ><em>MM</em><code>-</code><em>DD</em> <em>HH</em><code>:</code\n        ><em>MM</em><code>:</code><em>SS</em><br /><em>YYYY</em><code>-</code\n        ><em>MM</em><code>-</code><em>DD</em> <em>HH</em><code>:</code\n        ><em>MM</em><code>:</code><em>SS</em><code>.</code><em>mmm</em><br /><em\n          >YYYY</em\n        ><code>-</code><em>MM</em><code>-</code><em>DD</em><code>T</code\n        ><em>HH</em><code>:</code><em>MM</em><br /><em>YYYY</em><code>-</code\n        ><em>MM</em><code>-</code><em>DD</em><code>T</code><em>HH</em\n        ><code>:</code><em>MM</em><code>:</code><em>SS</em><br /><em>YYYY</em\n        ><code>-</code><em>MM</em><code>-</code><em>DD</em><code>T</code\n        ><em>HH</em><code>:</code><em>MM</em><code>:</code><em>SS</em\n        ><code>.</code><em>mmm</em>\n      </td>\n      <td>\n        <code\n          >2013-12-25 11:12<br />1972-07-25 13:43:07<br />1941-03-15\n          07:06:23.678<br />2013-12-25T11:12<br />1972-07-25T13:43:07<br />1941-03-15T07:06:23.678</code\n        >\n      </td>\n    </tr>\n    <tr>\n      <td>Valid time-zone offset string</td>\n      <td>\n        <code>Z</code><br /><code>+</code><em>HHMM</em><br /><code>+</code\n        ><em>HH</em><code>:</code><em>MM</em><br /><code>-</code><em>HHMM</em\n        ><br /><code>-</code><em>HH</em><code>:</code><em>MM</em>\n      </td>\n      <td>\n        <code>Z<br />+0200<br />+04:30<br />-0300<br />-08:00</code>\n      </td>\n    </tr>\n    <tr>\n      <td>Valid global date and time string</td>\n      <td>\n        <em\n          >Any combination of a valid local date and time string followed by a\n          valid time-zone offset string</em\n        >\n      </td>\n      <td>\n        <code\n          >2013-12-25 11:12+0200<br />1972-07-25 13:43:07+04:30<br />1941-03-15\n          07:06:23.678Z<br />2013-12-25T11:12-08:00</code\n        >\n      </td>\n    </tr>\n    <tr>\n      <td>Valid week string</td>\n      <td><em>YYYY</em><code>-W</code><em>WW</em></td>\n      <td><code>2013-W46</code></td>\n    </tr>\n    <tr>\n      <td>Four or more ASCII digits</td>\n      <td><em>YYYY</em></td>\n      <td><code>2013</code>, <code>0001</code></td>\n    </tr>\n    <tr>\n      <td>Valid duration string</td>\n      <td>\n        <code>P</code><em>d</em><code>D</code><code>T</code><em>h</em\n        ><code>H</code><em>m</em><code>M</code><em>s</em><code>S</code\n        ><br /><code>P</code><em>d</em><code>D</code><code>T</code><em>h</em\n        ><code>H</code><em>m</em><code>M</code><em>s</em><code>.</code>X<code\n          >S</code\n        ><br /><code>P</code><em>d</em><code>D</code><code>T</code><em>h</em\n        ><code>H</code><em>m</em><code>M</code><em>s</em><code>.</code>XX<code\n          >S</code\n        ><br /><code>P</code><em>d</em><code>D</code><code>T</code><em>h</em\n        ><code>H</code><em>m</em><code>M</code><em>s</em><code>.</code>XXX<code\n          >S</code\n        ><br /><code>P</code><code>T</code><em>h</em><code>H</code><em>m</em\n        ><code>M</code><em>s</em><code>S</code><br /><code>P</code><code>T</code\n        ><em>h</em><code>H</code><em>m</em><code>M</code><em>s</em\n        ><code>.</code>X<code>S</code><br /><code>P</code><code>T</code\n        ><em>h</em><code>H</code><em>m</em><code>M</code><em>s</em\n        ><code>.</code>XX<code>S</code><br /><code>P</code><code>T</code\n        ><em>h</em><code>H</code><em>m</em><code>M</code><em>s</em\n        ><code>.</code>XXX<code>S</code><br /><em>w</em><code>w </code><em>d</em\n        ><code>d </code><em>h</em><code>h </code><em>m</em><code>m </code\n        ><em>s</em><code>s</code>\n      </td>\n      <td>\n        <code\n          >P12DT7H12M13S<br />P12DT7H12M13.3S<br />P12DT7H12M13.45S<br />P12DT7H12M13.455S<br />PT7H12M13S<br />PT7H12M13.2S<br />PT7H12M13.56S<br />PT7H12M13.999S<br />7d\n          5h 24m 13s</code\n        >\n      </td>\n    </tr>\n  </tbody>\n</table>"
    }
  },
  "htmltitleelement": {
    "docs": "\n\nThe **`HTMLTitleElement`** interface is implemented by a document's `title`. This element inherits all of the properties and methods of the [HTMLElement] interface.\n\n",
    "properties": {
      "text": "\n\nThe **`text`** property of the [HTMLTitleElement] interface represents the text of the document's title. Only the text part is included; tags within the element and their content are stripped and ignored."
    }
  },
  "htmltrackelement": {
    "docs": "\n\nThe **`HTMLTrackElement`** interface represents an  `track` element within the . This element can be used as a child of either `audio` or `video` to specify a text track containing information such as closed captions or subtitles.\n\n",
    "properties": {
      "cuechange_event": "\n\nThe **`cuechange`** event fires when a [TextTrack] has changed the currently displaying cues. The event is fired on both the `TextTrack` and the [HTMLTrackElement] in which it's being presented, if any.",
      "src": "\n\nThe **`HTMLTrackElement.src`** property reflects the value of\nthe `track` element's [`src`](/en-US/docs/Web/HTML/Element/track#src) attribute, which\nindicates the URL of the text track's data."
    }
  },
  "htmlulistelement": {
    "docs": "\n\nThe **`HTMLUListElement`** interface provides special properties (beyond those defined on the regular [HTMLElement] interface it also has available to it by inheritance) for manipulating unordered list (`ul`) elements.\n\n"
  },
  "htmlunknownelement": {
    "docs": "\n\nThe **`HTMLUnknownElement`** interface represents an invalid HTML element and derives from the [HTMLElement] interface, but without implementing any additional properties or methods.\n\n"
  },
  "htmlvideoelement": {
    "docs": "\n\nImplemented by the `video` element, the **`HTMLVideoElement`** interface provides special properties and methods for manipulating video objects. It also inherits properties and methods of [HTMLMediaElement] and [HTMLElement].\n\nThe list of [supported media formats](/en-US/docs/Web/Media/Formats) varies from one browser to the other. You should either provide your video in a single format that all the relevant browsers supports, or provide multiple video sources in enough different formats that all the browsers you need to support are covered.\n\n",
    "properties": {
      "disablepictureinpicture": "\n\nThe [HTMLVideoElement] **`disablePictureInPicture`** property reflects the HTML attribute indicating whether the picture-in-picture feature is disabled for the current element.",
      "enterpictureinpicture_event": "\n\nThe `enterpictureinpicture` event is fired when the [HTMLVideoElement] enters picture-in-picture mode successfully.\n\nThis event is not cancelable and does not bubble.",
      "getvideoplaybackquality": "\n\nThe **[HTMLVideoElement]** method\n**`getVideoPlaybackQuality()`** creates and returns a\n[VideoPlaybackQuality] object containing metrics including how many\nframes have been lost.\n\nThe data returned can be used to evaluate the quality of the video stream.",
      "leavepictureinpicture_event": "\n\nThe `leavepictureinpicture` event is fired when the [HTMLVideoElement] leaves picture-in-picture mode successfully.\n\nThis event is not cancelable and does not bubble.",
      "requestpictureinpicture": "\n\nThe **[HTMLVideoElement]** method\n**`requestPictureInPicture()`** issues an asynchronous request\nto display the video in picture-in-picture mode.\n\nIt's not guaranteed that the video will be put into picture-in-picture. If permission\nto enter that mode is granted, the returned `Promise` will resolve and the\nvideo will receive a [HTMLVideoElement.enterpictureinpicture_event] event to let it know that it's now in picture-in-picture.",
      "videoheight": "\n\nThe [HTMLVideoElement] interface's read-only **`videoHeight`** property indicates the [intrinsic height](#about_intrinsic_width_and_height) of the video, expressed in CSS pixels.\nIn simple terms, this is the height of the media in its natural size.",
      "videowidth": "\n\nThe [HTMLVideoElement] interface's read-only **`videoWidth`** property indicates the [intrinsic width](/en-US/docs/Web/API/HTMLVideoElement/videoHeight#about_intrinsic_width_and_height) of the video, expressed in CSS pixels.\nIn simple terms, this is the width of the media in its natural size.\n\nSee [`HTMLVideoElement.videoHeight` > About intrinsic width and height](/en-US/docs/Web/API/HTMLVideoElement/videoHeight#about_intrinsic_width_and_height) for more details."
    }
  },
  "idbcursor": {
    "docs": "\n\n> **Note:** Not to be confused with [IDBCursorWithValue] which is just an **`IDBCursor`** interface with an additional **`value`** property.\n\nThe **`IDBCursor`** interface of the [IndexedDB API](/en-US/docs/Web/API/IndexedDB_API) represents a [cursor](/en-US/docs/Web/API/IndexedDB_API/Basic_Terminology#cursor) for traversing or iterating over multiple records in a database.\n\nThe cursor has a source that indicates which index or object store it is iterating over. It has a position within the range, and moves in a direction that is increasing or decreasing in the order of record keys. The cursor enables an application to asynchronously process all the records in the cursor's range.\n\nYou can have an unlimited number of cursors at the same time. You always get the same `IDBCursor` object representing a given cursor. Operations are performed on the underlying index or object store.\n\n",
    "properties": {
      "advance": "\n\nThe **`advance()`** method of the [IDBCursor]\ninterface sets the number of times a cursor should move\nits position forward.\n\n",
      "continue": "\n\nThe **`continue()`** method of the [IDBCursor]\ninterface advances the cursor to the next position along its direction, to the item\nwhose key matches the optional key parameter. If no key is specified, the cursor\nadvances to the immediate next position, based on its direction.\n\n",
      "continueprimarykey": "\n\nThe **`continuePrimaryKey()`** method of the\n[IDBCursor] interface advances the cursor to the item whose key\nmatches the key parameter as well as whose primary key matches the primary key\nparameter.\n\nA typical use case, is to resume the iteration where a previous cursor has been closed,\nwithout having to compare the keys one by one.\n\nCalling this method more than once before new cursor data has been loaded - for\nexample, calling `continuePrimaryKey()` twice from the same onsuccess handler\n\\- results in an `InvalidStateError` being thrown on the second call because\nthe cursor's got value flag has been unset.\n\nThis method is only valid for cursors coming from an index. Using it for cursors coming\nfrom an object store will throw an error.\n\n",
      "delete": "\n\nThe **`delete()`** method of the [IDBCursor]\ninterface returns an [IDBRequest] object, and, in a separate thread,\ndeletes the record at the cursor's position, without changing the cursor's position.\nOnce the record is deleted, the cursor's value is set to null.\n\nBe aware that you can't call `delete()` (or\n[IDBCursor.update]) on cursors obtained from\n[IDBIndex.openKeyCursor]. For such needs, you have to use\n[IDBIndex.openCursor] instead.\n\n",
      "direction": "\n\nThe **`direction`** read-only property of the\n[IDBCursor] interface is a string that returns the\ndirection of traversal of the cursor (set using\n[IDBObjectStore.openCursor] for example). See the [Values](#values)\nsection below for possible values.\n\n",
      "key": "\n\nThe **`key`** read-only property of the\n[IDBCursor] interface returns the key for the record at the cursor's\nposition. If the cursor is outside its range, this is set to undefined. The cursor's\nkey can be any data type.\n\n",
      "primarykey": "\n\nThe **`primaryKey`** read-only property of the\n[IDBCursor] interface returns the cursor's current effective key. If the\ncursor is currently being iterated or has iterated outside its range, this is set to\nundefined. The cursor's primary key can be any data type.\n\n",
      "request": "\n\nThe **`request`** read-only property of the [IDBCursor] interface returns the [IDBRequest] used to obtain the cursor.\n\n",
      "source": "\n\nThe **`source`** read-only property of the\n[IDBCursor] interface returns the [IDBObjectStore] or\n[IDBIndex] that the cursor is iterating over. This function never returns\nnull or throws an exception, even if the cursor is currently being iterated, has\niterated past its end, or its transaction is not active.\n\n",
      "update": "\n\nThe **`update()`** method of the [IDBCursor]\ninterface returns an [IDBRequest] object, and, in a separate thread,\nupdates the value at the current position of the cursor in the object store. If the\ncursor points to a record that has just been deleted, a new record is created.\n\nBe aware that you can't call `update()` (or\n[IDBCursor.delete]) on cursors obtained from\n[IDBIndex.openKeyCursor]. For such needs, you have to use\n[IDBIndex.openCursor] instead.\n\n"
    }
  },
  "idbcursorwithvalue": {
    "docs": "\n\nThe **`IDBCursorWithValue`** interface of the [IndexedDB API](/en-US/docs/Web/API/IndexedDB_API) represents a [cursor](/en-US/docs/Web/API/IndexedDB_API/Basic_Terminology#cursor) for traversing or iterating over multiple records in a database. It is the same as the [IDBCursor], except that it includes the `value` property.\n\nThe cursor has a source that indicates which index or object store it is iterating over. It has a position within the range, and moves in a direction that is increasing or decreasing in the order of record keys. The cursor enables an application to asynchronously process all the records in the cursor's range.\n\nYou can have an unlimited number of cursors at the same time. You always get the same `IDBCursorWithValue` object representing a given cursor. Operations are performed on the underlying index or object store.\n\n",
    "properties": {
      "value": "\n\nThe **`value`** read-only property of the\n[IDBCursorWithValue] interface returns the value of the current cursor,\nwhatever that is.\n\n"
    }
  },
  "idbdatabase": {
    "docs": "\n\nThe **`IDBDatabase`** interface of the IndexedDB API provides a [connection to a database](/en-US/docs/Web/API/IndexedDB_API#database_connection); you can use an `IDBDatabase` object to open a [transaction](/en-US/docs/Web/API/IndexedDB_API/Basic_Terminology#transaction) on your database then create, manipulate, and delete objects (data) in that database. The interface provides the only way to get and manage versions of the database.\n\n> **Note:** Everything you do in IndexedDB always happens in the context of a [transaction](/en-US/docs/Web/API/IndexedDB_API/Basic_Terminology#transaction), representing interactions with data in the database. All objects in IndexedDB — including object stores, indexes, and cursors — are tied to a particular transaction. Thus, you cannot execute commands, access data, or open anything outside of a transaction.\n\n",
    "properties": {
      "close": "\n\nThe **`close()`** method of the [IDBDatabase]\ninterface returns immediately and closes the connection in a separate thread.\n\nThe connection is not actually closed until all transactions created using this\nconnection are complete. No new transactions can be created for this connection once\nthis method is called. Methods that create transactions throw an exception if a closing\noperation is pending.\n\n",
      "close_event": "\n\nThe `close` event is fired on `IDBDatabase` when the database connection is unexpectedly closed. This could happen, for example, if the underlying storage is removed or if the user clears the database in the browser's history preferences.\n\nNote that it is not fired if the database connection is closed normally using [`IDBDatabase.close()`](/en-US/docs/Web/API/IDBDatabase/close).",
      "createobjectstore": "\n\nThe **`createObjectStore()`** method of the\n[IDBDatabase] interface creates and returns a new [IDBObjectStore].\n\nThe method takes the name of the store as well as a parameter object that lets you\ndefine important optional properties. You can use the property to uniquely identify\nindividual objects in the store. As the property is an identifier, it should be unique\nto every object, and every object should have that property.\n\nThis method can be called _only_ within a [`versionchange`](/en-US/docs/Web/API/IDBTransaction#version_change)\ntransaction.\n\n",
      "deleteobjectstore": "\n\nThe **`deleteObjectStore()`** method of the\n[IDBDatabase] interface destroys the object store with the given name in\nthe connected database, along with any indexes that reference it.\n\nAs with [IDBDatabase.createObjectStore], this method can be called\n_only_ within a [`versionchange`](/en-US/docs/Web/API/IDBTransaction#version_change)\ntransaction.\n\n",
      "name": "\n\nThe **`name`** read-only property of the\n`IDBDatabase` interface is a string that contains the\nname of the connected database.\n\n",
      "objectstorenames": "\n\nThe **`objectStoreNames`** read-only property of the\n[IDBDatabase] interface is a [DOMStringList] containing a\nlist of the names of the [object stores](/en-US/docs/Web/API/IndexedDB_API/Basic_Terminology#object_store) currently in the connected database.\n\n",
      "transaction": "\n\nThe **`transaction`** method of the [IDBDatabase] interface immediately\nreturns a transaction object ([IDBTransaction]) containing the\n[IDBTransaction.objectStore] method, which you can use to access your\nobject store.\n\n",
      "version": "\n\nThe **`version`** property of the [IDBDatabase]\ninterface is a [64-bit integer](/en-US/docs/NSPR_API_Reference/Long_Long_%2864-bit%29_Integers)\nthat contains the version of the connected database.\nWhen a database is first created, this attribute is an empty string.\n\n",
      "versionchange_event": "\n\nThe `versionchange` event is fired when a database structure change ([`upgradeneeded`](/en-US/docs/Web/API/IDBOpenDBRequest/upgradeneeded_event) event send on an [`IDBOpenDBRequest`](/en-US/docs/Web/API/IDBOpenDBRequest) or [`IDBFactory.deleteDatabase`](/en-US/docs/Web/API/IDBFactory/deleteDatabase)) was requested elsewhere (most probably in\nanother window/tab on the same computer)."
    }
  },
  "idbfactory": {
    "docs": "\n\nThe **`IDBFactory`** interface of the [IndexedDB API](/en-US/docs/Web/API/IndexedDB_API) lets applications asynchronously access the indexed databases. The object that implements the interface is `window.indexedDB`. You open — that is, create and access — and delete a database with this object, and not directly with `IDBFactory`.\n\n",
    "properties": {
      "cmp": "\n\nThe **`cmp()`** method of the [IDBFactory]\ninterface compares two values as keys to determine equality and ordering for IndexedDB\noperations, such as storing and iterating.\n\n> **Note:** Do not use this method for comparing arbitrary JavaScript\n> values, because many JavaScript values are either not valid IndexedDB keys (booleans\n> and objects, for example) or are treated as equivalent IndexedDB keys (for example,\n> since IndexedDB ignores arrays with non-numeric properties and treats them as empty\n> arrays, so any non-numeric arrays are treated as equivalent). This throws an exception\n> if either of the values is not a valid key.",
      "databases": "\n\nThe **`databases`** method of the [IDBFactory] interface returns a list representing all the available databases, including their names and versions.\n\n> **Note:** This method is introduced in a draft of a specifications and browser compatibility is limited.",
      "deletedatabase": "\n\nThe **`deleteDatabase()`** method of the\n[IDBFactory] interface requests the deletion of a database. The method\nreturns an [IDBOpenDBRequest] object immediately, and performs the deletion\noperation asynchronously.\n\nIf the database is successfully deleted, then a `success` event is fired on\nthe request object returned from this method, with its `result` set to\n`undefined`. If an error occurs while the database is being deleted, then an\n`error` event is fired on the request object that is returned from this\nmethod.\n\nWhen `deleteDatabase()` is called, any other open connections to this\nparticular database will get a [versionchange](/en-US/docs/Web/API/IDBDatabase/versionchange_event) event.\n\n",
      "open": "\n\nThe **`open()`** method of the [IDBFactory] interface requests opening a [connection to a database](/en-US/docs/Web/API/IndexedDB_API/Basic_Terminology#database_connection).\n\nThe method returns an [IDBOpenDBRequest] object immediately, and performs the open operation asynchronously.\nIf the operation is successful, a `success` event is fired on the request object that is returned from this method, with its `result` attribute set to the new [IDBDatabase] object for the connection.\n\nMay trigger `upgradeneeded`, `blocked` or `versionchange` events.\n\n"
    }
  },
  "idbindex": {
    "docs": "\n\n`IDBIndex` interface of the [IndexedDB API](/en-US/docs/Web/API/IndexedDB_API) provides asynchronous access to an [index](/en-US/docs/Web/API/IndexedDB_API/Basic_Terminology#index) in a database. An index is a kind of object store for looking up records in another object store, called the referenced object store. You use this interface to retrieve data.\n\nYou can retrieve records in an object store through the primary key or by using an index. An index lets you look up records in an object store using properties of the values in the object stores records other than the primary key\n\nThe index is a persistent key-value storage where the value part of its records is the key part of a record in the referenced object store. The records in an index are automatically populated whenever records in the referenced object store are inserted, updated, or deleted. Each record in an index can point to only one record in its referenced object store, but several indexes can reference the same object store. When the object store changes, all indexes that refers to the object store are automatically updated.\n\nYou can grab a set of keys within a range. To learn more, see [IDBKeyRange].\n\n",
    "properties": {
      "count": "\n\nThe **`count()`** method of the [IDBIndex]\ninterface returns an [IDBRequest] object, and in a separate thread,\nreturns the number of records within a key range.\n\n",
      "get": "\n\nThe **`get()`** method of the [IDBIndex]\ninterface returns an [IDBRequest] object, and, in a separate thread,\nfinds either the value in the referenced object store that corresponds to the given\nkey or the first corresponding value, if `key` is set to an\n[IDBKeyRange].\n\nIf a value is found, then a structured clone of it is created and set as the\n`result` of the request object: this returns the record the key is associated\nwith.\n\n",
      "getall": "\n\nThe **`getAll()`** method of the [IDBIndex]\ninterface retrieves all objects that are inside the index.\n\nThere is a performance cost associated with looking at the `value` property\nof a cursor, because the object is created lazily. To use a feature\nlike `getAll()`, the browser has to create all the objects at once. If you\nare just interested in looking at each of the keys, for instance, it is more efficient\nto use a [cursor](/en-US/docs/Web/API/IDBCursor). If you are trying to get an\narray of all the objects in an object store, though, you should\nuse `getAll()`.",
      "getallkeys": "\n\nThe **`getAllKeys()`** method of the [IDBIndex]\ninterface asynchronously retrieves the primary keys of all objects inside the index,\nsetting them as the `result` of the request object.",
      "getkey": "\n\nThe **`getKey()`** method of the [IDBIndex]\ninterface returns an [IDBRequest] object, and, in a separate thread,\nfinds either the primary key that corresponds to the given key in this index or the\nfirst corresponding primary key, if `key` is set to an\n[IDBKeyRange].\n\nIf a primary key is found, it is set as the `result` of the request object.\nNote that this doesn't return the whole record as [IDBIndex.get] does.\n\n",
      "isautolocale": "\n\nThe **`isAutoLocale`** read-only property of the [IDBIndex] interface returns a boolean value indicating whether the index had a `locale` value of `auto` specified upon its creation (see the [`options`](/en-US/docs/Web/API/IDBObjectStore/createIndex#options) parameter to [`IDBObjectStore.createIndex()`](/en-US/docs/Web/API/IDBObjectStore/createIndex).)",
      "keypath": "\n\nThe **`keyPath`** property of the [IDBIndex]\ninterface returns the [key path](/en-US/docs/Web/API/IndexedDB_API/Basic_Terminology#key_path) of the current index. If null, this index is not auto-populated.\n\n",
      "locale": "\n\nThe **`locale`** read-only property of the [IDBIndex] interface returns the locale of the index (for example `en-US`, or `pl`) if it had a `locale` value specified upon its creation (see the [`options`](/en-US/docs/Web/API/IDBObjectStore/createIndex#options) parameter to [`IDBObjectStore.createIndex()`](/en-US/docs/Web/API/IDBObjectStore/createIndex).) Note that this property always returns the current locale being used in this index, in other words, it never returns `\"auto\"`.",
      "multientry": "\n\nThe **`multiEntry`** read-only property of the\n[IDBIndex] interface returns a boolean value that affects how the index\nbehaves when the result of evaluating the index's key path yields an array.\n\nThis is decided when the index is created, using the\n[IDBObjectStore.createIndex] method. This method takes an optional\n`options` parameter whose `multiEntry` property is set to `true`/`false`.\n\n",
      "name": "\n\nThe **`name`** property of the [IDBIndex]\ninterface contains a string which names the index.\n\n",
      "objectstore": "\n\nThe **`objectStore`** property of the [IDBIndex]\ninterface returns the object store referenced by the current index.\n\n",
      "opencursor": "\n\nThe **`openCursor()`** method of the [IDBIndex]\ninterface returns an [IDBRequest] object, and, in a separate thread,\ncreates a [cursor](/en-US/docs/Web/API/IndexedDB_API/Basic_Terminology#cursor) over the specified key\nrange.\n\nThe method sets the position of the cursor to the appropriate record, based on the\nspecified direction.\n\nIf the key range is not specified or is null, then the range includes all the records.\n\n",
      "openkeycursor": "\n\nThe **`openKeyCursor()`** method of the\n[IDBIndex] interface returns an [IDBRequest] object, and, in\na separate thread, creates a cursor over the specified key range, as arranged by this\nindex.\n\nThe method sets the position of the cursor to the appropriate key, based on the\nspecified direction.\n\nIf the key range is not specified or is null, then the range includes all the keys.\n\n> **Note:** Cursors returned by `openKeyCursor()` do not\n> make the referenced value available as [`IDBIndex.openCursor`](/en-US/docs/Web/API/IDBIndex/openCursor) does.\n> This makes obtaining a list of keys much more efficient.\n\n",
      "unique": "\n\nThe **`unique`** read-only property returns a boolean that\nstates whether the index allows duplicate keys.\n\nThis is decided when the index is created, using the\n[IDBObjectStore.createIndex] method. This method takes an optional\nparameter, `unique`, which if set to `true` means that the index\nwill not be able to accept duplicate entries.\n\n"
    }
  },
  "idbkeyrange": {
    "docs": "\n\nThe **`IDBKeyRange`** interface of the [IndexedDB API](/en-US/docs/Web/API/IndexedDB_API) represents a continuous interval over some data type that is used for keys. Records can be retrieved from [IDBObjectStore] and [IDBIndex] objects using keys or a range of keys. You can limit the range using lower and upper bounds. For example, you can iterate over all values of a key in the value range A–Z.\n\nA key range can be a single value or a range with upper and lower bounds or endpoints. If the key range has both upper and lower bounds, then it is _bounded_; if it has no bounds, it is _unbounded_. A bounded key range can either be open (the endpoints are excluded) or closed (the endpoints are included). To retrieve all keys within a certain range, you can use the following code constructs:\n\n| Range                       | Code                                   |\n| --------------------------- | -------------------------------------- |\n| All keys ≥ **x**            | `IDBKeyRange.lowerBound(x)`            |\n| All keys > **x**            | `IDBKeyRange.lowerBound(x, true)`      |\n| All keys ≤ **y**            | `IDBKeyRange.upperBound(y)`            |\n| All keys < **y**            | `IDBKeyRange.upperBound(y, true)`      |\n| All keys ≥ **x** && ≤ **y** | `IDBKeyRange.bound(x, y)`              |\n| All keys > **x** &&< **y**  | `IDBKeyRange.bound(x, y, true, true)`  |\n| All keys > **x** && ≤ **y** | `IDBKeyRange.bound(x, y, true, false)` |\n| All keys ≥ **x** &&< **y**  | `IDBKeyRange.bound(x, y, false, true)` |\n| The key = **z**             | `IDBKeyRange.only(z)`                  |\n\nA key is in a key range if the following conditions are true:\n\n- The lower value of the key range is one of the following:\n\n  - `undefined`\n  - Less than key value\n  - Equal to key value if `lowerOpen` is `false`.\n\n- The upper value of the key range is one of the following:\n\n  - `undefined`\n  - Greater than key value\n  - Equal to key value if `upperOpen` is `false`.\n\n",
    "properties": {
      "bound_static": "\n\nThe **`bound()`** static method of the [IDBKeyRange]\ninterface creates a new key range with the specified upper and lower bounds. The\nbounds can be open (that is, the bounds exclude the endpoint values) or closed (that\nis, the bounds include the endpoint values). By default, the bounds are closed.\n\n",
      "includes": "\n\nThe `includes()` method of the [IDBKeyRange]\ninterface returns a boolean indicating whether a specified key is inside the key\nrange.\n\n",
      "lower": "\n\nThe **`lower`** read-only property of the\n[IDBKeyRange] interface returns the lower bound of the key range.\n\n",
      "lowerbound_static": "\n\nThe **`lowerBound()`** static method of the\n[IDBKeyRange] interface creates a new key range with only a lower bound.\nBy default, it includes the lower endpoint value and is closed.\n\n",
      "loweropen": "\n\nThe **`lowerOpen`** read-only property of the\n[IDBKeyRange] interface returns a boolean indicating whether the\nlower-bound value is included in the key range.\n\n",
      "only_static": "\n\nThe **`only()`** static method of the [IDBKeyRange]\ninterface creates a new key range containing a single value.\n\n",
      "upper": "\n\nThe **`upper`** read-only property of the\n[IDBKeyRange] interface returns the upper bound of the key range.\n\n",
      "upperbound_static": "\n\nThe **`upperBound()`** static method of the\n[IDBKeyRange] interface creates a new upper-bound key range. By default,\nit includes the upper endpoint value and is closed.\n\n",
      "upperopen": "\n\nThe **`upperOpen`** read-only property of the\n[IDBKeyRange] interface returns a boolean indicating whether the\nupper-bound value is included in the key range.\n\n"
    }
  },
  "idblocaleawarekeyrange": {
    "docs": "\n\nThe **`IDBLocaleAwareKeyRange`** interface of the [IndexedDB API](/en-US/docs/Web/API/IndexedDB_API) is a Firefox-specific version of [IDBKeyRange] — it functions in exactly the same fashion, and has the same properties and methods, but it is intended for use with [IDBIndex] objects when the original index had a `locale` value specified upon its creation (see the [`options`](/en-US/docs/Web/API/IDBObjectStore/createIndex#options) parameter to [`IDBObjectStore.createIndex()`](/en-US/docs/Web/API/IDBObjectStore/createIndex)) — that is, it has [locale aware sorting](/en-US/docs/Web/API/IndexedDB_API/Using_IndexedDB#locale-aware_sorting) enabled."
  },
  "idbobjectstore": {
    "docs": "\n\nThe **`IDBObjectStore`** interface of the [IndexedDB API](/en-US/docs/Web/API/IndexedDB_API) represents an object store in a database. Records within an object store are sorted according to their keys. This sorting enables fast insertion, look-up, and ordered retrieval.\n\n",
    "properties": {
      "add": "\n\nThe **`add()`** method of the [IDBObjectStore] interface returns an [IDBRequest] object, and, in a separate thread, creates a [structured clone](https://html.spec.whatwg.org/multipage/common-dom-interfaces.html#structured-clone) of the value, and stores the cloned value in the object store. This is for adding new records to an object store.\n\nTo determine if the add operation has completed successfully, listen for the\ntransaction's `complete` event in addition to the\n`IDBObjectStore.add` request's `success` event, because the\ntransaction may still fail after the success event fires. In other words, the success\nevent is only triggered when the transaction has been successfully queued.\n\nThe add method is an _insert only_ method. If a\nrecord already exists in the object store with the `key` parameter as its\nkey, then an error `ConstraintError` event is fired on the returned request\nobject. For updating existing records, you should use the\n[IDBObjectStore.put] method instead.\n\n",
      "autoincrement": "\n\nThe **`autoIncrement`** read-only property of the\n[IDBObjectStore] interface returns the value of the auto increment flag\nfor this object store.\n\nNote that every object store has its own separate auto increment counter.\n\n",
      "clear": "\n\nThe **`clear()`** method of the [IDBObjectStore]\ninterface creates and immediately returns an [IDBRequest] object, and\nclears this object store in a separate thread. This is for deleting all the current\ndata out of an object store.\n\nClearing an object store consists of removing all records from the object store and\nremoving all records in indexes that reference the object store. To remove only some of\nthe records in a store, use [IDBObjectStore.delete] passing a key\nor [IDBKeyRange].\n\n",
      "count": "\n\nThe **`count()`** method of the [IDBObjectStore]\ninterface returns an [IDBRequest] object, and, in a separate thread,\nreturns the total number of records that match the provided key or\n[IDBKeyRange]. If no arguments are provided, it returns the total number\nof records in the store.\n\n",
      "createindex": "\n\nThe **`createIndex()`** method of the\n[IDBObjectStore] interface creates and returns a new\n[IDBIndex] object in the connected database. It creates a new\nfield/column defining a new data point for each database record to contain.\n\nBear in mind that IndexedDB indexes can contain _any_ JavaScript data type;\nIndexedDB uses the [structured clone algorithm](/en-US/docs/Web/API/Web_Workers_API/Structured_clone_algorithm) to serialize stored objects, which allows for storage of simple\nand complex objects.\n\nNote that this method must be called only from a `VersionChange` transaction\nmode callback.\n\n",
      "delete": "\n\nThe **`delete()`** method of the\n[IDBObjectStore] interface returns an [IDBRequest] object,\nand, in a separate thread, deletes the specified record or records.\n\nEither a key or an [IDBKeyRange] can be passed, allowing one or multiple\nrecords to be deleted from a store. To delete all records in a store, use\n[IDBObjectStore.clear].\n\nBear in mind that if you are using a [IDBCursor], you can use\nthe [IDBCursor.delete] method to more efficiently delete the current\nrecord — without having to explicitly look up the record's key.\n\n",
      "deleteindex": "\n\nThe **`deleteIndex()`** method of the\n[IDBObjectStore] interface destroys the index with the specified name in\nthe connected database, used during a version upgrade.\n\nNote that this method must be called only from a `VersionChange` transaction\nmode callback. Note that this method synchronously modifies the\n[IDBObjectStore.indexNames] property.\n\n",
      "get": "\n\nThe **`get()`** method of the [IDBObjectStore]\ninterface returns an [IDBRequest] object, and, in a separate thread,\nreturns the object selected by the specified key. This is for retrieving\nspecific records from an object store.\n\nIf a value is successfully found, then a structured clone of it is created and set as\nthe [`result`](/en-US/docs/Web/API/IDBRequest#attr_result) of the\nrequest object.\n\n> **Note:** This method produces the same result for: a) a record that doesn't exist in the database and b) a record that has an undefined value.\n> To tell these situations apart, call the `openCursor()` method with the same key. That method provides a cursor if the record exists, and no cursor if it does not.\n\n",
      "getall": "\n\nThe **`getAll()`** method of the\n[IDBObjectStore] interface returns an [IDBRequest] object\ncontaining all objects in the object store matching the specified parameter or all\nobjects in the store if no parameters are given.\n\nIf a value is successfully found, then a structured clone of it is created and set as\nthe result of the request object.\n\nThis method produces the same result for:\n\n- a record that doesn't exist in the database\n- a record that has an undefined value\n\nTo tell these situations apart, you either call\n\n1. the [IDBObjectStore.openCursor] method with the same\n   key. That method provides a cursor if the record exists, and no cursor if it does not.\n2. the [IDBObjectStore.count] method with the same key, which\n   will return 1 if the row exists and 0 if it doesn't.",
      "getallkeys": "\n\nThe `getAllKeys()` method of the [IDBObjectStore]\ninterface returns an [IDBRequest] object retrieves record keys for all\nobjects in the object store matching the specified parameter or all objects in the\nstore if no parameters are given.\n\nIf a value is successfully found, then a structured clone of it is created and set as\nthe result of the request object.\n\nThis method produces the same result for:\n\n- a record that doesn't exist in the database\n- a record that has an undefined value\n\nTo tell these situations apart, you need to call the\n[IDBObjectStore.openCursor] method with the same key. That\nmethod provides a cursor if the record exists, and no cursor if it does not.",
      "getkey": "\n\nThe **`getKey()`** method of the\n[IDBObjectStore] interface returns an [IDBRequest] object,\nand, in a separate thread, returns the key selected by the specified query. This is\nfor retrieving specific records from an object store.\n\nIf a key is successfully found, then a structured clone of it is created and set as the\nresult of the request object.\n\n",
      "index": "\n\nThe **`index()`** method of the [IDBObjectStore]\ninterface opens a named index in the current object store, after which it can be used\nto, for example, return a series of records sorted by that index using a cursor.\n\n",
      "indexnames": "\n\nThe **`indexNames`** read-only property of the\n[IDBObjectStore] interface returns a list of the names of [indexes](/en-US/docs/Web/API/IndexedDB_API/Basic_Terminology#index) on objects\nin this object store.\n\n",
      "keypath": "\n\nThe **`keyPath`** read-only property of the\n[IDBObjectStore] interface returns the [key path](/en-US/docs/Web/API/IndexedDB_API/Basic_Terminology#key_path) of this object store.\n\nIf this property is null, the application must provide a key for each modification\noperation.\n\n",
      "name": "\n\nThe **`name`** property of the [IDBObjectStore]\ninterface indicates the name of this object store.\n\n",
      "opencursor": "\n\nThe **`openCursor()`** method of the\n[IDBObjectStore] interface returns an [IDBRequest] object,\nand, in a separate thread, returns a new [IDBCursorWithValue] object.\nUsed for iterating through an object store with a cursor.\n\nTo determine if the add operation has completed successfully, listen for the results's\n`success` event.\n\n",
      "openkeycursor": "\n\nThe **`openKeyCursor()`** method of the\n[IDBObjectStore] interface returns an [IDBRequest] object\nwhose result will be set to an [IDBCursor] that can be used to iterate\nthrough matching results. Used for iterating through the keys of an object store with\na cursor.\n\nTo determine if the add operation has completed successfully, listen for the\nresults's `success` event.",
      "put": "\n\nThe **`put()`** method of the [IDBObjectStore] interface updates a given record in a database, or inserts a new record if the given item does not already exist.\n\nIt returns an [IDBRequest] object, and, in a separate thread, creates a [structured clone](https://html.spec.whatwg.org/multipage/common-dom-interfaces.html#structured-clone) of the value and stores the cloned value in the object store. This is for adding new records, or updating existing records in an object store when the transaction's mode is `readwrite`. If the record is successfully stored, then a success event is fired on the returned request object with the `result` set to the key for the stored record, and the `transaction` set to the transaction in which this object store is opened.\n\nThe put method is an _update or insert_ method.\nSee the [IDBObjectStore.add] method for an _insert only_ method.\n\nBear in mind that if you have a [IDBCursor] to the record you\nwant to update, updating it with [IDBCursor.update] is preferable to\nusing [IDBObjectStore.put]. Doing so makes it clear that an existing\nrecord will be updated, instead of a new record being inserted.\n\n",
      "transaction": "\n\nThe **`transaction`** read-only property of the\n[IDBObjectStore] interface returns the transaction object to which this\nobject store belongs.\n\n"
    }
  },
  "idbopendbrequest": {
    "docs": "\n\nThe **`IDBOpenDBRequest`** interface of the IndexedDB API provides access to the results of requests to open or delete databases (performed using [IDBFactory.open] and [IDBFactory.deleteDatabase]), using specific event handler attributes.\n\n",
    "properties": {
      "blocked_event": "\n\nThe `blocked` handler is executed when an open connection to a database is blocking a `versionchange` transaction on the same database.\n\nThis event is not cancelable and does not bubble.",
      "upgradeneeded_event": "\n\nThe `upgradeneeded` event is fired when an attempt was made to open a database with a version number higher than its current version.\n\nThis event is not cancelable and does not bubble."
    }
  },
  "idbrequest": {
    "docs": "\n\nThe **`IDBRequest`** interface of the IndexedDB API provides access to results of asynchronous requests to databases and database objects using event handler attributes. Each reading and writing operation on a database is done using a request.\n\nThe request object does not initially contain any information about the result of the operation, but once information becomes available, an event is fired on the request, and the information becomes available through the properties of the `IDBRequest` instance.\n\nAll asynchronous operations immediately return an [IDBRequest] instance. Each request has a `readyState` that is set to the `'pending'` state; this changes to `'done'` when the request is completed or fails. When the state is set to `done`, every request returns a `result` and an `error`, and an event is fired on the request. When the state is still `pending`, any attempt to access the `result` or `error` raises an `InvalidStateError` exception.\n\nIn plain words, all asynchronous methods return a request object. If the request has been completed successfully, the result is made available through the `result` property and an event indicating success is fired at the request ([IDBRequest.success_event]). If an error occurs while performing the operation, the exception is made available through the `error` property and an error event is fired ([IDBRequest.error_event]).\n\nThe interface [IDBOpenDBRequest] is derived from `IDBRequest`.\n\n",
    "properties": {
      "error": "\n\nThe **`error`** read-only property of the\n[IDBRequest] interface returns the error in the event of an unsuccessful\nrequest.\n\n",
      "error_event": "\n\nThe `error` handler is executed when an error caused a request to fail.\n\nThis event is not cancelable and does not bubble.",
      "readystate": "\n\nThe **`readyState`** read-only property of the\n[IDBRequest] interface returns the state of the request.\n\nEvery request starts in the `pending` state. The state changes to\n`done` when the request completes successfully or when an error\noccurs.\n\n",
      "result": "\n\nThe **`result`** read-only property of the\n[IDBRequest] interface returns the result of the request. If the request\nis not completed, the result is not available and an `InvalidStateError` exception is\nthrown.\n\n",
      "source": "\n\nThe **`source`** read-only property of the\n[IDBRequest] interface returns the source of the request, such as an\nIndex or an object store. If no source exists (such as when calling\n[IDBFactory.open]), it returns null.\n\n",
      "success_event": "\n\nThe `success` event is fired when an `IDBRequest` succeeds.\n\nThis event is not cancelable and does not bubble.",
      "transaction": "\n\nThe **`transaction`** read-only property of the IDBRequest\ninterface returns the transaction for the request, that is, the transaction the\nrequest is being made inside.\n\nThis property can be `null` for requests not made within transactions,\nsuch as for requests returned from [IDBFactory.open] — in this case\nyou're just connecting to a database, so there is no transaction to return. If a\nversion upgrade is needed when opening a database then during the\n[IDBOpenDBRequest.upgradeneeded_event] event handler the\n**`transaction`** property will be an\n[IDBTransaction] with [IDBTransaction.mode] equal\nto `\"versionchange\"`, and can be used to access existing object stores and\nindexes, or abort the upgrade. Following the upgrade, the\n**`transaction`** property will again be `null`.\n\n"
    }
  },
  "idbtransaction": {
    "docs": "\n\nThe **`IDBTransaction`** interface of the [IndexedDB API](/en-US/docs/Web/API/IndexedDB_API) provides a static, asynchronous transaction on a database using event handler attributes. All reading and writing of data is done within transactions. You use [IDBDatabase] to start transactions, [IDBTransaction] to set the mode of the transaction (e.g. is it `readonly` or `readwrite`), and you access an [IDBObjectStore] to make a request. You can also use an `IDBTransaction` object to abort transactions.\n\nTransactions are started when the transaction is created, not when the first request is placed; for example consider this:\n\n```js\nconst trans1 = db.transaction(\"foo\", \"readwrite\");\nconst trans2 = db.transaction(\"foo\", \"readwrite\");\nconst objectStore2 = trans2.objectStore(\"foo\");\nconst objectStore1 = trans1.objectStore(\"foo\");\nobjectStore2.put(\"2\", \"key\");\nobjectStore1.put(\"1\", \"key\");\n```\n\nAfter the code is executed the object store should contain the value \"2\", since `trans2` should run after `trans1`.",
    "properties": {
      "abort": "\n\nThe **`abort()`** method of the [IDBTransaction]\ninterface rolls back all the changes to objects in the database associated with this\ntransaction.\n\nAll pending [IDBRequest] objects created during this transaction have\ntheir [IDBRequest.error] attribute set to an `AbortError` [DOMException].\n\n",
      "abort_event": "\n\nThe `abort` event is fired when an `IndexedDB` transaction is aborted.\n\nThis can happen for any of the following reasons:\n\n- Bad requests, (E.g., trying to add the same key twice, or put the same index key when the key has a uniqueness constraint).\n- An explicit [IDBTransaction.abort] call.\n- An uncaught exception in the request's success/error handler.\n- An I/O error (an actual failure to write to disk, for example disk detached, or other OS/hardware failure).\n- Quota exceeded.\n\nThis non-cancelable event [bubbles](/en-US/docs/Learn/JavaScript/Building_blocks/Events#bubbling_and_capturing_explained) to the associated [IDBDatabase] object.",
      "commit": "\n\nThe **`commit()`** method of the [IDBTransaction] interface commits the transaction if it is called on an active transaction.\n\nNote that `commit()` doesn't normally _have_ to be called — a transaction will automatically commit when all outstanding requests have been satisfied and no new requests have been made. `commit()` can be used to start the commit process without waiting for events from outstanding requests to be dispatched.\n\nIf it is called on a transaction that is not active, it throws an `InvalidStateError` [DOMException].\n\n",
      "complete_event": "\n\nThe **`complete`** event of the [IndexedDB API](/en-US/docs/Web/API/IndexedDB_API) is fired when the transaction successfully completed.",
      "db": "\n\nThe **`db`** read-only property of the [IDBTransaction] interface returns the database connection\nwith which this transaction is associated.\n\n",
      "durability": "`IndexedDB`\n\nThe **`durability`** read-only property of the\n[IDBTransaction] interface returns the durability hint the transaction was\ncreated with. This is a hint to the user agent of whether to prioritize performance or\ndurability when committing the transaction.\n\nThe value of this property is defined in the `options` parameter when creating a transaction using [IDBDatabase.transaction].",
      "error": "\n\nThe **`IDBTransaction.error`** property of the [IDBTransaction] interface\nreturns the type of error when there is an unsuccessful transaction.\n\n",
      "error_event": "\n\nThe `error` event is fired on `IDBTransaction` when a request returns an error and the event bubbles up to the transaction object.\n\n> **Note:** To handle all the ways a transaction can fail, consider listening for the [IDBTransaction.abort_event] event instead.",
      "mode": "\n\nThe **`mode`** read-only property of the\n[IDBTransaction] interface returns the current mode for accessing the\ndata in the object stores in the scope of the transaction (i.e. is the mode to be\nread-only, or do you want to write to the object stores?) The default value is\n`readonly`.\n\n",
      "objectstore": "\n\nThe **`objectStore()`** method of the\n[IDBTransaction] interface returns an object store that has already been\nadded to the scope of this transaction.\n\nEvery call to this method on the same transaction object, with the same name, returns\nthe same [IDBObjectStore] instance. If this method is called on a different\ntransaction object, a different [IDBObjectStore] instance is returned.\n\n",
      "objectstorenames": "\n\nThe **`objectStoreNames`** read-only property of the\n[IDBTransaction] interface returns a [DOMStringList] of names\nof [IDBObjectStore] objects."
    }
  },
  "idbversionchangeevent": {
    "docs": "\n\nThe **`IDBVersionChangeEvent`** interface of the [IndexedDB API](/en-US/docs/Web/API/IndexedDB_API) indicates that the version of the database has changed, as the result of an [IDBOpenDBRequest.upgradeneeded_event] event handler function.\n\n",
    "properties": {
      "newversion": "\n\nThe **`newVersion`** read-only property of the\n[IDBVersionChangeEvent] interface returns the new version number of the\ndatabase.\n\n",
      "oldversion": "\n\nThe **`oldVersion`** read-only property of the\n[IDBVersionChangeEvent] interface returns the old version number of the\ndatabase.\n\nWhen the opened database doesn't exist yet, the value of `oldVersion` is 0.\n\n"
    }
  },
  "identitycredential": {
    "docs": "\n\nThe **`IdentityCredential`** interface of the [Federated Credential Management API (FedCM)](/en-US/docs/Web/API/FedCM_API) represents a user identity credential arising from a successful federated sign-in.\n\nA successful [CredentialsContainer.get] call that includes an `identity` option fulfills with an `IdentityCredential` instance.\n\n",
    "properties": {
      "token": "\n\nThe **`token`** read-only property of the [IdentityCredential] interface returns the token used to validate the associated sign-in."
    }
  },
  "identityprovider": {
    "docs": "\n\nThe **`IdentityProvider`** interface of the [Federated Credential Management (FedCM) API](/en-US/docs/Web/API/FedCM_API) represents an identity provider (IdP) and provides access to related information.\n\n",
    "properties": {
      "getuserinfo_static": "\n\nThe **`getUserInfo()`** static method of the [IdentityProvider] interface returns information about a previously signed in user, which can be used to provide a personalized welcome message and sign-in button. This method has to be called from within an identity provider (IdP)-origin `iframe` so that RP scripts cannot access the data. This must occur after a previously signed in user returns to the relying party (RP) site.\n\nThis pattern is already common on sites that use identity federation for sign-in, but `getUserInfo()` provides a way to achieve it without relying on third-party cookies."
    }
  },
  "idledeadline": {
    "docs": "\n\nThe `IdleDeadline` interface is used as the data type of the input parameter to idle callbacks established by calling [Window.requestIdleCallback]. It offers a method, [IdleDeadline.timeRemaining], which lets you determine how much longer the user agent estimates it will remain idle and a property, [IdleDeadline.didTimeout], which lets you determine if your callback is executing because its timeout duration expired.\n\nTo learn more about how request callbacks work, see [Collaborative Scheduling of Background Tasks](/en-US/docs/Web/API/Background_Tasks_API).",
    "properties": {
      "didtimeout": "\n\nThe read-only **`didTimeout`** property on the\n**[IdleDeadline]** interface is a Boolean value which\nindicates whether or not the idle callback is being invoked because the timeout interval\nspecified when [Window.requestIdleCallback] was called has expired.\n\nIf `didTimeout` is `true`, the `IdleDeadline` object's\n[IdleDeadline.timeRemaining] method will return\napproximately 0.\n\nIdle callbacks support the concept of a timeout in order to ensure that whatever task\nthey're meant to perform actually happens, even if the user agent never has enough idle\ntime available. Your callback will typically check the value of `didTimeout`\nif it needs to perform an action even if the browser is too busy to grant you the time;\nyou should react by performing the needed task or, ideally, a minimal amount of work\nthat can be done to keep things moving along, then schedule a new callback to try again\nto get the rest of the work done.",
      "timeremaining": "\n\nThe **`timeRemaining()`** method\non the [IdleDeadline] interface returns the estimated number of\nmilliseconds remaining in the current idle period. The callback can call this method at\nany time to determine how much time it can continue to work before it must return. For\nexample, if the callback finishes a task and has another one to begin, it can call\n`timeRemaining()` to see if there's enough time to complete the next task. If\nthere isn't, the callback can just return immediately, or look for other work to do with\nthe remaining time.\n\nBy the time `timeRemaining()` reaches 0, it is suggested that the callback\nshould return control to the user agent's event loop."
    }
  },
  "idledetector": {
    "docs": "\n\nThe **`IdleDetector`** interface of the [idle_detection_api] provides methods and events for detecting user activity on a device or screen.\n\nThis interface requires a secure context.\n\n",
    "properties": {
      "change_event": "\n\nThe **`change`** event of the [IdleDetector] interface fires when the value of `userState` or `screenState` has changed.",
      "requestpermission_static": "\n\nThe **`requestPermission()`** static method of the [IdleDetector]\ninterface returns a `Promise` that resolves with a string when the user has chosen\nwhether to grant the origin access to their idle state. Resolves with\n`\"granted\"` on acceptance and `\"denied\"` on refusal.",
      "screenstate": "\n\nThe **`screenState`** read-only property of the [IdleDetector] interface\nreturns a string indicating whether the screen is locked, one of `\"locked\"` or\n`\"unlocked\"`.",
      "start": "\n\nThe **`start()`** method of the [IdleDetector] interface returns a\n`Promise` that resolves when the detector starts listening for changes in the\nuser's idle state. This\nmethod takes an optional `options` object with the `threshold` in milliseconds\nwhere inactivity should be reported and `signal` for an `AbortSignal` to abort\nthe idle detector.",
      "userstate": "\n\nThe **`userState`** read-only property of the [IdleDetector] interface returns a string indicating whether the user has interacted with the device since the call to `start()`."
    }
  },
  "iirfilternode": {
    "docs": "\n\nThe **`IIRFilterNode`** interface of the [Web Audio API](/en-US/docs/Web/API/Web_Audio_API) is a [AudioNode] processor which implements a general **[infinite impulse response](https://en.wikipedia.org/wiki/Infinite_impulse_response)** (IIR) filter; this type of filter can be used to implement tone control devices and graphic equalizers as well. It lets the parameters of the filter response be specified, so that it can be tuned as needed.\n\n<table class=\"properties\">\n  <tbody>\n    <tr>\n      <th scope=\"row\">Number of inputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Number of outputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count mode</th>\n      <td><code>\"max\"</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count</th>\n      <td>Same as on the input</td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel interpretation</th>\n      <td><code>\"speakers\"</code></td>\n    </tr>\n  </tbody>\n</table>\n\nTypically, it's best to use the [BiquadFilterNode] interface to implement higher-order filters. There are several reasons why:\n\n- Biquad filters are typically less sensitive to numeric quirks.\n- The filter parameters of biquad filters can be automated.\n- All even-ordered IIR filters can be created using [BiquadFilterNode].\n\nHowever, if you need to create an odd-ordered IIR filter, you'll need to use `IIRFilterNode`. You may also find this interface useful if you don't need automation, or for other reasons.\n\n> **Note:** Once the node has been created, you can't change its coefficients.\n\n`IIRFilterNode`s have a tail-time reference; they continue to output non-silent audio with zero input. As an IIR filter, the non-zero input continues forever, but this can be limited after some finite time in practice, when the output has approached zero closely enough. The actual time that takes depends on the filter coefficients provided.",
    "properties": {
      "getfrequencyresponse": "\n\nThe `getFrequencyResponse()` method of the [IIRFilterNode]\ninterface takes the current filtering algorithm's settings and calculates the\nfrequency response for frequencies specified in a specified array of frequencies.\n\nThe two output arrays, `magResponseOutput` and\n`phaseResponseOutput`, must be created before calling this method; they\nmust be the same size as the array of input frequency values\n(`frequencyArray`)."
    }
  },
  "imagebitmap": {
    "docs": "\n\nThe **`ImageBitmap`** interface represents a bitmap image which can be drawn to a `canvas` without undue latency. It can be created from a variety of source objects using the [createImageBitmap] factory method. `ImageBitmap` provides an asynchronous and resource efficient pathway to prepare textures for rendering in WebGL.\n\n`ImageBitmap` is a [transferable object](/en-US/docs/Web/API/Web_Workers_API/Transferable_objects).",
    "properties": {
      "close": "\n\nThe **`ImageBitmap.close()`**\nmethod disposes of all graphical resources associated with an `ImageBitmap`.",
      "height": "\n\nThe read-only **`ImageBitmap.height`** property returns the [ImageBitmap] object's height in CSS pixels.",
      "width": "\n\nThe read-only **`ImageBitmap.width`** property returns the [ImageBitmap] object's width in CSS pixels."
    }
  },
  "imagebitmaprenderingcontext": {
    "docs": "\n\nThe **`ImageBitmapRenderingContext`** interface is a canvas rendering context that provides the functionality to replace the canvas's contents with the given [ImageBitmap]. Its context id (the first argument to [HTMLCanvasElement.getContext] or [OffscreenCanvas.getContext]) is `\"bitmaprenderer\"`.\n\nThis interface is available in both the window and the [worker](/en-US/docs/Web/API/Web_Workers_API) context.",
    "properties": {
      "transferfromimagebitmap": "\n\nThe **`ImageBitmapRenderingContext.transferFromImageBitmap()`**\nmethod displays the given [ImageBitmap] in the canvas associated with this\nrendering context. The ownership of the `ImageBitmap` is transferred to the\ncanvas as well.\n\nThis method was previously named `transferImageBitmap()`, but was renamed in\na spec change. The old name is being kept as an alias to avoid code breakage."
    }
  },
  "imagecapture": {
    "docs": "\n\nThe **`ImageCapture`** interface of the [MediaStream Image Capture API](/en-US/docs/Web/API/MediaStream_Image_Capture_API) provides methods to enable the capture of images or photos from a camera or other photographic device. It provides an interface for capturing images from a photographic device referenced through a valid [MediaStreamTrack].",
    "properties": {
      "getphotocapabilities": "\n\nThe **`getPhotoCapabilities()`**\nmethod of the [ImageCapture] interface returns a `Promise`\nthat resolves with an object containing the ranges of\navailable configuration options.",
      "getphotosettings": "\n\nThe **`getPhotoSettings()`** method of\nthe [ImageCapture] interface returns a `Promise` that\nresolves with an object containing the current photo\nconfiguration settings.",
      "grabframe": "\n\nThe **`grabFrame()`** method of the\n[ImageCapture] interface takes a snapshot of the live video in a\n[MediaStreamTrack] and returns a `Promise` that resolves with\na [ImageBitmap] containing the snapshot.",
      "takephoto": "\n\nThe **`takePhoto()`** method of the\n[ImageCapture] interface takes a single exposure using the video capture\ndevice sourcing a [MediaStreamTrack] and returns a `Promise`\nthat resolves with a [Blob] containing the data.",
      "track": "\n\nThe **`track`** read-only property of the\n[ImageCapture] interface returns a reference to the\n[MediaStreamTrack] passed to the\n[ImageCapture.ImageCapture] constructor."
    }
  },
  "imagedata": {
    "docs": "\n\nThe **`ImageData`** interface represents the underlying pixel data of an area of a `canvas` element.\n\nIt is created using the [ImageData.ImageData] constructor or creator methods on the [CanvasRenderingContext2D] object associated with a canvas: [CanvasRenderingContext2D.createImageData] and [CanvasRenderingContext2D.getImageData]. It can also be used to set a part of the canvas by using [CanvasRenderingContext2D.putImageData].\n\n",
    "properties": {
      "colorspace": "\n\nThe read-only **`ImageData.colorSpace`** property is a string indicating the color space of the image data.\n\nThe color space can be set during `ImageData` initialization using either the [`ImageData()`](/en-US/docs/Web/API/ImageData/ImageData) constructor or the [`createImageData()`](/en-US/docs/Web/API/CanvasRenderingContext2D/createImageData) method.",
      "data": "\n\nThe readonly **`ImageData.data`** property returns a\n`Uint8ClampedArray` that contains the [ImageData] object's\npixel data. Data is stored as a one-dimensional array in the RGBA order, with integer\nvalues between `0` and `255` (inclusive).",
      "height": "\n\nThe readonly **`ImageData.height`** property returns the number\nof rows in the [ImageData] object.",
      "width": "\n\nThe readonly **`ImageData.width`** property returns the number\nof pixels per row in the [ImageData] object."
    }
  },
  "imagedecoder": {
    "docs": "\n\nThe **`ImageDecoder`** interface of the [WebCodecs API] provides a way to unpack and decode encoded image data.",
    "properties": {
      "close": "\n\nThe **`close()`** method of the [ImageDecoder] interface ends all pending work and releases system resources.",
      "complete": "\n\nThe **`complete`** read-only property of the [ImageDecoder] interface returns true if encoded data has completed buffering.",
      "completed": "\n\nThe **`completed`** read-only property of the [ImageDecoder] interface returns a promise that resolves once encoded data has finished buffering.",
      "decode": "\n\nThe **`decode()`** method of the [ImageDecoder] interface enqueues a control message to decode the frame of an image.",
      "istypesupported_static": "\n\nThe **`ImageDecoder.isTypeSupported()`** static method checks if a given [MIME type](/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types) can be decoded by the user agent.",
      "reset": "\n\nThe **`reset()`** method of the [ImageDecoder] interface aborts all pending `decode()` operations; rejecting all pending promises. All other state will be unchanged. Class methods can continue to be invoked after `reset()`. E.g., calling `decode()` after `reset()` is permitted.",
      "tracks": "\n\nThe **`tracks`** read-only property of the [ImageDecoder] interface returns a list of the tracks in the encoded image data.",
      "type": "\n\nThe **`type`** read-only property of the [ImageDecoder] interface reflects the [MIME type](/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types) configured during construction."
    }
  },
  "imagetrack": {
    "docs": "\n\nThe **`ImageTrack`** interface of the [WebCodecs API] represents an individual image track.\n\n",
    "properties": {
      "animated": "\n\nThe **`animated`** property of the [ImageTrack] interface returns `true` if the track is animated and therefore has multiple frames.",
      "framecount": "\n\nThe **`frameCount`** property of the [ImageTrack] interface returns the number of frames in the track.",
      "repetitioncount": "\n\nThe **`repetitionCount`** property of the [ImageTrack] interface returns the number of repetitions of this track.",
      "selected": "\n\nThe **`selected`** property of the [ImageTrack] interface returns `true` if the track is selected for decoding."
    }
  },
  "imagetracklist": {
    "docs": "\n\nThe **`ImageTrackList`** interface of the [WebCodecs API] represents a list of image tracks.",
    "properties": {
      "length": "\n\nThe **`length`** property of the [ImageTrackList] interface returns the length of the `ImageTrackList`.",
      "ready": "\n\nThe **`ready`** property of the [ImageTrackList] interface returns a `Promise` that resolves when the `ImageTrackList` is populated with [ImageTrack].",
      "selectedindex": "\n\nThe **`selectedIndex`** property of the [ImageTrackList] interface returns the `index` of the selected track.",
      "selectedtrack": "\n\nThe **`selectedTrack`** property of the [ImageTrackList] interface returns an [ImageTrack] object representing the currently selected track."
    }
  },
  "ink": {
    "docs": "\n\nThe **`Ink`** interface of the [Ink API](/en-US/docs/Web/API/Ink_API) provides access to [InkPresenter] objects for the application to use to render ink strokes.\n\n",
    "properties": {
      "requestpresenter": "\n\nThe **`requestPresenter()`** method of the [Ink] interface returns a `Promise` that fulfills with an [InkPresenter] object to handle rendering strokes."
    }
  },
  "inkpresenter": {
    "docs": "\n\nThe **`InkPresenter`** interface of the [Ink API](/en-US/docs/Web/API/Ink_API) provides the ability to instruct the OS-level compositor to render ink strokes between pointer event dispatches.\n\n",
    "properties": {
      "expectedimprovement": "\n\nThe **`expectedImprovement`** read-only property of the [InkPresenter] interface returns a value, in milliseconds, indicating the latency improvement that can be expected using this presenter.\n\n### Value\n\nA number.",
      "presentationarea": "\n\nThe **`presentationArea`** read-only property of the [InkPresenter] interface returns the [Element] inside which rendering of ink strokes is confined.\n\nIf the preceding [Ink.requestPresenter] method call included a specific `presentationArea` element definition, then that will be the element returned. Otherwise, the default is returned, which is the containing viewport.\n\nThis area is always the client coordinates for the element's border box, so moving the element or scrolling the element requires no recalculation on the developer's part.\n\n### Value\n\nAn [Element].",
      "updateinktrailstartpoint": "\n\nThe **`updateInkTrailStartPoint()`** method of the [InkPresenter] interface indicates which [PointerEvent] was used as the last rendering point for the current frame, allowing the OS-level compositor to render a delegated ink trail ahead of the next pointer event being dispatched."
    }
  },
  "inputdevicecapabilities": {
    "docs": "\n\nThe **`InputDeviceCapabilities`** interface of the [InputDeviceCapabilities API] provides information about the physical device or a group of related devices responsible for generating input events. Events caused by the same physical input device get the same instance of this object, but the converse isn't true. For example, two mice with the same capabilities in a system may appear as a single `InputDeviceCapabilities` instance.\n\nIn some instances, `InputDeviceCapabilities` represents the capabilities of logical devices rather than physical devices. This allows, for example, touchscreen keyboards and physical keyboards to be represented the same way when they produce the same input.",
    "properties": {
      "firestouchevents": "\n\nThe **`firesTouchEvents`** read-only property of the [InputDeviceCapabilities] interface returns a boolean value that indicates whether the device dispatches touch events.\n\nYou can use this property to detect mouse events that represent an action that may\nalready have been handled by touch event handlers. This doesn't necessarily mean the\ndevice is a touch screen. For example, stylus and mouse devices typically generate\ntouch events on mobile browsers."
    }
  },
  "inputdeviceinfo": {
    "docs": "\n\nThe **`InputDeviceInfo`** interface of the [Media Capture and Streams API] gives access to the capabilities of the input device that it represents.\n\n`InputDeviceInfo` objects are returned by [MediaDevices.enumerateDevices] if the returned device is an audio or video input device.\n\n",
    "properties": {
      "getcapabilities": "\n\nThe **`getCapabilities()`** method of the [InputDeviceInfo] interface returns a `MediaTrackCapabilities` object describing the primary audio or video track of the device's [MediaStream]."
    }
  },
  "inputevent": {
    "docs": "\n\nThe **`InputEvent`** interface represents an event notifying the user of editable content changes.\n\n",
    "properties": {
      "data": "\n\nThe **`data`** read-only property of the\n[InputEvent] interface returns a string with inserted\ncharacters. This may be an empty string if the change doesn't insert text, such as when\ncharacters are deleted.",
      "datatransfer": "\n\nThe **`dataTransfer`** read-only property of the\n[InputEvent] interface returns a [DataTransfer] object\ncontaining information about richtext or plaintext data being added to or removed from\neditable content.",
      "gettargetranges": "\n\nThe **`getTargetRanges()`** method of the [InputEvent] interface returns an array of static ranges that will be affected by a change to the DOM if the input event is not canceled.\n\nThis allows web apps to override text edit behavior before the browser modifies the DOM tree, and provides more control over input events to improve performance.\n\nDepending on the value of `inputType` and the current editing host, the expected return value of this method varies:\n\n<table>\n  <thead>\n    <tr>\n      <th>inputType</th>\n      <th>Editing host</th>\n      <th>Response of <code>getTargetRanges()</code></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td><code>\"historyUndo\"</code> or <code>\"historyRedo\"</code></td>\n      <td>Any</td>\n      <td>empty Array</td>\n    </tr>\n    <tr>\n      <td>All remaining</td>\n      <td><code>contenteditable</code></td>\n      <td>\n        an Array of\n        [StaticRange]\n        objects associated with event\n      </td>\n    </tr>\n    <tr>\n      <td>All remaining</td>\n      <td>\n        <a href=\"/en-US/docs/Web/HTML/Element/input\"><code>input</code></a>\n        or <a href=\"/en-US/docs/Web/HTML/Element/textarea\"><code>textarea</code></a>\n      </td>\n      <td>\n        an empty Array\n      </td>\n    </tr>\n  </tbody>\n</table>",
      "inputtype": "\n\nThe **`inputType`** read-only property of the\n[InputEvent] interface returns the type of change made to editable content.\nPossible changes include for example inserting, deleting, and formatting text.",
      "iscomposing": "\n\nThe **`InputEvent.isComposing`** read-only property returns a\nboolean value indicating if the event is fired after\n[Element/compositionstart_event] and before [Element/compositionend_event]."
    }
  },
  "installevent": {
    "docs": "\n\nThe parameter passed into the [ServiceWorkerGlobalScope.install_event] handler, the `InstallEvent` interface represents an install action that is dispatched on the [ServiceWorkerGlobalScope] of a [ServiceWorker]. As a child of [ExtendableEvent], it ensures that functional events such as [FetchEvent] are not dispatched during installation.\n\nThis interface inherits from the [ExtendableEvent] interface.\n\n> **Note:** Instead of using the deprecated `ServiceWorkerGlobalScope.oninstall()` handler to catch events of this type, instead handle the (non-deprecated) [`install`](/en-US/docs/Web/API/ServiceWorkerGlobalScope/install_event) using a listener added with [`addEventListener()`](/en-US/docs/Web/API/EventTarget/addEventListener)."
  },
  "intersectionobserver": {
    "docs": "\n\nThe **`IntersectionObserver`** interface of the [Intersection Observer API](/en-US/docs/Web/API/Intersection_Observer_API) provides a way to asynchronously observe changes in the intersection of a target element with an ancestor element or with a top-level document's . The ancestor element or viewport is referred to as the root.\n\nWhen an `IntersectionObserver` is created, it's configured to watch for given ratios of visibility within the root. The configuration cannot be changed once the `IntersectionObserver` is created, so a given observer object is only useful for watching for specific changes in degree of visibility; however, you can watch multiple target elements with the same observer.",
    "properties": {
      "disconnect": "\n\nThe [IntersectionObserver] method\n**`disconnect()`** stops watching all of its target elements\nfor visibility changes.",
      "observe": "\n\nThe [IntersectionObserver] method\n**`observe()`** adds an element to the set of target elements\nbeing watched by the `IntersectionObserver`. One observer has one set of\nthresholds and one root, but can watch multiple target elements for visibility changes\nin keeping with those.\n\nTo stop observing the element, call\n[IntersectionObserver.unobserve].\n\nWhen the visibility of the specified element crosses over one of the observer's\nvisibility thresholds (as listed in [IntersectionObserver.thresholds]), the\nobserver's callback is executed with an array of\n[IntersectionObserverEntry] objects representing the intersection changes\nwhich occurred. Note that this design allows multiple elements' intersection changes to\nbe processed by a single call to the callback.\n\n> **Note:** the observer [callback](/en-US/docs/Web/API/IntersectionObserver/IntersectionObserver#callback) will always fire the first render cycle after `observe()` is called, even if the observed element has not yet moved with respect to the viewport.\n> This means that, for example, an element that is outside the viewport when `observe()` is called on it will result in the callback being immediately called with at least one [entry](/en-US/docs/Web/API/IntersectionObserverEntry) with [`intersecting`](/en-US/docs/Web/API/IntersectionObserverEntry/isIntersecting) set to `false`.\n> An element inside the viewport will result in the callback being immediately called with at least one entry with `intersecting` set to `true`.",
      "root": "\n\nThe [IntersectionObserver] interface's read-only\n**`root`** property identifies the [Element] or\n[Document] whose bounds are treated as the \nof the  for the element which is the observer's target.\n\nIf the `root` is `null`, then the bounds of the actual document\nviewport are used.",
      "rootmargin": "\n\nThe [IntersectionObserver] interface's read-only\n**`rootMargin`** property is a string with syntax similar to\nthat of the CSS `margin` property. Each side of the rectangle represented\nby `rootMargin` is added to the corresponding side in the\n[IntersectionObserver.root] element's \nbefore the intersection test is performed. This lets you, for example, adjust the bounds\noutward so that the target element is considered 100% visible even if a certain number\nof pixels worth of width or height is clipped away, or treat the target as partially\nhidden if an edge is too close to the edge of the root's bounding box.\n\nSee [how intersections are calculated](/en-US/docs/Web/API/Intersection_Observer_API#how_intersection_is_calculated)\nfor a more in-depth look at the root margin and how it works with\nthe root's bounding box.",
      "takerecords": "\n\nThe [IntersectionObserver] method\n**`takeRecords()`** returns an array of\n[IntersectionObserverEntry] objects, one for each targeted element which\nhas experienced an intersection change since the last time the intersections were\nchecked, either explicitly through a call to this method or implicitly by an automatic\ncall to the observer's callback.\n\n> **Note:** If you use the callback to monitor these changes, you don't\n> need to call this method. Calling this method clears the pending intersection list, so\n> the callback will not be run.",
      "thresholds": "\n\nThe [IntersectionObserver] interface's read-only\n**`thresholds`** property returns the list of intersection\nthresholds that was specified when the observer was instantiated with\n[IntersectionObserver.IntersectionObserver]. If\nonly one threshold ratio was provided when instantiating the object, this will be an\narray containing that single value.\n\nSee the [Intersection Observer](/en-US/docs/Web/API/Intersection_Observer_API#thresholds) page to\nlearn how thresholds work.",
      "unobserve": "\n\nThe [IntersectionObserver] method\n**`unobserve()`** instructs the\n`IntersectionObserver` to stop observing the specified target\nelement."
    }
  },
  "intersectionobserverentry": {
    "docs": "\n\nThe **`IntersectionObserverEntry`** interface of the [Intersection Observer API](/en-US/docs/Web/API/Intersection_Observer_API) describes the intersection between the target element and its root container at a specific moment of transition.\n\nInstances of `IntersectionObserverEntry` are delivered to an [IntersectionObserver] callback in its `entries` parameter; otherwise, these objects can only be obtained by calling [IntersectionObserver.takeRecords].",
    "properties": {
      "boundingclientrect": "\n\nThe [IntersectionObserverEntry] interface's read-only\n**`boundingClientRect`** property returns a\n[DOMRectReadOnly] which in essence describes a rectangle describing the\nsmallest rectangle that contains the entire target element.",
      "intersectionratio": "\n\nThe [IntersectionObserverEntry] interface's\nread-only **`intersectionRatio`** property tells you how much\nof the target element is currently visible within the root's intersection ratio, as a\nvalue between 0.0 and 1.0.",
      "intersectionrect": "\n\nThe [IntersectionObserverEntry] interface's\nread-only **`intersectionRect`** property is a\n[DOMRectReadOnly] object which describes the smallest rectangle that\ncontains the entire portion of the target element which is currently visible within\nthe intersection root.",
      "isintersecting": "\n\nThe [IntersectionObserverEntry] interface's\nread-only **`isIntersecting`** property is a Boolean value\nwhich is `true` if the target element intersects with the intersection\nobserver's root. If this is `true`, then, the\n`IntersectionObserverEntry` describes a transition into a state of\nintersection; if it's `false`, then you know the transition is from\nintersecting to not-intersecting.",
      "rootbounds": "\n\nThe [IntersectionObserverEntry] interface's\nread-only **`rootBounds`** property is a\n[DOMRectReadOnly] corresponding to the\n[IntersectionObserverEntry.target]'s root intersection\nrectangle, offset by the [IntersectionObserver.rootMargin] if one is\nspecified.",
      "target": "\n\nThe [IntersectionObserverEntry] interface's\nread-only **`target`** property indicates which targeted\n[Element] has changed its amount of intersection with the intersection\nroot.",
      "time": "\n\nThe [IntersectionObserverEntry] interface's\nread-only **`time`** property is a\n[DOMHighResTimeStamp] that indicates the time at which the intersection\nchange occurred relative to the time at which the document was created."
    }
  },
  "interventionreportbody": {
    "docs": "\n\nThe `InterventionReportBody` interface of the [Reporting API](/en-US/docs/Web/API/Reporting_API) represents the body of an intervention report.\n\nAn intervention report is generated when usage of a feature in a web document has been blocked by the browser for reasons such as security, performance, or user annoyance. So for example, a script was been stopped because it was significantly slowing down the browser, or the browser's autoplay policy blocked audio from playing without a user gesture to trigger it.\n\nA deprecation report is generated when a deprecated feature (for example a deprecated API method) is used on a document being observed by a [ReportingObserver]. In addition to the support of this API, receiving useful intervention warnings relies on browser vendors adding these warnings for the relevant features.\n\n",
    "properties": {
      "columnnumber": "\n\nThe **`columnNumber`** read-only property of the [InterventionReportBody] interface returns the line in the source file in which the intervention occurred.\n\n> **Note:** This property is most useful alongside [InterventionReportBody.sourceFile] and [InterventionReportBody.lineNumber] as it enables the location of the column in that file and line where the feature is used.",
      "id": "\n\nThe **`id`** read-only property of the [InterventionReportBody] interface returns a string identifying the intervention that generated the report. This can be used to group reports.",
      "linenumber": "\n\nThe **`lineNumber`** read-only property of the [InterventionReportBody] interface returns the line in the source file in which the intervention occurred.\n\n> **Note:** This property is most useful alongside [InterventionReportBody.sourceFile] as it enables the location of the line in that file where the feature is used.",
      "message": "\n\nThe **`message`** read-only property of the [InterventionReportBody] interface returns a human-readable description of the intervention, including information such as how the intervention could be avoided. This typically matches the message a browser will display in its DevTools console when an intervention is imposed, if one is available.",
      "sourcefile": "\n\nThe **`sourceFile`** read-only property of the [InterventionReportBody] interface returns the path to the source file where the intervention occurred.\n\n> **Note:** This property can be used with [InterventionReportBody.lineNumber] and [InterventionReportBody.columnNumber] to locate the column and line in the file where the feature is used.",
      "tojson": "\n\nThe **`toJSON()`** method of the [InterventionReportBody] interface is a _serializer_, and returns a JSON representation of the `InterventionReportBody` object."
    }
  },
  "keyboard": {
    "docs": "\n\nThe **`Keyboard`** interface of the [Keyboard API] provides functions that retrieve keyboard layout maps and toggle capturing of key presses from the physical keyboard.\n\nA list of valid code values is found in the [UI Events KeyboardEvent code Values](https://www.w3.org/TR/uievents-code/#key-alphanumeric-writing-system) spec.\n\n",
    "properties": {
      "getlayoutmap": "\n\nThe **`getLayoutMap()`** method of the\n[Keyboard] interface returns a `Promise` that resolves with\nan instance of [KeyboardLayoutMap] which is a map-like object with\nfunctions for retrieving the strings associated with specific physical keys.",
      "lock": "\n\nThe **`lock()`** method of the\n[Keyboard] interface returns a `Promise` after enabling the\ncapture of keypresses for any or all of the keys on the physical keyboard. This method\ncan only capture keys that are granted access by the underlying operating\nsystem.\n\nIf `lock()` is called multiple times then only the key codes specified in the most recent call will be locked.\nAny keys locked by a previous call to `lock()` are unlocked.",
      "unlock": "\n\nThe **`unlock()`** method of the\n[Keyboard] interface unlocks all keys captured by the\n[Keyboard.lock] method and returns synchronously."
    }
  },
  "keyboardevent": {
    "docs": "\n\n**`KeyboardEvent`** objects describe a user interaction with the keyboard; each event describes a single interaction between the user and a key (or combination of a key with modifier keys) on the keyboard. The event type ([Element/keydown_event], [Element/keypress_event], or [Element/keyup_event]) identifies what kind of keyboard activity occurred.\n\n> **Note:** `KeyboardEvent` events just indicate what interaction the user had with a key on the keyboard at a low level, providing no contextual meaning to that interaction. When you need to handle text input, use the [Element/input_event] event instead. Keyboard events may not be fired if the user is using an alternate means of entering text, such as a handwriting system on a tablet or graphics tablet.\n\n",
    "properties": {
      "altkey": "\n\nThe **`KeyboardEvent.altKey`** read-only property is a\nboolean value that indicates if the <kbd>alt</kbd> key (<kbd>Option</kbd> or <kbd>⌥</kbd> on macOS) was pressed (`true`) or not (`false`) when\nthe event occurred.",
      "charcode": "\n\nThe **`charCode`** read-only property of the\n[KeyboardEvent] interface returns the Unicode value of a character key\npressed during a [Element/keypress_event] event.\n\n> **Warning:** Do not use this property, as it is deprecated. Instead, get the\n> Unicode value of the character using the [KeyboardEvent.key]\n> property.",
      "code": "\n\nThe `KeyboardEvent.code` property represents a physical key on the keyboard (as opposed to the character generated by pressing the key). In other words, this property returns a value that isn't altered by keyboard layout or the state of the modifier keys.\n\nIf the input device isn't a physical keyboard, but is instead a virtual keyboard or accessibility device, the returned value will be set by the browser to match as closely as possible to what would happen with a physical keyboard, to maximize compatibility between physical and virtual input devices.\n\nThis property is useful when you want to handle keys based on their physical positions on the input device rather than the characters associated with those keys; this is especially common when writing code to handle input for games that simulate a gamepad-like environment using keys on the keyboard. Be aware, however, that you can't use the value reported by `KeyboardEvent.code` to determine the character generated by the keystroke, because the keycode's name may not match the actual character that's printed on the key or that's generated by the computer when the key is pressed.\n\nFor example, the `code` returned is \"`KeyQ`\" for the <kbd>Q</kbd> key on a QWERTY layout keyboard, but the same `code` value also represents the <kbd>'</kbd> key on Dvorak keyboards and the <kbd>A</kbd> key on AZERTY keyboards. That makes it impossible to use the value of `code` to determine what the name of the key is to users if they're not using an anticipated keyboard layout.\n\nTo determine what character corresponds with the key event, use the [KeyboardEvent.key] property instead.",
      "ctrlkey": "\n\nThe **`KeyboardEvent.ctrlKey`** read-only property returns a\nboolean value that indicates if the <kbd>control</kbd> key was pressed\n(`true`) or not (`false`) when the event occurred.",
      "getmodifierstate": "\n\nThe **`KeyboardEvent.getModifierState()`** method returns the\ncurrent state of the specified modifier key: `true` if the modifier is active\n(that is the modifier key is pressed or locked), otherwise, `false`.",
      "initkeyboardevent": "\n\nThe **`KeyboardEvent.initKeyboardEvent()`** method initializes\nthe attributes of a keyboard event object. This method was introduced in draft of DOM\nLevel 3 Events, but deprecated in newer draft. Gecko won't support this feature since\nimplementing this method as experimental broke existing web apps (see [Firefox bug 999645](https://bugzil.la/999645)).\nWeb applications should use constructor instead of this if it's available.",
      "initkeyevent": "\n\n> **Warning:** Do NOT use this method; Use the [KeyboardEvent.KeyboardEvent] constructor instead!\n>\n> The method has been removed from the DOM specification and is not supported by any current browser.\n> Firefox hides this method behind the preference (`dom.keyboardevent.init_key_event.enabled`) from version 93 and plans to remove it shortly afterwards.\n\nThe **`KeyboardEvent.initKeyEvent()`** method is used to\ninitialize the value of an event created using\n[document.createEvent] `(\"KeyboardEvent\")`. Events initialized in\nthis way must have been created with the\n[document.createEvent] `(\"KeyboardEvent\")` method.\n`initKeyEvent()` must be called to set the event before it is [dispatched](/en-US/docs/Web/API/EventTarget/dispatchEvent).",
      "iscomposing": "\n\nThe **`KeyboardEvent.isComposing`** read-only property returns\na boolean value indicating if the event is fired within a composition\nsession, i.e. after [Element/compositionstart_event]\nand before [Element/compositionend_event].",
      "key": "\n\nThe [KeyboardEvent] interface's **`key`** read-only property returns the value of the key pressed by the user, taking into consideration the state of modifier keys such as <kbd>Shift</kbd> as well as the keyboard locale and layout.",
      "keycode": "\n\nThe deprecated **`KeyboardEvent.keyCode`** read-only property represents a system and implementation dependent numerical code identifying the unmodified value of the pressed key.\n\nThis is usually the decimal ASCII (`20`) or Windows 1252 code corresponding to the key. If the key can't be identified, this value is `0`.\n\nYou should avoid using this if possible; it's been deprecated for some time. Instead, you should use [KeyboardEvent.code], if it's implemented. Unfortunately, some browsers still don't have it, so you'll have to be careful to make sure you use one which is supported on all target browsers.\n\n> **Note:** Web developers shouldn't use the `keyCode` attribute for printable characters when handling `keydown` and `keyup` events. As described above, the `keyCode` attribute is not useful for printable characters, especially those input with the <kbd>Shift</kbd> or <kbd>Alt</kbd> key pressed. When implementing a shortcut key handler, the [Element/keypress_event] event is usually better (at least when Gecko is the runtime in use).",
      "keyidentifier": "\n\nThe deprecated **`KeyboardEvent.keyIdentifier`** read-only property returns a \"key identifier\" string that can be used to determine what key was pressed. Its non-deprecated replacement is [KeyboardEvent.key].",
      "location": "\n\nThe **`KeyboardEvent.location`** read-only property returns an\n`unsigned long` representing the location of the key on the keyboard or other\ninput device.\n\nPossible values are:\n\n<table class=\"standard-table\">\n  <thead>\n    <tr>\n      <th>Constant</th>\n      <th>Value</th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td><code>DOM_KEY_LOCATION_STANDARD</code></td>\n      <td>0</td>\n      <td>\n        The key has only one version, or can't be distinguished between the left\n        and right versions of the key, and was not pressed on the numeric keypad\n        or a key that is considered to be part of the keypad.\n      </td>\n    </tr>\n    <tr>\n      <td><code>DOM_KEY_LOCATION_LEFT</code></td>\n      <td>1</td>\n      <td>\n        The key was the left-hand version of the key; for example, the left-hand\n        <kbd>Control</kbd> key was pressed on a standard 101 key US keyboard.\n        This value is only used for keys that have more than one possible\n        location on the keyboard.\n      </td>\n    </tr>\n    <tr>\n      <td><code>DOM_KEY_LOCATION_RIGHT</code></td>\n      <td>2</td>\n      <td>\n        The key was the right-hand version of the key; for example, the\n        right-hand <kbd>Control</kbd> key is pressed on a standard 101 key US\n        keyboard. This value is only used for keys that have more than one\n        possible location on the keyboard.\n      </td>\n    </tr>\n    <tr>\n      <td><code>DOM_KEY_LOCATION_NUMPAD</code></td>\n      <td>3</td>\n      <td>\n        <p>\n          The key was on the numeric keypad, or has a virtual key code that\n          corresponds to the numeric keypad.\n        </p>\n        <div class=\"note\">\n          <p>\n            <strong>Note:</strong> When <kbd>NumLock</kbd> is locked, Firefox\n            always returns <code>DOM_KEY_LOCATION_NUMPAD</code> for the keys on\n            the numeric pad. Otherwise, when <kbd>NumLock</kbd> is unlocked and\n            the keyboard actually has a numeric keypad, Firefox always returns\n            <code>DOM_KEY_LOCATION_NUMPAD</code> too. On the other hand, if the\n            keyboard doesn't have a keypad, such as on a notebook computer, some\n            keys become Numpad only when NumLock is locked. When such keys fires\n            key events, the location attribute value depends on the key. That\n            is, it must not be <code>DOM_KEY_LOCATION_NUMPAD</code>.\n          </p>\n        </div>\n        <div class=\"note\">\n          <p>\n            <strong>Note:</strong> <kbd>NumLock</kbd> key's key events indicate\n            <code>DOM_KEY_LOCATION_STANDARD</code> both on Firefox and Internet\n            Explorer.\n          </p>\n        </div>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        <code>DOM_KEY_LOCATION_MOBILE</code>\n         \n      </td>\n      <td>4</td>\n      <td>\n        <p>\n          The key was on a mobile device; this can be on either a physical\n          keypad or a virtual keyboard.\n        </p>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        <code>DOM_KEY_LOCATION_JOYSTICK</code> \n        \n      </td>\n      <td>5</td>\n      <td>\n        <p>\n          The key was a button on a game controller or a joystick on a mobile\n          device.\n        </p>\n      </td>\n    </tr>\n  </tbody>\n</table>",
      "metakey": "\n\nThe **`KeyboardEvent.metaKey`** read-only property returning a\nboolean value that indicates if the <kbd>Meta</kbd> key was pressed\n(`true`) or not (`false`) when the event occurred. Some operating\nsystems may intercept the key so it is never detected.\n\n> **Note:** On Macintosh keyboards, this is the <kbd>⌘ Command</kbd> key.\n\n> **Note:** Before Firefox 118, the <kbd>⊞ Windows</kbd> key was handled\n> as an \"OS\" key rather than the \"Meta\" key. `KeyboardEvent.metaKey` was\n> `false` when the <kbd>⊞ Windows</kbd> key was pressed.",
      "repeat": "\n\nThe **`repeat`** read-only property of the\n[KeyboardEvent] interface returns a boolean value that is\n`true` if the given key is being held down such that it is automatically\nrepeating.",
      "shiftkey": "\n\nThe **`KeyboardEvent.shiftKey`** read-only property is a\nboolean value that indicates if the <kbd>shift</kbd> key was pressed\n(`true`) or not (`false`) when the event occurred."
    }
  },
  "keyboardlayoutmap": {
    "docs": "\n\nThe **`KeyboardLayoutMap`** interface of the [Keyboard API] is a read-only object with functions for retrieving the string associated with specific physical keys.\n\nA `KeyboardLayoutMap` instance is a read-only [`Map`-like object](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map#map-like_browser_apis), in which each key is a string identifying the unique physical key on the keyboard (a \"key code\"), and the corresponding value is the associated key attribute value (which may be affected by the keyboard layout, and so on).\n\nA list of valid keys is found in the [UI Events KeyboardEvent code Values](https://www.w3.org/TR/uievents-code/#key-alphanumeric-writing-system) specification.",
    "properties": {
      "entries": "\n\nThe **`entries()`** method of the [KeyboardLayoutMap] interface returns a new [Iterator](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Iterator) object that contains the key/value pairs, in the same order as that provided by a `for...in` loop (the difference being that a `for-in` loop enumerates properties in the prototype chain as well).\n\nThe method is otherwise the same as `Map.prototype.entries()`.",
      "foreach": "\n\nThe **`forEach()`** method of the\n[KeyboardLayoutMap] interface executes a provided function once for\neach element of the map.\n\nThe method is otherwise the same as `Map.prototype.forEach()`.",
      "get": "\n\nThe **`get()`** method of the\n[KeyboardLayoutMap] interface returns the element with the given\nkey.\n\nA list of valid keys is found in the [UI Events KeyboardEvent code Values](https://www.w3.org/TR/uievents-code/#key-alphanumeric-writing-system) spec.\n\nThe method is otherwise the same as `Map.prototype.get()`.",
      "has": "\n\nThe **`has()`** method of the\n[KeyboardLayoutMap] interface returns a boolean indicating whether the\nobject has an element with the specified key.\n\nA list of valid keys is found in\nthe [UI Events KeyboardEvent code Values](https://www.w3.org/TR/uievents-code/#key-alphanumeric-writing-system) spec.\n\nThe method is otherwise the same as `Map.prototype.has()`.",
      "keys": "\n\nThe **`keys()`** method of the [KeyboardLayoutMap] interface returns a new [Iterator](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Iterator) object that contains the keys for each index in the `KeyboardLayoutMap` object.\n\nThe method is otherwise the same as `Map.prototype.keys()`.",
      "size": "\n\nThe **`size`** read-only property of\nthe [KeyboardLayoutMap] interface returns the number of elements in the\nmap.\n\nThe property is otherwise the same as `Map.prototype.size`.",
      "values": "\n\nThe **`values()`** method of the [KeyboardLayoutMap] interface returns a new [Iterator](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Iterator) object that contains the values for each index in the `KeyboardLayoutMap` object.\n\nThe method is otherwise the same as `Map.prototype.values()`."
    }
  },
  "keyframeeffect": {
    "docs": "\n\nThe **`KeyframeEffect`** interface of the [Web Animations API](/en-US/docs/Web/API/Web_Animations_API) lets us create sets of animatable properties and values, called **keyframes.** These can then be played using the [Animation.Animation] constructor.\n\n",
    "properties": {
      "composite": "\n\nThe **`composite`** property of a [KeyframeEffect] resolves how an element's animation impacts its underlying property values.",
      "getkeyframes": "\n\nThe **`getKeyframes()`** method of a [KeyframeEffect] returns an Array of the computed keyframes that make up this animation along with their computed offsets.",
      "iterationcomposite": "\n\nThe **`iterationComposite`** property of a [KeyframeEffect] resolves how the animation's property value changes accumulate or override each other upon each of the animation's iterations.",
      "pseudoelement": "\n\nThe **`pseudoElement`** property of a [KeyframeEffect] interface is a string representing the pseudo-element being animated. It may be `null` for animations that do not target a pseudo-element. It performs as both a getter and a setter, except with animations and transitions generated by CSS.\n\n> **Note:** If set to the legacy single-colon syntax of , , , or , the string is transformed into its double-colon modern version (, , , and , respectively).",
      "setkeyframes": "\n\nThe **`setKeyframes()`** method of the [KeyframeEffect] interface replaces the keyframes that make up the affected `KeyframeEffect` with a new set of keyframes.",
      "target": "\n\nThe **`target`** property of a [KeyframeEffect] interface represents the element or pseudo-element being animated. It may be `null` for animations that do not target a specific element. It performs as both a getter and a setter, except with animations and transitions generated by CSS."
    }
  },
  "largestcontentfulpaint": {
    "docs": "\n\nThe `LargestContentfulPaint` interface provides timing information about the largest image or text paint before user input on a web page.",
    "properties": {
      "element": "\n\nThe **`element`** read-only property of the [LargestContentfulPaint] interface returns an object representing the [Element] that is the largest contentful paint.",
      "id": "\n\nThe **`id`** read-only property of the [LargestContentfulPaint] interface returns the ID of the element that is the largest contentful paint.",
      "loadtime": "\n\nThe **`loadTime`** read-only property of the [LargestContentfulPaint] interface returns the time that the element was loaded.",
      "rendertime": "\n\nThe **`renderTime`** read-only property of the [LargestContentfulPaint] interface represents the time that the element was rendered to the screen.",
      "size": "\n\nThe **`size`** read-only property of the [LargestContentfulPaint] interface returns the intrinsic size of the element that is the largest contentful paint.\n\nThe `size` of the element is the `width` times `height` of the [DOMRectReadOnly] that this element creates on the screen.",
      "tojson": "\n\nThe **`toJSON()`** method of the [LargestContentfulPaint] interface is a ; it returns a JSON representation of the [LargestContentfulPaint] object.",
      "url": "\n\nThe **`url`** read-only property of the [LargestContentfulPaint] interface returns the request URL of the element, if the element is an image."
    }
  },
  "launchparams": {
    "docs": "\n\nThe **`LaunchParams`** interface of the [Launch Handler API] is used when implementing custom launch navigation handling in a PWA. When [LaunchQueue.setConsumer] is invoked to set up the launch navigation handling functionality, the callback function inside `setConsumer()` is passed a `LaunchParams` object instance.\n\nSuch custom navigation handling is initiated via [Window.launchQueue] when a PWA has been launched with a [`launch_handler`](/en-US/docs/Web/Manifest/launch_handler) `client_mode` value of `focus-existing`, `navigate-new`, or `navigate-existing`.\n\n",
    "properties": {
      "files": "\n\nThe **`files`** read-only property of the [LaunchParams] interface returns an array of [FileSystemHandle] objects representing any files passed along with the launch navigation via the [`POST`](/en-US/docs/Web/HTTP/Methods/POST) method.",
      "targeturl": "\n\nThe **`targetURL`** read-only property of the [LaunchParams] interface returns the target URL of the associated web app launch."
    }
  },
  "launchqueue": {
    "docs": "\n\nThe **`LaunchQueue`** interface of the [Launch Handler API] is available via the [Window.launchQueue] property. When a [progressive web app](/en-US/docs/Web/Progressive_web_apps) (PWA) is launched with a [`launch_handler`](/en-US/docs/Web/Manifest/launch_handler) `client_mode` value of `focus-existing`, `navigate-new`, or `navigate-existing`, [LaunchQueue] provides access to functionality that allows custom launch navigation handling to be implemented in the PWA. This functionality is controlled by the properties of the [LaunchParams] object passed into the [LaunchQueue.setConsumer] callback function.\n\n",
    "properties": {
      "setconsumer": "\n\nThe **`setConsumer()`** method of the [LaunchQueue] interface is used to declare the callback that will handle custom launch navigation handling in a [progressive web app](/en-US/docs/Web/Progressive_web_apps) (PWA). Such custom navigation is initiated via [Window.launchQueue] when a PWA has been launched with a [`launch_handler`](/en-US/docs/Web/Manifest/launch_handler) `client_mode` value of `focus-existing`, `navigate-new`, or `navigate-existing`."
    }
  },
  "layoutshift": {
    "docs": "\n\nThe `LayoutShift` interface of the [Performance API](/en-US/docs/Web/API/Performance_API) provides insights into the layout stability of web pages based on movements of the elements on the page.",
    "properties": {
      "hadrecentinput": "\n\nThe **`hadRecentInput`** read-only property of the [LayoutShift] interface returns `true` if [LayoutShift.lastInputTime] is less than 500 milliseconds in the past.\n\nLayout shifts are only a problem if the user is not expecting them, so layout shifts that are the result of user interactions (such as a user expanding a UI element) are often not considered in layout shift metrics. The `hadRecentInput` property allows you to exclude these shifts.",
      "lastinputtime": "\n\nThe **`lastInputTime`** read-only property of the [LayoutShift] interface returns the time of the most recent excluding input or `0` if no excluding input has occurred.\n\nLayout shifts are only bad if the user wasn't expecting them. Many layout shift metrics (like [Cumulative Layout Shift (CLS)](https://web.dev/articles/cls)) exclude shifts that occurred soon after certain user interactions. These interactions are called _excluding inputs_. Excluding inputs are:\n\n- Any events which signal a user's active interaction with the document: ([`mousedown`](/en-US/docs/Web/API/Element/mousedown_event), [`keydown`](/en-US/docs/Web/API/Element/keydown_event), and [`pointerdown`](/en-US/docs/Web/API/Element/pointerdown_event))\n- Any events which directly changes the size of the viewport.\n- [`change`](/en-US/docs/Web/API/HTMLElement/change_event) events.\n\nThe [`mousemove`](/en-US/docs/Web/API/Element/mousemove_event) and [`pointermove`](/en-US/docs/Web/API/Element/pointermove_event) events are **not** excluding inputs.",
      "sources": "\n\nThe **`sources`** read-only property of the [LayoutShift] interface returns an array of [LayoutShiftAttribution] objects that indicate the DOM elements that moved during the layout shift.",
      "tojson": "\n\nThe **`toJSON()`** method of the [LayoutShift] interface is a ; it returns a JSON representation of the [LayoutShift] object.",
      "value": "\n\nThe **`value`** read-only property of the [LayoutShift] interface returns the layout shift score calculated as the impact fraction (fraction of the viewport that was shifted) multiplied by the distance fraction (distance moved as a fraction of viewport)."
    }
  },
  "layoutshiftattribution": {
    "docs": "\n\nThe `LayoutShiftAttribution` interface provides debugging information about elements which have shifted.\n\nInstances of `LayoutShiftAttribution` are returned in an array by calling [LayoutShift.sources].",
    "properties": {
      "currentrect": "\n\nThe **`currentRect`** read-only property of the [LayoutShiftAttribution] interface returns a [DOMRectReadOnly] object representing the position of the element after the shift.",
      "node": "\n\nThe **`node`** read-only property of the [LayoutShiftAttribution] interface returns a [Node] representing the object that has shifted.",
      "previousrect": "\n\nThe **`previousRect`** read-only property of the [LayoutShiftAttribution] interface returns a [DOMRectReadOnly] object representing the position of the element before the shift.",
      "tojson": "\n\nThe **`toJSON()`** method of the [LayoutShiftAttribution] interface is a _serializer_ that returns a JSON representation of the `LayoutShiftAttribution` object."
    }
  },
  "linearaccelerationsensor": {
    "docs": "\n\nThe **`LinearAccelerationSensor`** interface of the [Sensor APIs](/en-US/docs/Web/API/Sensor_APIs) provides on each reading the acceleration applied to the device along all three axes, but without the contribution of gravity.\n\nTo use this sensor, the user must grant permission to the `'accelerometer'` device sensor through the [Permissions API](/en-US/docs/Web/API/Permissions_API). In addition, this feature may be blocked by a [Permissions Policy](/en-US/docs/Web/HTTP/Permissions_Policy) set on your server.\n\n"
  },
  "location": {
    "docs": "\n\nThe **`Location`** interface represents the location (URL) of the object it is linked to. Changes done on it are reflected on the object it relates to. Both the [Document] and [Window] interface have such a linked `Location`, accessible via [Document.location] and [Window.location] respectively.",
    "properties": {
      "ancestororigins": "\n\nThe **`ancestorOrigins`** read-only\nproperty of the [Location] interface is a static\n[DOMStringList] containing, in reverse order, the origins of all ancestor\nbrowsing contexts of the document associated with the given [Location]\nobject.\n\nYou can use `location.ancestorOrigins` in the script for a document to\ndetermine, for example, whenever the document is being framed by a site which you don't\nexpect it to be framed by. You can also use it to vary the behavior of the document\nbased on what site or list of sites is framing it.",
      "assign": "\n\nThe **`Location.assign()`** method causes the window to load\nand display the document at the URL specified. After the navigation occurs, the user can\nnavigate back to the page that called `Location.assign()` by pressing the\n\"back\" button.\n\nIf the assignment can't happen because of a security violation, a\n[DOMException] of the `SECURITY_ERROR` type is thrown. This\nhappens if the origin of the script calling the method is different from the origin of\nthe page originally described by the [Location] object, mostly when the\nscript is hosted on a different domain.\n\nIf the provided URL is not valid, a [DOMException] of the\n`SYNTAX_ERROR` type is thrown.",
      "hash": "\n\nThe **`hash`** property of the\n[Location] interface returns a string containing a\n`'#'` followed by the fragment identifier of the URL — the ID on the page\nthat the URL is trying to target.\n\nThe fragment is not [URL decoded](https://en.wikipedia.org/wiki/URL_encoding). If the URL does not\nhave a fragment identifier, this property contains an empty string, `\"\"`.",
      "host": "\n\nThe **`host`** property of the [Location]\ninterface is a string containing the host, that is the\n_hostname_, and then, if the _port_ of the URL is nonempty, a\n`':'`, and the _port_ of the URL.",
      "hostname": "\n\nThe **`hostname`** property of the [Location]\ninterface is a string containing the domain of the URL.",
      "href": "\n\nThe **`href`** property of the [Location]\ninterface is a  that returns a string containing the whole\nURL, and allows the href to be updated.\n\nSetting the value of `href` _navigates_ to the provided URL. If you\nwant _redirection_, use [Location/replace]. The difference from setting the `href` property value is that when using the `location.replace()` method, after navigating to the given URL, the current page will not be saved in session [history](/en-US/docs/Web/API/History_API) — meaning the user won't be able to use the back button to navigate to it.",
      "origin": "\n\nThe **`origin`** read-only property of\nthe [Location] interface is a string containing the\nUnicode serialization of the origin of the represented URL.\n\nThat is:\n\n- for URL using the `http` or `https`, the scheme followed by\n  `'://'`, followed by the domain, followed by `':'`, followed by\n  the port (the default port, `80` and `443` respectively, if\n  explicitly specified);\n- for URL using `file:` scheme, the value is browser dependent;\n- for URL using the `blob:` scheme, the origin of the URL following\n  `blob:`. E.g `\"blob:https://mozilla.org\"` will have\n  `\"https://mozilla.org\".`\n\n",
      "pathname": "\n\nThe **`pathname`** property of the [Location]\ninterface is a string containing the path of the URL for the location. If there is no path, `pathname` will be empty: otherwise, `pathname` contains an initial '/' followed by the path of the URL, not including the query string or fragment.",
      "port": "\n\nThe **`port`** property of the [Location]\ninterface is a string containing the port number of the URL. If the\nURL does not contain an explicit port number, it will be set to `''`.",
      "protocol": "\n\nThe **`protocol`** property of the [Location]\ninterface is a string representing the protocol scheme of the URL,\nincluding the final `':'`.",
      "reload": "\n\nThe **`location.reload()`** method reloads the current URL, like the Refresh button.\n\nThe reload may be blocked and a `SECURITY_ERROR` [DOMException]\nthrown. This happens if the  of the script calling\n`location.reload()` differs from the origin of the page that owns the\n[Location] object. See [Same-origin policy](/en-US/docs/Web/Security/Same-origin_policy) for more\ninformation.",
      "replace": "\n\nThe **`replace()`** method of the [Location]\ninterface replaces the current resource with the one at the provided URL. The difference\nfrom the [Location.assign] method is that after using\n`replace()` the current page will not be saved in session\n[History], meaning the user won't be able to use the _back_ button\nto navigate to it.\n\nIf the assignment can't happen because of a security violation, a\n[DOMException] of the `SECURITY_ERROR` type is thrown. This\nhappens if the origin of the script calling the method is different from the origin of\nthe page originally described by the [Location] object, mostly when the\nscript is hosted on a different domain.\n\nIf the provided URL is not valid, a [DOMException] of the\n`SYNTAX_ERROR` type is thrown.",
      "search": "\n\nThe **`search`** property of the [Location]\ninterface is a search string, also called a _query string_; that is, a\nstring containing a `'?'` followed by the parameters of the\nURL.\n\nModern browsers provide\n[`URLSearchParams`](/en-US/docs/Web/API/URLSearchParams/get#examples)\nand\n[`URL.searchParams`](/en-US/docs/Web/API/URL/searchParams#examples)\nto make it easy to parse out the parameters from the querystring.",
      "tostring": "\n\nThe **`toString()`**  method of the\n[Location] interface returns a string containing the\nwhole URL. It is a read-only version of [Location.href]."
    }
  },
  "lock": {
    "docs": "\n\nThe **`Lock`** interface of the [Web Locks API](/en-US/docs/Web/API/Web_Locks_API) provides the name and mode of a lock.\nThis may be a newly requested lock that is received in the callback to [LockManager.request], or a record of an active or queued lock returned by [LockManager.query].\n\n",
    "properties": {
      "mode": "\n\nThe **`mode`** read-only property of the [Lock] interface returns the access mode passed to [LockManager.request] when the lock was requested.\nThe mode is either `\"exclusive\"` (the default) or `\"shared\"`.\n\n",
      "name": "\n\nThe **`name`** read-only property of\nthe [Lock] interface returns the _name_ passed to\n[LockManager.request] selected when the lock was requested.\n\nThe name of a lock is passed by script when the lock is requested. The name is selected\nby the developer to represent an abstract resource for which use is being coordinated\nacross multiple tabs, workers, or other code within the origin. For example, if only one\ntab of a web application should be synchronizing network resources with an offline\ndatabase, it could use a lock name such as `\"net_db_sync\"`.\n\n"
    }
  },
  "lockmanager": {
    "docs": "\n\nThe **`LockManager`** interface of the [Web Locks API](/en-US/docs/Web/API/Web_Locks_API) provides methods for requesting a new [Lock] object and querying for an existing `Lock` object. To get an instance of `LockManager`, call [navigator.locks].\n\n",
    "properties": {
      "query": "\n\nThe **`query()`** method of the [LockManager] interface returns a `Promise` that resolves with an object containing information about held and pending locks.\n\n",
      "request": "\n\nThe **`request()`** method of the [LockManager] interface requests a [Lock] object with parameters specifying its name and characteristics.\nThe requested `Lock` is passed to a callback, while the function itself returns a `Promise` that resolves (or rejects) with the result of the callback after the lock is released, or rejects if the request is aborted.\n\nThe `mode` property of the `options` parameter may be either `\"exclusive\"` or `\"shared\"`.\n\nRequest an `\"exclusive\"` lock when it should only be held by one code instance at a time.\nThis applies to code in both tabs and workers. Use this to represent mutually exclusive access to a resource.\nWhen an `\"exclusive\"` lock for a given name is held, no other lock with the same name can be held.\n\nRequest a `\"shared\"` lock when multiple instances of the code can share access to a resource.\nWhen a `\"shared\"` lock for a given name is held, other `\"shared\"` locks for the same name can be granted, but no `\"exclusive\"` locks with that name can be held or granted.\n\nThis shared/exclusive lock pattern is common in database transaction architecture, for example to allow multiple simultaneous readers (each requests a `\"shared\"` lock) but only one writer (a single `\"exclusive\"` lock).\nThis is known as the readers-writer pattern.\nIn the [IndexedDB API](/en-US/docs/Web/API/IndexedDB_API), this is exposed as `\"readonly\"` and `\"readwrite\"` transactions which have the same semantics.\n\n"
    }
  },
  "magnetometer": {
    "docs": "\n\nThe **`Magnetometer`** interface of the [Sensor APIs](/en-US/docs/Web/API/Sensor_APIs) provides information about the magnetic field as detected by the device's primary magnetometer sensor.\n\nTo use this sensor, the user must grant permission to the `'magnetometer'` device sensor through the [Permissions API](/en-US/docs/Web/API/Permissions_API). In addition, this feature may be blocked by a [Permissions Policy](/en-US/docs/Web/HTTP/Permissions_Policy) set on your server.\n\n",
    "properties": {
      "x": "\n\nThe **`x`** read-only property of the\n[Magnetometer] interface returns a number specifying\nthe magnetic field around the device's x-axis.",
      "y": "\n\nThe **`y`** read-only property of the\n[Magnetometer] interface returns a number specifying\nthe magnetic field around the device's y-axis.",
      "z": "\n\nThe **`z`** read-only property of the\n[Magnetometer] interface returns a number specifying\nthe magnetic field around the device's z-axis."
    }
  },
  "mathmlelement": {
    "docs": "\n\nThe **`MathMLElement`** interface represents any [MathML](/en-US/docs/Web/MathML) element.\n\n",
    "properties": {
      "style": "\n\nThe read-only **`style`** property of the [MathMLElement] returns the _inline_ style of an element in the form of a live [CSSStyleDeclaration] object that contains a list of all styles properties for that element with values assigned only for the attributes that are defined in the element's inline [`style`](/en-US/docs/Web/HTML/Global_attributes/style) attribute.\n\nShorthand properties are expanded. If you set `style=\"border-top: 1px solid black\"`, the longhand properties (, , and ) are set instead.\n\nThis property is read-only, meaning it is not possible to assign a [CSSStyleDeclaration] object to it. Nevertheless, it is possible to set an inline style by assigning a _string_ directly to the `style` property. In this case the string is forwarded to [CSSStyleDeclaration.cssText]. Using `style` in this manner will completely overwrite all inline styles on the element.\n\nTherefore, to add specific styles to an element without altering other style values, it is generally preferable to set individual properties on the [CSSStyleDeclaration] object. For example, you can write `element.style.backgroundColor = \"red\"`.\n\nA style declaration is reset by setting it to `null` or an empty string, e.g., `elt.style.color = null`.\n\n> **Note:** CSS property names are converted to JavaScript identifier with these rules:\n>\n> - If the property is made of one word, it remains as it is: `height` stays as is (in lowercase).\n> - If the property is made of several words, separated by dashes, the dashes are removed and it is converted to : `background-attachment` becomes `backgroundAttachment`.\n> - The property `float`, being a reserved JavaScript keyword, is converted to `cssFloat`.\n>\n> The `style` property has the same priority in the CSS cascade as an inline style declaration set via the `style` attribute."
    }
  },
  "mediacapabilities": {
    "docs": "\n\nThe **`MediaCapabilities`** interface of the [Media Capabilities API](/en-US/docs/Web/API/Media_Capabilities_API) provides information about the decoding abilities of the device, system and browser. The API can be used to query the browser about the decoding abilities of the device based on codecs, profile, resolution, and bitrates. The information can be used to serve optimal media streams to the user and determine if playback should be smooth and power efficient.\n\nThe information is accessed through the **`mediaCapabilities`** property of the [Navigator] interface.",
    "properties": {
      "decodinginfo": "\n\nThe **`MediaCapabilities.decodingInfo()`** method, part of the [Media Capabilities API](/en-US/docs/Web/API/MediaCapabilities), returns a promise with the tested media configuration's capabilities info.\nThis contains the three boolean properties `supported`, `smooth`, and `powerefficient`, which describe whether decoding the media described would be supported, smooth, and powerefficient.",
      "encodinginfo": "\n\nThe **`MediaCapabilities.encodingInfo()`** method, part of the [MediaCapabilities] interface of the [Media Capabilities API](/en-US/docs/Web/API/MediaCapabilities), returns a promise with the tested media configuration's capabilities information.\nThis contains the three boolean properties `supported`, `smooth`, and `powerefficient`, which describe how compatible the device is with the type of media."
    }
  },
  "mediadeviceinfo": {
    "docs": "\n\nThe **`MediaDeviceInfo`** interface of the [Media Capture and Streams API] contains information that describes a single media input or output device.\n\nThe list of devices obtained by calling [MediaDevices.enumerateDevices] is an array of `MediaDeviceInfo` objects, one per media device.",
    "properties": {
      "deviceid": "\n\nThe **`deviceId`** read-only property\nof the [MediaDeviceInfo] interface returns a string\nthat is an identifier for the represented device and is persisted across\nsessions.\n\nIt is un-guessable by other applications, and unique to the origin of\nthe calling application. It is reset when the user clears cookies. For private browsing,\na different identifier is used that is not persisted across sessions.",
      "groupid": "\n\nThe **`groupId`** read-only property of\nthe [MediaDeviceInfo] interface returns a string that\nis a group identifier.\n\nTwo devices have the same group identifier if they\nbelong to the same physical device; for example, a monitor with both a built-in camera\nand microphone.",
      "kind": "\n\nThe **`kind`** read-only property of\nthe [MediaDeviceInfo] interface returns an enumerated value, that is\neither `\"videoinput\"`, `\"audioinput\"` or `\"audiooutput\"`.",
      "label": "\n\nThe **`label`** read-only\nproperty of the [MediaDeviceInfo] interface returns a\nstring describing this device (for example\n\"External USB Webcam\").\n\nOnly available during active `MediaStream`\nuse, or when persistent permissions have been granted.",
      "tojson": "\n\nThe **`toJSON()`** method of the [MediaDeviceInfo] interface is a ; it returns a JSON representation of the [MediaDeviceInfo] object."
    }
  },
  "mediadevices": {
    "docs": "\n\nThe **`MediaDevices`** interface provides access to connected media input devices like cameras and microphones, as well as screen sharing. In essence, it lets you obtain access to any hardware source of media data.\n\n",
    "properties": {
      "devicechange_event": "\n\nA `devicechange` event is sent to a [MediaDevices] instance whenever a media device such as a camera, microphone, or speaker is connected to or removed from the system.\n\nThis event is not cancelable and does not bubble.",
      "enumeratedevices": "\n\nThe [MediaDevices] method **`enumerateDevices()`** requests a list of the currently available media input and output devices, such as microphones, cameras, headsets, and so forth.\nThe returned `Promise` is resolved with an array of [MediaDeviceInfo] objects describing the devices.\n\nThe returned list will omit any devices that are blocked by the document [Permission Policy](/en-US/docs/Web/HTTP/Headers/Permissions-Policy): [`microphone`](/en-US/docs/Web/HTTP/Headers/Permissions-Policy/microphone), [`camera`](/en-US/docs/Web/HTTP/Headers/Permissions-Policy/camera), [`speaker-selection`](/en-US/docs/Web/HTTP/Headers/Permissions-Policy/speaker-selection) (for output devices), and so on.\nAccess to particular non-default devices is also gated by the [Permissions API](/en-US/docs/Web/API/Permissions_API), and the list will omit devices for which the user has not granted explicit permission.",
      "getdisplaymedia": "\n\nThe **`getDisplayMedia()`** method of the [MediaDevices] interface prompts the user to select and\ngrant permission to capture the contents of a display or portion thereof (such as a window) as a [MediaStream].\n\nThe resulting stream can then be\nrecorded using the [MediaStream Recording API](/en-US/docs/Web/API/MediaStream_Recording_API) or transmitted as part of a [WebRTC](/en-US/docs/Web/API/WebRTC_API) session.\n\nSee [Using the Screen Capture API](/en-US/docs/Web/API/Screen_Capture_API/Using_Screen_Capture) for more details and an example.",
      "getsupportedconstraints": "\n\nThe\n**`getSupportedConstraints()`**\nmethod of the [MediaDevices] interface returns an object based on the\n[MediaTrackSupportedConstraints] dictionary, whose member fields each\nspecify one of the constrainable properties the  understands.",
      "getusermedia": "\n\nThe **`getUserMedia()`** method of the [MediaDevices] interface prompts the user for permission to use a media input which produces a [MediaStream] with tracks containing the requested types of media.\n\nThat stream can include, for example, a video track (produced by either a hardware or virtual video source such as a camera, video recording device, screen sharing service, and so forth), an audio track (similarly, produced by a physical or virtual audio source like a microphone, A/D converter, or the like), and possibly other track types.\n\nIt returns a `Promise` that resolves to a [MediaStream] object.\nIf the user denies permission, or matching media is not available, then the promise is rejected with `NotAllowedError` or `NotFoundError` [DOMException] respectively.\n\n> **Note:** It's possible for the returned promise to _neither_ resolve nor reject, as the user is not required to make a choice at all and may ignore the request.",
      "selectaudiooutput": "\n\nThe **`MediaDevices.selectAudioOutput()`** method of the [Audio Output Devices API](/en-US/docs/Web/API/Audio_Output_Devices_API) prompts the user to select an audio output device, such as a speaker or headset. If the user selects a device, the method grants user permission to use the selected device as an audio output sink.\n\nFollowing selection, if the device is available it can be enumerated using [MediaDevices.enumerateDevices] and set as the audio output sink using [HTMLMediaElement.setSinkId].\n\nOn success, the returned `Promise` is resolved with a [MediaDeviceInfo] describing the selected device."
    }
  },
  "mediaelementaudiosourcenode": {
    "docs": "\n\nThe `MediaElementAudioSourceNode` interface represents an audio source consisting of an HTML `audio` or `video` element. It is an [AudioNode] that acts as an audio source.\n\nA `MediaElementAudioSourceNode` has no inputs and exactly one output, and is created using the [AudioContext.createMediaElementSource] method. The number of channels in the output equals the number of channels of the audio referenced by the [HTMLMediaElement] used in the creation of the node, or is 1 if the [HTMLMediaElement] has no audio.\n\n<table class=\"properties\">\n  <tbody>\n    <tr>\n      <th scope=\"row\">Number of inputs</th>\n      <td><code>0</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Number of outputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count</th>\n      <td>\n        2 (but note that [AudioNode.channelCount] is only used for up-mixing and down-mixing [AudioNode] inputs, and [MediaElementAudioSourceNode] doesn't have any input)\n      </td>\n    </tr>\n  </tbody>\n</table>",
    "properties": {
      "mediaelement": "\n\nThe [MediaElementAudioSourceNode] interface's\nread-only **`mediaElement`** property indicates the\n[HTMLMediaElement] that contains the audio track from which the node is\nreceiving audio.\n\nThis stream was specified when the node was first created,\neither using the [MediaElementAudioSourceNode.MediaElementAudioSourceNode] constructor or the\n[AudioContext.createMediaElementSource] method."
    }
  },
  "mediaencryptedevent": {
    "docs": "\n\nThe **`MediaEncryptedEvent`** interface of the [Encrypted Media Extensions API](/en-US/docs/Web/API/Encrypted_Media_Extensions_API) contains the information associated with an [HTMLMediaElement/encrypted_event] event sent to a [HTMLMediaElement] when some initialization data is encountered in the media.\n\n",
    "properties": {
      "initdata": "\n\nThe read-only **`initData`** property of the [MediaKeyMessageEvent] returns the initialization data contained in this event, if any.",
      "initdatatype": "\n\nThe read-only **`initDataType`** property of the [MediaKeyMessageEvent] returns a case-sensitive string describing the type of the initialization data associated with this event."
    }
  },
  "mediaerror": {
    "docs": "\n\nThe **`MediaError`** interface represents an error which occurred while handling media in an HTML media element based on [HTMLMediaElement], such as `audio` or `video`.\n\nA `MediaError` object describes the error in general terms using a numeric `code` categorizing the kind of error, and a `message`, which provides specific diagnostics about what went wrong.",
    "properties": {
      "code": "\n\nThe read-only property **`MediaError.code`** returns a numeric\nvalue which represents the kind of error that occurred on a media element. To get a text\nstring with specific diagnostic information, see [MediaError.message].",
      "message": "\n\nThe read-only property **`MediaError.message`** returns a\nhuman-readable string offering specific\ndiagnostic details related to the error described by the `MediaError` object,\nor an empty string (`\"\"`) if no diagnostic information can be determined or\nprovided.",
      "msextendedcode": "\n\nIn the event of an error, the media element's error event will be fired. The element's error property will then contain an **`msExtendedCode`** read-only property with platform-specific error code information.\n\n**`msExtendedCode`** is a read-only proprietary property specific to Internet Explorer and Microsoft Edge."
    }
  },
  "mediakeymessageevent": {
    "docs": "\n\nThe **`MediaKeyMessageEvent`** interface of the [Encrypted Media Extensions API](/en-US/docs/Web/API/Encrypted_Media_Extensions_API) contains the content and related data when the content decryption module generates a message for the session.\n\n",
    "properties": {
      "message": "\n\nThe **`MediaKeyMessageEvent.message`** read-only property\nreturns an `ArrayBuffer` with a message from the content decryption module.\nMessages vary by key system.",
      "messagetype": "\n\nThe **`MediaKeyMessageEvent.messageType`** read-only property indicates the\ntype of message. It may be one of `license-request`,\n`license-renewal`, `license-release`, or\n`individualization-request`."
    }
  },
  "mediakeys": {
    "docs": "\n\nThe **`MediaKeys`** interface of [Encrypted Media Extensions API](/en-US/docs/Web/API/Encrypted_Media_Extensions_API) represents a set of keys that an associated [HTMLMediaElement] can use for decryption of media data during playback.",
    "properties": {
      "createsession": "\n\nThe `MediaKeys.createSession()` method returns a new\n[MediaKeySession] object, which represents a context for message exchange\nwith a content decryption module (CDM).",
      "setservercertificate": "\n\nThe **`MediaKeys.setServerCertificate()`** method provides a\nserver certificate to be used to encrypt messages to the license server."
    }
  },
  "mediakeysession": {
    "docs": "\n\nThe **`MediaKeySession`** interface of the [Encrypted Media Extensions API](/en-US/docs/Web/API/Encrypted_Media_Extensions_API) represents a context for message exchange with a content decryption module (CDM).\n\n",
    "properties": {
      "close": "\n\nThe `MediaKeySession.close()` method notifies that the current media session\nis no longer needed, and that the content decryption module should release any resources\nassociated with this object and close it. Then, it returns a `Promise`.",
      "closed": "\n\nThe `MediaKeySession.closed` read-only property returns a\n`Promise` signaling when a [MediaKeySession] closes. This\npromise can only be fulfilled and is never rejected. Closing a session means that\nlicenses and keys associated with it are no longer valid for decrypting media data.",
      "expiration": "\n\nThe **`MediaKeySession.expiration`** read-only property returns\nthe time after which the keys in the current session can no longer be used to decrypt\nmedia data, or NaN if no such time exists. This value is determined by the CDM and\nmeasured in milliseconds since January 1, 1970, UTC. This value may change during a\nsession lifetime, such as when an action triggers the start of a window.",
      "generaterequest": "\n\nThe `MediaKeySession.generateRequest()` method returns a\n`Promise` after generating a media request based on initialization data.",
      "keystatuses": "\n\nThe **`MediaKeySession.keyStatuses`** read-only property\nreturns a reference to a read-only [MediaKeyStatusMap] of the current\nsession's keys and their statuses.",
      "keystatuseschange_event": "\n\nThe **`keystatuseschange`** event of the [MediaKeySession] API fires when there has been a change in the keys or their statuses within a session.",
      "load": "\n\nThe `MediaKeySession.load()` method returns a `Promise` that\nresolves to a boolean value after loading data for a specified session object.",
      "message_event": "\n\nThe **`message`** event of the\n[MediaKeySession] interface fires when a message is generated by the\ncontent decryption module.",
      "remove": "\n\nThe `MediaKeySession.remove()` method returns a `Promise` after removing any session data associated with the current object.",
      "sessionid": "\n\nThe **`MediaKeySession.sessionId`** is a read-only property\nthat contains a unique string generated by the content decryption module (CDM) for the\ncurrent media object and its associated keys or licenses.",
      "update": "\n\nThe `MediaKeySession.update()` method loads messages and licenses to the\nCDM, and then returns a `Promise` ."
    }
  },
  "mediakeystatusmap": {
    "docs": "\n\nThe **`MediaKeyStatusMap`** interface of the [Encrypted Media Extensions API](/en-US/docs/Web/API/Encrypted_Media_Extensions_API) is a read-only map of media key statuses by key IDs.",
    "properties": {
      "entries": "\n\nThe **`entries()`** read-only property\nof the [MediaKeyStatusMap] interface returns a new Iterator object,\ncontaining an array of \\[key, value] pairs for each element in the status map, in\ninsertion order.",
      "foreach": "\n\nThe **`forEach`** property of the\n[MediaKeyStatusMap] interface calls callback once for each key-value pair\nin the status map, in insertion order. If an argument is present it will be passed to\nthe callback.",
      "get": "\n\nThe **`get`** property of the\n[MediaKeyStatusMap] interface returns the value associated with the given\nkey, or `undefined` if there is none.",
      "has": "\n\nThe **`has`** property of the\n[MediaKeyStatusMap] interface returns a `Boolean`, asserting\nwhether a value has been associated with the given key.",
      "keys": "\n\nThe **`keys`** property of the\n[MediaKeyStatusMap] interface returns a new Iterator object, containing\nkeys for each element in the status map, in insertion order.",
      "size": "\n\nThe **`size`** read-only property of\nthe [MediaKeyStatusMap] interface returns the number of key/value paIrs\nin the status map.",
      "values": "\n\nThe **`values`** property of the\n[MediaKeyStatusMap] interface returns a new Iterator object, containing\nvalues for each element in the status map, in insertion order."
    }
  },
  "mediakeysystemaccess": {
    "docs": "\n\nThe **`MediaKeySystemAccess`** interface of the [Encrypted Media Extensions API](/en-US/docs/Web/API/Encrypted_Media_Extensions_API) provides access to a Key System for decryption and/or a content protection provider. You can request an instance of this object using the [Navigator.requestMediaKeySystemAccess] method.",
    "properties": {
      "createmediakeys": "\n\nThe `MediaKeySystemAccess.createMediaKeys()` method returns a\n`Promise` that resolves to a new [MediaKeys] object.",
      "getconfiguration": "\n\nThe `MediaKeySystemAccess.getConfiguration()` method returns an object with the supported combination of\nthe following configuration options:\n\n- `initDataTypes` \n  - : Returns a list of supported initialization data type names. An initialization data type is a string indicating the format of the initialization data.\n- `audioCapabilities` \n  - : Returns a list of supported audio type and capability pairs.\n- `videoCapabilities` \n  - : Returns a list of supported video type and capability pairs.\n- `distinctiveIdentifier` \n  - : Indicates whether a persistent distinctive identifier is required.\n- `persistentState` \n  - : Indicates whether the ability to persist state is required.",
      "keysystem": "\n\nThe `MediaKeySystemAccess.keySystem` read-only property returns a\nstring identifying the key system being used."
    }
  },
  "medialist": {
    "docs": "\n\nThe **`MediaList`** interface represents the media queries of a stylesheet, e.g. those set using a `link` element's `media` attribute.\n\n> **Note:** `MediaList` is a live list; updating the list using properties or methods listed below will immediately update the behavior of the document.",
    "properties": {
      "appendmedium": "\n\nThe `appendMedium()` method of the [MediaList] interface adds a media query to the list. If the media query is already in the collection, this method does nothing.",
      "deletemedium": "\n\nThe `deleteMedium()` method of the [MediaList] interface removes from this `MediaList` the given media query.",
      "item": "\n\nThe **`item()`** method of the [MediaList] interface returns the media query at the specified `index`, or `null` if the specified `index` doesn't exist.",
      "length": "\n\nThe read-only **`length`** property of the [MediaList] interface returns the number of media queries in the list.",
      "mediatext": "\n\nThe **`mediaText`** property of the [MediaList]\ninterface is a  that returns a string representing the\n`MediaList` as text, and also allows you to set a new `MediaList`."
    }
  },
  "mediametadata": {
    "docs": "\n\nThe **`MediaMetadata`** interface of the [Media Session API] allows a web page to provide rich media metadata for display in a platform UI.",
    "properties": {
      "album": "\n\nThe **`album`** property of the\n[MediaMetaData] interface returns or sets the name of the album or\ncollection containing the media to be played.",
      "artist": "\n\nThe **`artist`** property of the\n[MediaMetaData] interface returns or sets the name of the artist, group,\ncreator, etc., of the media to be played.",
      "artwork": "\n\nThe **`artwork`** property of the\n[MediaMetaData] interface returns or sets an array of\nobjects representing images associated with playing\nmedia.",
      "title": "\n\nThe **`title`** property of the\n[MediaMetaData] interface returns or sets the title of the media to be\nplayed."
    }
  },
  "mediaquerylist": {
    "docs": "\n\nA **`MediaQueryList`** object stores information on a [media query](/en-US/docs/Web/CSS/CSS_media_queries) applied to a document, with support for both immediate and event-driven matching against the state of the document.\n\nYou can create a `MediaQueryList` by calling [Window.matchMedia] on the [window] object. The resulting object handles sending notifications to listeners when the media query state changes (i.e. when the media query test starts or stops evaluating to `true`).\n\nThis is very useful for adaptive design, since this makes it possible to observe a document to detect when its media queries change, instead of polling the values periodically, and allows you to programmatically make changes to a document based on media query status.\n\n",
    "properties": {
      "addlistener": "\n\nThe deprecated **`addListener()`** method of the\n[MediaQueryList] interface adds a listener to the\n`MediaQueryListener` that will run a custom callback function in response to\nthe media query status changing.\n\nIn older browsers `MediaQueryList` did not yet inherit from [EventTarget],\nso this method was provided as an alias of [EventTarget.addEventListener].\nUse `addEventListener()` instead of `addListener()` if it is\navailable in the browsers you need to support.",
      "change_event": "\n\nThe **`change`** event of the [MediaQueryList] interface fires when the status of media query support changes.",
      "matches": "\n\nThe **`matches`** read-only property of the\n[MediaQueryList] interface is a boolean value that returns\n`true` if the [document] currently matches the media query list,\nor `false` if not.\n\nYou can be notified when the value of `matches` changes by watching for the\n[MediaQueryList.change_event] event to be fired at the\n`MediaQueryList`.",
      "media": "\n\nThe **`media`** read-only property of the\n[MediaQueryList] interface is a string representing a\nserialized media query.",
      "removelistener": "\n\nThe **`removeListener()`** method of the\n[MediaQueryList] interface removes a listener from the\n`MediaQueryListener`.\n\nIn older browsers `MediaQueryList` did not yet inherit from [EventTarget],\nso this method was provided as an alias of [EventTarget.removeEventListener].\nUse `removeEventListener()` instead of `removeListener()` if it is\navailable in the browsers you need to support."
    }
  },
  "mediaquerylistevent": {
    "docs": "\n\nThe `MediaQueryListEvent` object stores information on the changes that have happened to a [MediaQueryList] object — instances are available as the event object on a function referenced by a [MediaQueryList.change_event] event.\n\n",
    "properties": {
      "matches": "\n\nThe **`matches`** read-only property of the\n[MediaQueryListEvent] interface is a boolean value that is\n`true` if the [document] currently matches the media query list,\nor `false` if not.",
      "media": "\n\nThe **`media`** read-only property of the\n[MediaQueryListEvent] interface is a string representing\na serialized media query."
    }
  },
  "mediarecorder": {
    "docs": "\n\nThe **`MediaRecorder`** interface of the [MediaStream Recording API](/en-US/docs/Web/API/MediaStream_Recording_API) provides functionality to easily record media. It is created using the [MediaRecorder.MediaRecorder] constructor.\n\n",
    "properties": {
      "audiobitratemode": "\n\nThe **`audioBitrateMode`** read-only property of the [MediaRecorder] interface returns the bitrate mode used to encode audio tracks.",
      "audiobitspersecond": "\n\nThe **`audioBitsPerSecond`** read-only\nproperty of the [MediaRecorder] interface returns the audio encoding bit\nrate in use.\n\nThis may differ from the bit rate specified in the constructor (if\nit was provided).",
      "dataavailable_event": "\n\nThe **`dataavailable`** event of the [MediaRecorder] interface is fired when the MediaRecorder delivers media\ndata to your application for its use. The data is provided in a [Blob]\nobject that contains the data. This occurs in four situations:\n\n- When the media stream ends, any media data not already delivered to your\n  `ondataavailable` handler is passed in a single [Blob].\n- When [MediaRecorder.stop] is called, all media data which has been\n  captured since recording began or the last time a `dataavailable` event\n  occurred is delivered in a [Blob]; after this, capturing ends.\n- When [MediaRecorder.requestData] is called, all media data which has\n  been captured since recording began or the last time a `dataavailable`\n  event occurred is delivered; then a new `Blob` is created and media capture\n  continues into that blob.\n- If a `timeslice` property was passed into the\n  [MediaRecorder.start] method that started media capture, a\n  `dataavailable` event is fired every `timeslice` milliseconds.\n  That means that each blob will have a specific time duration (except the last blob,\n  which might be shorter, since it would be whatever is left over since the last event).\n  So if the method call looked like this — `recorder.start(1000);` — the\n  `dataavailable` event would fire after each second of media capture, and\n  our event handler would be called every second with a blob of media data that's one\n  second long. You can use `timeslice` alongside\n  [MediaRecorder.stop] and [MediaRecorder.requestData] to\n  produce multiple same-length blobs plus other shorter blobs as well.\n\n> **Note:** The [Blob] containing the media data is available in the\n> [MediaRecorder.dataavailable_event] event's `data` property.",
      "error_event": "\n\nThe **`error`** event of the [MediaRecorder] interface is fired when an error occurs: for example because recording wasn't allowed or was attempted using an unsupported codec.\n\nThis event is not cancelable and does not bubble.",
      "istypesupported_static": "\n\nThe\n**`MediaRecorder.isTypeSupported()`** static method returns a\nBoolean which is `true` if the MIME type specified is one the user agent\nshould be able to successfully record.",
      "mimetype": "\n\nThe **`mimeType`** read-only\nproperty returns the  media type that was specified when creating\nthe [MediaRecorder] object, or, if none was specified, which was chosen\nby the browser. This is the file format of the file that would result from\nwriting all of the recorded data to disk.\n\nKeep in mind that not all codecs are supported by a given container; if you write media\nusing a codec that is not supported by a given media container, the resulting file may\nnot work reliably if at all when you try to play it back. See our [media type and format guide](/en-US/docs/Web/Media/Formats) for information\nabout container and codec support across browsers.\n\n> **Note:** The term \"MIME type\" is officially considered to be\n> historical; these strings are now officially known as **media types**.\n> MDN Web Docs content uses the terms interchangeably.",
      "pause": "\n\nThe **`MediaRecorder.pause()`** method (part\nof the [MediaStream Recording API](/en-US/docs/Web/API/MediaStream_Recording_API)) is used\nto pause recording of media streams.\n\nWhen a `MediaRecorder` object's `pause()`method is called, the\nbrowser queues a task that runs the below steps:\n\n1. If [MediaRecorder.state] is \"inactive\", raise a DOM\n   `InvalidState` error and terminate these steps. If not, continue to the\n   next step.\n2. Set [MediaRecorder.state] to \"paused\".\n3. Stop gathering data into the current [Blob], but keep it available so\n   that recording can be resumed later on.\n4. Raise a [MediaRecorder/pause_event] event.",
      "pause_event": "\n\nThe `pause` event is thrown as a result of the\n[MediaRecorder.pause] method being invoked.",
      "requestdata": "\n\nThe **`requestData()`**\nmethod of the [MediaRecorder] interface is used to raise a [MediaRecorder.dataavailable_event] event containing a\n[Blob] object of the captured media as it was when the method was\ncalled. This can then be grabbed and manipulated as you wish.\n\nWhen the `requestData()` method is invoked, the browser queues a task that\nruns the following steps:\n\n1. If [MediaRecorder.state] is \"inactive\", raise a DOM\n   `InvalidState` error and terminate these steps. If\n   [MediaRecorder.state] is not \"inactive\", continue to the next step.\n2. Raise a [MediaRecorder.dataavailable_event] event containing a [Blob] of the\n   currently captured data (the Blob is available under the event's `data`\n   attribute.)\n3. Create a new Blob and place subsequently captured data into it.",
      "resume": "\n\nThe **`MediaRecorder.resume()`**\nmethod (part of the [MediaStream Recording API](/en-US/docs/Web/API/MediaStream_Recording_API)) is used to resume media recording when it has been previously\npaused.\n\nWhen the `resume()` method is invoked, the browser queues a task that runs\nthe following steps:\n\n1. If [MediaRecorder.state] is \"inactive\", raise a DOM\n   `InvalidState` error and terminate these steps. If\n   [MediaRecorder.state] is not \"inactive\", continue to the next step.\n2. Set [MediaRecorder.state] to \"recording\".\n3. Continue gathering data into the current [Blob].\n4. Raise a `resume` event.",
      "resume_event": "\n\nThe `resume` event is thrown when\n[MediaRecorder.resume] is called.",
      "start": "\n\nThe [MediaRecorder] method\n**`start()`**, which is part of the MediaStream Recording API,\nbegins recording media into one or more [Blob] objects.\n\nYou can\nrecord the entire duration of the media into a single `Blob` (or until you\ncall [MediaRecorder.requestData]), or you can specify the\nnumber of milliseconds to record at a time. Then, each time that amount of media has\nbeen recorded, an event will be delivered to let you act upon the recorded media, while\na new `Blob` is created to record the next slice of the media.\n\nAssuming the `MediaRecorder`'s [MediaRecorder.state]\nis `inactive`, `start()` sets the `state` to\n`recording`, then begins capturing media from the input stream. A\n`Blob` is created and the data is collected in it until the time slice period\nelapses or the source media ends. Each time a `Blob` is filled up to that\npoint (the timeslice duration or the end-of-media, if no slice duration was provided), a\n[MediaRecorder.dataavailable_event] event is sent to the `MediaRecorder` with the\nrecorded data. If the source is still playing, a new `Blob` is created and\nrecording continues into that, and so forth.\n\nWhen the source stream ends, `state` is set to `inactive` and\ndata gathering stops. A final [MediaRecorder.dataavailable_event] event is sent to the\n`MediaRecorder`, followed by a [MediaRecorder/stop_event] event.\n\n> **Note:** If the browser is unable to start recording or continue\n> recording, it will raise an [MediaRecorder.error_event] event, followed by a\n> [MediaRecorder.dataavailable_event] event containing the `Blob` it\n> has gathered, followed by the [MediaRecorder/stop_event] event.",
      "start_event": "\n\nThe `start` event is fired when\n[MediaRecorder.start] is called. At this point, the data\nstarts being gathered into a [Blob].",
      "state": "\n\nThe **`MediaRecorder.state`** read-only property returns the\ncurrent state of the current `MediaRecorder` object.",
      "stop": "\n\nThe **`MediaRecorder.stop()`** method\n(part of the [MediaStream Recording API](/en-US/docs/Web/API/MediaStream_Recording_API)) is\nused to stop media capture.\n\nWhen the `stop()` method is invoked, the UA queues a task that runs the\nfollowing steps:\n\n1. If [MediaRecorder.state] is \"inactive\", raise a DOM\n   `InvalidState` error and terminate these steps. If the\n   [MediaRecorder.state] is not \"inactive\", continue on to the next step.\n2. Set the [MediaRecorder.state] to \"inactive\" and stop capturing media.\n3. Raise a `dataavailable` event containing the Blob of data that has been\n   gathered.\n4. Raise a `stop` event.",
      "stop_event": "\n\nThe `stop` event is fired when\n[MediaRecorder.stop] is called, or when the media stream being\ncaptured ends. In each case, the `stop` event is preceded by a\n`dataavailable` event, making the [Blob] captured up to that\npoint available for you to use in your application.",
      "stream": "\n\nThe **`MediaRecorder.stream`** read-only property returns the\nstream that was passed into the `MediaRecorder()` constructor when the\n`MediaRecorder` was created.",
      "videobitspersecond": "\n\nThe **`videoBitsPerSecond`** read-only\nproperty of the [MediaRecorder] interface returns the video encoding\nbit rate in use.\n\nThis may differ from the bit rate specified in the\nconstructor, if it was provided."
    }
  },
  "mediarecordererrorevent": {
    "docs": "\n\nThe **`MediaRecorderErrorEvent`** interface represents errors returned by the [MediaStream Recording API](/en-US/docs/Web/API/MediaStream_Recording_API). It is an [Event] object that encapsulates a reference to a [DOMException] describing the error that occurred.\n\n",
    "properties": {
      "error": "\n\nThe **`error`** read-only property of the\n[MediaRecorderErrorEvent] interface is a\n[DOMException] object providing details about the exception that was thrown\nby a [MediaRecorder] instance.\n\nWhen a `MediaRecorderErrorEvent` occurs, you can determine to some extent\nwhat went wrong by examining the `error` property within the\n`MediaRecorderErrorEvent` received by the `MediaRecorder`'s\n[MediaRecorder/error_event] event handler, [MediaRecorder/error_event]."
    }
  },
  "mediasession": {
    "docs": "\n\nThe **`MediaSession`** interface of the [Media Session API] allows a web page to provide custom behaviors for standard media playback interactions, and to report metadata that can be sent by the user agent to the device or operating system for presentation in standardized user interface elements.\n\nFor example, a smartphone might have a standard panel in its lock screen that provides controls for media playback and information display. A browser on the device can use `MediaSession` to make browser playback controllable from that standard/global user interface.",
    "properties": {
      "metadata": "\n\nThe **`metadata`** property of the [MediaSession]\ninterface contains a [MediaMetadata] object providing descriptive\ninformation about the currently playing media, or `null` if the metadata has\nnot been set. This metadata is provided by the browser to the device for presentation in\nany standard media control user interface the device might offer.",
      "playbackstate": "\n\nThe **`playbackState`** property of the\n[MediaSession] interface indicates whether the current media session is\nplaying or paused.",
      "setactionhandler": "\n\nThe **`setActionHandler()`** method of the [MediaSession] interface sets a handler for a media session action.\nThese actions let a web app receive notifications when the user engages a device's built-in physical or onscreen media controls, such as play, stop, or seek buttons.",
      "setcameraactive": "\n\nThe **`setCameraActive()`** method of the [MediaSession] interface is used to indicate to the user agent whether the user's camera is considered to be active.\n\nCall this method on the `navigator` object's\n[navigator.mediaSession] object.\n\nNote that the status of the camera is not tracked in the [MediaSession] itself, but must be tracked separately.",
      "setmicrophoneactive": "\n\nThe **`setMicrophoneActive()`** method of the [MediaSession] interface is used to indicate to the user agent whether the user's microphone is considered to be currently muted.\n\nCall this method on the `navigator` object's\n[navigator.mediaSession] object.\n\nNote that the status of the microphone is not tracked in the [MediaSession] itself, but must be tracked separately.",
      "setpositionstate": "\n\nThe **`setPositionState()`** method of the\n[MediaSession] interface is used to update the current\ndocument's media playback position and speed for presentation by user's device in any\nkind of interface that provides details about ongoing media. This can be\nparticularly useful if your code implements a player for type of media not directly\nsupported by the browser.\n\nCall this method on the `navigator` object's\n[navigator.mediaSession] object."
    }
  },
  "mediasource": {
    "docs": "\n\nThe **`MediaSource`** interface of the [Media Source Extensions API] represents a source of media data for an [HTMLMediaElement] object. A `MediaSource` object can be attached to a [HTMLMediaElement] to be played in the user agent.\n\n",
    "properties": {
      "activesourcebuffers": "\n\nThe **`activeSourceBuffers`** read-only property of the\n[MediaSource] interface returns a [SourceBufferList] object\ncontaining a subset of the [SourceBuffer] objects contained within\n[MediaSource.sourceBuffers] — the list of objects\nproviding the selected video track, enabled audio tracks, and shown/hidden text tracks.",
      "addsourcebuffer": "\n\nThe **`addSourceBuffer()`** method of the\n[MediaSource] interface creates a new [SourceBuffer] of the\ngiven  and adds it to the `MediaSource`'s\n[MediaSource.sourceBuffers] list. The new\n`SourceBuffer` is also returned.",
      "canconstructindedicatedworker_static": "\n\nThe **`canConstructInDedicatedWorker`** static property of the [MediaSource] interface returns `true` if `MediaSource` worker support is implemented, providing a low-latency feature detection mechanism.\n\nIf this were not available, the alternative would be a much higher latency approach such as attempting the creation of a `MediaSource` object from a dedicated worker and transferring the result back to the main thread.",
      "clearliveseekablerange": "\n\nThe **`clearLiveSeekableRange()`** method of the\n[MediaSource] interface clears a seekable range previously set with a call\nto [MediaSource.setLiveSeekableRange].",
      "duration": "\n\nThe **`duration`** property of the [MediaSource]\ninterface gets and sets the duration of the current media being presented.",
      "endofstream": "\n\nThe **`endOfStream()`** method of the\n[MediaSource] interface signals the end of the stream.",
      "handle": "\n\nThe **`handle`** read-only property of the [MediaSource] interface returns a [MediaSourceHandle] object, a proxy for the `MediaSource` that can be transferred from a dedicated worker back to the main thread and attached to a media element via its [HTMLMediaElement.srcObject] property.\n\n> **Note:** `handle` is only visible on [MediaSource] instances inside dedicated workers.\n\nEach `MediaSource` object created inside a dedicated worker has its own distinct `MediaSourceHandle`. The `handle` getter will always return the `MediaSourceHandle` instance specific to the associated dedicated worker `MediaSource` instance. If the handle has already been transferred to the main thread using [DedicatedWorkerGlobalScope.postMessage], the handle instance in the worker is technically detached and can't be transferred again.\n\n",
      "istypesupported_static": "\n\nThe **`MediaSource.isTypeSupported()`** static method returns a boolean value which is `true` if the given MIME type and (optional) codec are _likely_ to be supported by the current .\n\nThat is, if it can successfully create [SourceBuffer] objects for that media type.\nIf the returned value is `false`, then the user agent is certain that it _cannot_ access media of the specified format.",
      "readystate": "\n\nThe **`readyState`** read-only property of the\n[MediaSource] interface returns an enum representing the state of the\ncurrent `MediaSource`. The three possible values are:\n\n- `closed`: The source is not currently attached to a media element.\n- `open`: The source is attached to a media element and ready to receive\n  [SourceBuffer] objects.\n- `ended`: The source is attached to a media element but the stream has\n  been ended via a call to [MediaSource.endOfStream].",
      "removesourcebuffer": "\n\nThe **`removeSourceBuffer()`** method of the [MediaSource] interface removes the given [SourceBuffer] from the [SourceBufferList] associated with this `MediaSource` object.",
      "setliveseekablerange": "\n\nThe **`setLiveSeekableRange()`** method of the\n[MediaSource] interface sets the range that the user can seek to in the\nmedia element.",
      "sourcebuffers": "\n\nThe **`sourceBuffers`** read-only property of the\n[MediaSource] interface returns a [SourceBufferList] object\ncontaining the list of [SourceBuffer] objects associated with this\n`MediaSource`."
    }
  },
  "mediasourcehandle": {
    "docs": "\n\nThe **`MediaSourceHandle`** interface of the [Media Source Extensions API] is a proxy for a [MediaSource] that can be transferred from a dedicated worker back to the main thread and attached to a media element via its [HTMLMediaElement.srcObject] property. `MediaSource` objects are not transferable because they are event targets, hence the need for `MediaSourceHandle`s.\n\nIt can be accessed via the [MediaSource.handle] property.\n\nEach `MediaSource` object created inside a dedicated worker has its own distinct `MediaSourceHandle`. The `MediaSource.handle` getter will always return the `MediaSourceHandle` instance specific to the associated dedicated worker `MediaSource` instance. If the handle has already been transferred to the main thread using [DedicatedWorkerGlobalScope.postMessage], the handle instance in the worker is technically detached and can't be transferred again.\n\n"
  },
  "mediastream": {
    "docs": "\n\nThe **`MediaStream`** interface of the [Media Capture and Streams API] represents a stream of media content. A stream consists of several **tracks**, such as video or audio tracks. Each track is specified as an instance of [MediaStreamTrack].\n\nYou can obtain a `MediaStream` object either by using the constructor or by calling functions such as [MediaDevices.getUserMedia], [MediaDevices.getDisplayMedia], or [HTMLCanvasElement.captureStream] and [HTMLMediaElement.captureStream].\n\n",
    "properties": {
      "active": "\n\nThe **`active`** read-only property of the\n[MediaStream] interface returns a Boolean value which is\n`true` if the stream is currently active; otherwise, it returns\n`false`. A stream is considered **active** if at least one of\nits [MediaStreamTrack]s does not have its property [MediaStreamTrack.readyState]\nset to `ended`. Once every track has ended, the stream's `active` property becomes\n`false`.",
      "addtrack": "\n\nThe **`addTrack()`** method of the [MediaStream] interface adds a new track to the\nstream. The track is specified as a parameter of type [MediaStreamTrack].\n\n> **Note:** If the specified track is already in the stream's track set, this method has no\n> effect.",
      "addtrack_event": "\n\nThe **`addtrack`** event is fired when a new [`MediaStreamTrack`](/en-US/docs/Web/API/MediaStreamTrack) object has been added to a [`MediaStream`](/en-US/docs/Web/API/MediaStream).\n\nThis event is not cancelable and does not bubble.",
      "clone": "\n\nThe **`clone()`** method of the [MediaStream]\ninterface creates a duplicate of the `MediaStream`. This new\n`MediaStream` object has a new unique [MediaStream.id] and\ncontains clones of every [MediaStreamTrack] contained by the\n`MediaStream` on which `clone()` was called.",
      "getaudiotracks": "\n\nThe **`getAudioTracks()`** method of the\n[MediaStream] interface returns a sequence that represents all the\n[MediaStreamTrack] objects in this\nstream's [`track set`](https://www.w3.org/TR/mediacapture-streams/#track-set) where [MediaStreamTrack.kind]\nis `audio`.",
      "gettrackbyid": "\n\nThe **`getTrackById()`** method of the [MediaStream] interface\nreturns a [MediaStreamTrack] object representing the track with the specified ID\nstring. If there is no track with the specified ID, this method returns `null`.",
      "gettracks": "\n\nThe **`getTracks()`** method of the\n[MediaStream] interface returns a sequence that represents all the\n[MediaStreamTrack] objects in this\nstream's [`track set`](https://www.w3.org/TR/mediacapture-streams/#track-set),\nregardless of [MediaStreamTrack.kind].",
      "getvideotracks": "\n\nThe **`getVideoTracks()`** method of the\n[MediaStream] interface returns a sequence of\n[MediaStreamTrack] objects representing the video tracks in this stream.",
      "id": "\n\nThe **`id`** read-only property of the [MediaStream] interface is a\nstring containing 36 characters denoting a unique identifier (GUID)\nfor the object.",
      "removetrack": "\n\nThe **`removeTrack()`** method of the [MediaStream] interface removes a\n[MediaStreamTrack] from a stream.",
      "removetrack_event": "\n\nThe **`removetrack`** event is fired when a new [MediaStreamTrack] object has been removed from a [MediaStream].\n\nThis event is not cancelable and does not bubble."
    }
  },
  "mediastreamaudiodestinationnode": {
    "docs": "\n\nThe `MediaStreamAudioDestinationNode` interface represents an audio destination consisting of a [WebRTC](/en-US/docs/Web/API/WebRTC_API) [MediaStream] with a single `AudioMediaStreamTrack`, which can be used in a similar way to a `MediaStream` obtained from [MediaDevices.getUserMedia].\n\nIt is an [AudioNode] that acts as an audio destination, created using the [AudioContext.createMediaStreamDestination] method.\n\n<table class=\"properties\">\n  <tbody>\n    <tr>\n      <th scope=\"row\">Number of inputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Number of outputs</th>\n      <td><code>0</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count</th>\n      <td><code>2</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count mode</th>\n      <td><code>\"explicit\"</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count interpretation</th>\n      <td><code>\"speakers\"</code></td>\n    </tr>\n  </tbody>\n</table>",
    "properties": {
      "stream": "\n\nThe `stream` property of the [AudioContext] interface represents a [MediaStream] containing a single audio [MediaStreamTrack] with the same number of channels as the node itself.\n\nYou can use this property to get a stream out of the audio graph and feed it into another construct, such as a [Media Recorder](/en-US/docs/Web/API/MediaStream_Recording_API)."
    }
  },
  "mediastreamaudiosourcenode": {
    "docs": "\n\nThe **`MediaStreamAudioSourceNode`** interface is a type of [AudioNode] which operates as an audio source whose media is received from a [MediaStream] obtained using the WebRTC or Media Capture and Streams APIs.\n\nThis media could be from a microphone (through [MediaDevices.getUserMedia]) or from a remote peer on a WebRTC call (using the [RTCPeerConnection]'s audio tracks).\n\nA `MediaStreamAudioSourceNode` has no inputs and exactly one output, and is created using the [AudioContext.createMediaStreamSource] method.\n\nThe `MediaStreamAudioSourceNode` takes the audio from the _first_ [MediaStreamTrack] whose [MediaStreamTrack.kind] attribute's value is `audio`. See [Track ordering](#track_ordering) for more information about the order of tracks.\n\nThe number of channels output by the node matches the number of tracks found in the selected audio track.\n\n<table class=\"properties\">\n  <tbody>\n    <tr>\n      <th scope=\"row\">Number of inputs</th>\n      <td><code>0</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Number of outputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count</th>\n      <td>\n        2 (but note that [AudioNode.channelCount] is only used for up-mixing and down-mixing [AudioNode] inputs, and [MediaStreamAudioSourceNode] doesn't have any input)\n      </td>\n    </tr>\n  </tbody>\n</table>",
    "properties": {
      "mediastream": "\n\nThe [MediaStreamAudioSourceNode] interface's\nread-only **`mediaStream`** property indicates the\n[MediaStream] that contains the audio track from which the node is\nreceiving audio.\n\nThis stream was specified when the node was first created,\neither using the [MediaStreamAudioSourceNode.MediaStreamAudioSourceNode] constructor or the\n[AudioContext.createMediaStreamSource] method."
    }
  },
  "mediastreamevent": {
    "docs": "\n\nThe **`MediaStreamEvent`** interface represents events that occurs in relation to a [MediaStream]. Two events of this type can be thrown: [RTCPeerConnection.addstream_event] and [RTCPeerConnection.removestream_event].",
    "properties": {
      "stream": "\n\nThe read-only property **`MediaStreamEvent.stream`** returns\nthe [MediaStream] associated with the event."
    }
  },
  "mediastreamtrack": {
    "docs": "\n\nThe **`MediaStreamTrack`** interface of the [Media Capture and Streams API] represents a single media track within a stream; typically, these are audio or video tracks, but other track types may exist as well.\n\nSome user agents subclass this interface to provide more precise information or functionality, such as [CanvasCaptureMediaStreamTrack].\n\n",
    "properties": {
      "applyconstraints": "\n\nThe **`applyConstraints()`** method of the [MediaStreamTrack] interface applies a set of constraints to the track; these constraints let the website or app establish ideal values and acceptable ranges of values for the constrainable properties of the track, such as frame rate, dimensions, echo cancellation, and so forth.\n\nConstraints can be used to ensure that the media meets certain guidelines you prefer.\nFor example, you may prefer high-density video but require that the frame rate be a little low to help keep the data rate low enough not overtax the network.\nConstraints can also specify ideal and/or acceptable sizes or ranges of sizes.\nSee [Applying constraints](/en-US/docs/Web/API/Media_Capture_and_Streams_API/Constraints#applying_constraints) in [Capabilities, constraints, and settings](/en-US/docs/Web/API/Media_Capture_and_Streams_API/Constraints) for more information on how to apply your preferred constraints.",
      "clone": "\n\nThe **`clone()`** method of the [MediaStreamTrack]\ninterface creates a duplicate of the `MediaStreamTrack`. This new\n`MediaStreamTrack` object is identical except for its unique\n[MediaStreamTrack.id].",
      "contenthint": "\n\nThe **`contentHint`** property of the [MediaStreamTrack] interface is a string that hints at the type of content the track contains. Allowable values depend on the value of the [MediaStreamTrack.kind] property.",
      "enabled": "\n\nThe **`enabled`** property of the\n[MediaStreamTrack] interface is a Boolean value which is\n`true` if the track is allowed to render the source stream or\n`false` if it is not. This can be used to intentionally mute a\ntrack.\n\nWhen enabled, a track's data is output from the source to the\ndestination; otherwise, empty frames are output.\n\nIn the case of audio, a disabled track generates frames of silence (that is, frames in\nwhich every sample's value is 0). For video tracks, every frame is filled entirely with\nblack pixels.\n\nThe value of `enabled`, in essence, represents what a typical user would\nconsider the muting state for a track, whereas the [MediaStreamTrack.muted] property indicates a state in which the track is temporarily unable to output\ndata, such as a scenario in which frames have been lost in transit.\n\n> **Note:** If the track has been disconnected, the value of this property\n> can be changed, but has no effect.",
      "ended_event": "\n\nThe **`ended`** event of the [MediaStreamTrack] interface is fired when playback or streaming has stopped because the end of the media was reached or because no further data is available.\n\nThis event is not cancelable and does not bubble.",
      "getcapabilities": "\n\nThe **`getCapabilities()`** method of\nthe [MediaStreamTrack] interface returns a\n`MediaTrackCapabilities` object which specifies the values or range of\nvalues which each constrainable property, based upon the platform and .\n\nOnce you know what the browser's capabilities are, your script can use\n[MediaStreamTrack.applyConstraints] to ask for the\ntrack to be configured to match ideal or acceptable settings. See [Capabilities, constraints, and settings](/en-US/docs/Web/API/Media_Capture_and_Streams_API/Constraints) for details on how to work with constrainable properties.",
      "getconstraints": "\n\nThe **`getConstraints()`** method of\nthe [MediaStreamTrack] interface returns a\n[MediaTrackConstraints] object containing the set of constraints most\nrecently established for the track using a prior call to\n[MediaStreamTrack.applyConstraints]. These\nconstraints indicate values and ranges of values that the website or application has\nspecified are required or acceptable for the included constrainable properties.\n\nConstraints can be used to ensure that the media meets certain guidelines you prefer.\nFor example, you may prefer high definition video but require that the frame rate be a\nlittle low to help keep the data rate low enough not overtax the network. Constraints\ncan also specify ideal and/or acceptable sizes or ranges of sizes. See [Capabilities, constraints, and settings](/en-US/docs/Web/API/Media_Capture_and_Streams_API/Constraints) for details on how to work with constrainable properties.",
      "getsettings": "\n\nThe **`getSettings()`** method of the\n[MediaStreamTrack] interface returns a [MediaTrackSettings]\nobject containing the current values of each of the constrainable properties for the\ncurrent `MediaStreamTrack`.\n\nSee [Capabilities, constraints, and settings](/en-US/docs/Web/API/Media_Capture_and_Streams_API/Constraints) for details on how to work with constrainable properties.",
      "id": "\n\nThe **`id`** read-only property of the [MediaStreamTrack] interface returns a\nstring containing a unique identifier (GUID) for the track, which is\ngenerated by the .",
      "kind": "\n\nThe **`kind`** read-only property of the [MediaStreamTrack] interface returns a string set to `\"audio\"` if the track is an audio track and to `\"video\"` if it is a video track.\nIt doesn't change if the track is disassociated from its source.",
      "label": "\n\nThe **`label`** read-only property of the [MediaStreamTrack] interface returns a string containing a -assigned label that identifies the track source, as in `\"internal microphone\"`.\n\nThe string may be left empty and is empty as long as no source has been connected.\nWhen the track is disassociated from its source, the label is not changed.",
      "mute_event": "\n\nThe **`mute`** event is sent to a [MediaStreamTrack] when the track's source is temporarily unable to provide media data.\n\nWhen the track is once again able to produce media output, an [MediaStreamTrack/unmute_event] event is sent.\n\nDuring the time between the `mute` event and the `unmute` event, the value of the track's [MediaStreamTrack.muted] property is `true`.\n\n> **Note:** The condition that most people think of as \"muted\" (that is, a user-toggled state of silencing a track) is actually managed using the [MediaStreamTrack.enabled] property, for which there are no events.\n\nThis event is not cancelable and does not bubble.",
      "muted": "\n\nThe **`muted`** read-only property of the\n[MediaStreamTrack] interface returns a boolean value\nindicating whether or not the track is currently unable to provide media output.\n\n> **Note:** To implement a way for users to mute and unmute a track, use the\n> [MediaStreamTrack.enabled] property. When a track is disabled\n> by setting `enabled` to `false`, it generates only empty frames\n> (audio frames in which every sample is 0, or video frames in which every pixel is\n> black).",
      "readystate": "\n\nThe **`readyState`** read-only property of the [MediaStreamTrack] interface returns an enumerated value giving the status of the track.",
      "stop": "\n\nThe **`stop()`** method of the [MediaStreamTrack] interface stops the track.",
      "unmute_event": "\n\nThe **`unmute`** event is sent to a [MediaStreamTrack] when the track's source is once again able to provide media data after a period of not being able to do so.\n\nThis ends the [MediaStreamTrack.muted] state that began with the [MediaStreamTrack/mute_event] event.\n\n> **Note:** The condition that most people think of as \"muted\" (that is, a user-controllable way to silence a track) is actually managed using the [MediaStreamTrack.enabled] property, for which there are no events.\n\nThis event is not cancelable and does not bubble."
    }
  },
  "mediastreamtrackaudiosourcenode": {
    "docs": "\n\nThe **`MediaStreamTrackAudioSourceNode`** interface is a type of [AudioNode] which represents a source of audio data taken from a specific [MediaStreamTrack] obtained through the [WebRTC](/en-US/docs/Web/API/WebRTC_API) or [Media Capture and Streams](/en-US/docs/Web/API/Media_Capture_and_Streams_API) APIs.\n\nThe audio itself might be input from a microphone or other audio sampling device, or might be received through a [RTCPeerConnection], among other possible options.\n\nA `MediaStreamTrackAudioSourceNode` has no inputs and exactly one output, and is created using the [AudioContext.createMediaStreamTrackSource] method. This interface is similar to [MediaStreamAudioSourceNode], except it lets you specifically state the track to use, rather than assuming the first audio track on a stream.\n\n<table class=\"properties\">\n  <tbody>\n    <tr>\n      <th scope=\"row\">Number of inputs</th>\n      <td><code>0</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Number of outputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count</th>\n      <td>\n        defined by the first audio [MediaStreamTrack]\n        passed to the\n        [AudioContext.createMediaStreamTrackSource]\n        method that created it.\n      </td>\n    </tr>\n  </tbody>\n</table>"
  },
  "mediastreamtrackevent": {
    "docs": "\n\nThe **`MediaStreamTrackEvent`** interface of the [Media Capture and Streams API] represents events which indicate that a [MediaStream] has had tracks added to or removed from the stream through calls to [Media Capture and Streams API](/en-US/docs/Web/API/Media_Capture_and_Streams_API) methods. These events are sent to the stream when these changes occur.\n\nThe events based on this interface are [MediaStream/addtrack_event] and [MediaStream/removetrack_event].",
    "properties": {
      "track": "\n\nThe **`track`** read-only property of the [MediaStreamTrackEvent] interface returns the [MediaStreamTrack] associated with this event."
    }
  },
  "mediastreamtrackgenerator": {
    "docs": "\n\nThe **`MediaStreamTrackGenerator`** interface of the [Insertable Streams for MediaStreamTrack API] creates a [WritableStream] that acts as a [MediaStreamTrack] source.\nThe object consumes a stream of media frames as input, which can be audio or video frames.",
    "properties": {
      "writable": "\n\nThe **`writable`** property of the [MediaStreamTrackGenerator] interface returns a [WritableStream]. This allows the writing of media frames to the `MediaStreamTrackGenerator`. The frames will be audio or video. The type is dictated by the kind of `MediaStreamTrackGenerator` that was created."
    }
  },
  "mediastreamtrackprocessor": {
    "docs": "\n\nThe **`MediaStreamTrackProcessor`** interface of the [Insertable Streams for MediaStreamTrack API] consumes a [MediaStreamTrack] object's source and generates a stream of media frames.",
    "properties": {
      "readable": "\n\nThe **`readable`** property of the [MediaStreamTrackProcessor] interface returns a [ReadableStream]."
    }
  },
  "mediatrackconstraints": {
    "docs": "\n\nThe **`MediaTrackConstraints`** dictionary is used to describe a set of capabilities and the value or values each can take on. A constraints dictionary is passed into [MediaStreamTrack.applyConstraints] to allow a script to establish a set of exact (required) values or ranges and/or preferred values or ranges of values for the track, and the most recently-requested set of custom constraints can be retrieved by calling [MediaStreamTrack.getConstraints].",
    "properties": {
      "aspectratio": "\n\nThe [MediaTrackConstraints] dictionary's **`aspectRatio`** property is a [`ConstrainDouble`](/en-US/docs/Web/API/MediaTrackConstraints#constraindouble) describing the requested or mandatory constraints placed upon the value of the\n[MediaTrackSettings.aspectRatio] constrainable property.\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.aspectRatio] as returned by a\ncall to [MediaDevices.getSupportedConstraints]. However, typically this\nis unnecessary since browsers will ignore any constraints they're unfamiliar with.",
      "autogaincontrol": "\n\nThe [MediaTrackConstraints] dictionary's **`autoGainControl`** property is a [`ConstrainBoolean`](/en-US/docs/Web/API/MediaTrackConstraints#constrainboolean) describing the requested or mandatory constraints placed\nupon the value of the [MediaTrackSettings.autoGainControl] constrainable property.\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.autoGainControl] as returned\nby a call to [MediaDevices.getSupportedConstraints]. However, typically\nthis is unnecessary since browsers will ignore any constraints they're unfamiliar with.\n\nAutomatic gain control is typically a feature provided by microphones, although it can\nbe provided by other input sources as well.",
      "channelcount": "\n\nThe [MediaTrackConstraints] dictionary's\n**`channelCount`** property is a [`ConstrainULong`](/en-US/docs/Web/API/MediaTrackConstraints#constrainulong)\ndescribing the requested or mandatory constraints placed upon the value of the\n[MediaTrackSettings.channelCount] constrainable property.\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.channelCount] as returned by a\ncall to [MediaDevices.getSupportedConstraints]. However, typically this\nis unnecessary since browsers will ignore any constraints they're unfamiliar with.",
      "deviceid": "\n\nThe [MediaTrackConstraints] dictionary's\n**`deviceId`** property is a [`ConstrainDOMString`](/en-US/docs/Web/API/MediaTrackConstraints#constraindomstring)\ndescribing the requested or mandatory constraints placed upon the value of the\n[MediaTrackSettings.deviceId] constrainable property.\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.deviceId] as returned by a\ncall to [MediaDevices.getSupportedConstraints]. However, typically this\nis unnecessary since browsers will ignore any constraints they're unfamiliar with.\n\nBecause  doesn't include this information, tracks associated with a\n[WebRTC](/en-US/docs/Web/API/WebRTC_API) [RTCPeerConnection]\nwill never include this property.",
      "displaysurface": "\n\nThe [MediaTrackConstraints] dictionary's **`displaySurface`** property is a [`ConstrainDOMString`](/en-US/docs/Web/API/MediaTrackConstraints#constraindomstring) describing the preferred value for the [MediaTrackSettings.displaySurface] constrainable property.\n\nThis is set by the application to identify to the user agent the type of display surface (`window`, `browser`, or `monitor`) preferred by the application. It has no effect on what the user can choose to share, but may be used to present the options in a different order.\n\nIf needed, you can determine whether or not this constraint is supported by checking the value of [MediaTrackSupportedConstraints.displaySurface] as returned by a call to [MediaDevices.getSupportedConstraints]. However, typically this is unnecessary since browsers will ignore any constraints they're unfamiliar with.",
      "echocancellation": "\n\nThe [MediaTrackConstraints] dictionary's\n**`echoCancellation`** property is a\n[`ConstrainBoolean`](/en-US/docs/Web/API/MediaTrackConstraints#constrainboolean) describing the requested or mandatory constraints placed\nupon the value of the [MediaTrackSettings.echoCancellation] constrainable property.\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.echoCancellation] as returned\nby a call to [MediaDevices.getSupportedConstraints]. However, typically\nthis is unnecessary since browsers will ignore any constraints they're unfamiliar with.\n\nBecause  doesn't include this information, tracks associated with a\n[WebRTC](/en-US/docs/Web/API/WebRTC_API) [RTCPeerConnection]\nwill never include this property.",
      "facingmode": "\n\nThe [MediaTrackConstraints] dictionary's\n**`facingMode`** property is a [`ConstrainDOMString`](/en-US/docs/Web/API/MediaTrackConstraints#constraindomstring)\ndescribing the requested or mandatory constraints placed upon the value of the\n[MediaTrackSettings.facingMode] constrainable property.\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.facingMode] as returned by a\ncall to [MediaDevices.getSupportedConstraints]. However, typically this\nis unnecessary since browsers will ignore any constraints they're unfamiliar with.\n\nBecause  doesn't include this information, tracks associated with a\n[WebRTC](/en-US/docs/Web/API/WebRTC_API) [RTCPeerConnection]\nwill never include this property.",
      "framerate": "\n\nThe [MediaTrackConstraints] dictionary's\n**`frameRate`** property is a [`ConstrainDouble`](/en-US/docs/Web/API/MediaTrackConstraints#constraindouble)\ndescribing the requested or mandatory constraints placed upon the value of the\n[MediaTrackSettings.frameRate] constrainable property.\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.frameRate] as returned by a\ncall to [MediaDevices.getSupportedConstraints]. However, typically this\nis unnecessary since browsers will ignore any constraints they're unfamiliar with.",
      "groupid": "\n\nThe [MediaTrackConstraints] dictionary's\n**`groupId`** property is a [`ConstrainDOMString`](/en-US/docs/Web/API/MediaTrackConstraints#constraindomstring)\ndescribing the requested or mandatory constraints placed upon the value of the\n[MediaTrackSettings.groupId] constrainable property.\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.groupId] as returned by a call\nto [MediaDevices.getSupportedConstraints]. However, typically this is\nunnecessary since browsers will ignore any constraints they're unfamiliar with.",
      "height": "\n\nThe [MediaTrackConstraints] dictionary's\n**`height`** property is a [`ConstrainULong`](/en-US/docs/Web/API/MediaTrackConstraints#constrainulong)\ndescribing the requested or mandatory constraints placed upon the value of the\n[MediaTrackSettings.height] constrainable property.\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.height] as returned by a call\nto [MediaDevices.getSupportedConstraints]. However, typically this is\nunnecessary since browsers will ignore any constraints they're unfamiliar with.",
      "latency": "\n\nThe [MediaTrackConstraints] dictionary's\n**`latency`** property is a [`ConstrainDouble`](/en-US/docs/Web/API/MediaTrackConstraints#constraindouble)\ndescribing the requested or mandatory constraints placed upon the value of the\n[MediaTrackSettings.latency] constrainable property.\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.latency] as returned by a call\nto [MediaDevices.getSupportedConstraints]. However, typically this is\nunnecessary since browsers will ignore any constraints they're unfamiliar with.\n\nBecause  doesn't include this information, tracks associated with a\n[WebRTC](/en-US/docs/Web/API/WebRTC_API) [RTCPeerConnection]\nwill never include this property.",
      "logicalsurface": "\n\nThe [MediaTrackConstraints] dictionary's **`logicalSurface`** property is a [`ConstrainDOMString`](/en-US/docs/Web/API/MediaTrackConstraints#constraindomstring) describing the requested or mandatory constraints placed upon the value of the [MediaTrackSettings.logicalSurface] constrainable property.\n\nThis is used to specify whether or\nnot [MediaDevices.getDisplayMedia] should allow the\nuser to choose display surfaces which are not necessarily fully visible on the screen,\nsuch as occluded windows or the complete content of windows which are large enough to\nrequire scrolling to see their entire contents.\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.logicalSurface] as returned by\na call to [MediaDevices.getSupportedConstraints]. However, typically this\nis unnecessary since browsers will ignore any constraints they're unfamiliar with.",
      "noisesuppression": "\n\nThe [MediaTrackConstraints] dictionary's **`noiseSuppression`** property is a [`ConstrainBoolean`](/en-US/docs/Web/API/MediaTrackConstraints#constrainboolean) describing the requested or mandatory constraints placed upon the value of the [MediaTrackSettings.noiseSuppression] constrainable property.\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.noiseSuppression] as returned\nby a call to [MediaDevices.getSupportedConstraints]. However, typically\nthis is unnecessary since browsers will ignore any constraints they're unfamiliar with.\n\nNoise suppression is typically provided by microphones, although it can be provided by\nother input sources as well.",
      "samplerate": "\n\nThe [MediaTrackConstraints] dictionary's\n**`sampleRate`** property is a [`ConstrainULong`](/en-US/docs/Web/API/MediaTrackConstraints#constrainulong)\ndescribing the requested or mandatory constraints placed upon the value of the\n[MediaTrackSettings.sampleRate] constrainable property.\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.sampleRate] as returned by a\ncall to [MediaDevices.getSupportedConstraints]. However, typically this\nis unnecessary since browsers will ignore any constraints they're unfamiliar with.",
      "samplesize": "\n\nThe [MediaTrackConstraints] dictionary's\n**`sampleSize`** property is a [`ConstrainULong`](/en-US/docs/Web/API/MediaTrackConstraints#constrainulong)\ndescribing the requested or mandatory constraints placed upon the value of the\n[MediaTrackSettings.sampleSize] constrainable property.\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.sampleSize] as returned by a\ncall to [MediaDevices.getSupportedConstraints]. However, typically this\nis unnecessary since browsers will ignore any constraints they're unfamiliar with.",
      "suppresslocalaudioplayback": "\n\nThe [MediaTrackConstraints] dictionary's **`suppressLocalAudioPlayback`** property is a [`ConstrainBoolean`](/en-US/docs/Web/API/MediaTrackConstraints#constrainboolean) describing the requested or mandatory constraints placed upon the value of the [MediaTrackSettings.suppressLocalAudioPlayback] constrainable property. This property controls whether the audio playing in a tab will continue to be played out of a user's local speakers when the tab is captured.\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.suppressLocalAudioPlayback] as returned\nby a call to [MediaDevices.getSupportedConstraints]. However, typically\nthis is unnecessary since browsers will ignore any constraints they're unfamiliar with.",
      "volume": "\n\nThe [MediaTrackConstraints] dictionary's\n**`volume`** property is a [`ConstrainDouble`](/en-US/docs/Web/API/MediaTrackConstraints#constraindouble)\ndescribing the requested or mandatory constraints placed upon the value of the\n[MediaTrackSettings.volume] constrainable property.\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.volume] as returned by a call\nto [MediaDevices.getSupportedConstraints]. However, typically this is\nunnecessary since browsers will ignore any constraints they're unfamiliar with.",
      "width": "\n\nThe [MediaTrackConstraints] dictionary's\n**`width`** property is a [`ConstrainULong`](/en-US/docs/Web/API/MediaTrackConstraints#constrainulong)\ndescribing the requested or mandatory constraints placed upon the value of the\n[MediaTrackSettings.width] constrainable property.\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.width] as returned by a call\nto [MediaDevices.getSupportedConstraints]. However, typically this is\nunnecessary since browsers will ignore any constraints they're unfamiliar with."
    }
  },
  "mediatracksettings": {
    "docs": "\n\nThe **`MediaTrackSettings`** dictionary is used to return the current values configured for each of a [MediaStreamTrack]'s settings. These values will adhere as closely as possible to any constraints previously described using a [MediaTrackConstraints] object and set using [MediaStreamTrack.applyConstraints], and will adhere to the default constraints for any properties whose constraints haven't been changed, or whose customized constraints couldn't be matched.\n\nTo learn more about how constraints and settings work, see [Capabilities, constraints, and settings](/en-US/docs/Web/API/Media_Capture_and_Streams_API/Constraints).",
    "properties": {
      "aspectratio": "\n\nThe [MediaTrackSettings] dictionary's **`aspectRatio`** property is a double-precision floating-point number indicating the aspect ratio of the [MediaStreamTrack] as currently configured.\nThis lets you determine what value was selected to comply with your specified constraints for this property's value as described in the [MediaTrackConstraints.aspectRatio] property you provided when calling either [MediaDevices.getUserMedia] or [MediaStreamTrack.applyConstraints].\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.aspectRatio] as returned by a\ncall to [MediaDevices.getSupportedConstraints]. However, typically this\nis unnecessary since browsers will ignore any constraints they're unfamiliar with.",
      "autogaincontrol": "\n\nThe [MediaTrackSettings] dictionary's\n**`autoGainControl`** property is a Boolean value whose value\nindicates whether or not automatic gain control (AGC) is enabled on an audio track. This\nlets you determine what value was selected to comply with your specified constraints for\nthis property's value as described in the\n[MediaTrackConstraints.autoGainControl] property you provided when calling\neither [MediaDevices.getUserMedia] or\n[MediaStreamTrack.applyConstraints].\n\nAutomatic gain control is a feature in which a sound source automatically manages\nchanges in the volume of its source media to maintain a steady overall volume level.\nThis feature is typically used on microphones, although it can be provided by other\ninput sources as well.\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.autoGainControl] as returned\nby a call to [MediaDevices.getSupportedConstraints]. However, typically\nthis is unnecessary since browsers will ignore any constraints they're unfamiliar with.",
      "channelcount": "\n\nThe [MediaTrackSettings] dictionary's\n**`channelCount`** property is an integer indicating how many\naudio channels the [MediaStreamTrack] is currently configured to have. This\nlets you determine what value was selected to comply with your specified constraints for\nthis property's value as described in the\n[MediaTrackConstraints.channelCount] property you provided when calling\neither [MediaDevices.getUserMedia] or\n[MediaStreamTrack.applyConstraints].\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.channelCount] as returned by a\ncall to [MediaDevices.getSupportedConstraints]. However, typically this\nis unnecessary since browsers will ignore any constraints they're unfamiliar with.",
      "cursor": "\n\nThe [MediaTrackSettings] dictionary's **`cursor`** property indicates whether or not the cursor should be captured as part of the video track included in the [MediaStream] returned by [MediaDevices.getDisplayMedia].",
      "deviceid": "\n\nThe [MediaTrackSettings] dictionary's\n**`deviceId`** property is a string which\nuniquely identifies the source for the corresponding [MediaStreamTrack] for\nthe origin corresponding to the browsing session. This lets you determine what value was\nselected to comply with your specified constraints for this property's value as\ndescribed in the [MediaTrackConstraints.deviceId] property you provided\nwhen calling either [MediaDevices.getUserMedia].\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.deviceId] as returned by a\ncall to [MediaDevices.getSupportedConstraints]. However, typically this\nis unnecessary since browsers will ignore any constraints they're unfamiliar with.\n\nBecause  doesn't include this information, tracks associated with a\n[WebRTC](/en-US/docs/Web/API/WebRTC_API) [RTCPeerConnection]\nwill never include this property.",
      "displaysurface": "\n\nThe [MediaTrackSettings] dictionary's\n**`displaySurface`** property indicates the type of display\nsurface being captured.",
      "echocancellation": "\n\nThe [MediaTrackSettings] dictionary's\n**`echoCancellation`** property is a Boolean value whose value\nindicates whether or not echo cancellation is enabled on an audio track. This lets you\ndetermine what value was selected to comply with your specified constraints for this\nproperty's value as described in the\n[MediaTrackConstraints.echoCancellation] property you provided when calling\neither [MediaDevices.getUserMedia] or\n[MediaStreamTrack.applyConstraints].\n\nEcho cancellation is a feature which attempts to prevent echo effects on a two-way\naudio connection by attempting to reduce or eliminate crosstalk between the user's\noutput device and their input device. For example, it might apply a filter that negates\nthe sound being produced on the speakers from being included in the input track\ngenerated from the microphone.\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.echoCancellation] as returned\nby a call to [MediaDevices.getSupportedConstraints]. However, typically\nthis is unnecessary since browsers will ignore any constraints they're unfamiliar with.\n\nBecause  doesn't include this information, tracks associated with a\n[WebRTC](/en-US/docs/Web/API/WebRTC_API) [RTCPeerConnection]\nwill never include this property.",
      "facingmode": "\n\nThe [MediaTrackSettings] dictionary's\n**`facingMode`** property is a string\nindicating the direction in which the camera producing the video track represented by\nthe [MediaStreamTrack] is currently facing. This lets you determine what\nvalue was selected to comply with your specified constraints for this property's value\nas described in the [MediaTrackConstraints.facingMode] property you\nprovided when calling either [MediaDevices.getUserMedia]\nor [MediaStreamTrack.applyConstraints].\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.facingMode] as returned by a\ncall to [MediaDevices.getSupportedConstraints]. However, typically this\nis unnecessary since browsers will ignore any constraints they're unfamiliar with.\n\nBecause  doesn't include this information, tracks associated with a\n[WebRTC](/en-US/docs/Web/API/WebRTC_API) [RTCPeerConnection]\nwill never include this property.",
      "framerate": "\n\nThe [MediaTrackSettings] dictionary's\n**`frameRate`** property is a double-precision floating-point\nnumber indicating the frame rate, in frames per second, of the\n[MediaStreamTrack] as currently configured. This lets you determine what\nvalue was selected to comply with your specified constraints for this property's value\nas described in the [MediaTrackConstraints.frameRate] property you provided\nwhen calling either [MediaDevices.getUserMedia] or\n[MediaStreamTrack.applyConstraints].\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.frameRate] as returned by a\ncall to [MediaDevices.getSupportedConstraints]. However, typically this\nis unnecessary since browsers will ignore any constraints they're unfamiliar with.",
      "groupid": "\n\nThe [MediaTrackSettings] dictionary's\n**`groupId`** property is a browsing-session unique\nstring which identifies the group of devices which includes the source\nfor the [MediaStreamTrack]. This lets you determine what value was selected\nto comply with your specified constraints for this property's value as described in the\n[MediaTrackConstraints.groupId] property you provided when calling either\n[MediaDevices.getUserMedia].\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.groupId] as returned by a call\nto [MediaDevices.getSupportedConstraints]. However, typically this is\nunnecessary since browsers will ignore any constraints they're unfamiliar with.\n\nBecause  doesn't include this information, tracks associated with a\n[WebRTC](/en-US/docs/Web/API/WebRTC_API) [RTCPeerConnection]\nwill never include this property.",
      "height": "\n\nThe [MediaTrackSettings] dictionary's **`height`**\nproperty is an integer indicating the number of pixels tall\n[MediaStreamTrack] is currently configured to be. This lets you determine\nwhat value was selected to comply with your specified constraints for this property's\nvalue as described in the [MediaTrackConstraints.height] property you\nprovided when calling either [MediaDevices.getUserMedia]\nor [MediaStreamTrack.applyConstraints].\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.height] as returned by a call\nto [MediaDevices.getSupportedConstraints]. However, typically this is\nunnecessary since browsers will ignore any constraints they're unfamiliar with.",
      "latency": "\n\nThe [MediaTrackSettings] dictionary's\n**`latency`** property is a double-precision floating-point\nnumber indicating the estimated latency (specified in seconds) of the\n[MediaStreamTrack] as currently configured. This lets you determine what\nvalue was selected to comply with your specified constraints for this property's value\nas described in the [MediaTrackConstraints.latency] property you provided\nwhen calling either [MediaDevices.getUserMedia] or\n[MediaStreamTrack.applyConstraints].\n\nThis is, of course, an approximation, since latency can vary for many reasons including\nCPU, transmission, and storage overhead.\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.latency] as returned by a call\nto [MediaDevices.getSupportedConstraints]. However, typically this is\nunnecessary since browsers will ignore any constraints they're unfamiliar with.\n\nBecause  doesn't include this information, tracks associated with a\n[WebRTC](/en-US/docs/Web/API/WebRTC_API) [RTCPeerConnection]\nwill never include this property.",
      "logicalsurface": "\n\nThe [MediaTrackSettings] dictionary's\n**`logicalSurface`** property indicates whether or not the\ndisplay area being captured is a logical surface. Logical surfaces are those which are\nnot necessarily entirely onscreen, or may even be off-screen, such as windows' backing\nbuffers (where only part of the buffer is visible without scrolling the containing\nwindow) and offscreen rendering contexts.",
      "noisesuppression": "\n\nThe [MediaTrackSettings] dictionary's\n**`noiseSuppression`** property is a Boolean value whose value\nindicates whether or not noise suppression technology is enabled on an audio track. This\nlets you determine what value was selected to comply with your specified constraints for\nthis property's value as described in the\n[MediaTrackConstraints.noiseSuppression] property you provided when calling\neither [MediaDevices.getUserMedia] or\n[MediaStreamTrack.applyConstraints].\n\nNoise suppression automatically filters the audio to remove background noise, hum\ncaused by equipment, and the like from the sound before delivering it to your code. This\nfeature is typically used on microphones, although it is technically possible it could\nbe provided by other input sources as well.\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.noiseSuppression] as returned\nby a call to [MediaDevices.getSupportedConstraints]. However, typically\nthis is unnecessary since browsers will ignore any constraints they're unfamiliar with.",
      "samplerate": "\n\nThe [MediaTrackSettings] dictionary's\n**`sampleRate`** property is an integer indicating how many\naudio samples per second the [MediaStreamTrack] is currently configured\nfor. This lets you determine what value was selected to comply with your specified\nconstraints for this property's value as described in the\n[MediaTrackConstraints.sampleRate] property you provided when calling\neither [MediaDevices.getUserMedia] or\n[MediaStreamTrack.applyConstraints].\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.sampleRate] as returned by a\ncall to [MediaDevices.getSupportedConstraints]. However, typically this\nis unnecessary since browsers will ignore any constraints they're unfamiliar with.",
      "samplesize": "\n\nThe [MediaTrackSettings] dictionary's\n**`sampleSize`** property is an integer indicating the linear\nsample size (in bits per sample) the [MediaStreamTrack] is currently\nconfigured for. This lets you determine what value was selected to comply with your\nspecified constraints for this property's value as described in the\n[MediaTrackConstraints.sampleSize] property you provided when calling\neither [MediaDevices.getUserMedia] or\n[MediaStreamTrack.applyConstraints].\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.sampleSize] as returned by a\ncall to [MediaDevices.getSupportedConstraints]. However, typically this\nis unnecessary since browsers will ignore any constraints they're unfamiliar with.",
      "suppresslocalaudioplayback": "\n\nThe [MediaTrackSettings] dictionary's **`suppressLocalAudioPlayback`** property controls whether the audio playing in a tab will continue to be played out of a user's local speakers when the tab is captured.\n\nFor example, in cases where you broadcast a video call to an external AV system in a conference room, you will want the audio to play out of the AV system, and not the local speakers. This way, the audio will be louder and clearer, and also in sync with the conference video.",
      "volume": "\n\nThe [MediaTrackSettings] dictionary's **`volume`**\nproperty is a double-precision floating-point number indicating the volume of the\n[MediaStreamTrack] as currently configured, as a value from 0.0 (silence)\nto 1.0 (maximum supported volume for the device). This lets you determine what value was\nselected to comply with your specified constraints for this property's value as\ndescribed in the [MediaTrackConstraints.volume] property you provided when\ncalling either [MediaDevices.getUserMedia] or\n[MediaStreamTrack.applyConstraints].\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.volume] as returned by a call\nto [MediaDevices.getSupportedConstraints]. However, typically this is\nunnecessary since browsers will ignore any constraints they're unfamiliar with.",
      "width": "\n\nThe [MediaTrackSettings] dictionary's **`width`**\nproperty is an integer indicating the number of pixels wide\n[MediaStreamTrack] is currently configured to be. This lets you determine\nwhat value was selected to comply with your specified constraints for this property's\nvalue as described in the [MediaTrackConstraints.width] property you\nprovided when calling either [MediaDevices.getUserMedia]\nor [MediaStreamTrack.applyConstraints].\n\nIf needed, you can determine whether or not this constraint is supported by checking\nthe value of [MediaTrackSupportedConstraints.width] as returned by a call\nto [MediaDevices.getSupportedConstraints]. However, typically this is\nunnecessary since browsers will ignore any constraints they're unfamiliar with."
    }
  },
  "mediatracksupportedconstraints": {
    "docs": "\n\nThe **`MediaTrackSupportedConstraints`** dictionary establishes the list of constrainable properties recognized by the  or browser in its implementation of the [MediaStreamTrack] object. An object conforming to `MediaTrackSupportedConstraints` is returned by [MediaDevices.getSupportedConstraints].\n\nBecause of the way interface definitions in WebIDL work, if a constraint is requested but not supported, no error will occur. Instead, the specified constraints will be applied, with any unrecognized constraints stripped from the request. That can lead to confusing and hard to debug errors, so be sure to use `getSupportedConstraints()` to retrieve this information before attempting to establish constraints if you need to know the difference between silently ignoring a constraint and a constraint being accepted.\n\nAn actual constraint set is described using an object based on the [MediaTrackConstraints] dictionary.\n\nTo learn more about how constraints work, see [Capabilities, constraints, and settings](/en-US/docs/Web/API/Media_Capture_and_Streams_API/Constraints).",
    "properties": {
      "aspectratio": "\n\nThe [MediaTrackSupportedConstraints] dictionary's **`aspectRatio`** property is a read-only Boolean value which is present (and set to `true`) in the object returned by [MediaDevices.getSupportedConstraints] if and only if the\n supports the `aspectRatio` constraint.\nIf the constraint isn't supported, it's not included in the list, so this value will never be `false`.\n\nYou can access the supported constraints dictionary by calling `navigator.mediaDevices.getSupportedConstraints()`.",
      "autogaincontrol": "\n\nThe [MediaTrackSupportedConstraints] dictionary's **`autoGainControl`** property is a read-only Boolean value which is present (and set to `true`) in the object returned by [MediaDevices.getSupportedConstraints] if and only if the  supports the **`autoGainControl`** constraint.\nIf the constraint isn't supported, it's not included in the list, so this value will never be `false`.\n\nYou can access the supported constraints dictionary by calling `navigator.mediaDevices.getSupportedConstraints()`.\n\nThe `autoGainControl` constraint indicates whether or not the browser offers the ability to automatically control the gain (volume) on media tracks; this obviously is contingent on whether or not the individual device supports automatic gain control as well; it's typically a feature provided by microphones.",
      "channelcount": "\n\nThe [MediaTrackSupportedConstraints] dictionary's\n**`channelCount`** property is a read-only Boolean value which\nis present (and set to `true`) in the object returned by\n[MediaDevices.getSupportedConstraints] if and only if the\n supports the `channelCount` constraint. If the\nconstraint isn't supported, it's not included in the list, so this value will never be\n`false`.\n\nYou can access the supported constraints dictionary by calling\n`navigator.mediaDevices.getSupportedConstraints()`.",
      "deviceid": "\n\nThe [MediaTrackSupportedConstraints] dictionary's\n**`deviceId`** property is a read-only Boolean value which is\npresent (and set to `true`) in the object returned by\n[MediaDevices.getSupportedConstraints] if and only if the\n supports the `deviceId` constraint. If the\nconstraint isn't supported, it's not included in the list, so this value will never be\n`false`.\n\nYou can access the supported constraints dictionary by calling\n`navigator.mediaDevices.getSupportedConstraints()`.",
      "displaysurface": "\n\nThe [MediaTrackSupportedConstraints] dictionary's **`displaySurface`** property indicates whether or not the [MediaTrackConstraints.displaySurface] constraint is supported by the user agent and the device on which the content is being used.\n\nThe supported constraints list is obtained by calling [MediaDevices.getSupportedConstraints].",
      "echocancellation": "\n\nThe [MediaTrackSupportedConstraints] dictionary's\n**`echoCancellation`** property is a read-only Boolean value\nwhich is present (and set to `true`) in the object returned by\n[MediaDevices.getSupportedConstraints] if and only if the\n supports the `echoCancellation` constraint. If the\nconstraint isn't supported, it's not included in the list, so this value will never be\n`false`.\n\nYou can access the supported constraints dictionary by calling\n`navigator.mediaDevices.getSupportedConstraints()`.",
      "facingmode": "\n\nThe [MediaTrackSupportedConstraints] dictionary's\n**`facingMode`** property is a read-only Boolean value which is\npresent (and set to `true`) in the object returned by\n[MediaDevices.getSupportedConstraints] if and only if the\n supports the `facingMode` constraint. If the\nconstraint isn't supported, it's not included in the list, so this value will never be\n`false`.\n\nYou can access the supported constraints dictionary by calling\n`navigator.mediaDevices.getSupportedConstraints()`.",
      "framerate": "\n\nThe [MediaTrackSupportedConstraints] dictionary's **`frameRate`** property is a read-only Boolean value which is\npresent (and set to `true`) in the object returned by [MediaDevices.getSupportedConstraints] if and only if the  supports the [MediaTrackConstraints.frameRate] constraint.\n\nIf the constraint isn't supported, it's not included in the list, so this value will never be `false`.\n\nThe `frameRate` constraint can be used to establish acceptable upper and lower bounds on the video frame rate for a new video track, or to specify an exact frame rate that must be provided for the request to succeed.\nChecking the value of this property lets you determine if the user agent allows constraining the video track configuration by frame rate. See the [example](#examples) to see how this can be used.",
      "groupid": "\n\nThe [MediaTrackSupportedConstraints] dictionary's\n**`groupId`** property is a read-only Boolean value which is\npresent (and set to `true`) in the object returned by\n[MediaDevices.getSupportedConstraints] if and only if the\n supports the `groupId` constraint. If the\nconstraint isn't supported, it's not included in the list, so this value will never be\n`false`.\n\nYou can access the supported constraints dictionary by calling\n`navigator.mediaDevices.getSupportedConstraints()`.",
      "height": "\n\nThe [MediaTrackSupportedConstraints] dictionary's\n**`height`** property is a read-only Boolean value which is\npresent (and set to `true`) in the object returned by\n[MediaDevices.getSupportedConstraints] if and only if the\n supports the `height` constraint. If the\nconstraint isn't supported, it's not included in the list, so this value will never be\n`false`.\n\nYou can access the supported constraints dictionary by calling\n`navigator.mediaDevices.getSupportedConstraints()`.",
      "latency": "\n\nThe [MediaTrackSupportedConstraints] dictionary's **`latency`** property is a read-only Boolean value which is present (and set to `true`) in the object returned by [MediaDevices.getSupportedConstraints] if and only if the  supports the `latency` constraint.\nIf the constraint isn't supported, it's not included in the list, so this value will never be `false`.\n\nYou can access the supported constraints dictionary by calling `navigator.mediaDevices.getSupportedConstraints()`.",
      "logicalsurface": "\n\nThe [MediaTrackSupportedConstraints] dictionary's **`logicalSurface`** property indicates whether or not the [MediaTrackConstraints.logicalSurface] constraint is supported by the user agent and the device on which the content is being used.\n\nThe supported constraints list is obtained by calling [MediaDevices.getSupportedConstraints].",
      "noisesuppression": "\n\nThe [MediaTrackSupportedConstraints] dictionary's\n**`noiseSuppression`** property is a read-only Boolean value\nwhich is present (and set to `true`) in the object returned by\n[MediaDevices.getSupportedConstraints] if and only if the\n supports the **`noiseSuppression`**\nconstraint. If the constraint isn't supported, it's not included in the list, so this\nvalue will never be `false`.\n\nYou can access the supported constraints dictionary by calling\n`navigator.mediaDevices.getSupportedConstraints()`.\n\nThe `noiseSuppression` constraint indicates whether or not the browser\noffers the ability to automatically control the gain (volume) on media tracks; this\nobviously is contingent on whether or not the individual device supports automatic gain\ncontrol as well.",
      "samplerate": "\n\nThe [MediaTrackSupportedConstraints] dictionary's\n**`sampleRate`** property is a read-only Boolean value which is\npresent (and set to `true`) in the object returned by\n[MediaDevices.getSupportedConstraints] if and only if the\n supports the `sampleRate` constraint. If the\nconstraint isn't supported, it's not included in the list, so this value will never be\n`false`.\n\nYou can access the supported constraints dictionary by calling\n`navigator.mediaDevices.getSupportedConstraints()`.",
      "samplesize": "\n\nThe [MediaTrackSupportedConstraints] dictionary's\n**`sampleSize`** property is a read-only Boolean value which is\npresent (and set to `true`) in the object returned by\n[MediaDevices.getSupportedConstraints] if and only if the\n supports the `sampleSize` constraint. If the\nconstraint isn't supported, it's not included in the list, so this value will never be\n`false`.\n\nYou can access the supported constraints dictionary by calling\n`navigator.mediaDevices.getSupportedConstraints()`.",
      "suppresslocalaudioplayback": "\n\nThe [MediaTrackSupportedConstraints] dictionary's **`suppressLocalAudioPlayback`** property indicates whether or not the [MediaTrackConstraints.suppressLocalAudioPlayback] constraint is supported by the user agent and the device on which the content is being used.\n\nThe supported constraints list is obtained by calling [MediaDevices.getSupportedConstraints].",
      "volume": "\n\nThe [MediaTrackSupportedConstraints] dictionary's\n**`volume`** property is a read-only Boolean value which is\npresent (and set to `true`) in the object returned by\n[MediaDevices.getSupportedConstraints] if and only if the\n supports the `volume` constraint. If the\nconstraint isn't supported, it's not included in the list, so this value will never be\n`false`.\n\nYou can access the supported constraints dictionary by calling\n`navigator.mediaDevices.getSupportedConstraints()`.",
      "width": "\n\nThe [MediaTrackSupportedConstraints] dictionary's\n**`width`** property is a read-only Boolean value which is\npresent (and set to `true`) in the object returned by\n[MediaDevices.getSupportedConstraints] if and only if the\n supports the `width` constraint. If the constraint\nisn't supported, it's not included in the list, so this value will never be\n`false`.\n\nYou can access the supported constraints dictionary by calling\n`navigator.mediaDevices.getSupportedConstraints()`."
    }
  },
  "merchantvalidationevent": {
    "docs": "\n\nThe **`MerchantValidationEvent`** interface of the [Payment Request API](/en-US/docs/Web/API/Payment_Request_API) enables a merchant to verify themselves as allowed to use a particular payment handler.\n\nLearn more about [merchant validation](/en-US/docs/Web/API/Payment_Request_API/Concepts#merchant_validation).",
    "properties": {
      "complete": "\n\nThe [MerchantValidationEvent] method **`complete()`** takes merchant-specific information previously received from the [MerchantValidationEvent.validationURL] and uses it to validate the merchant.\n\nAll you have to do is call `complete()` from your handler for the [PaymentRequest.merchantvalidation_event] event, passing in the data fetched from the `validationURL`.",
      "methodname": "\n\nThe [MerchantValidationEvent] property\n**`methodName`** is a read-only value which returns a string\nindicating the payment method identifier which represents the payment handler that\nrequires merchant validation.",
      "validationurl": "\n\nThe [MerchantValidationEvent] property\n**`validationURL`** is a read-only string value providing the\nURL from which to fetch the payment handler-specific data needed to validate the\nmerchant.\n\nThis data should be passed into the [MerchantValidationEvent.complete] method to let the user agent complete the transaction."
    }
  },
  "messagechannel": {
    "docs": "\n\nThe **`MessageChannel`** interface of the [Channel Messaging API](/en-US/docs/Web/API/Channel_Messaging_API) allows us to create a new message channel and send data through it via its two [MessagePort] properties.\n\n",
    "properties": {
      "port1": "\n\nThe **`port1`** read-only property of the\n[MessageChannel] interface returns the first port of the message channel —\nthe port attached to the context that originated the channel.\n\n",
      "port2": "\n\nThe **`port2`** read-only property of the\n[MessageChannel] interface returns the second port of the message channel —\nthe port attached to the context at the other end of the channel, which the message is\ninitially sent to.\n\n"
    }
  },
  "messageevent": {
    "docs": "\n\nThe **`MessageEvent`** interface represents a message received by a target object.\n\nThis is used to represent messages in:\n\n- [Server-sent events](/en-US/docs/Web/API/Server-sent_events) (see [EventSource.message_event]).\n- [Web sockets](/en-US/docs/Web/API/WebSockets_API) (see the `onmessage` property of the [WebSocket](/en-US/docs/Web/API/WebSocket) interface).\n- Cross-document messaging (see [Window.postMessage] and [Window.message_event]).\n- [Channel messaging](/en-US/docs/Web/API/Channel_Messaging_API) (see [MessagePort.postMessage] and [MessagePort.message_event]).\n- Cross-worker/document messaging (see the above two entries, but also [Worker.postMessage], [Worker.message_event], [ServiceWorkerGlobalScope.message_event], etc.)\n- [Broadcast channels](/en-US/docs/Web/API/Broadcast_Channel_API) (see [BroadcastChannel.postMessage]) and [BroadcastChannel.message_event]).\n- WebRTC data channels (see [RTCDataChannel.message_event]).\n\nThe action triggered by this event is defined in a function set as the event handler for the relevant `message` event (e.g. using an `onmessage` handler as listed above).\n\n",
    "properties": {
      "data": "\n\nThe **`data`** read-only property of the\n[MessageEvent] interface represents the data sent by the message emitter.",
      "lasteventid": "\n\nThe **`lastEventId`** read-only property of the\n[MessageEvent] interface is a string representing a\nunique ID for the event.",
      "origin": "\n\nThe **`origin`** read-only property of the\n[MessageEvent] interface is a string representing the\norigin of the message emitter.",
      "ports": "\n\nThe **`ports`** read-only property of the\n[MessageEvent] interface is an array of [MessagePort] objects\nrepresenting the ports associated with the channel the message is being sent through\n(where appropriate, e.g. in channel messaging or when sending a message to a shared\nworker).",
      "source": "\n\nThe **`source`** read-only property of the\n[MessageEvent] interface is a `MessageEventSource` (which can be\na , [MessagePort], or\n[ServiceWorker] object) representing the message emitter."
    }
  },
  "messageport": {
    "docs": "\n\nThe **`MessagePort`** interface of the [Channel Messaging API](/en-US/docs/Web/API/Channel_Messaging_API) represents one of the two ports of a [MessageChannel], allowing messages to be sent from one port and listening out for them arriving at the other.\n\n`MessagePort` is a [transferable object](/en-US/docs/Web/API/Web_Workers_API/Transferable_objects).\n\n",
    "properties": {
      "close": "\n\nThe **`close()`** method of the [MessagePort]\ninterface disconnects the port, so it is no longer active. This stops the flow of\nmessages to that port.\n\n",
      "message_event": "\n\nThe `message` event is fired on a [MessagePort] object when a message arrives on that channel.\n\nThis event is not cancellable and does not bubble.",
      "messageerror_event": "\n\nThe `messageerror` event is fired on a [MessagePort] object when it receives a message that can't be deserialized.\n\nThis event is not cancellable and does not bubble.",
      "postmessage": "\n\nThe **`postMessage()`** method of the\n[MessagePort] interface sends a message from the port, and optionally,\ntransfers ownership of objects to other browsing contexts.\n\n",
      "start": "\n\nThe **`start()`** method of the [MessagePort]\ninterface starts the sending of messages queued on the port. This method is only needed\nwhen using [EventTarget.addEventListener]; it is implied when using\n[MessagePort.message_event].\n\n"
    }
  },
  "metadata": {
    "docs": "\n\nThe **`Metadata`** interface contains information about a file system entry. This metadata includes the file's size and modification date and time.\n\n> **Note:** This interface isn't available through the global scope; instead, you obtain a `Metadata` object describing a [FileSystemEntry] using the method [FileSystemEntry.getMetadata].",
    "properties": {
      "modificationtime": "\n\nThe read-only **`modificationTime`**\nproperty of the [Metadata] interface is a `Date` object which\nspecifies the date and time the file system entry (or the data referenced by the\nentry) was last modified. A file system entry is considered to have been\nmodified if the metadata or the contents of the referenced file (or directory, or\nwhatever other kind of file system entry might exist on the platform in use) has\nchanged.",
      "size": "\n\nThe read-only **`size`** property of\nthe [Metadata] interface specifies the size, in bytes, of the referenced\nfile or other file system object on disk."
    }
  },
  "midiaccess": {
    "docs": "\n\nThe **`MIDIAccess`** interface of the [Web MIDI API](/en-US/docs/Web/API/Web_MIDI_API) provides methods for listing MIDI input and output devices, and obtaining access to those devices.\n\n",
    "properties": {
      "inputs": "\n\nThe **`inputs`** read-only property of the [MIDIAccess] interface provides access to any available MIDI input ports.",
      "outputs": "\n\nThe **`outputs`** read-only property of the [MIDIAccess] interface provides access to any available MIDI output ports.",
      "statechange_event": "\n\nThe **`statechange`** event of the [MIDIAccess] interface is fired when a new MIDI port is added or when an existing port changes state.",
      "sysexenabled": "\n\nThe **`sysexEnabled`** read-only property of the [MIDIAccess] interface indicates whether system exclusive support is enabled on the current MIDIAccess instance."
    }
  },
  "midiconnectionevent": {
    "docs": "\n\nThe **`MIDIConnectionEvent`** interface of the [Web MIDI API](/en-US/docs/Web/API/Web_MIDI_API) is the event passed to the [MIDIAccess.statechange_event] event of the [MIDIAccess] interface and the [MIDIPort.statechange_event] event of the [MIDIPort] interface. This occurs any time a new port becomes available, or when a previously available port becomes unavailable. For example, this event is fired whenever a MIDI device is either plugged in to or unplugged from a computer.\n\n",
    "properties": {
      "port": "\n\nThe **`port`** read-only property of the [MIDIConnectionEvent] interface returns the port that has been disconnected or connected."
    }
  },
  "midiinput": {
    "docs": "\n\nThe **`MIDIInput`** interface of the [Web MIDI API](/en-US/docs/Web/API/Web_MIDI_API) receives messages from a MIDI input port.\n\n",
    "properties": {
      "midimessage_event": "\n\nThe `midimessage` event of the [Web MIDI API](/en-US/docs/Web/API/Web_MIDI_API) is fired when the MIDI port corresponding to this [MIDIInput] finishes receiving one or more MIDI messages. An instance of [MIDIMessageEvent] containing the message that was received is passed to the event handler."
    }
  },
  "midiinputmap": {
    "docs": "\n\nThe **`MIDIInputMap`** read-only interface of the [Web MIDI API](/en-US/docs/Web/API/Web_MIDI_API) provides the set of MIDI input ports that are currently available.\n\nA `MIDIInputMap` instance is a read-only [`Map`-like object](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map#map-like_browser_apis), in which each key is the ID string for MIDI input, and the associated value is the corresponding [MIDIInput] object."
  },
  "midimessageevent": {
    "docs": "\n\nThe **`MIDIMessageEvent`** interface of the [Web MIDI API](/en-US/docs/Web/API/Web_MIDI_API) represents the event passed to the [MIDIInput.midimessage_event] event of the [MIDIInput] interface. A `midimessage` event is fired every time a MIDI message is sent from a device represented by a [MIDIInput], for example when a MIDI keyboard key is pressed, a knob is tweaked, or a slider is moved.\n\n",
    "properties": {
      "data": "\n\nThe **`data`** read-only property of the [MIDIMessageEvent] interface returns the MIDI data bytes of a single MIDI message."
    }
  },
  "midioutput": {
    "docs": "\n\nThe **`MIDIOutput`** interface of the [Web MIDI API] provides methods to add messages to the queue of an output device, and to clear the queue of messages.\n\n",
    "properties": {
      "clear": "\n\nThe **`clear()`** method of the [MIDIOutput] interface clears the queue of messages being sent to the output device.",
      "send": "\n\nThe **`send()`** method of the [MIDIOutput] interface queues messages for the corresponding MIDI port. The message can be sent immediately, or with an optional timestamp to delay sending."
    }
  },
  "midioutputmap": {
    "docs": "\n\nThe **`MIDIOutputMap`** read-only interface of the [Web MIDI API](/en-US/docs/Web/API/Web_MIDI_API) provides the set of MIDI output ports that are currently available.\n\nA `MIDIOutputMap` instance is a read-only [`Map`-like object](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map#map-like_browser_apis), in which each key is the ID string for MIDI output, and the associated value is the corresponding [MIDIOutput] object."
  },
  "midiport": {
    "docs": "`Web MIDI API`\n\nThe **`MIDIPort`** interface of the [Web MIDI API] represents a MIDI input or output port.\n\nA `MIDIPort` instance is created when a new MIDI device is connected. Therefore it has no constructor.\n\n",
    "properties": {
      "close": "`Web MIDI API`\n\nThe **`close()`** method of the [MIDIPort] interface makes the access to the MIDI device connected to this `MIDIPort` unavailable.\n\nIf the port is successfully closed a new [MIDIConnectionEvent] is queued to the [MIDIPort.statechange_event] and [MIDIAccess.statechange_event] events, and the [MIDIPort.connection] property is changed to `\"closed\"`.",
      "connection": "`Web MIDI API`\n\nThe **`connection`** read-only property of the [MIDIPort] interface returns the connection state of the port.",
      "id": "`Web MIDI API`\n\nThe **`id`** read-only property of the [MIDIPort] interface returns the unique ID of the port.",
      "manufacturer": "`Web MIDI API`\n\nThe **`manufacturer`** read-only property of the [MIDIPort] interface returns the manufacturer of the port.",
      "name": "`Web MIDI API`\n\nThe **`name`** read-only property of the [MIDIPort] interface returns the system name of the port.",
      "open": "`Web MIDI API`\n\nThe **`open()`** method of the [MIDIPort] interface makes the MIDI device connected to this `MIDIPort` explicitly available.\n\nIf the port is successfully opened a new [MIDIConnectionEvent] is queued to the [MIDIPort.statechange_event] and [MIDIAccess.statechange_event] events, and the [MIDIPort.connection] property is changed to `\"open\"`.\n\nIf the port is already open when this method is called, then the promise will resolve successfully.",
      "state": "`Web MIDI API`\n\nThe **`state`** read-only property of the [MIDIPort] interface returns the state of the port.",
      "statechange_event": "`Web MIDI API`\n\nThe **`statechange`** event of the [MIDIPort] interface is fired when a port changes from open to closed, or closed to open.",
      "type": "`Web MIDI API`\n\nThe **`type`** read-only property of the [MIDIPort] interface returns the type of the port, indicating whether this is an input or output MIDI port.",
      "version": "`Web MIDI API`\n\nThe **`version`** read-only property of the [MIDIPort] interface returns the version of the port."
    }
  },
  "mimetype": {
    "docs": "\n\nThe **`MimeType`** interface provides contains information about a MIME type associated with a particular plugin. [Navigator.mimeTypes] returns an array of this object."
  },
  "mimetypearray": {
    "docs": "\n\nThe **`MimeTypeArray`** interface returns an array of [MimeType] instances, each of which contains information about a supported browser plugins. This object is returned by [Navigator.mimeTypes].\n\n> **Note:** This interface was an [attempt to create an unmodifiable list](https://stackoverflow.com/questions/74630989/why-use-domstringlist-rather-than-an-array/74641156#74641156) and only continues to be supported to not break code that's already using it. Modern APIs use types that wrap around ECMAScript array types instead, so you can treat them like ECMAScript arrays, and at the same time impose additional semantics on their usage (such as making their items read-only)."
  },
  "mouseevent": {
    "docs": "\n\nThe **`MouseEvent`** interface represents events that occur due to the user interacting with a pointing device (such as a mouse).\nCommon events using this interface include [Element/click_event], [Element/dblclick_event], [Element/mouseup_event], [Element/mousedown_event].\n\n`MouseEvent` derives from [UIEvent], which in turn derives from [Event].\nThough the [MouseEvent.initMouseEvent] method is kept for backward compatibility, creating of a `MouseEvent` object should be done using the [MouseEvent.MouseEvent] constructor.\n\nSeveral more specific events are based on `MouseEvent`, including [WheelEvent], [DragEvent], and [PointerEvent].\n\n",
    "properties": {
      "altkey": "\n\nThe **`MouseEvent.altKey`** read-only property is a boolean value that indicates whether the <kbd>alt</kbd> key was pressed or not when a given mouse event occurs.\n\nBe aware that the browser can't always detect the <kbd>alt</kbd> key on some operating systems.\nOn some Linux variants, for example, a left mouse click combined with the <kbd>alt</kbd> key is used to move or resize windows.\n\n> **Note:** On Macintosh keyboards, this key is also known as the <kbd>option</kbd> key.",
      "button": "\n\nThe **`MouseEvent.button`** read-only property indicates which button was pressed on the mouse to trigger the event.\n\nThis property only guarantees to indicate which buttons are pressed during events caused by pressing or releasing one or multiple buttons.\nAs such, it is not reliable for events such as [Element/mouseenter_event], [Element/mouseleave_event], [Element/mouseover_event], [Element/mouseout_event], or [Element/mousemove_event].\n\nUsers may change the configuration of buttons on their pointing device so that if an event's button property is zero, it may not have been caused by the button that is physically left–most on the pointing device; however, it should behave as if the left button was clicked in the standard button layout.\n\n> **Note:** Do not confuse this property with the [MouseEvent.buttons] property, which indicates which buttons are pressed for all mouse events types.",
      "buttons": "\n\nThe **`MouseEvent.buttons`** read-only property indicates which buttons are pressed on the mouse (or other input device) when a mouse event is triggered.\n\nEach button that can be pressed is represented by a given number (see below).\nIf more than one button is pressed, the button values are added together to produce a new number.\nFor example, if the secondary (`2`) and auxiliary (`4`) buttons are pressed simultaneously, the value is `6` (i.e., `2 + 4`).\n\n> **Note:** Do not confuse this property with the [MouseEvent.button] property.\n> The [MouseEvent.buttons] property indicates the state of buttons pressed during any kind of mouse event,\n> while the [MouseEvent.button] property only guarantees the correct value for mouse events caused by pressing or releasing one or multiple buttons.",
      "clientx": "\n\nThe **`clientX`** read-only property of the [MouseEvent] interface provides the horizontal coordinate within the application's  at which the event occurred (as opposed to the coordinate within the page).\n\nFor example, clicking on the left edge of the viewport will always result in a mouse event with a `clientX` value of `0`, regardless of whether the page is scrolled horizontally.",
      "clienty": "\n\nThe **`clientY`** read-only property of the [MouseEvent] interface provides the vertical coordinate within the application's  at which the event occurred (as opposed to the coordinate within the page).\n\nFor example, clicking on the top edge of the viewport will always result in a mouse event with a `clientY` value of `0`, regardless of whether the page is scrolled vertically.",
      "ctrlkey": "\n\nThe **`MouseEvent.ctrlKey`** read-only property is a boolean value that indicates whether the <kbd>ctrl</kbd> key was pressed or not when a given mouse event occurs.\n\nOn Macintosh keyboards, this key is labeled the <kbd>control</kbd> key. Also, note that on a Mac, a click combined with the <kbd>control</kbd> key is intercepted by the operating system and used to open a context menu, so `ctrlKey` is not detectable on click events.",
      "getmodifierstate": "\n\nThe **`MouseEvent.getModifierState()`** method returns the current state of the specified modifier key: `true` if the modifier is active (i.e., the modifier key is pressed or locked), otherwise, `false`.\n\nSee [KeyboardEvent.getModifierState] for details.",
      "initmouseevent": "\n\nThe **`MouseEvent.initMouseEvent()`** method initializes the\nvalue of a mouse event once it's been created (normally using the [Document.createEvent] method).\n\n> **Warning:** Do not use this method anymore as it is deprecated.\n>\n> Instead use specific event constructors, like [MouseEvent.MouseEvent].\n> The page on [Creating and triggering events](/en-US/docs/Web/Events/Creating_and_triggering_events) gives more information about the way to use these.\n\nEvents initialized in this way must have been created with the [Document.createEvent] method.\nThis method must be called to set the event\nbefore it is dispatched, using [EventTarget.dispatchEvent].",
      "layerx": "\n\nThe **`MouseEvent.layerX`** read-only property returns the\nhorizontal coordinate of the event relative to the current layer.\n\nThis property takes scrolling of the page into account and returns a value relative to\nthe whole of the document unless the event occurs inside a positioned element, where the\nreturned value is relative to the top left of the positioned element.",
      "layery": "\n\nThe **`MouseEvent.layerY`** read-only property returns the\nvertical coordinate of the event relative to the current layer.\n\nThis property takes scrolling of the page into account, and returns a value relative to\nthe whole of the document, unless the event occurs inside a positioned element, where\nthe returned value is relative to the top left of the positioned element.",
      "metakey": "\n\nThe **`MouseEvent.metaKey`** read-only property is a boolean value that indicates whether the <kbd>meta</kbd> key was pressed or not when a given mouse event occurs.\n\nBe aware that many operating systems bind special functionality to the <kbd>meta</kbd> key, so this property may be `false` even when the key is actually pressed.\nOn Windows, for example, this key may open the Start menu.\n\n> **Note:** On Macintosh keyboards, this key is the <kbd>command</kbd> key (<kbd>⌘</kbd>).\n> On Windows keyboards, this key is the Windows key (<kbd>⊞</kbd>).",
      "movementx": "\n\nThe **`movementX`** read-only property of the [MouseEvent] interface provides the difference in the X coordinate of the mouse pointer between the given event and the previous [Element/mousemove_event] event.\nIn other words, the value of the property is computed like this: `currentEvent.movementX = currentEvent.screenX - previousEvent.screenX`.\n\n> **Warning:** Browsers [use different units for `movementX` and [MouseEvent.screenX]](https://github.com/w3c/pointerlock/issues/42) than what the specification defines. Depending on the browser and operating system, the `movementX` units may be a physical pixel, a logical pixel, or a CSS pixel.",
      "movementy": "\n\nThe **`movementY`** read-only property of the [MouseEvent] interface provides the difference in the Y coordinate of the mouse pointer between the given event and the previous [Element/mousemove_event] event.\nIn other words, the value of the property is computed like this: `currentEvent.movementY = currentEvent.screenY - previousEvent.screenY`.\n\n> **Warning:** Browsers [use different units for `movementY` and [MouseEvent.screenY]](https://github.com/w3c/pointerlock/issues/42) than what the specification defines. Depending on the browser and operating system, the `movementY` units may be a physical pixel, a logical pixel, or a CSS pixel.",
      "mozinputsource": " \n\nThe **`MouseEvent.mozInputSource`** read-only property on [MouseEvent] provides information indicating the type of device that generated the event.\nThis lets you, for example, determine whether a mouse event was generated by an actual mouse or by a touch event (which might affect the degree of accuracy with which you interpret the coordinates associated with the event).",
      "offsetx": "\n\nThe **`offsetX`** read-only property of the [MouseEvent] interface provides the offset in the X coordinate of the mouse pointer between that event and the padding edge of the target node.",
      "offsety": "\n\nThe **`offsetY`** read-only property of the [MouseEvent] interface provides the offset in the Y coordinate of the mouse pointer between that event and the padding edge of the target node.",
      "pagex": "\n\nThe **`pageX`** read-only property of the [MouseEvent] interface returns the X (horizontal) coordinate (in pixels) at which the mouse was clicked, relative to the left edge of the entire document.\nThis includes any portion of the document not currently visible.\n\nBeing based on the edge of the document as it is, this property takes into account any horizontal scrolling of the page.\nFor example, if the page is scrolled such that 200 pixels of the left side of the document are scrolled out of view, and the mouse is clicked 100 pixels inward from the left edge of the view, the value returned by `pageX` will be 300.\n\nOriginally, this property was defined as a `long` integer. The [CSSOM View Module](/en-US/docs/Web/CSS/CSSOM_view) redefined it as a\n`double` float. See the [Browser compatibility](#browser_compatibility) section for\ndetails.\n\nSee [Coordinate systems](/en-US/docs/Web/CSS/CSSOM_view/Coordinate_systems#page) for additional information about coordinates specified in this fashion.",
      "pagey": "\n\nThe **`pageY`** read-only property of the [MouseEvent] interface returns the Y (vertical) coordinate in pixels of the event relative to the whole document.\nThis property takes into account any vertical scrolling of the page.",
      "relatedtarget": "\n\nThe **`MouseEvent.relatedTarget`** read-only property is the secondary target for the mouse event, if there is one.\n\nThat is:\n\n<table class=\"no-markdown\">\n  <thead>\n    <tr>\n      <th>Event name</th>\n      <th><code>target</code></th>\n      <th><code>relatedTarget</code></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>[Element/mouseenter_event]</td>\n      <td>\n        The [EventTarget] the pointing device entered to\n      </td>\n      <td>\n        The [EventTarget] the pointing device exited from\n      </td>\n    </tr>\n    <tr>\n      <td>[Element/mouseleave_event]</td>\n      <td>\n        The [EventTarget] the pointing device exited from\n      </td>\n      <td>\n        The [EventTarget] the pointing device entered to\n      </td>\n    </tr>\n    <tr>\n      <td>[Element/mouseout_event]</td>\n      <td>\n        The [EventTarget] the pointing device exited from\n      </td>\n      <td>\n        The [EventTarget] the pointing device entered to\n      </td>\n    </tr>\n    <tr>\n      <td>[Element/mouseover_event]</td>\n      <td>\n        The [EventTarget] the pointing device entered to\n      </td>\n      <td>\n        The [EventTarget] the pointing device exited from\n      </td>\n    </tr>\n    <tr>\n      <td>[HTMLElement/dragenter_event]</td>\n      <td>\n        The [EventTarget] the pointing device entered to\n      </td>\n      <td>\n        The [EventTarget] the pointing device exited from\n      </td>\n    </tr>\n    <tr>\n      <td>[HTMLElement/dragleave_event]</td>\n      <td>\n        The [EventTarget] the pointing device exited from\n      </td>\n      <td>\n        The [EventTarget] the pointing device entered to\n      </td>\n    </tr>\n  </tbody>\n</table>\n\nFor events with no secondary target, `relatedTarget` returns\n`null`.\n\n[FocusEvent.relatedTarget] is a similar property for focus events.",
      "screenx": "\n\nThe **`screenX`** read-only property of the [MouseEvent] interface provides the horizontal coordinate (offset) of the mouse pointer in [screen coordinates](/en-US/docs/Web/CSS/CSSOM_view/Coordinate_systems#screen).\n\n> **Note:** In a multiscreen environment, screens aligned horizontally will be treated as a single device, and so the range of the `screenX` value will increase to the combined width of the screens.",
      "screeny": "\n\nThe **`screenY`** read-only property of the [MouseEvent] interface provides the vertical coordinate (offset) of the mouse pointer in [screen coordinates](/en-US/docs/Web/CSS/CSSOM_view/Coordinate_systems#screen).",
      "shiftkey": "\n\nThe **`MouseEvent.shiftKey`** read-only property is a boolean value that indicates whether the <kbd>shift</kbd> key was pressed or not when a given mouse event occurs.",
      "webkit_force_at_force_mouse_down_static": "\n\n**`MouseEvent.WEBKIT_FORCE_AT_FORCE_MOUSE_DOWN`** is a proprietary, WebKit-specific, static numeric property whose value is the minimum force necessary for a force click.\n\nBecause `WEBKIT_FORCE_AT_FORCE_MOUSE_DOWN` is a static property of `MouseEvent`, you always use it as `MouseEvent.WEBKIT_FORCE_AT_FORCE_MOUSE_DOWN`, rather than as a property of a `MouseEvent` instance.",
      "webkit_force_at_mouse_down_static": "\n\n**`MouseEvent.WEBKIT_FORCE_AT_MOUSE_DOWN`** is a proprietary, WebKit-specific, static numeric property whose value is the minimum force necessary for a normal click.\n\nBecause `WEBKIT_FORCE_AT_MOUSE_DOWN` is a static property of `MouseEvent`, you always use it as `MouseEvent.WEBKIT_FORCE_AT_MOUSE_DOWN`, rather than as a property of a `MouseEvent` instance.",
      "webkitforce": "\n\n**`MouseEvent.webkitForce`** is a proprietary, WebKit-specific numeric property whose value represents the amount of pressure that is being applied on the touchpad or touchscreen.",
      "x": "\n\nThe **`MouseEvent.x`** property is an alias for the [MouseEvent.clientX] property.",
      "y": "\n\nThe **`MouseEvent.y`** property is an alias for the [MouseEvent.clientY] property."
    }
  },
  "mousescrollevent": {
    "docs": "\n\nThe **`MouseScrollEvent`** interface represents events that occur due to the user moving a mouse wheel or similar input device.\n\n> **Warning:** Do not use this interface for wheel events.\n>\n> Like `MouseWheelEvent`, this interface is non-standard and deprecated. It was used in Gecko-based browsers only. Instead use the standard _[WheelEvent]._"
  },
  "mutationevent": {
    "docs": "\n\nThe **`MutationEvent`** interface provides event properties that are specific to modifications to the Document Object Model (DOM) hierarchy and nodes.\n\n> **Note:** Using _mutation events_ is problematic:\n>\n> - Their design is [flawed](https://lists.w3.org/Archives/Public/public-webapps/2011JulSep/0779.html).\n> - Adding DOM mutation listeners to a document [profoundly degrades the performance](https://groups.google.com/d/topic/mozilla.dev.platform/L0Lx11u5Bvs?pli=1) of further DOM modifications to that document (making them 1.5 - 7 times slower!). Moreover, removing the listeners does not reverse the damage.\n> - They have poor cross-browser compatibility: Safari doesn't support `DOMAttrModified` (see [WebKit bug 8191](https://webkit.org/b/8191)) and Firefox doesn't support _mutation name events_ (like `DOMElementNameChanged` and `DOMAttributeNameChanged`).\n>\n> They have been deprecated in favor of [mutation observers](/en-US/docs/Web/API/MutationObserver). **Consider using these instead.**\n\n",
    "properties": {
      "attrchange": "\n\nThe **`attrChange`** read-only property of the [MutationEvent] interface returns a number indicating what kind of change triggered the `DOMAttrModified` event. The three possible values are `MODIFICATION` (`1`), `ADDITION` (`2`) or `REMOVAL` (`3`). It has no meaning for other events and is then set to `0`.",
      "attrname": "\n\nThe **`attrName`** read-only property of the [MutationEvent] interface returns a string with the name of the node affected by the `DOMAttrModified` event. It has no meaning for other events and is then set to the empty string (`\"\"`).",
      "initmutationevent": "\n\nThe **`initMutationEvent()`** method of the [MutationEvent] interface initializes the\nvalue of a mutation event once it's been created (normally using the [Document.createEvent] method).\n\nThis method must be called to set the event before it is dispatched, using [EventTarget.dispatchEvent].\n\n> **Note:** In general, you won't create these events yourself; they are created by the browser.",
      "newvalue": "\n\nThe **`newValue`** read-only property of the [MutationEvent] interface returns a string. In `DOMAttrModified` events, it represents the new value of the [Attr] node. In `DOMCharacterDataModified` events, it contains the new value of the [CharacterData] node. In all other cases, returns the empty string (`\"\"`).",
      "prevvalue": "\n\nThe **`prevValue`** read-only property of the [MutationEvent] interface returns a string. In `DOMAttrModified` events, it represents the previous value of the [Attr] node. In `DOMCharacterDataModified` events, it contains the previous value of the [CharacterData] node. In all other cases, returns the empty string (`\"\"`).",
      "relatednode": "\n\nThe **`relatedNode`** read-only property of the [MutationEvent] interface returns a string indicating the node related to the event, like the changed node inside the subtree for `DOMSubtreeModified`."
    }
  },
  "mutationobserver": {
    "docs": "\n\nThe [MutationObserver] interface provides the ability to watch for changes being made to the [DOM](/en-US/docs/Web/API/Document_Object_Model) tree. It is designed as a replacement for the older [Mutation Events](/en-US/docs/Web/API/MutationEvent) feature, which was part of the DOM3 Events specification.",
    "properties": {
      "disconnect": "\n\nThe [MutationObserver] method\n**`disconnect()`** tells the observer to stop watching for\nmutations.\n\nThe observer can be reused by calling its\n[MutationObserver.observe] method again.",
      "observe": "\n\nThe [MutationObserver] method **`observe()`** configures the `MutationObserver`\ncallback to begin receiving notifications of changes to the DOM that match the given options.\n\nDepending on the configuration, the observer may watch a single [Node] in the DOM tree, or that node and some or all of its descendant nodes.\n\nTo stop the `MutationObserver` (so that none of its callbacks will be triggered any longer), call [MutationObserver.disconnect].",
      "takerecords": "\n\nThe [MutationObserver] method\n**`takeRecords()`** returns a list of all matching DOM changes\nthat have been detected but not yet processed by the observer's callback function,\nleaving the mutation queue empty.\n\nThe most common use case for this is to\nimmediately fetch all pending mutation records immediately prior to disconnecting the\nobserver, so that any pending mutations can be processed when shutting down the\nobserver."
    }
  },
  "mutationrecord": {
    "docs": "\n\nThe [MutationRecord] is a read-only interface that represents an individual DOM mutation observed by a [MutationObserver]. It is the object inside the array passed to the callback of a [MutationObserver].",
    "properties": {
      "addednodes": "\n\nThe [MutationRecord] read-only property **`addedNodes`** is a [NodeList] of nodes added to a target node by a mutation observed with a [MutationObserver].",
      "attributename": "\n\nThe [MutationRecord] read-only property **`attributeName`** contains the name of a changed attribute belonging to a node that is observed by a [MutationObserver].",
      "attributenamespace": "\n\nThe [MutationRecord] read-only property **`attributeNamespace`** is the namespace of the mutated attribute in the [MutationRecord] observed by a [MutationObserver].",
      "nextsibling": "\n\nThe [MutationRecord] read-only property **`nextSibling`** is the next sibling of an added or removed child node of the [`target`](/en-US/docs/Web/API/MutationRecord/target) of a [MutationObserver].",
      "oldvalue": "\n\nThe [MutationRecord] read-only property **`oldValue`** contains the character data or attribute value of an observed node before it was changed.",
      "previoussibling": "\n\nThe [MutationRecord] read-only property **`previousSibling`** is the previous sibling of an added or removed child node of the [`target`](/en-US/docs/Web/API/MutationRecord/target) of a [MutationObserver].",
      "removednodes": "\n\nThe [MutationRecord] read-only property **`removedNodes`** is a [NodeList] of nodes removed from a target node by a mutation observed with a [MutationObserver].",
      "target": "\n\nThe [MutationRecord] read-only property **`target`** is the target (i.e. the mutated/changed node) of a mutation observed with a [MutationObserver].",
      "type": "\n\nThe [MutationRecord] read-only property **`type`** is the type of the [MutationRecord] observed by a [MutationObserver]."
    }
  },
  "namednodemap": {
    "docs": "\n\nThe **`NamedNodeMap`** interface represents a collection of [Attr] objects. Objects inside a `NamedNodeMap` are not in any particular order, unlike [NodeList], although they may be accessed by an index as in an array.\n\nA `NamedNodeMap` object is _live_ and will thus be auto-updated if changes are made to its contents internally or elsewhere.\n\n> **Note:** Although called `NamedNodeMap`, this interface doesn't deal with [Node] objects but with [Attr] objects, which are a specialized class of [Node] objects.",
    "properties": {
      "getnameditem": "\n\nThe **`getNamedItem()`** method of the [NamedNodeMap] interface returns the [Attr] corresponding to the given name, or `null` if there is no corresponding attribute.\n\n> **Note:** This method is also called when you use the operator `[]` syntax.\n> So, `myMap[str]`is equivalent to `myMap.getNamedItem(str)` where `str` is a string.",
      "getnameditemns": "\n\nThe **`getNamedItemNS()`** method of the [NamedNodeMap] interface returns the [Attr] corresponding to the given local name in the given namespace, or `null` if there is no corresponding attribute.",
      "item": "\n\nThe **`item()`** method of the [NamedNodeMap] interface\nreturns the item in the map matching the index.\n\n> **Note:** This method is also called when you use the operator `[]` syntax.\n> So, `myMap[i]`is equivalent to `myMap.item(i)` where `i` is a number.",
      "length": "\n\nThe read-only **`length`** property of the [NamedNodeMap] interface\nis the number of objects stored in the map.",
      "removenameditem": "\n\nThe **`removeNamedItem()`** method of the [NamedNodeMap] interface\nremoves the [Attr] corresponding to the given name from the map.",
      "removenameditemns": "\n\nThe **`removedNamedItemNS()`** method of the [NamedNodeMap] interface\nremoves the [Attr] corresponding to the given namespace and local name from the map.",
      "setnameditem": "\n\nThe **`setNamedItem()`** method of the [NamedNodeMap] interface\nputs the [Attr] identified by its name in the map.\nIf there is already an [Attr] with the same name in the map,\nit is _replaced_.",
      "setnameditemns": "\n\nThe **`setNamedItemNS()`** method of the [NamedNodeMap] interface\nputs the [Attr] identified by its name in the map.\nIf there was already an [Attr] with the same name in the map,\nit is _replaced_.\n\n> **Note:** This method is an alias of `setNamedItem()` you can use them\n> interchangeably."
    }
  },
  "navigateevent": {
    "docs": "\n\nThe **`NavigateEvent`** interface of the [Navigation API] is the event object for the [Navigation/navigate_event] event, which fires when [any type of navigation](https://github.com/WICG/navigation-api#appendix-types-of-navigations) is initiated (this includes usage of [History API] features like [History.go]). `NavigateEvent` provides access to information about that navigation, and allows developers to intercept and control the navigation handling.\n\n",
    "properties": {
      "canintercept": "\n\nThe **`canIntercept`** read-only property of the\n[NavigateEvent] interface returns `true` if the navigation can be intercepted and have its URL rewritten, or `false` otherwise\n\nThere are several rules around when a navigation can be intercepted. For example:\n\n- You can't intercept cross-origin navigations.\n- You can intercept `http` or `https` URLs if only the `path`, `query`, and `fragment` portions of the new URL differ from the current URL.\n- You can intercept `file` URLs if only the `query` and `fragment` portions of the new URL differ.\n- For other URL types you can intercept the navigation if only the `fragment` portion differs.\n\nSee the spec for more explanation on [when a Document can have its URL rewritten](https://html.spec.whatwg.org/multipage/nav-history-apis.html#can-have-its-url-rewritten), including a table of examples.",
      "destination": "\n\nThe **`destination`** read-only property of the\n[NavigateEvent] interface returns a [NavigationDestination] object representing the destination being navigated to.",
      "downloadrequest": "\n\nThe **`downloadRequest`** read-only property of the\n[NavigateEvent] interface returns the filename of the file requested for download, in the case of a download navigation (e.g. an `a` or `area` element with a `download` attribute), or `null` otherwise.",
      "formdata": "\n\nThe **`formData`** read-only property of the\n[NavigateEvent] interface returns the [FormData] object representing the submitted data in the case of a [`POST`](/en-US/docs/Web/HTTP/Methods/POST) form submission, or `null` otherwise.",
      "hashchange": "\n\nThe **`hashChange`** read-only property of the\n[NavigateEvent] interface returns `true` if the navigation is a fragment navigation (i.e. to a fragment identifier in the same document), or `false` otherwise.",
      "info": "\n\nThe **`info`** read-only property of the\n[NavigateEvent] interface returns the `info` data value passed by the initiating navigation operation (e.g. [Navigation.back], or [Navigation.navigate]), or `undefined` if no `info` data was passed.",
      "intercept": "\n\nThe **`intercept()`** method of the\n[NavigateEvent] interface intercepts this navigation, turning it into a same-document navigation to the [NavigationDestination.url] URL.",
      "navigationtype": "\n\nThe **`navigationType`** read-only property of the\n[NavigateEvent] interface returns the type of the navigation — `push`, `reload`, `replace`, or `traverse`.",
      "scroll": "\n\nThe **`scroll()`** method of the\n[NavigateEvent] interface can be called to manually trigger the browser-driven scrolling behavior that occurs in response to the navigation, if you want it to happen before the navigation handling has completed.",
      "signal": "\n\nThe **`signal`** read-only property of the\n[NavigateEvent] interface returns an [AbortSignal], which will become aborted if the navigation is cancelled (e.g. by the user pressing the browser's \"Stop\" button, or another navigation starting and thus cancelling the ongoing one).",
      "userinitiated": "\n\nThe **`userInitiated`** read-only property of the\n[NavigateEvent] interface returns `true` if the navigation was initiated by the user (e.g. by clicking a link, submitting a form, or pressing the browser's \"Back\"/\"Forward\" buttons), or `false` otherwise.\n\n> **Note:** The table found at [Appendix: types of navigations](https://github.com/WICG/navigation-api#appendix-types-of-navigations) shows which navigation types are user-initiated."
    }
  },
  "navigation": {
    "docs": "\n\nThe **`Navigation`** interface of the [Navigation API] allows control over all navigation actions for the current `window` in one central place, including initiating navigations programmatically, examining navigation history entries, and managing navigations as they happen.\n\nIt is accessed via the [Window.navigation] property.\n\nThe Navigation API only exposes history entries created in the current browsing context that have the same origin as the current page (e.g. not navigations inside embedded `iframe`s, or cross-origin navigations), providing an accurate list of all previous history entries just for your app. This makes traversing the history a much less fragile proposition than with the older [History API].\n\n",
    "properties": {
      "back": "\n\nThe **`back()`** method of the\n[Navigation] interface navigates backwards by one entry in the navigation history.",
      "cangoback": "\n\nThe **`canGoBack`** read-only property of the\n[Navigation] interface returns `true`\nif it is possible to navigate backwards in the navigation history\n(i.e. the [Navigation.currentEntry] is\nnot the first one in the history entry list),\nand `false` if it is not.",
      "cangoforward": "\n\nThe **`canGoForward`** read-only property of the\n[Navigation] interface returns `true` if it is possible to navigate forwards in the navigation history\n(i.e. the [Navigation.currentEntry] is not the last one in the history entry list),\nand `false` if it is not.",
      "currententry": "\n\nThe **`currentEntry`** read-only property of the\n[Navigation] interface returns a [NavigationHistoryEntry] object representing the location the user is currently navigated to right now.",
      "currententrychange_event": "\n\nThe **`currententrychange`** event of the [Navigation] interface is fired when the [Navigation.currentEntry] has changed.\n\nThis event will fire for:\n\n- Same-document navigations (e.g. [Navigation.back] or [Navigation.traverseTo]).\n\n- Replacements (i.e. a [Navigation.navigate] call with `history` set to `replace`).\n\n- Other calls that change the entry's state (e.g. [Navigation.updateCurrentEntry], or the [History API]'s [History.replaceState]).\n\nThis event fires after the navigation is committed, meaning that the visible URL has changed and the [NavigationHistoryEntry] update has occurred. It is useful for migrating from usage of older API features like the [Window/hashchange_event] or [Window/popstate_event] events.",
      "entries": "\n\nThe **`entries()`** method of the\n[Navigation] interface returns an array of [NavigationHistoryEntry] objects representing all existing history entries.",
      "forward": "\n\nThe **`forward()`** method of the\n[Navigation] interface navigates forwards by one entry in the navigation history.",
      "navigate": "\n\nThe **`navigate()`** method of the\n[Navigation] interface navigates to a specific URL, updating any provided state in the history entries list.",
      "navigate_event": "\n\nThe **`navigate`** event of the [Navigation] interface is fired when [any type of navigation](https://github.com/WICG/navigation-api#appendix-types-of-navigations) is initiated, allowing you to intercept as required.",
      "navigateerror_event": "\n\nThe **`navigateerror`** event of the [Navigation] interface is fired when a navigation fails.\n\nFor example, if the network is down, any [fetch] method invoked to handle a navigation will fail, and the error will be routed to `navigateerror`.",
      "navigatesuccess_event": "\n\nThe **`navigatesuccess`** event of the [Navigation] interface is fired when a successful navigation has finished.\n\nIn the case of an intercepted navigation, this would occur after any promises returned by your [NavigateEvent.intercept] handler are fulfilled. The [NavigationTransition.finished] promise will also fulfill at the same time.",
      "reload": "\n\nThe **`reload()`** method of the\n[Navigation] interface reloads the current URL, updating any provided state in the history entries list.",
      "transition": "\n\nThe **`transition`** read-only property of the [Navigation] interface returns a [NavigationTransition] object representing the status of an in-progress navigation, which can be used to track it.",
      "traverseto": "\n\nThe **`traverseTo()`** method of the [Navigation] interface navigates to the [NavigationHistoryEntry] identified by the given [NavigationHistoryEntry.key].",
      "updatecurrententry": "\n\nThe **`updateCurrentEntry()`** method of the [Navigation] interface updates the `state` of the [Navigation.currentEntry]; used in cases where the state change will be independent of a navigation or reload."
    }
  },
  "navigationcurrententrychangeevent": {
    "docs": "\n\nThe **`NavigationCurrentEntryChangeEvent`** interface of the [Navigation API] is the event object for the [Navigation/currententrychange_event] event, which fires when the [Navigation.currentEntry] has changed.\n\nThis event will fire for same-document navigations (e.g. [Navigation.back] or [Navigation.traverseTo]), replacements (i.e. a [Navigation.navigate] call with `history` set to `replace`), or other calls that change the entry's state (e.g. [Navigation.updateCurrentEntry], or the [History API]'s [History.replaceState]).\n\nThis event fires after the navigation is committed, meaning that the visible URL has changed and the [NavigationHistoryEntry] update has occurred. It is useful for migrating from usage of older API features like the [Window/hashchange_event] or [Window/popstate_event] events.\n\n",
    "properties": {
      "from": "\n\nThe **`from`** read-only property of the [NavigationCurrentEntryChangeEvent] interface returns the [NavigationHistoryEntry] that was navigated from.",
      "navigationtype": "\n\nThe **`navigationType`** read-only property of the [NavigationCurrentEntryChangeEvent] interface returns the type of the navigation that resulted in the change. The property may be `null` if the change occurs due to [Navigation.updateCurrentEntry]."
    }
  },
  "navigationdestination": {
    "docs": "\n\nThe **`NavigationDestination`** interface of the [Navigation API] represents the destination being navigated to in the current navigation.\n\nIt is accessed via the [NavigateEvent.destination] property.\n\n",
    "properties": {
      "getstate": "\n\nThe **`getState()`** method of the\n[NavigationDestination] interface returns a clone of the developer-supplied state associated with the destination [NavigationHistoryEntry], or navigation operation (e.g. [Navigation.navigate]) as appropriate.",
      "id": "\n\nThe **`id`** read-only property of the\n[NavigationDestination] interface returns the [NavigationHistoryEntry.id] value of the destination [NavigationHistoryEntry] if the [NavigateEvent.navigationType] is `traverse`, or an empty string otherwise.\n\nThe `id` is a unique, UA-generated value that always represents the history entry, useful to correlate a history entry with an external resource such as a storage cache.",
      "index": "\n\nThe **`index`** read-only property of the\n[NavigationDestination] interface returns the [NavigationHistoryEntry.index] value of the destination [NavigationHistoryEntry] if the [NavigateEvent.navigationType] is `traverse`, or `-1` otherwise.",
      "key": "\n\nThe **`key`** read-only property of the\n[NavigationDestination] interface returns the [NavigationHistoryEntry.key] value of the destination [NavigationHistoryEntry] if the [NavigateEvent.navigationType] is `traverse`, or an empty string otherwise.\n\nThe `key` is a unique, UA-generated value that represents the history entry's slot in the history entries list, used to navigate to this place in the history via [Navigation.traverseTo]. It will be reused by other entries that replace the entry in the list (i.e. if the [NavigateEvent.navigationType] is `replace`).",
      "samedocument": "\n\nThe **`sameDocument`** read-only property of the\n[NavigationDestination] interface returns `true` if the navigation is to the same `document` as the current [Document] value, or `false` otherwise.\n\nThis is useful for checking whether the navigation will be same-document or cross-document.",
      "url": "\n\nThe **`url`** read-only property of the\n[NavigationDestination] interface returns the URL being navigated to."
    }
  },
  "navigationhistoryentry": {
    "docs": "\n\nThe **`NavigationHistoryEntry`** interface of the [Navigation API] represents a single navigation history entry.\n\nThese objects are commonly accessed via the [Navigation.currentEntry] property and [Navigation.entries] method.\n\nThe Navigation API only exposes history entries created in the current browsing context that have the same origin as the current page (e.g. not navigations inside embedded `iframe`s, or cross-origin navigations), providing an accurate list of all previous history entries just for your app. This makes traversing the history a much less fragile proposition than with the older [History API].\n\n",
    "properties": {
      "dispose_event": "\n\nThe **`dispose`** event of the [NavigationHistoryEntry] interface is fired when the entry is no longer part of the history entry list.\n\nDisposal occurs when:\n\n- Forward history entries are cleared. See the example at [Notifications on entry disposal](https://github.com/wicg/navigation-api#notifications-on-entry-disposal) for more information.\n- The user clears their browser history using settings or provided UI controls.\n- The history limit is exceeded. This is not specified anywhere, but browsers tend to have a history limit of 50 pages.",
      "getstate": "\n\nThe **`getState()`** method of the [NavigationHistoryEntry] interface returns a clone of the developer-supplied state associated with this history entry.",
      "id": "\n\nThe **`id`** read-only property of the [NavigationHistoryEntry] interface returns the `id` of the history entry, or an empty string if current document is not fully active. This is a unique, UA-generated value that always represents a specific history entry, useful to correlate it with an external resource such as a storage cache.\n\nThis differs from the [NavigationHistoryEntry.key] of a history entry. The `key` is a unique, UA-generated value that represents the history entry's slot in the entries list rather than the entry itself. It is used to navigate that particular slot via [Navigation.traverseTo]. The `key` will be reused by other entries that replace the entry in the list (that is, if the [NavigateEvent.navigationType] is `replace`).",
      "index": "\n\nThe **`index`** read-only property of the [NavigationHistoryEntry] interface returns the index of the history entry in the history entries list (that is, the list returned by [Navigation.entries]), or `-1` if the entry does not appear in the list or if current document is not fully active.",
      "key": "\n\nThe **`key`** read-only property of the [NavigationHistoryEntry] interface returns the `key` of the history entry, or an empty string if current document is not fully active. This is a unique, UA-generated value that represents the history entry's slot in the entries list. It is used to navigate that particular slot via [Navigation.traverseTo]. The `key` will be reused by other entries that replace the entry in the list (that is, if the [NavigateEvent.navigationType] is `replace`).\n\nThis differs from the [NavigationHistoryEntry.id] of a history entry. The `id` is a unique, UA-generated value that always represents a specific history entry rather than its slot in the entries list. This is useful to correlate it with an external resource such as a storage cache.",
      "samedocument": "\n\nThe **`sameDocument`** read-only property of the [NavigationHistoryEntry] interface returns `true` if this history entry is for the same `document` as the current [Document] value and current document is fully active, or `false` otherwise.",
      "url": "\n\nThe **`url`** read-only property of the [NavigationHistoryEntry] interface returns the absolute URL of this history entry. If the entry corresponds to a different Document than the current one (like `sameDocument` property is `false`), and that Document was fetched with a  header set to `no-referrer` or `origin`, the property returns `null`. If current document is not fully active, it returns an empty string."
    }
  },
  "navigationpreloadmanager": {
    "docs": "\n\nThe **`NavigationPreloadManager`** interface of the [Service Worker API](/en-US/docs/Web/API/Service_Worker_API) provides methods for managing the preloading of resources in parallel with service worker bootup.\n\nIf supported, an object of this type is returned by [ServiceWorkerRegistration.navigationPreload].\nThe result of a preload fetch request is waited on using the promise returned by [FetchEvent.preloadResponse].",
    "properties": {
      "disable": "\n\nThe **`disable()`** method of the [NavigationPreloadManager] interface halts the automatic preloading of service-worker-managed resources previously started using [NavigationPreloadManager.enable]\nIt returns a promise that resolves with `undefined`.\n\nThe method may be called in the service worker's `activate` event handler (before the `fetch` event handler can be called).",
      "enable": "\n\nThe **`enable()`** method of the [NavigationPreloadManager] interface is used to enable preloading of resources managed by the service worker.\nIt returns a promise that resolves with `undefined`.\n\nThe method should be called in the service worker's `activate` event handler, which ensures it is called before any `fetch` event handler can fire.",
      "getstate": "\n\nThe **`getState()`** method of the [NavigationPreloadManager] interface returns a `Promise` that resolves to an object with properties that indicate whether preload is enabled and what value will be sent in the  HTTP header.",
      "setheadervalue": "\n\nThe **`setHeaderValue()`** method of the [NavigationPreloadManager] interface sets the value of the  header that will be sent with requests resulting from a [fetch] operation made during service worker navigation preloading.\nIt returns an empty `Promise` that resolves with `undefined`.\n\nThe presence of the  header in preloading requests allows servers to configure the returned resource differently for preloading fetch requests than from normal fetch requests.\nThe default directive is set to `true`: this method allows the possibility of configuring multiple different responses to preload requests.\n\n> **Note:** If a different response may result from setting this header, the server must set `Vary: Service-Worker-Navigation-Preload` to ensure that the different responses are cached."
    }
  },
  "navigationtransition": {
    "docs": "\n\nThe **`NavigationTransition`** interface of the [Navigation API] represents an ongoing navigation, that is, a navigation that hasn't yet reached the [Navigation/navigatesuccess_event] or [Navigation/navigateerror_event] stage.\n\nIt is accessed via the [Navigation.transition] property.\n\n",
    "properties": {
      "finished": "\n\nThe **`finished`** read-only property of the\n[NavigationTransition] interface returns a `Promise` that fulfills at the same time the [Navigation/navigatesuccess_event] event fires, or rejects at the same time the [Navigation/navigateerror_event] event fires.",
      "from": "\n\nThe **`from`** read-only property of the\n[NavigationTransition] interface returns the [NavigationHistoryEntry] that the transition is coming from.",
      "navigationtype": "\n\nThe **`navigationType`** read-only property of the\n[NavigationTransition] interface returns the type of the ongoing navigation."
    }
  },
  "navigator": {
    "docs": "\n\nThe **`Navigator`** interface represents the state and the identity of the user agent. It allows scripts to query it and to register themselves to carry on some activities.\n\nA `Navigator` object can be retrieved using the read-only [window.navigator] property.",
    "properties": {
      "activevrdisplays": "\n\nThe **`activeVRDisplays`** read-only property of the\n[Navigator] interface returns an array containing every\n[VRDisplay] object that is currently presenting\n([VRDisplay.ispresenting] is `true`).\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
      "appcodename": " \n\nThe value of the **`Navigator.appCodeName`** property is\nalways \"`Mozilla`\", in any browser. This property is kept only for\ncompatibility purposes.\n\n> **Note:** Do not rely on this property to return a real\n> product name. All browsers return \"`Mozilla`\" as the value of this property.",
      "appname": " \n\nThe value of the **`Navigator.appName`** property is always\n\"`Netscape`\", in any browser. This property is kept only for compatibility\npurposes.\n\n> **Note:** Do not rely on this property to return a real browser name. All browsers return \"`Netscape`\" as the value of this property.",
      "appversion": " \n\nReturns either \"`4.0`\" or a string representing version information about\nthe browser.\n\n> **Note:** Do not rely on this property to return the correct browser version.",
      "bluetooth": "\n\nThe **`bluetooth`** read-only property of the [Navigator] interface returns a [Bluetooth] object for the current document, providing access to [Web Bluetooth API](/en-US/docs/Web/API/Web_Bluetooth_API) functionality.",
      "buildid": "\n\nReturns the build identifier of the browser. In modern browsers this property now returns a fixed timestamp as a privacy measure, e.g. `20181001000000` in Firefox 64 onwards.",
      "canshare": "\n\nThe **`Navigator.canShare()`** method of the [Web Share API](/en-US/docs/Web/API/Web_Share_API) returns `true` if the equivalent call to [navigator.share] would succeed.\n\nThe method returns `false` if the data cannot be _validated_. Reasons the data might be invalid include:\n\n- The `data` parameter has been omitted or only contains properties with unknown values. Note that any properties that are not recognized by the user agent are ignored.\n- A URL is badly formatted.\n- Files are specified but the implementation does not support file sharing.\n- Sharing the specified data would be considered a \"hostile share\" by the user-agent.\n\nThe Web Share API is gated by the [web-share](/en-US/docs/Web/HTTP/Headers/Permissions-Policy/web-share) permission policy.\nThe **`canShare()`** method will return `false` if the permission is supported but has not been granted.",
      "clearappbadge": "\n\nThe **`clearAppBadge()`** method of the [Navigator] interface clears a badge on the current app's icon by setting it to `nothing`. The value `nothing` indicates that no badge is currently set, and the status of the badge is _cleared_.",
      "clipboard": "\n\nThe [Clipboard API](/en-US/docs/Web/API/Clipboard_API) adds to the **[Navigator]** interface the\nread-only **`clipboard`** property, which returns the\n[Clipboard] object used to read and write the clipboard's\ncontents.\n\nThe Clipboard API can be used to implement cut, copy, and paste\nfeatures within a web application.\n\nUse of the asynchronous clipboard read and write methods requires that the user grant\nthe website or app permission to access the clipboard. This permission must be obtained\nfrom the [Permissions API](/en-US/docs/Web/API/Permissions_API) using the\n`\"clipboard-read\"` and/or `\"clipboard-write\"` permissions.",
      "connection": "\n\nThe **`Navigator.connection`** read-only property returns a [NetworkInformation] object containing information about the system's connection, such as the current bandwidth of the user's device or whether the connection is metered.\n\nThis could be used to select high definition content or low definition content based on the user's connection.",
      "contacts": "\n\nThe **`contacts`** read-only property of the\n[Navigator] interface returns a [ContactsManager] interface\nwhich allows users to select entries from their contact list and share limited details\nof the selected entries with a website or application.",
      "cookieenabled": "\n\n`navigator.cookieEnabled` returns a Boolean value that indicates whether cookies are enabled or not.\n\nThe property is read-only.",
      "credentials": "\n\nThe **`credentials`** property of the [Navigator]\ninterface returns the [CredentialsContainer] interface, which exposes\nmethods to request credentials. The [CredentialsContainer] interface also\nnotifies the user agent when an interesting event occurs, such as a successful sign-in\nor sign-out. This interface can be used for feature detection.",
      "devicememory": "\n\nThe **`deviceMemory`** read-only\nproperty of the [Navigator] interface returns the approximate amount of\ndevice memory in gigabytes.\n\nThe reported value is imprecise to curtail . It's approximated by\nrounding down to the nearest power of 2, then dividing that number by 1024. It is then\nclamped within lower and upper bounds to protect the privacy of owners of very low-memory or\nhigh-memory devices.",
      "donottrack": "\n\nThe **`Navigator.doNotTrack`** property returns the user's Do Not Track setting, which indicates whether the user is requesting websites and advertisers to not track them.\n\nThe value of the property reflects that of the `DNT` HTTP header, i.e. values of `\"1\"`, `\"0\"`, or `null`.",
      "geolocation": "\n\nThe **`Navigator.geolocation`** read-only property returns a\n[Geolocation] object that gives Web content access to the location of the\ndevice. This allows a website or app to offer customized results based on the user's\nlocation.\n\n> **Note:** For security reasons, when a web page tries to access location\n> information, the user is notified and asked to grant permission. Be aware that each\n> browser has its own policies and methods for requesting this permission.",
      "getautoplaypolicy": "\n\nThe **`getAutoplayPolicy()`** method of the _Autoplay Policy Detection API_ provides information about whether [autoplay](/en-US/docs/Web/Media/Autoplay_guide) of media elements and audio contexts is allowed, disallowed, or only allowed if the audio is muted.\n\nApplications can use this information to provide an appropriate user experience.\nFor example, if the user agent policy only allows autoplay of inaudible content, the application might mute videos so that they can still autoplay.\n\nThe method can be used to get either the broad autoplay policy for all items of a particular type in the document, or for specific media elements or audio contexts.",
      "getbattery": "\n\nThe **`getBattery()`** method provides information about the system's battery.\nIt returns a battery promise, which resolves with a [BatteryManager] object providing some properties to get the battery status also some events you can handle to monitor the battery status.\nThis implements the [Battery Status API]; see that documentation for additional details, a guide to using the API, and sample code.\n\nSince Chrome 103, the `Navigator.getBattery()` method of [Battery Status API] only expose to secure context.\n\n> **Note:** Access to this feature may be controlled by the  directive .",
      "getgamepads": "\n\nThe **`Navigator.getGamepads()`** method returns an array of\n[Gamepad] objects, one for each gamepad connected to the device.\n\nElements in the array may be `null` if a gamepad disconnects during a\nsession, so that the remaining gamepads retain the same index.",
      "getinstalledrelatedapps": "\n\nThe **`getInstalledRelatedApps()`** method returns a promise that resolves with an array of objects representing any related platform-specific apps or [Progressive Web Apps](/en-US/docs/Web/Progressive_web_apps) that the user has installed. This could be used for content personalization such as removing \"install our app\" banners from the web app if the platform-specific app and/or PWA is already installed.\n\n> **Note:** This method must be invoked in a top-level [secure context](/en-US/docs/Web/Security/Secure_Contexts), that is, not embedded in an `iframe`.",
      "getusermedia": "\n\nThe deprecated **`Navigator.getUserMedia()`** method prompts the user for permission to use up to one video input device (such as a camera or shared screen) and up to one audio input device (such as a microphone) as the source for a [MediaStream].\n\nIf permission is granted, a `MediaStream` whose video and/or audio tracks come from those devices is delivered to the specified success callback.\nIf permission is denied, no compatible input devices exist, or any other error condition occurs, the error callback is executed with an object describing what went wrong.\nIf the user instead doesn't make a choice at all, neither callback is executed.\n\n> **Note:** This is a legacy method.\n> Please use the newer [MediaDevices.getUserMedia] instead.\n> While technically not deprecated, this old callback version is marked as such, since the specification strongly encourages using the newer promise returning version.",
      "getvrdisplays": "\n\nThe **`getVRDisplays()`** method of the [Navigator] interface returns a promise that resolves to an array of [VRDisplay] objects representing any available VR displays connected to the computer.",
      "globalprivacycontrol": "\n\nThe **`Navigator.globalPrivacyControl`** read-only property returns the user's [Global Privacy Control](https://globalprivacycontrol.org/) setting for the current website.\nThis setting indicates whether the user consents to the website or service selling or sharing their personal information with third parties.\n\nThe value of the property reflects that of the  HTTP header.",
      "gpu": "\n\nThe **`Navigator.gpu`** read-only property returns the [GPU] object for the current browsing context, which is the entry point for the [WebGPU_API].",
      "hardwareconcurrency": "\n\nThe **`navigator.hardwareConcurrency`** read-only property\nreturns the number of logical processors available to run threads on the user's\ncomputer.",
      "hid": "\n\nThe **`Navigator.hid`**\nread-only property returns an [HID] object providing methods\nfor connecting to HID devices, listing attached HID devices, and event\nhandlers for connected HID devices.\n\nWhere a defined [Permissions Policy](/en-US/docs/Web/HTTP/Permissions_Policy) blocks WebHID usage, the `Navigator.hid` property will not be available.",
      "ink": "\n\nThe **`ink`** read-only property of the [Navigator] interface returns an [Ink] object for the current document, providing access to [Ink API](/en-US/docs/Web/API/Ink_API) functionality.",
      "javaenabled": "\n\nThis method always returns false.",
      "keyboard": "\n\nThe **`keyboard`** read-only property\nof the [Navigator] interface returns a [Keyboard] object\nwhich provides access to functions that retrieve keyboard layout maps and toggle\ncapturing of key presses from the physical keyboard.",
      "language": "\n\nThe **`Navigator.language`** read-only property returns a string representing the preferred language of the user, usually the language of the browser UI.",
      "languages": "\n\nThe **`Navigator.languages`** read-only property\nreturns an array of strings representing the user's preferred\nlanguages. The language is described using language tags according to\n`5646, \"Tags for Identifying Languages (also known as BCP 47)\"`. In the returned\narray they are ordered by preference with the most preferred language first.\n\nThe value of [Navigator.language] is the\nfirst element of the returned array.\n\nWhen its value changes, as the user's preferred languages are changed a\n[Window.languagechange_event] event is fired on the [Window] object.\n\nThe `Accept-Language` HTTP header in every HTTP request from the user's\nbrowser uses the same value for the `navigator.languages` property except for\nthe extra `qvalues` (quality values) field (e.g. `en-US;q=0.8`).",
      "locks": "\n\nThe **`locks`** read-only property of\nthe [Navigator] interface returns a [LockManager] object\nwhich provides methods for requesting a new [Lock] object and querying\nfor an existing `Lock` object.",
      "maxtouchpoints": "\n\nThe **`maxTouchPoints`** read-only property of the\n[Navigator] interface returns the maximum number of simultaneous touch\ncontact points are supported by the current device.",
      "mediacapabilities": "\n\nThe **`Navigator.mediaCapabilities`** read-only property\nreturns a [MediaCapabilities] object that can expose information about the\ndecoding and encoding capabilities for a given format and output capabilities as defined\nby the [Media Capabilities API](/en-US/docs/Web/API/Media_Capabilities_API).",
      "mediadevices": "\n\nThe **`Navigator.mediaDevices`** read-only property returns a\n[MediaDevices] object, which provides access to connected media input\ndevices like cameras and microphones, as well as screen sharing.",
      "mediasession": "\n\nThe read-only **`mediaSession`** property of the [Navigator]\ninterface returns a [MediaSession]\nobject that can be used to share with the browser metadata and other information about\nthe current playback state of media being handled by a document.\n\nThis\ninformation may, in turn, be shared with the device and/or operating system in order to\na device's standard media control user experience to describe and control the playback\nof the media.\n\nIn addition, the `MediaSession` interface provides the\n[MediaSession.setActionHandler] method, which lets\nyou receive events when the user engages device controls such as either onscreen or\nphysical play, pause, seek, and other similar controls. An internet radio app, for\nexample, can use `setActionHandler()` to let the media controls on a keyboard\nor elsewhere on the user's device be used to control the app's media playback.",
      "mimetypes": "\n\nReturns a [MimeTypeArray] object, which contains a list of [MimeType] objects representing the MIME types recognized and supported by the browser.\nThe array can be queried for information about the enabled plugin that is used to handle a file of the specified type.\nNamed properties of the returned object are not enumerable (except in very old browser versions).\n\nRecent versions of the specification hard-code the returned set of MIME types.\nIf PDF files can be displayed inline then `application/pdf` and `text/pdf` are listed.\nOtherwise an empty list is returned.\n\n> **Note:** Use [Navigator.pdfViewerEnabled] to determine if inline viewing of PDF files is supported. Do not infer it from this property.\n\nLegacy browser versions do not hard-code the list returned by the property, and might return other MIME types.",
      "online": "\n\nReturns the online status of the browser. The property returns a boolean value, with\n`true` meaning online and `false` meaning offline. The property\nsends updates whenever the browser's ability to connect to the network changes. The\nupdate occurs when the user follows links or when a script requests a remote page. For\nexample, the property should return `false` when users click links soon after\nthey lose internet connection.\n\nBrowsers implement this property differently.\n\nIn Chrome and Safari, if the browser is not able to connect to a local area network\n(LAN) or a router, it is offline; all other conditions return `true`. So\nwhile you can assume that the browser is offline when it returns a `false`\nvalue, you cannot assume that a true value necessarily means that the browser can access\nthe internet. You could be getting false positives, such as in cases where the computer\nis running a virtualization software that has virtual ethernet adapters that are always\n\"connected.\" Therefore, if you really want to determine the online status of the\nbrowser, you should develop additional means for checking.\n\nIn Firefox, switching the browser to offline mode sends a `false` value. Until Firefox\n41, all other conditions returned a `true` value; testing actual behavior on Nightly 68 on\nWindows shows that it only looks for LAN connection like Chrome and Safari giving false\npositives.\n\nYou can see changes in the network state by listening to the [`online`](/en-US/docs/Web/API/Window/online_event) and [`offline`](/en-US/docs/Web/API/Window/offline_event) events.",
      "oscpu": " \n\nThe **`Navigator.oscpu`** property returns a string that identifies the current operating system.",
      "pdfviewerenabled": "\n\nThe **`pdfViewerEnabled`** read-only property of the [Navigator] interface indicates whether the browser supports inline display of PDF files when navigating to them.\n\nIf inline viewing is not supported the PDF is downloaded and may then be handled by some external application.\n\n> **Note:** This method replaces a number of legacy methods of inferring support for inline viewing of PDF files.",
      "permissions": "\n\nThe **`Navigator.permissions`** read-only property returns a\n[Permissions] object that can be used to query and update permission\nstatus of APIs covered by the [Permissions API](/en-US/docs/Web/API/Permissions_API).",
      "platform": "\n\nThe **`platform`** property read-only property of the [Navigator] interface returns a string identifying the platform on which the user's browser is running.\n\n> **Note:** In general, you should whenever possible avoid writing code that uses methods or properties like this one to try to find out information about the user's environment, and instead write code that does [feature detection](/en-US/docs/Learn/Tools_and_testing/Cross_browser_testing/Feature_detection).",
      "plugins": "\n\nReturns a [PluginArray] object, listing the [Plugin] objects describing the plugins installed in the application.\nNamed properties of the returned object are not enumerable (except in very old browser versions).\n\nRecent versions of the specification hard-code the returned list.\nIf inline viewing of PDF files is supported the property lists five standard plugins.\nIf inline PDF viewing is not supported then an empty list is returned.\n\n> **Note:** Use [Navigator.pdfViewerEnabled] to determine if inline viewing of PDF files is supported. Do not infer it from this property.\n>\n> The \"five standard plugins\" are those that developers have most commonly used to feature detect inline PDF viewing.\n> Returning these ensures that legacy code can more reliably determine whether inline viewing is supported.\n> However this approach is not recommended for new code because this property may eventually be removed.\n\nLegacy browser versions also list plugins for Adobe Flash and PDF viewer extensions.",
      "presentation": "\n\nThe `presentation` read-only property of [Navigator] serves as the entry\npoint for the [Presentation API](/en-US/docs/Web/API/Presentation_API) and\nreturns a reference to [Presentation] object.",
      "product": " \n\nThe value of the **`Navigator.product`** property is always\n\"`Gecko`\", in any browser. This property is kept only for compatibility\npurposes.\n\n> **Note:** Do not rely on this property to return a real product name. All browsers return \"`Gecko`\" as the value of this property.",
      "productsub": " \n\nThe **`Navigator.productSub`** read-only property returns the\nbuild number of the current browser.",
      "registerprotocolhandler": "\n\nThe **[Navigator]** method **`registerProtocolHandler()`** lets websites register their ability to open or handle particular URL schemes (aka protocols).\n\nFor example, this API lets webmail sites open `mailto:` URLs, or VoIP sites open `tel:` URLs.",
      "requestmediakeysystemaccess": "`Encrypted Media Extensions`\n\nThe **`Navigator.requestMediaKeySystemAccess()`** method\nreturns a `Promise` which delivers a [MediaKeySystemAccess]\nobject that can be used to access a particular media key system, which can in turn be\nused to create keys for decrypting a media stream. This method is part of the [Encrypted Media Extensions API](/en-US/docs/Web/API/Encrypted_Media_Extensions_API), which brings support for encrypted media and DRM-protected video to the web.\n\nThis method may have user-visible effects such as asking for permission to access one\nor more system resources. Consider that when deciding when to call\n`requestMediaKeySystemAccess()`; you don't want those requests\nto happen at inconvenient times. As a general rule, this function should be called only\nwhen it's about time to create and use a [MediaKeys] object by calling the\nreturned [MediaKeySystemAccess] object's\n[MediaKeySystemAccess.createMediaKeys] method.",
      "requestmidiaccess": "`Web MIDI API`\n\nThe **`requestMIDIAccess()`** method of the [Navigator] interface returns a `Promise` representing a request for access to MIDI devices on a user's system.\nThis method is part of the [Web MIDI API](/en-US/docs/Web/API/Web_MIDI_API), which provides a means for accessing, enumerating, and manipulating MIDI devices.\n\nThis method may prompt the user for access to MIDI devices available to their system, or it may use a previously established preference to grant or deny access.\nIf permission is granted then the `Promise` resolves and a [`MIDIAccess`](/en-US/docs/Web/API/MIDIAccess) object is returned.",
      "scheduling": "\n\nThe **`scheduling`** read-only property of the [Navigator] interface returns a [Scheduling] object for the current document, which provides methods and properties to control scheduling tasks.",
      "sendbeacon": "\n\nThe **`navigator.sendBeacon()`**\nmethod  sends an [HTTP POST](/en-US/docs/Web/HTTP/Methods/POST) request containing a small amount of data to a web server.\n\nIt's intended to be used for\nsending analytics data to a web server, and avoids some of the problems with\nlegacy techniques for sending analytics, such as the use of\n[XMLHttpRequest].\n\n> **Note:** For use cases that need the ability to send requests with methods other than `POST`, or to change any request properties, or that need access to the server response, instead use the [`fetch()`](/en-US/docs/Web/API/fetch) method with [`keepalive`](/en-US/docs/Web/API/fetch#keepalive) set to true.",
      "serial": "\n\nThe **`serial`** read-only property of the [Navigator] interface returns a [Serial] object which represents the entry point into the [Web Serial API].\n\nWhen getting, the same instance of the [Serial] object will always be returned.",
      "serviceworker": "\n\nThe **`serviceWorker`** read-only property of the [Navigator] interface returns the [ServiceWorkerContainer] object for the [associated document](https://html.spec.whatwg.org/multipage/browsers.html#concept-document-window), which provides access to registration, removal, upgrade, and communication with the [ServiceWorker].\n\nThe feature may not be available in private mode.",
      "setappbadge": "\n\nThe **`setAppBadge()`** method of the [Navigator] interface sets a badge on the icon associated with this app. If a value is passed to the method, this will be set as the value of the badge. Otherwise the badge will display as a dot, or other indicator as defined by the platform.",
      "share": "\n\nThe **`navigator.share()`** method of the [Web Share API](/en-US/docs/Web/API/Web_Share_API) invokes the native sharing mechanism of the device to share data such as text, URLs, or files. The available _share targets_ depend on the device, but might include the clipboard, contacts and email applications, websites, Bluetooth, etc.\n\nThe method resolves a `Promise` with `undefined`.\nOn Windows this happens when the share popup is launched, while on Android the promise resolves once the data has successfully been passed to the _share target_.",
      "storage": "\n\nThe **`Navigator.storage`**\nread-only property returns the singleton [StorageManager] object used to\naccess the overall storage capabilities of the browser for the current site or app.\nThe returned object lets you examine and configure persistence of data stores and\nlearn approximately how much more space your browser has available for local storage\nuse.",
      "taintenabled": " \n\nThe **`Navigator.taintEnabled()`** method always returns\n`false`.\n\nTainting was a security method used by JavaScript 1.2. It has long been removed; this\nmethod only stays for maintaining compatibility with very old scripts.",
      "unregisterprotocolhandler": "\n\nThe **[Navigator]** method **`unregisterProtocolHandler()`** removes a protocol handler for a given URL [scheme](#permitted_schemes).\n\nThis method is the inverse of **`registerProtocolHandler()`**.",
      "usb": "\n\nThe **`usb`** read-only property of the [Navigator] interface returns a [USB] object for the current document, providing access to [WebUSB API](/en-US/docs/Web/API/WebUSB_API) functionality.",
      "useractivation": "\n\nThe read-only **`userActivation`** property of the [Navigator] interface returns a [UserActivation] object which contains information about the current window's user activation state.",
      "useragent": "\n\nThe **`Navigator.userAgent`** read-only property returns the\nuser agent string for the current browser.\n\n> **Note:** The specification asks browsers to provide as little information via this field as\n> possible. Never assume that the value of this property will stay the same in future\n> versions of the same browser. Try not to use it at all, or only for current and past\n> versions of a browser. New browsers may start using the same UA, or part of it, as an\n> older browser: you really have no guarantee that the browser agent is indeed the one\n> advertised by this property.\n>\n> Also keep in mind that users of a browser can change the value of this field if they\n> want (UA spoofing).\n\nBrowser identification based on detecting the user agent string is\n**unreliable** and **is not recommended**, as the user agent\nstring is user configurable. For example:\n\n- In Firefox, you can change the preference `general.useragent.override` in\n  `about:config`. Some Firefox extensions do that; however, this only changes\n  the HTTP header that gets sent and that is returned by `navigator.userAgent`.\n  There might be other methods that utilize JavaScript code to identify the browser.\n- Opera 6+ allows users to set the browser identification string via a menu.",
      "useragentdata": "\n\nThe **`userAgentData`** read-only property of the [Navigator] interface returns a [NavigatorUAData] object\nwhich can be used to access the .",
      "vendor": "\n\nThe value of the [Navigator] **`vendor`** property is always either \"`Google Inc.`\", \"`Apple Computer, Inc.`\", or (in Firefox) the empty string.",
      "vendorsub": " \n\nThe value of the **`Navigator.vendorSub`** property is always\nthe empty string, in any browser.",
      "vibrate": "\n\nThe **`Navigator.vibrate()`** method pulses the vibration\nhardware on the device, if such hardware exists. If the device doesn't support\nvibration, this method has no effect. If a vibration pattern is already in progress when\nthis method is called, the previous pattern is halted and the new one begins instead.\n\nIf the method was unable to vibrate because of invalid parameters, it will return\n`false`, else it returns `true`. If the pattern leads to a too\nlong vibration, it is truncated: the max length depends on the implementation.",
      "virtualkeyboard": "\n\nThe **`virtualKeyboard`** read-only property\nof the [navigator] interface returns a reference to the [VirtualKeyboard] instance object.\n\nThe [VirtualKeyboard_API] gives developers control over the layout of their applications when the on-screen virtual keyboard appears and disappears on devices such as tablets, mobile phones, or other devices where a hardware keyboard may not be available.",
      "wakelock": "\n\nThe **`wakeLock`** read-only property of the [Navigator] interface\nreturns a [WakeLock] interface which allows a document to acquire a\nscreen wake lock. While a screen wake lock is active, the user agent will try to\nprevent the device from dimming the screen, turning it off completely, or showing a\nscreensaver.",
      "webdriver": "\n\nThe **`webdriver`** read-only property\nof the [navigator] interface indicates whether the user agent is\ncontrolled by automation.\n\nIt defines a standard way for co-operating user agents to inform the document that it\nis controlled by [WebDriver](/en-US/docs/Web/WebDriver), for example, so that\nalternate code paths can be triggered during automation.\n\nThe `navigator.webdriver` property is true when in:\n\n- Chrome\n  - : The `--enable-automation` or the `--headless` flag or the\n    `--remote-debugging-port` is used.\n- Firefox\n  - : The `marionette.enabled` preference or `--marionette` flag is\n    passed.",
      "windowcontrolsoverlay": "\n\nThe **`windowControlsOverlay`** read-only property of the [Navigator]\ninterface returns the [WindowControlsOverlay] interface, which exposes\ninformation about the title bar geometry in desktop Progressive Web Apps that use the [Window Controls Overlay API](/en-US/docs/Web/API/Window_Controls_Overlay_API).\n\nProgressive Web Apps installed on desktop Operating Systems can opt-in to the\nWindow Controls Overlay feature by using the `window-controls-overlay` value in the\n[`display_override`](/en-US/docs/Web/Manifest/display_override) web app manifest member.\n\nDoing so hides the default window title bar and gives the app access to the full area\nof the app window.",
      "xr": "\n\nThe read-only **`xr`** property\nprovided by the [Navigator] interface returns an [XRSystem] object\nwhich can be used to access the [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API)."
    }
  },
  "navigatoruadata": {
    "docs": "\n\nThe **`NavigatorUAData`** interface of the  returns information about the browser and operating system of a user.\n\nAn instance of this object is returned by calling [Navigator.userAgentData]. Therefore, this interface has no constructor.\n\n> **Note:** The terms _high entropy_ and _low entropy_ refer to the amount of information these values reveal about the browser. The values returned as properties are deemed low entropy, and unlikely to identify a user. The values returned by [NavigatorUAData.getHighEntropyValues] could potentially reveal more information. These values are therefore retrieved via a `Promise`, allowing time for the browser to request user permission, or make other checks.",
    "properties": {
      "brands": "\n\nThe **`brands`** read-only property of the [NavigatorUAData] interface returns an array of brand information.",
      "gethighentropyvalues": "\n\nThe **`getHighEntropyValues()`** method of the [NavigatorUAData] interface is a `Promise` that resolves with a dictionary object containing the _high entropy_ values the user-agent returns.\n\n> **Note:** The terms _high entropy_ and _low entropy_ refer to the amount of information these values reveal about the browser.\n> The values returned as properties are deemed low entropy, and unlikely to identify a user.\n> The values returned by [NavigatorUAData.getHighEntropyValues] could potentially reveal more information.\n> These values are therefore retrieved via a `Promise`, allowing time for the browser to request user permission, or make other checks.",
      "mobile": "\n\nThe **`mobile`** read-only property of the [NavigatorUAData] interface returns a value indicating whether the device is a mobile device.",
      "platform": "\n\nThe **`platform`** read-only property of the [NavigatorUAData] interface returns the platform brand information.",
      "tojson": "\n\nThe **`toJSON()`** method of the [NavigatorUAData] interface is a _serializer_ that returns a JSON representation of the _low entropy_ properties of the `NavigatorUAData` object.\n\n> **Note:** The terms _high entropy_ and _low entropy_ refer to the amount of information these values reveal about the browser. The low entropy values returned by this method are those which do not reveal information able to identify a user. High entropy values can only be returned by the [NavigatorUAData.getHighEntropyValues] method."
    }
  },
  "ndefmessage": {
    "docs": "\n\nThe **`NDEFMessage`** interface of the [Web NFC API](/en-US/docs/Web/API/Web_NFC_API) represents the content of an NDEF message that has been read from or could be written to an NFC tag. An instance is acquired by calling the `NDEFMessage()` constructor or from the [NDEFReadingEvent.message] property, which is passed to the [NDEFReader.reading_event] event.",
    "properties": {
      "records": "\n\nThe `records` property of\n[NDEFMessage] interface represents a list of [NDEFRecord]s\npresent in the NDEF message."
    }
  },
  "ndefreader": {
    "docs": "\n\nThe **`NDEFReader`** interface of the [Web NFC API](/en-US/docs/Web/API/Web_NFC_API) is used to read from and write data to compatible NFC devices, e.g. NFC tags supporting NDEF, when these devices are within the reader's magnetic induction field.\n\n",
    "properties": {
      "reading_event": "\n\nThe `reading` event of the [NDEFReader] interface is fired whenever a new reading is available from compatible NFC devices (e.g. NFC tags supporting NDEF) when these devices are within the reader's magnetic induction field.",
      "readingerror_event": "\n\nThe `readingerror` event of the [NDEFReader] interface is fired whenever an error occurs during reading of NFC tags, e.g. when tags leave the reader's magnetic induction field.",
      "scan": "\n\nThe `scan()` method of the [NDEFReader] interface activates a reading device and returns a `Promise` that either resolves when an NFC tag read operation is scheduled or rejects if a hardware or permission error is encountered. This method triggers a permission prompt if the \"nfc\" permission has not been previously granted.",
      "write": "\n\nThe `write()` method of the [NDEFReader] interface attempts to write an NDEF message to a tag and returns a `Promise` that either resolves when a message has been written to the tag or rejects if a hardware or permission error is encountered. This method triggers a permission prompt if the \"nfc\" permission has not been previously granted."
    }
  },
  "ndefreadingevent": {
    "docs": "\n\nThe **`NDEFReadingEvent`** interface of the [Web NFC API](/en-US/docs/Web/API/Web_NFC_API) represents events dispatched on new NFC readings obtained by [NDEFReader].\n\n",
    "properties": {
      "message": "\n\nThe **`message`** property of the [NDEFReadingEvent] interface returns an [NDEFMessage] object containing the received message.",
      "serialnumber": "\n\nThe **`serialNumber`** property of the [NDEFReadingEvent] interface returns the serial number of the device, which is used for anti-collision and identification, or an empty string if no serial number is available."
    }
  },
  "ndefrecord": {
    "docs": "\n\nThe **`NDEFRecord`** interface of the [Web NFC API](/en-US/docs/Web/API/Web_NFC_API) provides data that can be read from, or written to, compatible NFC devices, e.g. NFC tags supporting NDEF.",
    "properties": {
      "data": "\n\nThe **`data`**\nproperty of the [NDEFRecord] interface returns a\n`DataView` containing the raw bytes of the record's payload.",
      "encoding": "\n\nThe **`encoding`**\nproperty of the [NDEFRecord] interface returns the encoding of\na textual payload, or `null` otherwise.",
      "id": "\n\nThe **`id`** property of the\n[NDEFRecord] interface returns the record identifier, which is an\nabsolute or relative URL used to identify the record.\n\nThis identifier is created by the generator of the record which is solely responsible\nfor enforcing record identifier uniqueness. Web NFC does not sign the NFC content, thus\nrecord consumer should not make any assumptions about integrity or authenticity of the\nidentifier or any other part of the records.",
      "lang": "\n\nThe **`lang`**\nproperty of the [NDEFRecord] interface returns the language of\na textual payload, or `null` if one was not supplied.\n\nThe record might be missing a language tag, for example, if the recorded information is\nnot locale-specific.",
      "mediatype": "\n\nThe **`mediaType`**\nproperty of the [NDEFRecord] interface returns the  of the record. This value will be `null` if `recordType` is not equal to `\"mime\"`.",
      "recordtype": "\n\nThe **`recordType`**\nproperty of the [NDEFRecord] interface returns the record type of the record.",
      "torecords": "\n\nThe **`toRecords()`**\nmethod of the [NDEFRecord] interface converts\n[NDEFRecord.data] to a sequence of records based on\n[NDEFRecord.recordType], and returns the result. This allows\nparsing the payloads of record types which may contain nested records, such\nas smart poster and external type records."
    }
  },
  "networkinformation": {
    "docs": "\n\nThe **`NetworkInformation`** interface of the [Network Information API](/en-US/docs/Web/API/Network_Information_API) provides information about the connection a device is using to communicate with the network and provides a means for scripts to be notified if the connection type changes.\nThe `NetworkInformation` interface cannot be instantiated. It is instead accessed through the `connection` property of the [Navigator] interface.\n\n",
    "properties": {
      "change_event": "\n\nThe **`change`** event fires when connection information changes, and the event\nis received by the [NetworkInformation] object.",
      "downlink": "\n\nThe **`downlink`** read-only property of the\n[NetworkInformation] interface returns the effective bandwidth estimate in\nmegabits per second, rounded to the nearest multiple of 25 kilobits per seconds. This\nvalue is based on recently observed application layer throughput across recently active\nconnections, excluding connections made to a private address space. In the absence of\nrecent bandwidth measurement data, the attribute value is determined by the properties\nof the underlying connection technology.",
      "downlinkmax": "\n\nThe **`NetworkInformation.downlinkMax`** read-only property\nreturns the maximum downlink speed, in megabits per second (Mbps), for the underlying\nconnection technology.\n\n",
      "effectivetype": "\n\nThe **`effectiveType`** read-only property of the\n[NetworkInformation] interface returns the effective type of the connection\nmeaning one of `slow-2g`, `2g`, `3g`, or `4g`. This value is determined using a\ncombination of recently observed, round-trip time and downlink values.",
      "rtt": "\n\nThe **`NetworkInformation.rtt`** read-only property returns the\nestimated effective round-trip time of the current connection, rounded to the nearest\nmultiple of 25 milliseconds. This value is based on recently observed application-layer\nRTT measurements across recently active connections. It excludes connections made to a\nprivate address space. If no recent measurement data is available, the value is based on\nthe properties of the underlying connection technology.\n\n",
      "savedata": "\n\nThe **`NetworkInformation.saveData`** read-only\nproperty of the [NetworkInformation] interface returns `true` if\nthe user has set a reduced data usage option on the user agent.",
      "type": "\n\nThe **`NetworkInformation.type`** read-only property returns\nthe type of connection a device is using to communicate with the network.\n\n"
    }
  },
  "node": {
    "docs": "\n\nThe  **`Node`** interface is an abstract base\nclass upon which many other DOM API objects are based, thus letting those object types\nto be used similarly and often interchangeably. As an abstract class, there is\nno such thing as a plain `Node` object. All objects that implement\n`Node` functionality are based on one of its subclasses. Most notable are\n[Document], [Element], and [DocumentFragment].\n\nIn addition, every kind of DOM node is represented by an interface based on\n`Node`. These include [Attr], [CharacterData]\n(which [Text], [Comment], [CDATASection] and\n[ProcessingInstruction] are all based on), and [DocumentType].\n\nIn some cases, a particular feature of the base `Node` interface may not\napply to one of its child interfaces; in that case, the inheriting node may\nreturn `null` or throw an exception, depending on circumstances. For example,\nattempting to add children to a node type that cannot have children will throw an\nexception.\n\n",
    "properties": {
      "appendchild": "\n\nThe **`appendChild()`** method of the [Node] interface adds a node to the end of the list of children of a specified parent node.\n\n> **Note:** If the given child is a reference to an existing node in the document, `appendChild()` moves it from its current position to the new position.\n\nIf the given child is a [DocumentFragment], the entire contents of the [DocumentFragment] are moved into the child list of the specified parent node.\n\n`appendChild()` returns the newly appended node, or if the child is a [DocumentFragment], the emptied fragment.\n\n> **Note:** Unlike this method, the [Element.append] method supports multiple arguments and appending strings. You can prefer using it if your node is an element.",
      "baseuri": "\n\nThe read-only **`baseURI`** property of the [Node] interface\nreturns the absolute base URL of the document containing the node.\n\nThe base URL is used to resolve relative URLs when the browser needs to obtain an absolute URL, for example when processing the HTML `img` element's `src` attribute or the `xlink:href`  or `href` attributes in SVG.\n\nAlthough this property is read-only, its value is determined by an algorithm each time\nthe property is accessed, and may change if the conditions changed.\n\nThe base URL is determined as follows:\n\n1. By default, the base URL is the location of the document (as determined by [window.location]).\n2. If it is an HTML Document and there is a `Base` element in the document,\n   the `href` value of the _first_ `Base` element with such an attribute is used instead.",
      "childnodes": "\n\nThe read-only **`childNodes`** property of the [Node] interface returns a live\n[NodeList] of child [Node] of the given element where\nthe first child node is assigned index `0`. Child nodes include elements, text and\ncomments.\n\n> **Note:** The [NodeList] being live means that its content is changed each time\n> new children are added or removed.\n>\n> Browsers insert text nodes into a document to represent whitespace in the source markup.\n> Therefore a node obtained, for example, using `Node.childNodes[0]`\n> may refer to a whitespace text node rather than the actual element the author intended to get.\n>\n> See [Whitespace in the DOM](/en-US/docs/Web/API/Document_Object_Model/Whitespace) for more information.\n\nThe items in the collection of nodes are objects, not strings. To get data from node\nobjects, use their properties. For example, to get the name of the first\nchildNode, you can use `elementNodeReference.childNodes[0].nodeName`.\n\nThe [document] object itself has two children: the Doctype declaration and the\nroot element, typically referred to as `documentElement`. In HTML\ndocuments the latter is the `html` element.\n\nIt is important to keep in mind that `childNodes` includes _all_ child nodes,\nincluding non-element nodes like text and comment.\nTo get a collection containing only elements, use [Element.children] instead.",
      "clonenode": "\n\nThe **`cloneNode()`** method of the [Node] interface\nreturns a duplicate of the node on which this method was called.\nIts parameter controls if the subtree contained in a node is also cloned or not.\n\nCloning a node copies all of its attributes and their values,\nincluding intrinsic (inline) listeners. It does _not_ copy event listeners added\nusing [`addEventListener()`](/en-US/docs/Web/API/EventTarget/addEventListener) or\nthose assigned to element properties (e.g., `node.onclick = someFunction`).\nAdditionally, for a `canvas` element, the painted image is not copied.\n\n> **Warning:** `cloneNode()` may lead to duplicate element IDs in a document!\n>\n> If the original node has an `id` attribute, and the clone\n> will be placed in the same document, then you should modify the clone's ID to be\n> unique.\n>\n> Also, `name` attributes may need to be modified,\n> depending on whether duplicate names are expected.\n\nTo clone a node to insert into a _different_ document, use\n[Document.importNode] instead.",
      "comparedocumentposition": "\n\nThe **`compareDocumentPosition()`** method of the [Node] interface\nreports the position of its argument node relative to the node on which it is called.",
      "contains": "\n\nThe **`contains()`** method of the [Node] interface\nreturns a boolean value indicating\nwhether a node is a descendant of a given node, that is the node itself,\none of its direct children ([Node.childNodes]),\none of the children's direct children, and so on.\n\n> **Note:** A node is _contained_ inside itself.",
      "firstchild": "\n\nThe read-only **`firstChild`** property of the [Node] interface\nreturns the node's first child in the tree,\nor `null` if the node has no children.\n\nIf the node is a [Document],\nthis property returns the first node in the list of its direct children.\n\n> **Note:** This property returns any type of node that is the first child of this one.\n> It may be a [Text] or a [Comment] node.\n> If you want to get the first [Element] that is a child of another element,\n> consider using [Element.firstElementChild].",
      "getrootnode": "\n\nThe **`getRootNode()`** method of the [Node] interface\nreturns the context object's root,\nwhich optionally includes the shadow root if it is available.",
      "haschildnodes": "\n\nThe **`hasChildNodes()`** method of the [Node] interface\nreturns a boolean value indicating\nwhether the given [Node] has [child nodes](/en-US/docs/Web/API/Node/childNodes) or not.",
      "insertbefore": "\n\nThe **`insertBefore()`** method of the [Node] interface\ninserts a node before a _reference node_ as a child of a specified _parent node_.\n\nIf the given node already exists in the document,\n`insertBefore()` moves it from its current position to the new position.\n(That is, it will automatically be removed from its existing parent\nbefore appending it to the specified new parent.)\n\nThis means that a node cannot be in two locations of the document simultaneously.\n\n> **Note:** The [Node.cloneNode] can be used to make a copy\n> of the node before appending it under the new parent. Note that the copies made with\n> `cloneNode()` will not be automatically kept in sync.\n\nIf the given child is a [DocumentFragment], the entire contents of the\n`DocumentFragment` are moved into the child list of the specified parent\nnode.",
      "isconnected": "\n\nThe read-only **`isConnected`** property of the [Node] interface\nreturns a boolean indicating whether the node is connected\n(directly or indirectly) to a [Document] object.",
      "isdefaultnamespace": "\n\nThe **`isDefaultNamespace()`** method of the [Node] interface accepts a namespace URI as an argument.\nIt returns a boolean value that is `true` if the namespace is the default namespace on the given node and `false` if not.\n\n> **Note:** The default namespace of an HTML element is always `\"\"`. For a SVG element, it is set by the `xmlns` attribute.",
      "isequalnode": "\n\nThe **`isEqualNode()`** method of the [Node] interface tests whether two nodes are equal.\nTwo nodes are equal when they have the same type, defining characteristics (for\nelements, this would be their ID, number of children, and so forth), its attributes\nmatch, and so on. The specific set of data points that must match varies depending on\nthe types of the nodes.",
      "issamenode": "\n\nThe **`isSameNode()`** method of the [Node] interface\nis a legacy alias the [for the `===` strict equality operator](/en-US/docs/Web/JavaScript/Reference/Operators/Strict_equality).\nThat is, it tests whether two nodes are the same\n(in other words, whether they reference the same object).\n\n> **Note:** There is no need to use `isSameNode()`; instead use the `===` strict equality operator.",
      "lastchild": "\n\nThe read-only **`lastChild`** property of the [Node] interface\nreturns the last child of the node, or `null` if there are no child nodes.\n\n> **Note:** This property returns any type of node that is the last child of this one.\n> It may be a [Text] or a [Comment] node.\n> If you want to get the last [Element] that is a child of another element,\n> consider using [Element.lastElementChild].",
      "lookupnamespaceuri": "\n\nThe **`lookupNamespaceURI()`** method of the [Node] interface\ntakes a prefix as parameter and returns the namespace URI associated with it on the given node if found (and\n`null` if not).",
      "lookupprefix": "\n\nThe **`lookupPrefix()`** method of the [Node] interface\nreturns a string containing the prefix for a given namespace URI, if present,\nand `null` if not.\nWhen multiple prefixes are possible, the first prefix is returned.",
      "nextsibling": "\n\nThe read-only **`nextSibling`** property of the [Node] interface\nreturns the node immediately following the specified one in their\nparent's [Node.childNodes], or returns `null`\nif the specified node is the last child in the parent element.\n\n> **Note:** Browsers insert [Text] nodes into a document to represent whitespace in the source markup.\n> Therefore a node obtained, for example, using [`Node.firstChild`](/en-US/docs/Web/API/Node/firstChild)\n> or [`Node.previousSibling`](/en-US/docs/Web/API/Node/previousSibling)\n> may refer to a whitespace text node rather than the actual element the author\n> intended to get.\n>\n> The article [Whitespace in the DOM](/en-US/docs/Web/API/Document_Object_Model/Whitespace)\n> contains more information about this behavior.\n>\n> You can use [Element.nextElementSibling] to obtain the next element\n> skipping any whitespace nodes, other between-element text, or comments.\n>\n> To navigate the opposite way through the child nodes list use [Node.previousSibling](/en-US/docs/Web/API/Node/previousSibling).",
      "nodename": "\n\nThe read-only **`nodeName`** property of [Node] returns the name of the current node as a string.",
      "nodetype": "\n\nThe read-only **`nodeType`** property of a [Node] interface is an integer\nthat identifies what the node is. It distinguishes different kind of nodes from each other,\nsuch as [Element], [Text] and [Comment].",
      "nodevalue": "\n\nThe **`nodeValue`** property of the [Node] interface returns or sets the value of the current node.",
      "normalize": "\n\nThe **`normalize()`** method of the [Node] interface puts the specified node\nand all of its sub-tree into a _normalized_ form.\nIn a normalized sub-tree, no text nodes in the sub-tree are empty and there are no adjacent text nodes.",
      "ownerdocument": "\n\nThe read-only **`ownerDocument`** property of the [Node] interface\nreturns the top-level document object of the node.",
      "parentelement": "\n\nThe read-only **`parentElement`** property of [Node] interface\nreturns the DOM node's parent [Element], or `null` if the node either has no\nparent, or its parent isn't a DOM [Element].",
      "parentnode": "\n\nThe read-only **`parentNode`** property of the [Node] interface\nreturns the parent of the specified node in the DOM tree.\n\n`Document` and `DocumentFragment` [nodes](/en-US/docs/Web/API/Node/nodeType) can never have a parent, so\n`parentNode` will always return `null`.\nIt also returns `null` if the node has just been created\nand is not yet attached to the tree.",
      "previoussibling": "\n\nThe read-only **`previousSibling`** property of the [Node] interface\nreturns the node immediately preceding the specified one in its parent's\n[Node.childNodes] list,\nor `null` if the specified node is the first in that list.\n\n> **Note:** Browsers insert text nodes into a document to represent whitespace in the source markup.\n> Therefore a node obtained, for example, using [`Node.firstChild`](/en-US/docs/Web/API/Node/firstChild)\n> or `Node.previousSibling`\n> may refer to a whitespace text node rather than the actual element the author intended to get.\n>\n> See [Whitespace in the DOM](/en-US/docs/Web/API/Document_Object_Model/Whitespace) for more information.\n>\n> You can use [`previousElementSibling`](/en-US/docs/Web/API/Element/previousElementSibling)\n> to get the previous element node (skipping text nodes and any other non-element nodes).\n>\n> To navigate the opposite way through the child nodes list use [Node.nextSibling](/en-US/docs/Web/API/Node/nextSibling).",
      "removechild": "\n\nThe **`removeChild()`** method of the [Node] interface\nremoves a child node from the DOM and returns the removed node.\n\n> **Note:** As long as a reference is kept on the removed child,\n> it still exists in memory, but is no longer part of the DOM.\n> It can still be reused later in the code.\n>\n> If the return value of `removeChild()` is not stored, and no other reference is kept,\n> it will be [automatically deleted](/en-US/docs/Web/JavaScript/Memory_management) from memory after a short time.\n\nUnlike [Node.cloneNode] the return value preserves the `EventListener` objects associated with it.",
      "replacechild": "\n\nThe **`replaceChild()`** method of the [Node] interface replaces a child node within the given (parent) node.",
      "selectstart_event": "\n\nThe **`selectstart`** event of the [Selection API](/en-US/docs/Web/API/Selection) is fired when a user starts a new selection.\n\nIf the event is canceled, the selection is not changed.",
      "textcontent": "\n\nThe **`textContent`** property of the [Node]\ninterface represents the text content of the node and its descendants.\n\n> **Note:** `textContent` and [HTMLElement.innerText] are easily confused,\n> but the two properties are [different in important ways](#differences_from_innertext)."
    }
  },
  "nodeiterator": {
    "docs": "\n\nThe **`NodeIterator`** interface represents an iterator to traverse nodes of a DOM subtree in document order.",
    "properties": {
      "detach": "\n\nThe **`NodeIterator.detach()`** method is a no-op, kept for\nbackward compatibility only.\n\nOriginally, it detached the [NodeIterator] from the set over which it\niterates, releasing any resources used by the set and setting the iterator's state to\n`INVALID`. Once this method had been called, calls to other methods on\n`NodeIterator` would raise the `INVALID_STATE_ERR` exception.",
      "filter": "\n\nThe **`NodeIterator.filter`** read-only property returns a\n`NodeFilter` object, that is an object which implements an\n`acceptNode(node)` method, used to screen nodes.\n\nWhen creating the [NodeIterator], the filter object is passed in as the\nthird parameter, and the object method `acceptNode(node)` is\ncalled on every single node to determine whether or not to accept it. This function\nshould return the constant `NodeFilter.FILTER_ACCEPT` for cases when the\nnode should be accepted and `NodeFilter.FILTER_REJECT` for cases when the\nnode should be rejected.",
      "nextnode": "\n\nThe **`NodeIterator.nextNode()`** method returns the next node\nin the set represented by the [NodeIterator] and advances the position of\nthe iterator within the set. The first call to `nextNode()` returns the\nfirst node in the set.\n\nThis method returns `null` when there are no nodes left in the set.\n\nIn old browsers, as specified in old versions of the specifications, the method may\nthrows the `INVALID_STATE_ERR` [DOMException] if this method\nis called after the [NodeIterator.detach]method. Recent browsers never\nthrow.",
      "pointerbeforereferencenode": "\n\nThe **`NodeIterator.pointerBeforeReferenceNode`** read-only\nproperty returns a boolean flag that indicates whether the\n`NodeFilter` is anchored before (if this value is `true`) or\nafter (if this value is `false`) the anchor node indicated by the\n[NodeIterator.referenceNode] property.",
      "previousnode": "\n\nThe **`NodeIterator.previousNode()`** method returns the\nprevious node in the set represented by the [NodeIterator] and moves the\nposition of the iterator backwards within the set.\n\nThis method returns `null` when the current node is the first node in the\nset.\n\nIn old browsers, as specified in old versions of the specifications, the method may\nthrows the `INVALID_STATE_ERR` [DOMException] if this method\nis called after the [NodeIterator.detach]method. Recent browsers never\nthrow.",
      "referencenode": "\n\nThe **`NodeIterator.referenceNode`** read-only property returns the\n[Node] to which the iterator is anchored; as new nodes are inserted, the\niterator remains anchored to the reference node as specified by this property.",
      "root": "\n\nThe **`NodeIterator.root`** read-only property represents the\n[Node] that is the root of what the [NodeIterator]\ntraverses.",
      "whattoshow": "\n\nThe **`NodeIterator.whatToShow`** read-only property represents\nan `unsigned integer` representing a bitmask signifying what types of nodes\nshould be returned by the [NodeIterator]."
    }
  },
  "nodelist": {
    "docs": "\n\n**`NodeList`** objects are collections of [nodes](/en-US/docs/Web/API/Node), usually returned by properties such as [Node.childNodes] and methods such as [document.querySelectorAll].\n\n> **Note:** Although `NodeList` is not an `Array`, it is possible to iterate over it with `forEach()`. It can also be converted to a real `Array` using `Array.from()`.",
    "properties": {
      "entries": "\n\nThe **`NodeList.entries()`** method returns an\n`iterator` allowing to go through all key/value pairs\ncontained in this object. The values are [Node] objects.",
      "foreach": "\n\nThe **`forEach()`** method of the [NodeList]\ninterface calls the callback given in parameter once for each value pair in the list, in\ninsertion order.",
      "item": "\n\nReturns a node from a [`NodeList`](/en-US/docs/Web/API/NodeList) by index. This method\ndoesn't throw exceptions as long as you provide arguments. A value of `null`\nis returned if the index is out of range, and a `TypeError` is thrown if no\nargument is provided.",
      "keys": "\n\nThe **`NodeList.keys()`** method returns an\n`iterator` allowing to go through all keys contained\nin this object. The keys are `unsigned integer`.",
      "length": "\n\nThe **`NodeList.length`** property returns the number of items\nin a [NodeList].",
      "values": "\n\nThe **`NodeList.values()`** method returns an\n`iterator` allowing to go through all values contained\nin this object. The values are [Node] objects."
    }
  },
  "notification": {
    "docs": "\n\nThe **`Notification`** interface of the [Notifications API] is used to configure and display desktop notifications to the user.\n\nThese notifications' appearance and specific functionality vary across platforms but generally they provide a way to asynchronously provide information to the user.\n\n",
    "properties": {
      "actions": "\n\nThe **`actions`** read-only property of the [Notification] interface provides the actions available for users to choose from for interacting with the notification.\n\nThe actions are set using the `actions` option of the second argument for the [`showNotification()`](/en-US/docs/Web/API/ServiceWorkerRegistration/showNotification) method and [`Notification()`](/en-US/docs/Web/API/Notification/Notification) constructor.\n\n> **Note:** Browsers typically limit the maximum number of actions they will display for a particular notification. Check the static [Notification.maxActions_static] property to determine the limit.",
      "badge": "\n\nThe **`badge`** property of the [Notification]\ninterface returns a string containing the URL of an image to represent the notification when there is not enough space to display the notification itself such as for example, the Android Notification Bar. On Android devices, the badge should accommodate devices up to 4x resolution, about 96 by 96 px, and the image will be automatically masked.",
      "body": "\n\nThe **`body`** read-only property of the\n[Notification] interface indicates the body string of the notification, as\nspecified in the `body` option of the\n[Notification.Notification] constructor.",
      "click_event": "\n\nThe **`click`** event of the [Notification]\ninterface fires when the user clicks on displayed [Notification].\n\nThe default behavior is to move the focus to the viewport of the notification's related\n[browsing context](https://html.spec.whatwg.org/multipage/browsers.html#browsing-context).\nIf you don't want that behavior, call [Event/preventDefault] on the event object.",
      "close": "\n\nThe `close()` method of the [Notification] interface is used to\nclose/remove a previously displayed notification.\n\n> **Note:** This API shouldn't be used just to have the notification\n> removed from the screen after a fixed delay since this method will also remove the\n> notification from any notification tray, preventing users from interacting with it\n> after it was initially shown. A valid use for this API would be to remove a\n> notification that is no longer relevant (e.g. the user already read the notification\n> on the webpage in the case of a messaging app or the following song is already playing\n> in a music app).",
      "close_event": "\n\nThe **`close`** event of the [Notification] interface fires when a [Notification] is closed.",
      "data": "\n\nThe **`data`** read-only property of the\n[Notification] interface returns a structured clone of the notification's\ndata, as specified in the `data` option of the\n[Notification.Notification] constructor.\n\nThe notification's data can be any arbitrary data that you want associated with the\nnotification.",
      "dir": "\n\nThe `dir` read-only property of the [Notification] interface indicates the text direction of the notification, as specified in the `dir` option of the [Notification.Notification] constructor.",
      "error_event": "\n\nThe **`error`** event of the [Notification] interface fires when something goes wrong with a [Notification] (in many cases an error preventing the notification from being displayed.)",
      "icon": "\n\nThe **`icon`** read-only property of the\n[Notification] interface contains the URL of an icon to be displayed as\npart of the notification, as specified in the `icon` option of the\n[Notification.Notification] constructor.",
      "image": "\n\nThe `image` read-only property of the\n[Notification] interface contains the URL of an image to be displayed as\npart of the notification, as specified in the `image` option of the\n[Notification.Notification] constructor.",
      "lang": "\n\nThe **`lang`** read-only property of the\n[Notification] interface indicates the language used in the notification,\nas specified in the `lang` option of the\n[Notification.Notification] constructor.\n\nThe language itself is specified using a string representing a language tag according to `5646, \"Tags for Identifying Languages (also known as BCP 47)\"`.\nSee the Sitepoint [ISO 2 letter language codes](https://www.sitepoint.com/iso-2-letter-language-codes/) page for a simple reference.",
      "maxactions_static": "\n\nThe **`maxActions`** attribute of the\n[Notification] interface returns the maximum number of actions supported by\nthe device and the User Agent. Effectively, this is the maximum number of elements in\n[Notification.actions] array which will be respected by the User Agent.",
      "permission_static": "\n\nThe `permission` read-only property of the [Notification]\ninterface indicates the current permission granted by the user for the current origin to\ndisplay web notifications.",
      "renotify": "\n\nThe **`renotify`** read-only property of the\n[Notification] interface specifies whether the user should be notified\nafter a new notification replaces an old one, as specified in the `renotify`\noption of the [Notification.Notification] constructor.",
      "requestpermission_static": "\n\nThe **`requestPermission()`** static method of the [Notification] interface requests permission from the user for the current origin to display notifications.",
      "requireinteraction": "\n\nThe **`requireInteraction`** read-only property of the [Notification] interface returns a boolean value indicating that a notification should remain active until the user clicks or dismisses it, rather than closing automatically.\n\n> **Note:** This can be set when the notification is first created by setting the `requireInteraction` option to `true` in the options object of the [Notification.Notification] constructor.",
      "show_event": "\n\nThe **`show`** event of the [Notification] interface fires when a [Notification] is displayed.",
      "silent": "\n\nThe **`silent`** read-only property of the\n[Notification] interface specifies whether the notification should be\nsilent, i.e., no sounds or vibrations should be issued, regardless of the device\nsettings. This is specified in the `silent` option of the\n[Notification.Notification] constructor.",
      "tag": "\n\nThe **`tag`** read-only property of the\n[Notification] interface signifies an identifying tag for the notification,\nas specified in the `tag` option of the\n[Notification.Notification] constructor.\n\nThe idea of notification tags is that more than one notification can share the same\ntag, linking them together. One notification can then be programmatically replaced with\nanother to avoid the users' screen being filled up with a huge number of similar\nnotifications.",
      "timestamp": "\n\nThe **`timestamp`** read-only property of the\n[Notification] interface returns a number, as\nspecified in the `timestamp` option of the\n[Notification.Notification] constructor.\n\nThe notification's timestamp can represent the time, in milliseconds since 00:00:00 UTC\non 1 January 1970, of the event for which the notification was created, or it can be an\narbitrary timestamp that you want associated with the notification. For example, a\ntimestamp for an upcoming meeting could be set in the future, whereas a timestamp for a\nmissed message could be set in the past.",
      "title": "\n\nThe **`title`** read-only property of the\n[Notification] interface indicates the title of the notification, as\nspecified in the `title` parameter of the\n[Notification.Notification] constructor.",
      "vibrate": "\n\nThe `vibrate` read-only property of the [Notification]\ninterface specifies a [vibration pattern](/en-US/docs/Web/API/Vibration_API#vibration_patterns)\nfor the device's vibration hardware to emit when the notification fires. This is\nspecified in the `vibrate` option of the\n[Notification.Notification] constructor."
    }
  },
  "notificationevent": {
    "docs": "\n\nThe **`NotificationEvent`** interface of the [Notifications API] represents a notification event dispatched on the [ServiceWorkerGlobalScope] of a [ServiceWorker].\n\nThis interface inherits from the [ExtendableEvent] interface.\n\n> **Note**: Only persistent notification events, fired at the [ServiceWorkerGlobalScope] object, implement the `NotificationEvent` interface. Non-persistent notification events, fired at the [Notification] object, implement the `Event` interface.\n\n",
    "properties": {
      "action": "\n\nThe **`action`** read-only property of the [NotificationEvent] interface returns the string ID of the notification button the user clicked. This value returns an empty string if the user clicked the notification somewhere other than an action button, or the notification does not have a button. The notification id is set during the creation of the Notification via the actions array attribute and can't be modified unless the notification is replaced.",
      "notification": "\n\nThe **`notification`** read-only property of the [NotificationEvent] interface returns the instance of the [Notification] that was clicked to fire the event. The [Notification] provides read-only access to many properties that were set at the instantiation time of the Notification such as `tag` and `data` attributes that allow you to store information for deferred use in the `notificationclick` event."
    }
  },
  "oes_draw_buffers_indexed": {
    "docs": "\n\nThe **`OES_draw_buffers_indexed`** extension is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and enables the use of different blend options when writing to multiple color buffers simultaneously.\n\nWebGL extensions are available using the [WebGLRenderingContext.getExtension] method. For more information, see also [Using Extensions](/en-US/docs/Web/API/WebGL_API/Using_Extensions) in the [WebGL tutorial](/en-US/docs/Web/API/WebGL_API/Tutorial).\n\n> **Note:** This extension is only available to [WebGL2RenderingContext] contexts.",
    "properties": {
      "blendequationioes": "\n\nThe `blendEquationiOES()` method of the `OES_draw_buffers_indexed` WebGL extension sets both the RGB blend and alpha blend equations for a particular draw buffer.\n\nSee [OES_draw_buffers_indexed.blendEquationSeparateiOES] for setting RGB and alpha separately and [WebGLRenderingContext.blendEquation] for the WebGL 1 version of this method.",
      "blendequationseparateioes": "\n\nThe `blendEquationSeparateiOES()` method of the [OES_draw_buffers_indexed] WebGL extension sets the RGB and alpha blend equations separately for a particular draw buffer.\n\nSee [OES_draw_buffers_indexed.blendEquationiOES] for setting RGB and alpha together and [WebGLRenderingContext.blendEquationSeparate] for the WebGL 1 version of this method.",
      "blendfuncioes": "\n\nThe `blendFunciOES()` method of the [OES_draw_buffers_indexed] WebGL extension defines which function is used when blending pixels for a particular draw buffer.\n\nSee [OES_draw_buffers_indexed.blendFuncSeparateiOES] for setting RGB and alpha components separately and [WebGLRenderingContext.blendFunc] for the WebGL 1 version of this method.",
      "blendfuncseparateioes": "\n\nThe `blendFuncSeparateiOES()` method of the [OES_draw_buffers_indexed] WebGL extension defines which function is used when blending pixels for RGB and alpha components separately for a particular draw buffer.\n\nSee [OES_draw_buffers_indexed.blendFunciOES] for setting RGB and alpha together and [WebGLRenderingContext.blendFuncSeparate] for the WebGL 1 version of this method.",
      "colormaskioes": "\n\nThe `colorMaskiOES()` method of the [OES_draw_buffers_indexed] WebGL extension sets which color components to enable or to disable when drawing or rendering for a particular draw buffer. It's the indexed version of WebGL 1's [WebGLRenderingContext.colorMask] method.",
      "disableioes": "\n\nThe `disableiOES()` method of the [OES_draw_buffers_indexed] WebGL extension enables blending for a particular draw buffer.",
      "enableioes": "\n\nThe `enableiOES()` method of the [OES_draw_buffers_indexed] WebGL extension enables blending for a particular draw buffer."
    }
  },
  "offlineaudiocompletionevent": {
    "docs": "\n\nThe [Web Audio API](/en-US/docs/Web/API/Web_Audio_API) `OfflineAudioCompletionEvent` interface represents events that occur when the processing of an [OfflineAudioContext] is terminated. The [OfflineAudioContext/complete_event] event uses this interface.\n\n> **Note:** This interface is marked as deprecated; it is still supported for legacy reasons, but it will soon be superseded when the promise version of [OfflineAudioContext.startRendering] is supported in browsers, which will no longer need it.\n\n",
    "properties": {
      "renderedbuffer": "\n\nThe **`renderedBuffer`** read-only property of the\n[OfflineAudioCompletionEvent] interface is an [AudioBuffer]\ncontaining the result of processing an [OfflineAudioContext]."
    }
  },
  "offlineaudiocontext": {
    "docs": "\n\nThe `OfflineAudioContext` interface is an [AudioContext] interface representing an audio-processing graph built from linked together [AudioNode]s. In contrast with a standard [AudioContext], an `OfflineAudioContext` doesn't render the audio to the device hardware; instead, it generates it, as fast as it can, and outputs the result to an [AudioBuffer].\n\n",
    "properties": {
      "complete_event": "`Web Audio API`\n\nThe `complete` event of the [OfflineAudioContext] interface is fired when the rendering of an offline audio context is complete.\n\nThis event is not cancelable and does not bubble.",
      "length": "\n\nThe **`length`** property of the\n[OfflineAudioContext] interface returns an integer representing the size of\nthe buffer in sample-frames.",
      "resume": "\n\nThe **`resume()`** method of the\n[OfflineAudioContext] interface resumes the progression of time in an audio\ncontext that has been suspended. The promise resolves immediately because the\n`OfflineAudioContext` does not require the audio hardware.",
      "startrendering": "\n\nThe `startRendering()` method of the [OfflineAudioContext] Interface starts rendering the audio graph, taking into account the current connections and the current scheduled changes.\n\nThe [OfflineAudioContext/complete_event] event (of type [OfflineAudioCompletionEvent]) is raised when the rendering is finished, containing the resulting [AudioBuffer] in its `renderedBuffer` property.\n\nBrowsers currently support two versions of the `startRendering()` method — an older event-based version and a newer promise-based version.\nThe former will eventually be removed, but currently both mechanisms are provided for legacy reasons.",
      "suspend": "\n\nThe **`suspend()`** method of the [OfflineAudioContext] interface schedules a suspension of the time\nprogression in the audio context at the specified time and returns a promise. This is\ngenerally useful at the time of manipulating the audio graph synchronously on\nOfflineAudioContext.\n\nNote that the maximum precision of suspension is the size of the render quantum and the\nspecified suspension time will be rounded down to the nearest render quantum boundary.\nFor this reason, it is not allowed to schedule multiple suspends at the same quantized\nframe. Also scheduling should be done while the context is not running to ensure the\nprecise suspension."
    }
  },
  "offscreencanvas": {
    "docs": "\n\nWhen using the `canvas` element or the [Canvas API](/en-US/docs/Web/API/Canvas_API), rendering, animation, and user interaction usually happen on the main execution thread of a web application.\nThe computation relating to canvas animations and rendering can have a significant impact on application performance.\n\nThe **`OffscreenCanvas`** interface provides a canvas that can be rendered off screen, decoupling the DOM and the Canvas API so that the `canvas` element is no longer entirely dependent on the DOM.\nRendering operations can also be run inside a [worker](/en-US/docs/Web/API/Web_Workers_API) context, allowing you to run some tasks in a separate thread and avoid heavy work on the main thread.\n\n`OffscreenCanvas` is a [transferable object](/en-US/docs/Web/API/Web_Workers_API/Transferable_objects).\n\n",
    "properties": {
      "converttoblob": "\n\nThe **`OffscreenCanvas.convertToBlob()`** method creates a [Blob] object representing the image contained in the canvas.\n\nThe desired file format and image quality may be specified.\nIf the file format is not specified, or if the given format is not supported, then the data will be exported as `image/png`.\nBrowsers are required to support `image/png`; many will support additional formats including `image/jpeg` and `image/webp`.\n\nThe created image will have a resolution of 96dpi for file formats that support encoding resolution metadata.",
      "getcontext": "\n\nThe **`OffscreenCanvas.getContext()`** method returns a drawing context for an offscreen canvas, or [`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null) if the context identifier is not supported.",
      "height": "\n\nThe **`height`** property returns and sets the height of an [OffscreenCanvas] object.",
      "transfertoimagebitmap": "\n\nThe **`OffscreenCanvas.transferToImageBitmap()`** method creates an [ImageBitmap] object from the most recently rendered image of the `OffscreenCanvas`. The `OffscreenCanvas` allocates a new image for its subsequent rendering.",
      "width": "\n\nThe **`width`** property returns and sets the width of an [OffscreenCanvas] object."
    }
  },
  "offscreencanvasrenderingcontext2d": {
    "docs": "\n\nThe **`OffscreenCanvasRenderingContext2D`** interface is a [CanvasRenderingContext2D] rendering context for drawing to the bitmap of an `OffscreenCanvas` object.\nIt is similar to the `CanvasRenderingContext2D` object, with the following differences:\n\n- there is no support for user-interface features (`drawFocusIfNeeded`, and `scrollPathIntoView`)\n- its `canvas` attribute refers to an `OffscreenCanvas` object rather than a `canvas` element\n- it has a `commit()` method for pushing rendered images to the context's `OffscreenCanvas` object's placeholder `canvas` element",
    "properties": {
      "commit": "\n\nThe\n**`OffscreenCanvasRenderingContext2D.commit()`**\nmethod of the [Canvas 2D API](/en-US/docs/Web/API/OffscreenCanvasRenderingContext2D) copies the rendering context's bitmap to the bitmap of the placeholder `canvas` element of the associated `OffscreenCanvas` object.\nThe copy operation is synchronous. Calling this method is not needed for the transfer, since it happens automatically during the event-loop execution."
    }
  },
  "orientationsensor": {
    "docs": "\n\nThe **`OrientationSensor`** interface of the [Sensor APIs](/en-US/docs/Web/API/Sensor_APIs) is the base class for orientation sensors. This interface cannot be used directly. Instead it provides properties and methods accessed by interfaces that inherit from it.\n\nThis feature may be blocked by a [Permissions Policy](/en-US/docs/Web/HTTP/Permissions_Policy) set on your server.\n\n",
    "properties": {
      "populatematrix": "\n\nThe **`populateMatrix`** method of the\n[OrientationSensor] interface populates the given target matrix with the\nrotation matrix based on the latest sensor reading. The rotation matrix is shown\nbelow.\n\n![The formulas used to convert the sensor's quaternion to the provided matrix.](quaternion_to_rotation_matrix.png)\n\nwhere:\n\n- W = cos(θ/2)\n- X = Vx \\* sin(θ/2)\n- Y = Vy \\* sin(θ/2)\n- Z = Vz \\* sin(θ/2)",
      "quaternion": "\n\nThe **`quaternion`** read-only\nproperty of the [OrientationSensor] interface returns a four element\n`Array` whose elements contain the components of the unit\n representing the device's orientation.\n\nBecause [OrientationSensor] is a base class, `quaternion` may\nonly be read from one of its derived classes."
    }
  },
  "oscillatornode": {
    "docs": "\n\nThe **`OscillatorNode`** interface represents a periodic waveform, such as a sine wave. It is an [AudioScheduledSourceNode] audio-processing module that causes a specified frequency of a given wave to be created—in effect, a constant tone.\n\n<table class=\"properties\">\n  <tbody>\n    <tr>\n      <th scope=\"row\">Number of inputs</th>\n      <td><code>0</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Number of outputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count mode</th>\n      <td><code>max</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count</th>\n      <td><code>2</code> (not used in the default count mode)</td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel interpretation</th>\n      <td><code>speakers</code></td>\n    </tr>\n  </tbody>\n</table>",
    "properties": {
      "detune": "\n\nThe `detune` property of the [OscillatorNode] interface is an [a-rate](/en-US/docs/Web/API/AudioParam#a-rate) [AudioParam] representing detuning of oscillation in [cents](https://en.wikipedia.org/wiki/Cent_%28music%29).\n\n> **Note:** though the `AudioParam` returned is read-only, the value it represents is not.",
      "frequency": "\n\nThe **`frequency`** property of the [OscillatorNode] interface is an [a-rate](/en-US/docs/Web/API/AudioParam#a-rate) [AudioParam] representing the frequency of oscillation in hertz.\n\n> **Note:** though the `AudioParam` returned is read-only, the value it represents is not.",
      "setperiodicwave": "\n\nThe **`setPeriodicWave()`** method of the [OscillatorNode] interface is used to point to a [PeriodicWave]\ndefining a periodic waveform that can be used to shape the oscillator's output, when\n[OscillatorNode.type] is `custom`.",
      "type": "\n\nThe **`type`** property of the [OscillatorNode] interface specifies what shape of [waveform](https://en.wikipedia.org/wiki/Waveform) the\noscillator will output. There are several common waveforms available, as well as an\noption to specify a custom waveform shape. The shape of the waveform will affect the\ntone that is produced."
    }
  },
  "otpcredential": {
    "docs": "\n\nThe **`OTPCredential`** interface of the [WebOTP API] is returned when a WebOTP [CredentialsContainer.get] call (i.e. invoked with an `otp` option) fulfills. It includes a `code` property that contains the retrieved one-time password (OTP).\n\n",
    "properties": {
      "code": "\n\nThe **`code`** property of the [OTPCredential] interface contains the one-time password (OTP)."
    }
  },
  "overconstrainederror": {
    "docs": "\n\nThe **`OverconstrainedError`** interface of the [Media Capture and Streams API](/en-US/docs/Web/API/Media_Capture_and_Streams_API) indicates that the set of desired capabilities for the current [MediaStreamTrack] cannot currently be met. When this event is thrown on a MediaStreamTrack, it is muted until either the current constraints can be established or until satisfiable constraints are applied.\n\n",
    "properties": {
      "constraint": "\n\nThe **`constraint`** read-only property of the\n[OverconstrainedError] interface returns the constraint that was supplied\nin the constructor, meaning the constraint that was not satisfied."
    }
  },
  "pagetransitionevent": {
    "docs": "\n\nThe **`PageTransitionEvent`** event object is available inside handler functions for the [`pageshow`](/en-US/docs/Web/API/Window/pageshow_event) and [`pagehide`](/en-US/docs/Web/API/Window/pagehide_event) events, fired when a document is being loaded or unloaded.\n\n",
    "properties": {
      "persisted": "\n\nThe **`persisted`** read-only property indicates if a webpage is loading from a cache."
    }
  },
  "paintworkletglobalscope": {
    "docs": "\n\nThe **`PaintWorkletGlobalScope`** interface of the [CSS Painting API](/en-US/docs/Web/API/CSS_Painting_API) represents the global object available inside a paint [Worklet].",
    "properties": {
      "devicepixelratio": "\n\nThe **`devicePixelRatio`** read-only property of the [PaintWorkletGlobalScope] interface returns the current device's ratio of physical pixels to logical pixels.",
      "registerpaint": "\n\nThe **`registerPaint()`** method of the\n[PaintWorkletGlobalScope] interface registers a class to programmatically generate an\nimage where a CSS property expects a file."
    }
  },
  "pannernode": {
    "docs": "\n\nThe `PannerNode` interface defines an audio-processing object that represents the location, direction, and behavior of an audio source signal in a simulated physical space. This [AudioNode] uses right-hand Cartesian coordinates to describe the source's _position_ as a vector and its _orientation_ as a 3D directional cone.\n\nA `PannerNode` always has exactly one input and one output: the input can be _mono_ or _stereo_ but the output is always _stereo_ (2 channels); you can't have panning effects without at least two audio channels!\n\n![The PannerNode defines a spatial position and direction for a given signal.](webaudiopannernode.png)\n\n<table class=\"properties\">\n  <tbody>\n    <tr>\n      <th scope=\"row\">Number of inputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Number of outputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count mode</th>\n      <td><code>\"clamped-max\"</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count</th>\n      <td><code>2</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel interpretation</th>\n      <td><code>\"speakers\"</code></td>\n    </tr>\n  </tbody>\n</table>",
    "properties": {
      "coneinnerangle": "\n\nThe `coneInnerAngle` property of the [PannerNode] interface is a double value describing the angle, in degrees, of a cone inside of which there will be no volume reduction.\n\nThe `coneInnerAngle` property's default value is `360`, suitable for a non-directional source.",
      "coneouterangle": "\n\nThe `coneOuterAngle` property of the [PannerNode] interface is a double value describing the angle, in degrees, of a cone outside of which the volume will be reduced by a constant value, defined by the [PannerNode.coneOuterGain] property.\n\nThe `coneOuterAngle` property's default value is `0`.",
      "coneoutergain": "\n\nThe `coneOuterGain` property of the [PannerNode] interface is a double value, describing the amount of volume reduction outside the cone, defined by the [PannerNode.coneOuterAngle] attribute.\n\nThe `coneOuterGain` property's default value is `0`, meaning that no sound can be heard outside the cone.",
      "distancemodel": "\n\nThe `distanceModel` property of the [PannerNode] interface is an enumerated value determining which algorithm to use to reduce the volume of the audio source as it moves away from the listener.\n\nThe possible values are:\n\n- `linear`: A _linear distance model_ calculating the gain induced by the distance according to:\n  `1 - rolloffFactor * (distance - refDistance) / (maxDistance - refDistance)`\n- `inverse`: An _inverse distance model_ calculating the gain induced by the distance according to:\n  `refDistance / (refDistance + rolloffFactor * (Math.max(distance, refDistance) - refDistance))`\n- `exponential`: An _exponential distance model_ calculating the gain induced by the distance according to:\n  `pow((Math.max(distance, refDistance) / refDistance, -rolloffFactor)`.\n\n`inverse` is the default value of `distanceModel`.",
      "maxdistance": "\n\nThe `maxDistance` property of the [PannerNode] interface is a double value representing the maximum distance between the audio source and the listener, after which the volume is not reduced any further. This value is used only by the `linear` distance model.\n\nThe `maxDistance` property's default value is `10000`.",
      "orientationx": "\n\nThe **`orientationX`** property of the [PannerNode] interface indicates the X (horizontal) component of the\ndirection in which the audio source is facing, in a 3D Cartesian coordinate space.\n\nThe complete vector is defined by the position of the audio source, given as\n([PannerNode.positionX], [PannerNode.positionY], [PannerNode.positionZ]), and the orientation\nof the audio source (that is, the direction in which it's facing), given as\n([PannerNode.orientationX],\n[PannerNode.orientationY],\n[PannerNode.orientationZ]).\n\nDepending on the directionality of the sound (as specified using the attributes\n[PannerNode.coneInnerAngle],\n[PannerNode.coneOuterAngle], and\n[PannerNode.coneOuterGain]), the orientation of the\nsound may alter the perceived volume of the sound as it's being played. If the sound\nis pointing toward the listener, it will be louder than if the sound is pointed away\nfrom the listener.\n\nThe [AudioParam] contained by this property is read only; however, you\ncan still change the value of the parameter by assigning a new value to its\n[AudioParam.value] property.",
      "orientationy": "\n\nThe **`orientationY`** property of the [PannerNode] interface\nindicates the Y (vertical) component of the direction the audio source is facing, in 3D Cartesian coordinate space.\n\nThe complete vector is defined by the position of the audio source, given as\n([PannerNode.positionX], [PannerNode.positionY], [PannerNode.positionZ]), and the orientation\nof the audio source (that is, the direction in which it's facing), given as\n([PannerNode.orientationX],\n[PannerNode.orientationY],\n[PannerNode.orientationZ]).\n\nDepending on the directionality of the sound (as specified using the attributes\n[PannerNode.coneInnerAngle],\n[PannerNode.coneOuterAngle], and\n[PannerNode.coneOuterGain]), the orientation of the\nsound may alter the perceived volume of the sound as it's being played. If the sound\nis pointing toward the listener, it will be louder than if the sound is pointed away\nfrom the listener.\n\nThe [AudioParam] contained by this property is read only; however, you\ncan still change the value of the parameter by assigning a new value to its\n[AudioParam.value] property.",
      "orientationz": "\n\nThe **`orientationZ`** property of the [PannerNode] interface\nindicates the Z (depth) component of the direction the audio source is facing, in 3D Cartesian coordinate space.\n\nThe complete vector is defined by the position of the audio source, given as\n([PannerNode.positionX], [PannerNode.positionY], [PannerNode.positionZ]), and the orientation\nof the audio source (that is, the direction in which it's facing), given as\n([PannerNode.orientationX],\n[PannerNode.orientationY],\n[PannerNode.orientationZ]).\n\nDepending on the directionality of the sound (as specified using the attributes\n[PannerNode.coneInnerAngle],\n[PannerNode.coneOuterAngle], and\n[PannerNode.coneOuterGain]), the orientation of the\nsound may alter the perceived volume of the sound as it's being played. If the sound\nis pointing toward the listener, it will be louder than if the sound is pointed away\nfrom the listener.\n\nThe [AudioParam] contained by this property is read only; however, you\ncan still change the value of the parameter by assigning a new value to its\n[AudioParam.value] property.",
      "panningmodel": "\n\nThe `panningModel` property of the [PannerNode] interface is an enumerated value determining which spatialization algorithm to use to position the audio in 3D space.\n\nThe possible values are:\n\n- `equalpower`: Represents the equal-power panning algorithm, generally regarded as simple and efficient. `equalpower` is the default value.\n- `HRTF`: Renders a stereo output of higher quality than `equalpower` — it uses a convolution with measured impulse responses from human subjects.",
      "positionx": "\n\nThe **`positionX`** property of the [PannerNode] interface specifies the X coordinate of the audio source's position in 3D Cartesian\ncoordinates, corresponding to the _horizontal_ axis (left-right).\n\nThe complete vector is defined by the position of the audio source, given as\n([PannerNode.positionX], [PannerNode.positionY], [PannerNode.positionZ]), and the orientation\nof the audio source (that is, the direction in which it's facing), given as\n([PannerNode.orientationX],\n[PannerNode.orientationY],\n[PannerNode.orientationZ]).\n\nDepending on the directionality of the sound (as specified using the attributes\n[PannerNode.coneInnerAngle],\n[PannerNode.coneOuterAngle], and\n[PannerNode.coneOuterGain]), the orientation of the\nsound may alter the perceived volume of the sound as it's being played. If the sound\nis pointing toward the listener, it will be louder than if the sound is pointed away\nfrom the listener.\n\nThe [AudioParam] contained by this property is read only; however, you\ncan still change the value of the parameter by assigning a new value to its\n[AudioParam.value] property.",
      "positiony": "\n\nThe **`positionY`** property of the [PannerNode] interface specifies the Y coordinate of the audio source's position in 3D Cartesian\ncoordinates, corresponding to the _vertical_ axis (top-bottom). The complete\nvector is defined by the position of the audio source, given as\n([PannerNode.positionX], [PannerNode.positionY], [PannerNode.positionZ]), and the orientation\nof the audio source (that is, the direction in which it's facing), given as\n([PannerNode.orientationX],\n[PannerNode.orientationY],\n[PannerNode.orientationZ]).\n\nDepending on the directionality of the sound (as specified using the attributes\n[PannerNode.coneInnerAngle],\n[PannerNode.coneOuterAngle], and\n[PannerNode.coneOuterGain]), the orientation of the\nsound may alter the perceived volume of the sound as it's being played. If the sound\nis pointing toward the listener, it will be louder than if the sound is pointed away\nfrom the listener.\n\nThe [AudioParam] contained by this property is read only; however, you\ncan still change the value of the parameter by assigning a new value to its\n[AudioParam.value] property.",
      "positionz": "\n\nThe **`positionZ`** property of the [PannerNode] interface specifies the Z coordinate of the audio source's position in 3D Cartesian\ncoordinates, corresponding to the _depth_ axis (behind-in front of the\nlistener). The complete vector is defined by the position of the audio source, given\nas ([PannerNode.positionX],\n[PannerNode.positionY], [PannerNode.positionZ]), and the orientation of the audio source (that is, the direction in\nwhich it's facing), given as ([PannerNode.orientationX],\n[PannerNode.orientationY],\n[PannerNode.orientationZ]).\n\nDepending on the directionality of the sound (as specified using the attributes\n[PannerNode.coneInnerAngle],\n[PannerNode.coneOuterAngle], and\n[PannerNode.coneOuterGain]), the orientation of the\nsound may alter the perceived volume of the sound as it's being played. If the sound\nis pointing toward the listener, it will be louder than if the sound is pointed away\nfrom the listener.\n\nThe [AudioParam] contained by this property is read only; however, you\ncan still change the value of the parameter by assigning a new value to its\n[AudioParam.value] property.",
      "refdistance": "\n\nThe `refDistance` property of the [PannerNode] interface is a double value representing the reference distance for reducing volume as the audio source moves further from the listener – i.e. the distance at which the volume reduction starts taking effect. This value is used by all distance models.\n\nThe `refDistance` property's default value is `1`.",
      "rollofffactor": "\n\nThe `rolloffFactor` property of the [PannerNode] interface is a double value describing how quickly the volume is reduced as the source moves away from the listener. This value is used by all distance models. The `rolloffFactor` property's default value is `1`.",
      "setorientation": "\n\n> **Note:** The suggested replacement for this deprecated method is to instead set the [`orientationX`](/en-US/docs/Web/API/PannerNode/orientationX), [`orientationY`](/en-US/docs/Web/API/PannerNode/orientationY), and [`orientationZ`](/en-US/docs/Web/API/PannerNode/orientationZ) attributes directly.\n\nThe `setOrientation()` method of the [PannerNode] Interface defines the direction the audio source is playing in.\n\nThis can have a big effect if the sound is very directional — controlled by the three cone-related attributes [PannerNode.coneInnerAngle], [PannerNode.coneOuterAngle], and [PannerNode.coneOuterGain]. In such a case, a sound pointing away from the listener can be very quiet or even silent.\n\nThe three parameters `x`, `y` and `z` are unitless and describe a direction vector in 3D space using the right-hand Cartesian coordinate system. The default value of the direction vector is `(1, 0, 0)`.",
      "setposition": "\n\n> **Note:** The suggested replacement for this deprecated method is to instead set the [`positionX`](/en-US/docs/Web/API/PannerNode/positionX), [`positionY`](/en-US/docs/Web/API/PannerNode/positionY), and [`positionZ`](/en-US/docs/Web/API/PannerNode/positionZ) attributes directly.\n\nThe `setPosition()` method of the [PannerNode] Interface defines the position of the audio source relative to the listener (represented by an [AudioListener] object stored in the [BaseAudioContext.listener] attribute.) The three parameters `x`, `y` and `z` are unitless and describe the source's position in 3D space using the right-hand Cartesian coordinate system.\n\nThe `setPosition()` method's default value of the position is `(0, 0, 0)`."
    }
  },
  "passwordcredential": {
    "docs": "\n\nThe interface of the [Credential Management API](/en-US/docs/Web/API/Credential_Management_API) provides information about a username/password pair. In supporting browsers an instance of this class may be passed in the `credential` member of the `init` object for global [fetch].\n\n> **Note:** This interface is restricted to top-level contexts and cannot be used from an `iframe`.\n\n",
    "properties": {
      "iconurl": "\n\nThe **`iconURL`** read-only property\nof the [PasswordCredential] interface returns a string\ncontaining a URL pointing to an image for an icon. This image is intended for display\nin a credential chooser. The URL must be accessible without authentication.",
      "name": "\n\nThe **`name`** read-only property of\nthe [PasswordCredential] interface returns a string\ncontaining a human-readable public name for display in a credential chooser.",
      "password": "\n\nThe **`password`** read-only property\nof the [PasswordCredential] interface returns a string\ncontaining the password of the credential."
    }
  },
  "path2d": {
    "docs": "\n\nThe **`Path2D`** interface of the Canvas 2D API is used to declare a path that can then be used on a [CanvasRenderingContext2D] object. The [path methods](/en-US/docs/Web/API/CanvasRenderingContext2D#paths) of the `CanvasRenderingContext2D` interface are also present on this interface, which gives you the convenience of being able to retain and replay your path whenever desired.",
    "properties": {
      "addpath": "\n\nThe **`Path2D.addPath()`** method\nof the Canvas 2D API adds one [Path2D] object to another\n`Path2D` object."
    }
  },
  "paymentaddress": {
    "docs": "\n\nThe **`PaymentAddress`** interface of the [Payment Request API](/en-US/docs/Web/API/Payment_Request_API) is used to store shipping or payment address information.\n\nIt may be useful to refer to the Universal Postal Union website's [Addressing S42 standard](https://www.upu.int/en/Postal-Solutions/Programmes-Services/Addressing-Solutions#addressing-s42-standard) materials, which provide information about international standards for postal addresses.",
    "properties": {
      "addressline": "\n\nThe **`addressLine`** read-only\nproperty of the [PaymentAddress] interface is an array of\nstrings, each specifying a line of the address that is not\ncovered by one of the other properties of `PaymentAddress`.\n\nThese\nlines may include the street name, house number, apartment number, rural delivery route,\ndescriptive instructions, or post office box.",
      "city": "\n\nThe **`city`** read-only property of\nthe [PaymentAddress] interface returns a string containing the city or\ntown portion of the address.",
      "country": "\n\nThe **`country`** read-only property of the\n[PaymentAddress] interface is a string identifying the address's country\nusing the [ISO 3166-1 alpha-2](https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2) standard. The string is\nalways in its canonical upper-case form.\n\nSome examples of valid `country` values: `\"US\"`,\n`\"GB\"`, `\"CN\"`, or `\"JP\"`.",
      "dependentlocality": "\n\nThe read-only **`dependentLocality`**\nproperty of the [PaymentAddress] interface is a string containing a\nsublocality designation within a city, such as a neighborhood, borough, district, or,\nin the United Kingdom, a dependent locality. Also known as a _post\ntown_.",
      "organization": "\n\nThe **`organization`** read-only\nproperty of the [PaymentAddress] interface returns a string containing\nthe name of the organization, firm, company, or institution at the address.",
      "phone": "\n\nThe read-only **`phone`** property of the\n[PaymentAddress] interface returns a string containing the telephone number\nof the recipient or contact person.",
      "postalcode": "\n\nThe **`postalCode`** read-only property of the\n[PaymentAddress] interface returns a string containing a code used by a\njurisdiction for mail routing, for example, the [ZIP Code](https://en.wikipedia.org/wiki/ZIP_Code)\nin the United States or the [Postal Index Number](https://en.wikipedia.org/wiki/Postal_Index_Number) (PIN code)\nin India.",
      "recipient": "\n\nThe read-only **`recipient`** property of the\n[PaymentAddress] interface returns a string containing the name of the\nrecipient, purchaser, or contact person at the payment address.",
      "region": "\n\nThe read-only **`region`** property of the\n[PaymentAddress] interface returns a string containing the top-level\nadministrative subdivision of the country in which the address is located. For example,\nthis may be a state, province, oblast, or prefecture.",
      "sortingcode": "\n\nThe **`sortingCode`** read-only property of the\n[PaymentAddress] interface returns a string containing a postal sorting\ncode such as is used in France.",
      "tojson": "\n\nThe **`toJSON()`** method of the [PaymentAddress] interface is a standard serializer that returns a JSON representation of the PaymentAddress object's properties."
    }
  },
  "paymentmanager": {
    "docs": "\n\nThe **`PaymentManager`** interface of the [Payment Handler API] is used to manage various aspects of payment app functionality.\n\nIt is accessed via the [ServiceWorkerRegistration.paymentManager] property.\n\n",
    "properties": {
      "enabledelegations": "\n\nThe **`enableDelegations()`** method of the [PaymentManager] interface delegates responsibility for providing various parts of the required payment information to the payment app rather than collecting it from the browser (for example, via autofill).\n\nFor example, if the `requestShipping` option is set to `true` in the options object when invoking the [PaymentRequest.PaymentRequest] constructor, a shipping address will be returned.\n\n- If `enableDelegations()` was used to delegate `shippingAddress`, that address will come from the payment app.\n- If not, it will come from the browser autofill.",
      "userhint": "\n\nThe **`userHint`** property of the [PaymentManager] interface provides a hint for the browser to display along with the payment app's name and icon in the Payment Handler UI."
    }
  },
  "paymentmethodchangeevent": {
    "docs": "\n\nThe **`PaymentMethodChangeEvent`** interface of the [Payment Request API](/en-US/docs/Web/API/Payment_Request_API) describes the [PaymentRequest/paymentmethodchange_event] event which is fired by some payment handlers when the user switches payment instruments (e.g., a user selects a \"store\" card to make a purchase while using Apple Pay).\n\n",
    "properties": {
      "methoddetails": "\n\nThe read-only **`methodDetails`** property of the [PaymentMethodChangeEvent] interface is an object\ncontaining any data the payment handler may provide to describe the change the user\nhas made to their payment method. The value is `null` if no details\nare available.",
      "methodname": "\n\nThe read-only **`methodName`** property of the [PaymentMethodChangeEvent] interface is a string which\nuniquely identifies the payment handler currently selected by the user. The\npayment handler may be a payment technology, such as Apple Pay or Android Pay, and each\npayment handler may support multiple payment methods; changes to the payment method\nwithin the payment handler are described by the `PaymentMethodChangeEvent`."
    }
  },
  "paymentrequest": {
    "docs": "\n\nThe [Payment Request API's](/en-US/docs/Web/API/Payment_Request_API) **`PaymentRequest`** interface is the primary access point into the API, and lets web content and apps accept payments from the end user on behalf of the operator of the site or the publisher of the app.\n\n",
    "properties": {
      "abort": "\n\nThe `PaymentRequest.abort()` method of the [PaymentRequest]\ninterface causes the user agent to end the payment request and to remove any user\ninterface that might be shown.",
      "canmakepayment": "\n\nThe [PaymentRequest] method\n**`canMakePayment()`** determines whether or not the request\nis configured in a way that is compatible with at least one payment method supported\nby the .\n\nYou can call this before calling\n[PaymentRequest.show] to provide a streamlined user experience\nwhen the user's browser can't handle any of the payment methods you accept.\n\nFor instance, you might call `canMakePayment()` to determine if the browser\nwill let the user pay using Payment Request API, and if it won't, you could fall back to\nanother payment method, or offer a list of methods that aren't handled by Payment\nRequest API (or even provide instructions for paying by mail or by phone).",
      "id": "\n\nThe **`id`** read-only attribute of the\n[PaymentRequest] interface returns a unique identifier for a particular\n[PaymentRequest] instance.\n\nWhen constructing an instance of the [PaymentRequest], you are able to\nsupply an custom id. If none is provided, the browser automatically sets the id value to a UUID.",
      "merchantvalidation_event": "\n\n**`merchantvalidation`** events are delivered by the [Payment Request API](/en-US/docs/Web/API/Payment_Request_API) to a [PaymentRequest] object when a payment handler requires that the merchant requesting the purchase validate itself as permitted to use the payment handler.\n\nLearn how the [merchant validation](/en-US/docs/Web/API/Payment_Request_API/Concepts#merchant_validation) process works.\n\nThis event is not cancelable and does not bubble.",
      "paymentmethodchange_event": "\n\nThe **`paymentmethodchange`** event is delivered the [Payment Request API](/en-US/docs/Web/API/Payment_Request_API) to a [PaymentRequest] object when the user changes the payment method within a given payment handler.\n\nFor example, if the user switches from one credit card to another on their [Apple Pay](https://www.apple.com/apple-pay/) account, a `paymentmethodchange` event is fired to let you know about the change.\n\nThis event is not cancelable and does not bubble.",
      "shippingaddress": "\n\nThe **`shippingAddress`** read-only property of\nthe [PaymentRequest] interface returns the shipping address provided by the\nuser. It is `null` by default.",
      "shippingaddresschange_event": "\n\nThe **`shippingaddresschange`** event is sent to the [PaymentRequest] object when the user selects a shipping address or changes details of their shipping address.\n\nThis event is not cancelable and does not bubble.",
      "shippingoption": "\n\nThe **`shippingOption`** read-only attribute of\nthe [PaymentRequest] interface returns either the id of a selected shipping\noption, null (if no shipping option was set to be selected) or a shipping option\nselected by the user. It is initially `null` by when no \"selected\" shipping\noptions are provided.\n\nThis attribute is only populated if the constructor is called with the\n`requestShipping` flag set to `true`. If\n`requestShipping` was `false` (or missing),\n`shippingOption` returns `null`, even the developer provides\na selected a shipping option.",
      "shippingoptionchange_event": "\n\nFor payment requests that request shipping information, and for which shipping options are offered, the **`shippingoptionchange`** event is sent to the [PaymentRequest] whenever the user chooses a shipping option from the list of available options.\n\nThe string identifying the currently-selected shipping option can be found in the [PaymentRequest.shippingOption] property.\n\nThis event is not cancelable and does not bubble.",
      "shippingtype": "\n\nThe **`shippingType`** read-only property of the\n[PaymentRequest] interface returns one of `\"shipping\"`,\n`\"delivery\"`, `\"pickup\"`, or `null` if one was not\nprovided by the constructor.",
      "show": "\n\nThe **[PaymentRequest]** interface's\n**`show()`** method instructs the user agent to begin the\nprocess of showing and handling the user interface for the payment request to the\nuser.\n\nOnly one payment request can be in the process of being handled at once, across all\ndocuments. Once one `PaymentRequest`'s `show()` method has been\ncalled, any other call to `show()` will by rejected with an\n`AbortError` until the returned promise has been concluded, either by being\nfulfilled with a [PaymentResponse] indicating the results of the payment\nrequest, or by being rejected with an error.\n\n> **Note:** In reality, despite the fact that the specification says this\n> can't be done, some browsers, including Firefox, support multiple active payment\n> requests at a time.\n\nIf your architecture doesn't necessarily have all of the data ready to go at the moment\nit instantiates the payment interface by calling `show()`, specify the\n`detailsPromise` parameter, providing a `Promise` that is\nfulfilled once the data is ready. If this is provided, `show()` will not\nallow the user to interact with the payment interface until the promise is fulfilled, so\nthat data can be updated prior to the user engaging with the payment process.\n\nProcessing the result and, if necessary, calling [PaymentResponse.retry]\nto retry a failed payment can all be done either asynchronously or synchronously,\ndepending on your needs. For the best user experience, asynchronous solutions are\ntypically the best way to go. Most examples on MDN and elsewhere use\n[`async`](/en-US/docs/Web/JavaScript/Reference/Statements/async_function)/[`await`](/en-US/docs/Web/JavaScript/Reference/Operators/await)\nto wait asynchronously while results are validated and so forth."
    }
  },
  "paymentrequestevent": {
    "docs": "\n\nThe **`PaymentRequestEvent`** interface of the [Payment Handler API] is the object passed to a payment handler when a [PaymentRequest] is made.\n\n",
    "properties": {
      "changepaymentmethod": "\n\nThe **`changePaymentMethod()`** method of the [PaymentRequestEvent] interface is used by the payment handler to get an updated total, given such payment method details as the billing address.\n\nWhen this method is invoked, a [PaymentMethodChangeEvent] is fired.",
      "instrumentkey": "\n\nThe **`instrumentKey`** read-only property of the\n[PaymentRequestEvent] interface returns a\n`PaymentInstrument` object reflecting the payment instrument selected by\nthe user or an empty string if the user has not registered or chosen a payment\ninstrument.",
      "methoddata": "\n\nThe **`methodData`** read-only property of the\n[PaymentRequestEvent] interface returns an array of\n`PaymentMethodData` objects containing payment method identifiers for the\npayment methods that the website accepts and any associated payment method-specific\ndata.",
      "modifiers": "\n\nThe **`modifiers`** read-only property of the\n[PaymentRequestEvent] interface returns an array of `PaymentDetailsModifier` objects containing modifiers for payment details.",
      "openwindow": "\n\nThe **`openWindow()`** method of the [PaymentRequestEvent] interface opens the specified URL in a new window, only if the given URL is on the same origin as the calling page. It returns a `Promise` that resolves with a reference to a [WindowClient].",
      "paymentrequestid": "\n\nThe **`paymentRequestId`** read-only property of the\n[PaymentRequestEvent] interface returns the ID of the\n[PaymentRequest] object.",
      "paymentrequestorigin": "\n\nThe **`paymentRequestOrigin`** read-only property of the\n[PaymentRequestEvent] interface returns the origin where the\n[PaymentRequest] object was initialized.",
      "respondwith": "\n\nThe **`respondWith()`** method of the [PaymentRequestEvent] interface prevents the default event handling and allows you to provide a `Promise` for a [PaymentResponse] object yourself.",
      "toporigin": "\n\nThe **`topOrigin`** read-only property of the\n[PaymentRequestEvent] interface returns the top-level payee origin where\nthe [PaymentRequest] object was initialized.",
      "total": "\n\nThe **`total`** read-only property of the [PaymentRequestEvent] interface returns a\n`PaymentCurrencyAmount` object containing the total amount being requested for payment."
    }
  },
  "paymentrequestupdateevent": {
    "docs": "\n\nThe **`PaymentRequestUpdateEvent`** interface is used for events sent to a [PaymentRequest] instance when changes are made to shipping-related information for a pending [PaymentRequest]. Those events are:\n\n- [PaymentRequest.shippingaddresschange_event]\n  - : Dispatched whenever the user changes their shipping address.\n- [PaymentRequest.shippingoptionchange_event]\n  - : Dispatched whenever the user changes a shipping option.\n\n",
    "properties": {
      "updatewith": "\n\nThe **`updateWith()`** method of the\n[PaymentRequestUpdateEvent] interface updates the details of an existing\n[PaymentRequest]."
    }
  },
  "paymentresponse": {
    "docs": "\n\nThe **`PaymentResponse`** interface of the [Payment Request API](/en-US/docs/Web/API/Payment_Request_API) is returned after a user selects a payment method and approves a payment request.\n\n",
    "properties": {
      "complete": "\n\nThe [PaymentRequest] method\n**`complete()`** of the [Payment Request API](/en-US/docs/Web/API/Payment_Request_API) notifies the\n that the user interaction is over, and causes any remaining\nuser interface to be closed.\n\nThis method must be called after the user accepts\nthe payment request and the `Promise` returned by the\n[PaymentRequest.show] method is resolved.",
      "details": "\n\nThe **`details`** read-only property of the\n[PaymentResponse] interface returns a JSON-serializable object that\nprovides a payment method specific message used by the merchant to process the\ntransaction and determine a successful funds transfer.\n\nThis data is returned by the payment app that satisfies the payment request. Developers need to consult whomever controls the URL for the expected shape of the details object.",
      "methodname": "\n\nThe **`methodName`** read-only\nproperty of the [PaymentResponse] interface returns a string uniquely\nidentifying the payment handler selected by the user.\n\nThis string may be either\none of the standardized payment method identifiers or a URL used by the payment handler\nto process payments.",
      "payerdetailchange_event": "\n\nA **`payerdetailchange`** event is fired by the [Payment Request API](/en-US/docs/Web/API/Payment_Request_API) to a [PaymentResponse] object when the user makes changes to their personal information while filling out a payment request form. This can happen when the payer is retrying to submit its details after an error has been detected.\n\nThe event handler for `payerdetailchange` should check each value in the form that has changed and ensure that the values are valid. If any are invalid, appropriate error messages should be configured and the [PaymentResponse.retry] method should be called on the [PaymentResponse] to ask the user to update the invalid entries.\n\nThis event is not cancelable and does not bubble.",
      "payeremail": "\n\nThe `payerEmail` read-only property of the [PaymentResponse]\ninterface returns the email address supplied by the user. This option is only present\nwhen the `requestPayerEmail` option is set to `true` in the\n[PaymentOptions] object passed to the\n[PaymentRequest.PaymentRequest] constructor.",
      "payername": "\n\nThe **`payerName`** read-only property of the\n[PaymentResponse] interface returns the name supplied by the user. This\noption is only present when the `requestPayerName` option is set to\n`true` in the options parameter of the\n[PaymentRequest.PaymentRequest] constructor.",
      "payerphone": "\n\nThe `payerPhone` read-only property of the [PaymentResponse]\ninterface returns the phone number supplied by the user. This option is only present\nwhen the `requestPayerPhone` option is set to `true` in the\n[PaymentOptions] object passed to the\n[PaymentRequest.PaymentRequest] constructor.",
      "requestid": "\n\nThe **`requestId`** read-only property of the\n[PaymentResponse] interface returns the free-form identifier supplied by\nthe `PaymentResponse()` constructor by details.id.",
      "retry": "\n\nThe [PaymentResponse] interface's\n**`retry()`** method makes it possible to ask the user to\nretry a payment after an error occurs during processing.\n\nThis lets your app\ngracefully deal with situations such as invalid shipping addresses or declined credit\ncards.",
      "shippingaddress": "\n\nThe **`shippingAddress`** read-only property of\nthe `PaymentRequest` interface returns a [PaymentAddress] object\ncontaining the shipping address provided by the user.",
      "shippingoption": "\n\nThe **`shippingOption`** read-only property of\nthe `PaymentRequest` interface returns the ID attribute of the shipping\noption selected by the user. This option is only present when the\n`requestShipping` option is set to `true` in the\n[PaymentOptions] object passed to the\n[PaymentRequest.PaymentRequest] constructor.",
      "tojson": "\n\nThe **`toJSON()`** method of the [PaymentResponse] interface is a ; it returns a JSON representation of the [PaymentResponse] object."
    }
  },
  "pbkdf2params": {
    "docs": "\n\nThe **`Pbkdf2Params`** dictionary of the [Web Crypto API](/en-US/docs/Web/API/Web_Crypto_API) represents the object that should be passed as the `algorithm` parameter into [SubtleCrypto.deriveKey], when using the [PBKDF2](/en-US/docs/Web/API/SubtleCrypto/deriveKey#pbkdf2) algorithm."
  },
  "performance": {
    "docs": "\n\nThe **`Performance`** interface provides access to performance-related information for the current page.\n\nAn object of this type can be obtained by calling `window.performance` or `self.performance` in workers. Note that Performance entries are per context. If you create a mark on the main thread (or other worker), you cannot see it in a worker thread, and vice versa. See [`self.performance`](/en-US/docs/Web/API/performance_property) for which APIs are available in window and worker contexts.\n\n",
    "properties": {
      "clearmarks": "\n\nThe **`clearMarks()`** method removes all or specific [PerformanceMark] objects from the browser's performance timeline.",
      "clearmeasures": "\n\nThe **`clearMeasures()`** method removes all or specific [PerformanceMeasure] objects from the browser's performance timeline.",
      "clearresourcetimings": "\n\nThe **`clearResourceTimings()`** method removes all performance entries with an [PerformanceEntry.entryType] of \"`resource`\" from the browser's performance timeline and sets the size of the performance resource data buffer to zero.\n\nTo set the size of the browser's performance resource data buffer, use the\n[Performance.setResourceTimingBufferSize] method.\n\nTo get notified when the browser's resource timing buffer is full, listen for the [Performance.resourcetimingbufferfull_event] event.",
      "eventcounts": "\n\nThe read-only `performance.eventCounts` property is an [EventCounts] map containing the number of events which have been dispatched per event type.\n\nNot all event types are exposed. You can only get counts for event types supported by the [PerformanceEventTiming] interface.",
      "getentries": "\n\nThe **`getEntries()`** method returns an array of all [PerformanceEntry] objects currently present in the performance timeline.\n\nIf you are only interested in performance entries of certain types or that have certain names, see [Performance.getEntriesByType] and [Performance.getEntriesByName].\n\n> **Note:** This method does not notify you about new performance entries; you will only get entries that are present in the performance timeline at the time you call this method.\n> To receive notifications about entries as they become available, use a [PerformanceObserver].\n\nThe following entry types are not supported by this method at all and won't be returned even if entries for these types might exist:\n\n- `\"element\"` ([PerformanceElementTiming])\n- `\"event\"` ([PerformanceEventTiming])\n- `\"largest-contentful-paint\"` ([LargestContentfulPaint])\n- `\"layout-shift\"` ([LayoutShift])\n- `\"longtask\"` ([PerformanceLongTaskTiming])\n\nTo access entries of these types, you must use a [PerformanceObserver] instead.",
      "getentriesbyname": "\n\nThe **`getEntriesByName()`** method returns an array of [PerformanceEntry] objects currently present in the performance timeline with the given _name_ and _type_.\n\nIf you are interested in performance entries of certain types, see [Performance.getEntriesByType]. For all performance entries, see [Performance.getEntries].\n\n> **Note:** This method does not notify you about new performance entries; you will only get entries that are present in the performance timeline at the time you call this method.\n> To receive notifications about entries as they become available, use a [PerformanceObserver].\n\nThe following entry types are not supported by this method at all and won't be returned even if entries for these types might exist:\n\n- `\"element\"` ([PerformanceElementTiming])\n- `\"event\"` ([PerformanceEventTiming])\n- `\"largest-contentful-paint\"` ([LargestContentfulPaint])\n- `\"layout-shift\"` ([LayoutShift])\n- `\"longtask\"` ([PerformanceLongTaskTiming])\n\nTo access entries of these types, you must use a [PerformanceObserver] instead.",
      "getentriesbytype": "\n\nThe **`getEntriesByType()`** method returns an array of [PerformanceEntry] objects currently present in the performance timeline for a given _type_.\n\nIf you are interested in performance entries of certain name, see [Performance.getEntriesByName]. For all performance entries, see [Performance.getEntries].\n\n> **Note:** This method does not notify you about new performance entries; you will only get entries that are present in the performance timeline at the time you call this method.\n> To receive notifications about entries as they become available, use a [PerformanceObserver].\n\nThe following entry types are not supported by this method at all and won't be returned even if entries for these types might exist:\n\n- `\"element\"` ([PerformanceElementTiming])\n- `\"event\"` ([PerformanceEventTiming])\n- `\"largest-contentful-paint\"` ([LargestContentfulPaint])\n- `\"layout-shift\"` ([LayoutShift])\n- `\"longtask\"` ([PerformanceLongTaskTiming])\n\nTo access entries of these types, you must use a [PerformanceObserver] instead.",
      "mark": "\n\nThe **`mark()`** method creates a named [PerformanceMark] object representing a high resolution timestamp marker in the browser's performance timeline.",
      "measure": "\n\nThe **`measure()`** method creates a named [PerformanceMeasure] object representing a time measurement between two marks in the browser's performance timeline.\n\nWhen measuring between two marks, there is a _start mark_ and _end mark_, respectively.\nThe named timestamp is referred to as a _measure_.",
      "measureuseragentspecificmemory": " \n\nThe **`measureUserAgentSpecificMemory()`** method is used to estimate the memory usage of a web application including all its iframes and workers.",
      "memory": " \n\nThe non-standard and legacy `performance.memory` property returns the size of the JavaScript heap which can be helpful to measure and reduce the memory footprint of websites.\n\nNote that the information this API provides is unreliable as it might overestimate actual memory usage if web pages share the same heap, or might underestimate actual memory usage if web pages use workers and/or cross-site iframes that are allocated in separate heaps. It is not standardized what \"heap\" means exactly. The API is only available in Chromium-based browsers.\n\nA new API aiming to replace `performance.memory` is [Performance.measureUserAgentSpecificMemory]. It tries to estimate the memory used by a web page.",
      "navigation": "\n\nThe legacy\n**`Performance.navigation`**\nread-only property returns a [PerformanceNavigation] object representing\nthe type of navigation that occurs in the given browsing context, such as the number of\nredirections needed to fetch the resource.\n\nThis property is not available in workers.\n\n> **Warning:** This property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete). Please use the\n> [PerformanceNavigationTiming] interface instead.",
      "now": "\n\nThe **`performance.now()`** method returns a high resolution timestamp in milliseconds. It represents the time elapsed since [Performance.timeOrigin] (the time when navigation has started in window contexts, or the time when the worker is run in [Worker] and [ServiceWorker] contexts).",
      "resourcetimingbufferfull_event": "\n\nThe `resourcetimingbufferfull` event is fired when the browser's [resource timing buffer](/en-US/docs/Web/API/Performance/setResourceTimingBufferSize) is full.",
      "setresourcetimingbuffersize": "\n\nThe **`setResourceTimingBufferSize()`** method sets the desired size of the browser's resource timing buffer which stores the \"`resource`\" performance entries.\n\nThe specification requires the resource timing buffer initially to be 250 or greater.\n\nTo clear the browser's performance resource data buffer, use the\n[Performance.clearResourceTimings] method.\n\nTo get notified when the browser's resource timing buffer is full, listen for the [Performance.resourcetimingbufferfull_event] event.",
      "timeorigin": "\n\nThe **`timeOrigin`** read-only property of the [Performance] interface returns the high resolution timestamp that is used as the baseline for performance-related timestamps.\n\nIn Window contexts, this value represents the time when navigation has started. In [Worker] and [ServiceWorker] contexts, this value represents the time when the worker is run. You can use this property to synchronize the time origins between the contexts (see example below).\n\n> **Note:** The value of `performance.timeOrigin` may differ from the value returned by `Date.now()` executed at the time origin, because `Date.now()` may have been impacted by system and user clock adjustments, clock skew, etc. The `timeOrigin` property is a [monotonic clock](https://w3c.github.io/hr-time/#dfn-monotonic-clock) which current time never decreases and which isn't subject to these adjustments.",
      "timing": "\n\nThe legacy\n**`Performance.timing`** read-only\nproperty returns a [PerformanceTiming] object containing latency-related\nperformance information.\n\nThis property is not available in workers.\n\n> **Warning:** This property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete). Please use the [PerformanceNavigationTiming]\n> interface instead.",
      "tojson": "\n\nThe **`toJSON()`** method of the [Performance] interface is a ; it returns a JSON representation of the [Performance] object."
    }
  },
  "performanceelementtiming": {
    "docs": "\n\nThe **`PerformanceElementTiming`** interface contains render timing information for image and text node elements the developer annotated with an [`elementtiming`](/en-US/docs/Web/HTML/Attributes/elementtiming) attribute for observation.",
    "properties": {
      "element": "\n\nThe **`element`** read-only property of the [PerformanceElementTiming] interface returns an [Element] which is a pointer to the observed element.",
      "id": "\n\nThe **`id`** read-only property of the [PerformanceElementTiming] interface returns the [`id`](/en-US/docs/Web/HTML/Global_attributes#id) of the associated element.",
      "identifier": "\n\nThe **`identifier`** read-only property of the [PerformanceElementTiming] interface returns the value of the [`elementtiming`](/en-US/docs/Web/HTML/Attributes/elementtiming) attribute on the element.",
      "intersectionrect": "\n\nThe **`intersectionRect`** read-only property of the [PerformanceElementTiming] interface returns the rectangle of the element within the viewport.",
      "loadtime": "\n\nThe **`loadTime`** read-only property of the [PerformanceElementTiming] interface always returns `0` for text. For images it returns the time which is the latest between the time the image resource is loaded and the time it is attached to the element.",
      "naturalheight": "\n\nThe **`naturalHeight`** read-only property of the [PerformanceElementTiming] interface returns the intrinsic height of the image element.",
      "naturalwidth": "\n\nThe **`naturalWidth`** read-only property of the [PerformanceElementTiming] interface returns the intrinsic width of the image element.",
      "rendertime": "\n\nThe **`renderTime`** read-only property of the [PerformanceElementTiming] interface returns the render time of the associated element.",
      "tojson": "\n\nThe **`toJSON()`** method of the [PerformanceElementTiming] interface is a ; it returns a JSON representation of the [PerformanceElementTiming] object.",
      "url": "\n\nThe **`url`** read-only property of the [PerformanceElementTiming] interface returns the initial URL of the resource request when the element is an image."
    }
  },
  "performanceentry": {
    "docs": " \n\nThe **`PerformanceEntry`** object encapsulates a single performance metric that is part of the browser's performance timeline.\n\nThe Performance API offers built-in metrics which are specialized subclasses of `PerformanceEntry`. This includes entries for resource loading, event timing,  (FID), and more.\n\nA performance entry can also be created by calling the [Performance.mark] or [Performance.measure] methods at an explicit point in an application. This allows you to add your own metrics to the performance timeline.\n\nThe `PerformanceEntry` instances will always be one of the following subclasses:\n\n- [LargestContentfulPaint]\n- [LayoutShift]\n- [PerformanceEventTiming]\n- [PerformanceLongTaskTiming]\n- [PerformanceMark]\n- [PerformanceMeasure]\n- [PerformanceNavigationTiming]\n- [PerformancePaintTiming]\n- [PerformanceResourceTiming]\n- [PerformanceServerTiming]\n- [TaskAttributionTiming]\n- [VisibilityStateEntry]",
    "properties": {
      "duration": "\n\nThe read-only **`duration`** property returns a  that is the duration of the . The meaning of this property depends on the value of this entry's [PerformanceEntry.entryType].",
      "entrytype": " \n\nThe read-only **`entryType`** property returns a string representing the type of performance metric that this entry represents.\n\nAll supported `entryTypes` are available using the static property [PerformanceObserver.supportedEntryTypes_static].",
      "name": " \n\nThe read-only **`name`** property of the [PerformanceEntry] interface is a string representing the name for a performance entry. It acts as an identifier, but it does not have to be unique. The value depends on the subclass.",
      "starttime": "\n\nThe read-only **`startTime`** property returns the first  recorded for this . The meaning of this property depends on the value of this entry's [PerformanceEntry.entryType].",
      "tojson": "\n\nThe **`toJSON()`** method is a ; it returns a JSON representation of the [PerformanceEntry] object."
    }
  },
  "performanceeventtiming": {
    "docs": "\n\nThe `PerformanceEventTiming` interface of the Event Timing API provides insights into the latency of certain event types triggered by user interaction.",
    "properties": {
      "cancelable": "\n\nThe read-only **`cancelable`** property returns the associated event's [`cancelable`](/en-US/docs/Web/API/Event/cancelable) property, indicating whether the event can be canceled.",
      "interactionid": "\n\nThe read-only **`interactionId`** property returns an ID that uniquely identifies a user interaction which triggered a series of associated events.",
      "processingend": "\n\nThe read-only **`processingEnd`** property returns the time the last event handler finished executing.\n\nIt's equal to [PerformanceEventTiming.processingStart] when there are no such event handlers.",
      "processingstart": "\n\nThe read-only **`processingStart`** property returns the time at which event dispatch started. This is when event handlers are about to be executed.",
      "target": "\n\nThe read-only **`target`** property returns the associated event's last [`target`](/en-US/docs/Web/API/Event/target) which is the node onto which the event was last dispatched.",
      "tojson": "\n\nThe **`toJSON()`** method of the [PerformanceEventTiming] interface is a ; it returns a JSON representation of the [PerformanceEventTiming] object."
    }
  },
  "performancelongtasktiming": {
    "docs": "\n\nThe **`PerformanceLongTaskTiming`** interface provides information about tasks that occupy the UI thread for 50 milliseconds or more.",
    "properties": {
      "attribution": "\n\nThe **`attribution`** readonly property of the [PerformanceLongTaskTiming] interface returns an array of [TaskAttributionTiming] objects.",
      "tojson": "\n\nThe **`toJSON()`** method of the [PerformanceLongTaskTiming] interface is a ; it returns a JSON representation of the [PerformanceLongTaskTiming] object."
    }
  },
  "performancemark": {
    "docs": "\n\n**`PerformanceMark`** is an interface for [PerformanceEntry] objects with an [PerformanceEntry.entryType] of \"`mark`\".\n\nEntries of this type are typically created by calling [Performance.mark] to add a _named_ [DOMHighResTimeStamp] (the _mark_) to the browser's performance timeline. To create a performance mark that isn't added to the browser's performance timeline, use the constructor.\n\n",
    "properties": {
      "detail": "\n\nThe read-only **`detail`** property returns arbitrary metadata that was included in the mark upon construction (either when using [Performance.mark] or the [PerformanceMark.PerformanceMark] constructor)."
    }
  },
  "performancemeasure": {
    "docs": "\n\n**`PerformanceMeasure`** is an _abstract_ interface for [PerformanceEntry] objects with an [PerformanceEntry.entryType] of \"`measure`\". Entries of this type are created by calling [Performance.measure] to add a _named_ [DOMHighResTimeStamp] (the _measure_) between two _marks_ to the browser's _performance timeline_.\n\n",
    "properties": {
      "detail": "\n\nThe read-only **`detail`** property returns arbitrary metadata that was included in the mark upon construction (when using [Performance.measure]."
    }
  },
  "performancenavigation": {
    "docs": "\n\nThe legacy **`PerformanceNavigation`** interface represents information about how the navigation to the current document was done.\n\n> **Warning:** This interface is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete).\n> Please use the [PerformanceNavigationTiming] interface instead.\n\nAn object of this type can be obtained by calling the [Performance.navigation] read-only attribute.",
    "properties": {
      "redirectcount": "\n\nThe legacy\n**`PerformanceNavigation.redirectCount`**\nread-only property returns an `unsigned short` representing the number of\nREDIRECTs done before reaching the page.\n\n> **Warning:** This interface of this property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete).\n> Please use the [PerformanceNavigationTiming] interface instead.",
      "tojson": " \n\n> **Warning:** This interface of this property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete). Please use the [PerformanceNavigationTiming]\n> interface instead.\n\nThe **`toJSON()`** method of the [PerformanceNavigation] interface is a ; it returns a JSON representation of the [PerformanceNavigation] object.",
      "type": "\n\nThe legacy\n**`PerformanceNavigation.type`**\nread-only property returns an `unsigned short` containing a constant\ndescribing how the navigation to this page was done.\n\n> **Warning:** This interface of this property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete).\n> Please use the [PerformanceNavigationTiming] interface instead."
    }
  },
  "performancenavigationtiming": {
    "docs": "\n\nThe **`PerformanceNavigationTiming`** interface provides methods and properties to store and retrieve metrics regarding the browser's document navigation events. For example, this interface can be used to determine how much time it takes to load or unload a document.\n\nOnly the current document is included in the performance timeline, so there is only one `PerformanceNavigationTiming` object in the performance timeline. It inherits all of the properties and methods of [PerformanceResourceTiming] and [PerformanceEntry].\n\nThe following diagram shows all of the timestamp properties defined in `PerformanceNavigationTiming`.\n\n![Timestamp diagram listing timestamps in the order in which they are recorded for the fetching of a document](timestamp-diagram.svg)",
    "properties": {
      "activationstart": "\n\nThe **`activationStart`** read-only property represents the time between when a document starts prerendering and when it is activated.",
      "domcomplete": "\n\nThe **`domComplete`** read-only property returns a [DOMHighResTimeStamp] representing the time immediately before the user agent sets the document's [`readyState`](/en-US/docs/Web/API/Document/readyState) to `\"complete\"`.\n\nSee also the `complete` state of [Document.readyState] which corresponds to this property and refers to the state in which the document and all sub-resources have finished loading. The state also indicates that the [Window/load_event] event is about to fire.",
      "domcontentloadedeventend": "\n\nThe **`domContentLoadedEventEnd`** read-only property returns a [DOMHighResTimeStamp] representing the time immediately after the current document's [`DOMContentLoaded`](/en-US/docs/Web/API/Document/DOMContentLoaded_event) event handler completes.\n\nTypically frameworks and libraries wait for the `DOMContentLoaded` event before starting to run their code. We can use the `domContentLoadedEventEnd` and the [`domContentLoadedEventStart`](/en-US/docs/Web/API/PerformanceNavigationTiming/domContentLoadedEventStart) properties to calculate how long this takes to run.",
      "domcontentloadedeventstart": "\n\nThe **`domContentLoadedEventStart`** read-only property returns a [DOMHighResTimeStamp] representing the time immediately before the current document's [`DOMContentLoaded`](/en-US/docs/Web/API/Document/DOMContentLoaded_event) event handler starts.\n\nTypically frameworks and libraries wait for the `DOMContentLoaded` event before starting to run their code. We can use the `domContentLoadedEventStart` and the [`domContentLoadedEventEnd`](/en-US/docs/Web/API/PerformanceNavigationTiming/domContentLoadedEventEnd) properties to calculate how long this takes to run.",
      "dominteractive": "\n\nThe **`domInteractive`** read-only property returns a [DOMHighResTimeStamp] representing the time immediately before the user agent sets the document's [`readyState`](/en-US/docs/Web/API/Document/readyState) to `\"interactive\"`.\n\n> **Note:** This property is **not**  (TTI). This property refers to the time when DOM construction is finished and interaction to it from JavaScript is possible. See also the `interactive` state of [Document.readyState] which corresponds to this property.\n\nMeasuring DOM processing time may not be consequential unless your site has a very large HTML source to a construct a Document Object Model from.\n\nIf there is no parser-blocking JavaScript then the [`DOMContentLoaded`](/en-US/docs/Web/API/Document/DOMContentLoaded_event) event (see [`domContentLoadedEventStart`](/en-US/docs/Web/API/PerformanceNavigationTiming/domContentLoadedEventStart) for the timestamp) will fire immediately after `domInteractive`.",
      "loadeventend": "\n\nThe **`loadEventEnd`** read-only property returns a [DOMHighResTimeStamp] representing the time immediately after the current document's [`load`](/en-US/docs/Web/API/Window/load_event) event handler completes.",
      "loadeventstart": "\n\nThe **`loadEventStart`** read-only property returns a [DOMHighResTimeStamp] representing the time immediately before the current document's [`load`](/en-US/docs/Web/API/Window/load_event) event handler starts.",
      "redirectcount": "\n\nThe **`redirectCount`** read-only property returns a number representing the number of redirects since the last non-redirect navigation in the current browsing context.\n\nThe higher the number of redirects on a page, the longer the page load time. To improve the performance of your web page, avoid multiple redirects.\n\nThe [PerformanceResourceTiming.redirectStart] and [PerformanceResourceTiming.redirectEnd] properties can be used to measure redirection time. Note that they will return `0` for cross-origin redirects.\n\nNote that client side redirects, such as `<meta http-equiv=\"refresh\" content=\"0; url=https://example.com/\">` are not considered here.",
      "tojson": "\n\nThe **`toJSON()`** method of the [PerformanceNavigationTiming] interface is a ; it returns a JSON representation of the [PerformanceNavigationTiming] object.",
      "type": "\n\nThe **`type`** read-only property returns the type of navigation.\n\nYou can use this property to categorize your navigation timing data as each of these types will have different performance characteristics. Users going back and forth might experience a faster site than users performing navigation for the first time or submitting forms, etc.\n\nFor example, if your site provides new content frequently, you might want to refresh that content using [Fetch](/en-US/docs/Web/API/Fetch_API) or similar and avoid users having to hit reload for the entire page all the time. The `\"reload\"` type can help you find pages that are reloaded frequently.",
      "unloadeventend": "\n\nThe **`unloadEventEnd`** read-only property returns a [DOMHighResTimeStamp] representing the time immediately after the current document's [`unload`](/en-US/docs/Web/API/Window/unload_event) event handler completes.",
      "unloadeventstart": "\n\nThe **`unloadEventStart`** read-only property returns a [DOMHighResTimeStamp] representing the time immediately before the current document's [`unload`](/en-US/docs/Web/API/Window/unload_event) event handler starts."
    }
  },
  "performanceobserver": {
    "docs": " \n\nThe **`PerformanceObserver`** interface is used to observe performance measurement events and be notified of new [PerformanceEntry] as they are recorded in the browser's _performance timeline_.",
    "properties": {
      "disconnect": "\n\nThe **`disconnect()`** method of the [PerformanceObserver] interface is used to stop the performance observer from receiving any [PerformanceEntry] events.",
      "observe": "\n\nThe **`observe()`** method of the **[PerformanceObserver]** interface is used to specify the set of performance entry types to observe.\n\nSee [PerformanceEntry.entryType] for a list of entry types and [PerformanceObserver.supportedEntryTypes_static] for a list of entry types the user agent supports.\n\nWhen a matching performance entry is recorded, the performance observer's callback function—set when creating the [PerformanceObserver]—is invoked.",
      "supportedentrytypes_static": "\n\nThe static **`supportedEntryTypes`** read-only property of the [PerformanceObserver] interface returns an array of the [PerformanceEntry.entryType] values supported by the user agent.\n\nAs the list of supported entries varies per browser and is evolving, this property allows web developers to check which are available.",
      "takerecords": "\n\nThe **`takeRecords()`** method of the [PerformanceObserver] interface returns the current list of [PerformanceEntry] stored in the performance observer, emptying it out."
    }
  },
  "performanceobserverentrylist": {
    "docs": "\n\nThe **`PerformanceObserverEntryList`** interface is a list of [PerformanceEntry] that were explicitly observed via the [PerformanceObserver.observe] method.",
    "properties": {
      "getentries": "\n\nThe **`getEntries()`** method of the [PerformanceObserverEntryList] interface returns a list of explicitly observed [PerformanceEntry] objects. The list's members are determined by the set of [PerformanceEntry.entryType] specified in the call to the [PerformanceObserver.observe] method. The list is available in the observer's callback function (as the first parameter in the callback).",
      "getentriesbyname": "\n\nThe **`getEntriesByName()`** method of the [PerformanceObserverEntryList] interface returns a list of explicitly observed [PerformanceEntry] objects for a given [PerformanceEntry.name] and [PerformanceEntry.entryType]. The list's members are determined by the set of [PerformanceEntry.entryType] specified in the call to the [PerformanceObserver.observe] method. The list is available in the observer's callback function (as the first parameter in the callback).",
      "getentriesbytype": "\n\nThe **`getEntriesByType()`** method of the [PerformanceObserverEntryList] returns a list of explicitly _observed_ [PerformanceEntry] objects for a given [PerformanceEntry.entryType]. The list's members are determined by the set of [PerformanceEntry.entryType] specified in the call to the [PerformanceObserver.observe] method. The list is available in the observer's callback function (as the first parameter in the callback)."
    }
  },
  "performancepainttiming": {
    "docs": "\n\nThe **`PerformancePaintTiming`** interface provides timing information about \"paint\" (also called \"render\") operations during web page construction. \"Paint\" refers to conversion of the render tree to on-screen pixels.\n\nThere are two key paint moments this API provides:\n\n-  (FP): Time when anything is rendered. Note that the marking of the first paint is optional, not all user agents report it.\n-  (FCP): Time when the first bit of DOM text or image content is rendered.\n\nA third key paint moment is provided by the [LargestContentfulPaint] API:\n\n-  (LCP): Render time of the largest image or text block visible within the viewport, recorded from when the page first begins to load.\n\nThe data this API provides helps you minimize the time that users have to wait before they can see the site's content start to appear. Decreasing the time until these key paint moments make sites feel more responsive, performant, and engaging for your users.\n\nLike other Performance APIs, this API extends [PerformanceEntry].\n\n"
  },
  "performanceresourcetiming": {
    "docs": " \n\nThe **`PerformanceResourceTiming`** interface enables retrieval and analysis of detailed network timing data regarding the loading of an application's resources. An application can use the timing metrics to determine, for example, the length of time it takes to fetch a specific resource, such as an [XMLHttpRequest], , image, or script.",
    "properties": {
      "connectend": "\n\nThe **`connectEnd`** read-only property returns the [DOMHighResTimeStamp] immediately after the browser finishes establishing the connection to the server to retrieve the resource. The timestamp value includes the time interval to establish the transport connection, as well as other time intervals such as TLS handshake and [SOCKS](https://en.wikipedia.org/wiki/SOCKS) authentication.",
      "connectstart": "\n\nThe **`connectStart`** read-only property returns the [DOMHighResTimeStamp] immediately before the user agent starts establishing the connection to the server to retrieve the resource.",
      "decodedbodysize": "\n\nThe **`decodedBodySize`** read-only property returns the size (in octets) received from the fetch (HTTP or cache) of the message body after removing any applied content encoding (like gzip or Brotli). If the resource is retrieved from an application cache or local resources, it returns the size of the payload after removing any applied content encoding.",
      "deliverytype": "\n\nThe **`deliveryType`** read-only property is a string indicating how the resource was delivered — for example from the cache or from a navigational prefetch.",
      "domainlookupend": "\n\nThe **`domainLookupEnd`** read-only property returns the [DOMHighResTimeStamp] immediately after the browser finishes the domain-name lookup for the resource.\n\nIf the user agent has the domain information in cache, [PerformanceResourceTiming.domainLookupStart] and [PerformanceResourceTiming.domainLookupEnd] represent the times when the user agent starts and ends the domain data retrieval from the cache.",
      "domainlookupstart": "\n\nThe **`domainLookupStart`** read-only property returns the [DOMHighResTimeStamp] immediately before the browser starts the domain name lookup for the resource.",
      "encodedbodysize": "\n\nThe **`encodedBodySize`** read-only property represents the size (in octets) received from the fetch (HTTP or cache) of the payload body before removing any applied content encodings (like gzip or Brotli). If the resource is retrieved from an application cache or a local resource, it must\nreturn the size of the payload body before removing any applied content encoding.",
      "fetchstart": "\n\nThe **`fetchStart`** read-only property represents a [DOMHighResTimeStamp] immediately before the browser starts to fetch the resource.\n\nIf there are HTTP redirects, the property returns the time immediately before the user agent starts to fetch the final resource in the redirection.\n\nUnlike many other `PerformanceResourceTiming` properties, the `fetchStart` property is available for cross-origin requests without the need of the  HTTP response header.",
      "firstinterimresponsestart": "\n\nThe **`firstInterimResponseStart`** read-only property returns a [DOMHighResTimeStamp] immediately after the browser receives the first byte of the interim 1xx response (for example, 100 Continue or 103 Early Hints) from the server.\n\nThere is no _end_ property for `firstInterimResponseStart`.",
      "initiatortype": "\n\nThe **`initiatorType`** read-only property is a string representing web platform feature that initiated the resource load.\n\n> **Note:** This property does not represent the type of content fetched. A `.css` file can be fetched using a `link` element leading to an `initiatorType` of `link`. When loading images using `background: url()` in a CSS file, the `initiatorType` will be `css` and not `img`.",
      "nexthopprotocol": "\n\nThe **`nextHopProtocol`** read-only property is a string representing the network protocol used to fetch the resource, as identified by the [ALPN Protocol ID (RFC7301)](https://www.iana.org/assignments/tls-extensiontype-values/tls-extensiontype-values.xhtml#alpn-protocol-ids).\n\nWhen a proxy is used, if a tunnel connection is established, this property returns the ALPN Protocol ID of the tunneled protocol. Otherwise, this property returns the ALPN Protocol ID of the first hop to the proxy.",
      "redirectend": "\n\nThe **`redirectEnd`** read-only property returns a [DOMHighResTimeStamp] immediately after receiving the last byte of the response of the last redirect.\n\nWhen fetching a resource, if there are multiple HTTP redirects, and any of the redirects have an origin that is different from the current document, and the timing allow check algorithm passes for each redirected resource, this property returns the time immediately after receiving the last byte of the response of the last redirect; otherwise, zero is returned.\n\nTo get the amount of redirects, see also [PerformanceNavigationTiming.redirectCount].",
      "redirectstart": "\n\nThe **`redirectStart`** read-only property returns a [DOMHighResTimeStamp] representing the start time of the fetch which that initiates the redirect.\n\nIf there are HTTP redirects when fetching the resource and if any of the redirects are not from the same origin as the current document, but the timing allow check algorithm passes for each redirected resource, this property returns the starting time of the fetch that initiates the redirect; otherwise, zero is returned.\n\nTo get the amount of redirects, see also [PerformanceNavigationTiming.redirectCount].",
      "renderblockingstatus": "\n\nThe **`renderBlockingStatus`** read-only property returns the render-blocking status of the resource.\n\nIt is useful to determine resources that:\n\n- weren't render-blocking and therefore could be delayed, or\n- were render-blocking and therefore could be preloaded.",
      "requeststart": "\n\nThe **`requestStart`** read-only property returns a [DOMHighResTimeStamp] of the time immediately before the browser starts requesting the resource from the server, cache, or local resource. If the transport connection fails and the browser retires the request, the value returned will be the start of the retry request.\n\nThere is no _end_ property for `requestStart`. To measure the request time, calculate [PerformanceResourceTiming.responseStart] - `requestStart` (see the example below).",
      "responseend": "\n\nThe **`responseEnd`** read-only property returns a [DOMHighResTimeStamp] immediately after the browser receives the last byte of the resource or immediately before the transport connection is closed, whichever comes first.\n\nUnlike many other `PerformanceResourceTiming` properties, the `responseEnd` property is available for cross-origin requests without the need of the  HTTP response header.",
      "responsestart": "\n\nThe **`responseStart`** read-only property returns a [DOMHighResTimeStamp] immediately after the browser receives the first byte of the response from the server, cache, or local resource.",
      "responsestatus": " \n\nThe **`responseStatus`** read-only property represents the HTTP response status code returned when fetching the resource.\n\nThis property maps to [Response.status] from the [Fetch API](/en-US/docs/Web/API/Fetch_API).",
      "secureconnectionstart": "\n\nThe **`secureConnectionStart`** read-only property returns a [DOMHighResTimeStamp] immediately before the browser starts the handshake process to secure the current connection. If a secure connection is not used, the property returns zero.",
      "servertiming": " \n\nThe **`serverTiming`** read-only property returns an array of [PerformanceServerTiming] entries containing server timing metrics.\n\nServer timing metrics require the server to send the  header. For example:\n\n```http\nServer-Timing: cache;desc=\"Cache Read\";dur=23.2\n```\n\nThe `serverTiming` entries can live on `navigation` and `resource` entries.",
      "tojson": "\n\nThe **`toJSON()`** method of the [PerformanceResourceTiming] interface is a ; it returns a JSON representation of the [PerformanceResourceTiming] object.",
      "transfersize": "\n\nThe **`transferSize`** read-only property represents the size (in octets) of the fetched resource. The size includes the response header fields plus the response payload body (as defined by [RFC7230](https://httpwg.org/specs/rfc7230.html#message.body)).\n\nIf the resource is fetched from a local cache, or if it is a cross-origin resource, this property returns zero.",
      "workerstart": "\n\nThe **`workerStart`** read-only property of the [PerformanceResourceTiming] interface returns a\n[DOMHighResTimeStamp] immediately before dispatching the [FetchEvent] if a Service Worker thread is already running, or immediately before starting the Service Worker thread if it is not already running. If the resource is not intercepted by a Service Worker the property will always return 0."
    }
  },
  "performanceservertiming": {
    "docs": "  \n\nThe **`PerformanceServerTiming`** interface surfaces server metrics that are sent with the response in the  HTTP header.\n\nThis interface is restricted to the same origin, but you can use the  header to specify the domains that are allowed to access the server metrics. Note that this interface is only available in secure contexts (HTTPS) in some browsers.",
    "properties": {
      "description": "\n\nThe **`description`** read-only property returns a\nstring value of the server-specified metric description, or an empty\nstring.",
      "duration": "\n\nThe **`duration`** read-only property returns a double that contains the server-specified metric duration, or the value `0.0`.",
      "name": "\n\nThe **`name`** read-only property returns a\nstring value of the server-specified metric name.",
      "tojson": "\n\nThe **`toJSON()`** method of the [PerformanceServerTiming] interface is a ; it returns a JSON representation of the [PerformanceServerTiming] object."
    }
  },
  "performancetiming": {
    "docs": "\n\n> **Warning:** This interface is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete). Please use the [PerformanceNavigationTiming] interface instead.\n\nThe **`PerformanceTiming`** interface is a legacy interface kept for backwards compatibility and contains properties that offer performance timing information for various events which occur during the loading and use of the current page. You get a `PerformanceTiming` object describing your page using the [Performance.timing] property.",
    "properties": {
      "connectend": "\n\n> **Warning:** This interface of this property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete). Please use the [PerformanceNavigationTiming]\n> interface instead.\n\nThe legacy\n**`PerformanceTiming.connectEnd`**\nread-only property returns an `unsigned long long` representing the moment,\nin milliseconds since the UNIX epoch, where the connection is opened network. If the\ntransport layer reports an error and the connection establishment is started again, the\nlast connection establishment end time is given. If a persistent connection is used, the\nvalue will be the same as [PerformanceTiming.fetchStart]. A connection is\nconsidered as opened when all secure connection handshake, or SOCKS authentication, is\nterminated.",
      "connectstart": "\n\n> **Warning:** This interface of this property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete). Please use the [PerformanceNavigationTiming]\n> interface instead.\n\nThe legacy\n**`PerformanceTiming.connectStart`**\nread-only property returns an `unsigned long long` representing the moment,\nin milliseconds since the UNIX epoch, where the request to open a connection is sent to\nthe network. If the transport layer reports an error and the connection establishment is\nstarted again, the last connection establishment start time is given. If a persistent\nconnection is used, the value will be the same as\n[PerformanceTiming.fetchStart].",
      "domainlookupend": "\n\n> **Warning:** This interface of this property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete). Please use the [PerformanceNavigationTiming]\n> interface instead.\n\nThe legacy\n**`PerformanceTiming.domainLookupEnd`**\nread-only property returns an `unsigned long long` representing the moment,\nin milliseconds since the UNIX epoch, where the domain lookup is finished. If a\npersistent connection is used, or the information is stored in a cache or a local\nresource, the value will be the same as [PerformanceTiming.fetchStart].",
      "domainlookupstart": "\n\n> **Warning:** This interface of this property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete). Please use the [PerformanceNavigationTiming]\n> interface instead.\n\nThe legacy\n**`PerformanceTiming.domainLookupStart`**\nread-only property returns an `unsigned long long` representing the moment,\nin milliseconds since the UNIX epoch, where the domain lookup starts. If a persistent\nconnection is used, or the information is stored in a cache or a local resource, the\nvalue will be the same as [PerformanceTiming.fetchStart].",
      "domcomplete": "\n\n> **Warning:** This interface of this property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete). Please use the [PerformanceNavigationTiming]\n> interface instead.\n\nThe legacy\n**`PerformanceTiming.domComplete`**\nread-only property returns an `unsigned long long` representing the moment,\nin milliseconds since the UNIX epoch, when the parser finished its work on the main\ndocument, that is when its [Document.readyState] changes to\n`'complete'` and the corresponding [Document/readystatechange_event] event is\nthrown.",
      "domcontentloadedeventend": "\n\n> **Warning:** This interface of this property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete). Please use the [PerformanceNavigationTiming]\n> interface instead.\n\nThe legacy\n**`PerformanceTiming.domContentLoadedEventEnd`**\nread-only property returns an `unsigned long long` representing the moment,\nin milliseconds since the UNIX epoch, right after all the scripts that need to be\nexecuted as soon as possible, in order or not, has been executed.",
      "domcontentloadedeventstart": "\n\n> **Warning:** This interface of this property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete). Please use the [PerformanceNavigationTiming]\n> interface instead.\n\nThe legacy\n**`PerformanceTiming.domContentLoadedEventStart`**\nread-only property returns an `unsigned long long` representing the moment,\nin milliseconds since the UNIX epoch, right before the parser sent the\n[Document/DOMContentLoaded_event] event, that is right after all the scripts that need to be\nexecuted right after parsing has been executed.",
      "dominteractive": "\n\n> **Warning:** This interface of this property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete). Please use the [PerformanceNavigationTiming]\n> interface instead.\n\nThe legacy\n**`PerformanceTiming.domInteractive`**\nread-only property returns an `unsigned long long` representing the moment,\nin milliseconds since the UNIX epoch, when the parser finished its work on the main\ndocument, that is when its [Document.readyState] changes to\n`'interactive'` and the corresponding [Document/readystatechange_event] event is\nthrown.\n\nThis property can be used to measure the speed of loading websites that users\n_feels_. Nevertheless there are a few caveats that happens if scripts are\nblocking rendering and not loaded asynchronously or with custom Web fonts. [Check if you are in one of these cases](https://www.stevesouders.com/blog/2015/08/07/dominteractive-is-it-really/) before using this property as a proxy for the\nuser experience of a website's speed of loading.",
      "domloading": "\n\n> **Warning:** This interface of this property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete). Please use the [PerformanceNavigationTiming]\n> interface instead.\n\nThe legacy\n**`PerformanceTiming.domLoading`**\nread-only property returns an `unsigned long long` representing the moment,\nin milliseconds since the UNIX epoch, when the parser started its work, that is when its\n[Document.readyState] changes to `'loading'` and the\ncorresponding [Document/readystatechange_event] event is thrown.",
      "fetchstart": "\n\n> **Warning:** This interface of this property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete). Please use the [PerformanceNavigationTiming]\n> interface instead.\n\nThe legacy\n**`PerformanceTiming.fetchStart`**\nread-only property returns an `unsigned long long` representing the moment,\nin milliseconds since the UNIX epoch, the browser is ready to fetch the document using\nan HTTP request. This moment is _before_ the check to any application cache.",
      "loadeventend": "\n\n> **Warning:** This interface of this property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete). Please use the [PerformanceNavigationTiming]\n> interface's [PerformanceNavigationTiming.loadEventEnd] read-only property instead.\n\nThe legacy\n**`PerformanceTiming.loadEventEnd`**\nread-only property returns an `unsigned long long` representing the moment,\nin milliseconds since the UNIX epoch, when the [Window/load_event] event handler\nterminated, that is when the load event is completed. If this event has not yet been\nsent, or is not yet completed, it returns `0.`",
      "loadeventstart": "\n\n> **Warning:** This interface of this property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete). Please use the [PerformanceNavigationTiming]\n> interface's [PerformanceNavigationTiming.loadEventStart] read-only property instead.\n\nThe legacy\n**`PerformanceTiming.loadEventStart`**\nread-only property returns an `unsigned long long` representing the moment,\nin milliseconds since the UNIX epoch, when the [Window/load_event] event was sent for the\ncurrent document. If this event has not yet been sent, it returns `0.`",
      "msfirstpaint": "\n\n**`msFirstPaint`** is a read-only property which gets the time\nwhen the document loaded by the window object began to be displayed to the user.\n\nPut another way, `msFirstPaint` utilizes the browser to measure when the\nfirst content completes being painted in the window. It is available from JavaScript and\ncan be reported from the field.\n\nThis proprietary property is specific to Internet Explorer and Microsoft Edge.",
      "navigationstart": "\n\n> **Warning:** This interface of this property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete).\n> Please use the [PerformanceNavigationTiming] interface instead.\n\nThe legacy\n**`PerformanceTiming.navigationStart`**\nread-only property returns an `unsigned long long` representing the moment,\nin milliseconds since the UNIX epoch, right after the prompt for unload terminates on\nthe previous document in the same browsing context. If there is no previous document,\nthis value will be the same as [PerformanceTiming.fetchStart].",
      "redirectend": "\n\n> **Warning:** This interface of this property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete). Please use the [PerformanceNavigationTiming]\n> interface instead.\n\nThe legacy\n**`PerformanceTiming.redirectEnd`**\nread-only property returns an `unsigned long long` representing the moment,\nin milliseconds since the UNIX epoch, the last HTTP redirect is completed, that is when\nthe last byte of the HTTP response has been received. If there is no redirect, or if one\nof the redirect is not of the same origin, the value returned is `0`.",
      "redirectstart": "\n\n> **Warning:** This interface of this property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete). Please use the [PerformanceNavigationTiming]\n> interface instead.\n\nThe legacy\n**`PerformanceTiming.redirectStart`**\nread-only property returns an `unsigned long long` representing the moment,\nin milliseconds since the UNIX epoch, the first HTTP redirect starts. If there is no\nredirect, or if one of the redirect is not of the same origin, the value returned is\n`0`.",
      "requeststart": " \n\n> **Warning:** This interface of this property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete). Please use the [PerformanceNavigationTiming]\n> interface instead.\n\nThe legacy\n**`PerformanceTiming.requestStart`**\nread-only property returns an `unsigned long long` representing the moment,\nin milliseconds since the UNIX epoch, when the browser sent the request to obtain the\nactual document, from the server or from a cache. If the transport layer fails after the\nstart of the request and the connection is reopened, this property will be set to the\ntime corresponding to the new request.",
      "responseend": "\n\n> **Warning:** This interface of this property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete). Please use the [PerformanceNavigationTiming]\n> interface instead.\n\nThe legacy\n**`PerformanceTiming.responseEnd`**\nread-only property returns an `unsigned long long` representing the moment,\nin milliseconds since the UNIX epoch, when the browser received the last byte of the\nresponse, or when the connection is closed if this happened first, from the server from\na cache or from a local resource.",
      "responsestart": "\n\n> **Warning:** This interface of this property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete). Please use the [PerformanceNavigationTiming]\n> interface instead.\n\nThe legacy\n**`PerformanceTiming.responseStart`**\nread-only property returns an `unsigned long long` representing the moment in\ntime (in milliseconds since the UNIX epoch) when the browser received the first byte of\nthe response from the server, cache, or local resource.",
      "secureconnectionstart": "\n\n> **Warning:** This interface of this property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete). Please use the [PerformanceNavigationTiming] interface instead.\n\nThe legacy\n**`PerformanceTiming.secureConnectionStart`**\nread-only property returns an `unsigned long long` representing the moment,\nin milliseconds since the UNIX epoch, where the secure connection handshake starts. If\nno such connection is requested, it returns `0`.",
      "tojson": "\n\n> **Warning:** This interface of this property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete). Please use the [PerformanceNavigationTiming]\n> interface instead.\n\nThe legacy **`toJSON()`** method of the [PerformanceTiming] interface is a ; it returns a JSON representation of the [PerformanceTiming] object.",
      "unloadeventend": "\n\n> **Warning:** This interface of this property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete). Please use the [PerformanceNavigationTiming]\n> interface instead.\n\nThe legacy\n**`PerformanceTiming.unloadEventEnd`**\nread-only property returns an `unsigned long long` representing the moment,\nin milliseconds since the UNIX epoch, the [Window/unload_event] event handler finishes. If\nthere is no previous document, or if the previous document, or one of the needed\nredirects, is not of the same origin, the value returned is `0`.",
      "unloadeventstart": "\n\n> **Warning:** This interface of this property is deprecated in the [Navigation Timing Level 2 specification](https://w3c.github.io/navigation-timing/#obsolete). Please use the [PerformanceNavigationTiming]\n> interface instead.\n\nThe legacy\n**`PerformanceTiming.unloadEventStart`**\nread-only property returns an `unsigned long long` representing the moment,\nin milliseconds since the UNIX epoch, the [Window/unload_event] event has been thrown. If\nthere is no previous document, or if the previous document, or one of the needed\nredirects, is not of the same origin, the value returned is `0`."
    }
  },
  "periodicsyncevent": {
    "docs": "\n\nThe **`PeriodicSyncEvent`** interface of the [Web Periodic Background Synchronization API] provides a way to run tasks in the service worker with network connectivity.\n\nAn instance of this event is passed to the [ServiceWorkerGlobalScope.periodicsync_event] handler. This happens periodically, at an interval greater than or equal to that set in the [PeriodicSyncManager.register] method. Other implementation-specific factors such as the user's engagement with the site decide the actual interval.\n\n",
    "properties": {
      "tag": "\n\nThe **`tag`** read-only property of the\n[PeriodicSyncEvent] interface returns the developer-defined identifier for\nthe [PeriodicSyncEvent]. This is specified when calling the\n[PeriodicSyncManager.register] method of the\n[PeriodicSyncManager] interface. Multiple tags can be used by the web app\nto run different periodic tasks at different frequencies."
    }
  },
  "periodicsyncmanager": {
    "docs": "\n\nThe **`PeriodicSyncManager`** interface of the [Web Periodic Background Synchronization API] provides a way to register tasks to be run in a service worker at periodic intervals with network connectivity. These tasks are referred to as periodic background sync requests. Access `PeriodicSyncManager` through the [ServiceWorkerRegistration.periodicSync].",
    "properties": {
      "gettags": "\n\nThe **`getTags()`** method of the\n[PeriodicSyncManager] interface returns a `Promise` that\nresolves with a list of `String` objects representing the tags that are\ncurrently registered for periodic syncing.",
      "register": "\n\nThe **`register()`** method of the\n[PeriodicSyncManager] interface registers a periodic sync request with the\nbrowser with the specified tag and options. It returns a `Promise` that\nresolves when the registration completes.",
      "unregister": "\n\nThe **`unregister()`** method of the\n[PeriodicSyncManager] interface unregisters the periodic sync request\ncorresponding to the specified tag and returns a `Promise` that resolves\nwhen unregistration completes."
    }
  },
  "periodicwave": {
    "docs": "\n\nThe **`PeriodicWave`** interface defines a periodic waveform that can be used to shape the output of an [OscillatorNode].\n\n`PeriodicWave` has no inputs or outputs; it is used to define custom oscillators when calling [OscillatorNode.setPeriodicWave]. The `PeriodicWave` itself is created/returned by [BaseAudioContext.createPeriodicWave]."
  },
  "permissions": {
    "docs": " \n\nThe Permissions interface of the [Permissions API](/en-US/docs/Web/API/Permissions_API) provides the core Permission API functionality, such as methods for querying and revoking permissions",
    "properties": {
      "query": "\n\nThe **`Permissions.query()`** method of the [Permissions] interface returns the state of a user permission on the global scope.",
      "revoke": "\n\nThe **`Permissions.revoke()`** method of the\n[Permissions] interface reverts a currently set permission back to its\ndefault state, which is usually `prompt`.\nThis method is called on the global [Permissions] object\n[navigator.permissions]."
    }
  },
  "permissionstatus": {
    "docs": " \n\nThe **`PermissionStatus`** interface of the [Permissions API](/en-US/docs/Web/API/Permissions_API) provides the state of an object and an event handler for monitoring changes to said state.\n\n",
    "properties": {
      "change_event": "\n\nThe **`change`** event of the [PermissionStatus] interface fires whenever the [PermissionStatus.state] property changes.",
      "name": "\n\nThe **`name`** read-only property of the [PermissionStatus] interface returns the name of a requested permission.",
      "state": "\n\nThe **`state`** read-only property of the\n[PermissionStatus] interface returns the state of a requested permission.\nThis property returns one of `'granted'`, `'denied'`, or\n`'prompt'`."
    }
  },
  "pictureinpictureevent": {
    "docs": "\n\nThe **`PictureInPictureEvent`** interface represents picture-in-picture-related events, including [HTMLVideoElement/enterpictureinpicture_event], [HTMLVideoElement/leavepictureinpicture_event] and [PictureInPictureWindow/resize_event]\n\n",
    "properties": {
      "pictureinpicturewindow": "\n\nThe read-only **`pictureInPictureWindow`** property of the [PictureInPictureEvent] interface returns the [PictureInPictureWindow] the event relates to."
    }
  },
  "pictureinpicturewindow": {
    "docs": "\n\nThe **`PictureInPictureWindow`** interface represents an object able to programmatically obtain the **`width`** and **`height`** and **`resize event`** of the floating video window.\n\nAn object with this interface is obtained using the [HTMLVideoElement.requestPictureInPicture] promise return value.\n\n",
    "properties": {
      "height": "\n\nThe read-only **`height`** property of the [PictureInPictureWindow] interface returns the height of the floating video window in pixels.",
      "resize_event": "\n\nThe **`resize`** event fires when the floating video window has been resized.\n\nThis event is not cancelable and does not bubble.",
      "width": "\n\nThe read-only **`width`** property of the [PictureInPictureWindow] inbterface returns the width of the floating video window in pixels."
    }
  },
  "plugin": {
    "docs": "\n\nThe `Plugin` interface provides information about a browser plugin.\n\n> **Note:** Own properties of `Plugin` objects are no longer enumerable in the latest browser versions."
  },
  "pluginarray": {
    "docs": "\n\nThe `PluginArray` interface is used to store a list of [Plugin] objects describing the available [plugins](/en-US/docs/Mozilla/Add-ons/Plugins); it's returned by the [Navigator.plugins] property. The `PluginArray` is not a JavaScript array, but has the `length` property and supports accessing individual items using bracket notation (`plugins[2]`), as well as via `item(index)` and `namedItem(\"name\")` methods.\n\n> **Note:** Own properties of `PluginArray` objects are no longer enumerable in the latest browser versions."
  },
  "pointerevent": {
    "docs": "\n\nThe **`PointerEvent`** interface represents the state of a DOM event produced by a pointer such as the geometry of the contact point, the device type that generated the event, the amount of pressure that was applied on the contact surface, etc.\n\nA _pointer_ is a hardware agnostic representation of input devices (such as a mouse, pen or contact point on a touch-enable surface). The pointer can target a specific coordinate (or set of coordinates) on the contact surface such as a screen.\n\nA pointer's _hit test_ is the process a browser uses to determine the target element for a pointer event. Typically, this is determined by considering the pointer's location and also the visual layout of elements in a document on screen media.\n\n",
    "properties": {
      "altitudeangle": "\n\nThe **`altitudeAngle`** read-only property of the [PointerEvent] interface represents the angle between a transducer (a pointer or stylus) axis and the X-Y plane of a device screen.\nThe altitude angle describes whether the transducer is perpendicular to the screen, parallel, or at some angle in between.\n\nDepending on the specific hardware and platform, user agents will likely only receive one set of values for the transducer orientation relative to the screen plane — either [PointerEvent.tiltx] and [PointerEvent.tilty] or `altitudeAngle` and [PointerEvent.azimuthAngle].\n\n![The azimuth angle of a pointer compared to the altitude angle](./azimuth_altitude_angles.svg)\n\nFor an additional illustration of this property, see [Figure 4 in the specification](https://w3c.github.io/pointerevents/#figure_altitudeAngle).",
      "azimuthangle": "\n\nThe **`azimuthAngle`** read-only property of the [PointerEvent] interface represents the angle between the Y-Z plane and the plane containing both the transducer (pointer or stylus) axis and the Y axis.\n\nDepending on the specific hardware and platform, user agents will likely only receive one set of values for the transducer orientation relative to the screen plane — either [PointerEvent.tiltx] and [PointerEvent.tilty] or [PointerEvent.altitudeAngle] and `azimuthAngle`.\n\n![The azimuth angle of a pointer compared to the altitude angle](azimuth_altitude_angles.svg)\n\nFor an additional illustration of this property, see [Figure 5 in the specification](https://w3c.github.io/pointerevents/#figure_azimuthAngle).",
      "getcoalescedevents": " \n\nThe **`getCoalescedEvents()`** method of the [PointerEvent] interface returns a sequence of `PointerEvent` instances that were coalesced (merged) into a single [Element/pointermove_event] or [Element/pointerrawupdate_event] event.\nInstead of a stream of many [Element/pointermove_event] events, user agents coalesce multiple updates into a single event.\nThis helps with performance as the user agent has less event handling to perform, but there is a reduction in the granularity and accuracy when tracking, especially with fast and large movements.\n\nThe **`getCoalescedEvents()`** method lets applications access all un-coalesced position changes for precise handling of pointer movement data where necessary.\nUn-coalesced position changes are desirable in drawing applications, for instance, where having access to all events helps to build smoother curves that better match the movement of a pointer.\n\nFor an illustration of coalesced events, see [Figure 7 in the specification](https://w3c.github.io/pointerevents/#figure_coalesced).",
      "getpredictedevents": "\n\nThe **`getPredictedEvents()`** method of the [PointerEvent] interface returns a sequence of `PointerEvent` instances that are estimated future pointer positions.\nHow the predicted positions are calculated depends on the user agent, but they are based on past points, current velocity, and trajectory.\n\nApplications can use the predicted events to \"draw ahead\" to a predicted position which may reduce perceived latency depending on the application's interpretation of the predicted events and the use case.\n\nFor an illustration of predicted events, see [Figure 8 in the specification](https://w3c.github.io/pointerevents/#figure_predicted).",
      "height": "\n\nThe **`height`** read-only property of the\n[PointerEvent] interface represents the height of the pointer's contact\ngeometry, along the y-axis (in CSS pixels). Depending on the source of the pointer\ndevice (for example a finger), for a given pointer, each event may produce a different\nvalue.\n\nIf the input hardware cannot report the contact geometry to the browser, the height\ndefaults to `1`.",
      "isprimary": "\n\nThe **`isPrimary`** read-only property of the\n[PointerEvent] interface indicates whether or not the pointer device that\ncreated the event is the _primary_ pointer. It returns `true` if the\npointer that caused the event to be fired is the primary one and returns\n`false` otherwise.\n\nIn a multi-pointer scenario (such as a touch screen that supports more than one touch\npoint), this property is used to identify a _master pointer_ among the set of\nactive pointers for each pointer type. Only a primary pointer will produce\n_compatibility mouse events_. Authors who desire only single-pointer interaction\ncan achieve that by ignoring non-primary pointers.\n\nA pointer is considered primary if the pointer represents a mouse device. A pointer\nrepresenting pen input is considered the primary pen input if its\n[Element/pointerdown_event] event was dispatched when no other active pointers representing\npen input existed. A pointer representing touch input is considered the primary touch\ninput if its [Element/pointerdown_event] event was dispatched when no other active pointers\nrepresenting touch input existed.\n\nWhen two or more pointer device types are being used concurrently, multiple pointers\n(one for each [PointerEvent.pointerType]) are considered\nprimary. For example, a touch contact and a mouse cursor moved simultaneously will\nproduce pointers that are both considered primary. If there are multiple primary\npointers, these pointers will all produce _compatibility mouse events_ (see\n[Pointer_events] for more information about pointer, mouse and touch\ninteraction).",
      "pointerid": "\n\nThe **`pointerId`** read-only property of the\n[PointerEvent] interface is an identifier assigned to a given pointer\nevent. The identifier is unique, being different from the identifiers of all other\nactive pointer events. Since the value may be randomly generated, it is not guaranteed\nto convey any particular meaning.",
      "pointertype": "\n\nThe **`pointerType`** read-only property of the\n[PointerEvent] interface indicates the device type (mouse, pen, or touch)\nthat caused a given pointer event.",
      "pressure": "\n\nThe **`pressure`** read-only property of the\n[PointerEvent] interface indicates the normalized pressure of the pointer\ninput.",
      "tangentialpressure": "\n\nThe **`tangentialPressure`** read-only property of the\n[PointerEvent] interface represents the normalized tangential pressure of\nthe pointer input (also known as barrel pressure or [cylinder stress](https://en.wikipedia.org/wiki/Cylinder_stress)).",
      "tiltx": "\n\nThe **`tiltX`** read-only property of the\n[PointerEvent] interface is the angle (in degrees) between the _Y-Z\nplane_ of the pointer and the screen. This property is typically only useful for a\npen/stylus pointer type.\n\nFor an illustration of this property see [Figure 2 in the specification](https://w3c.github.io/pointerevents/#dom-pointerevent-tiltx).",
      "tilty": "\n\nThe **`tiltY`** read-only property of the\n[PointerEvent] interface is the angle (in degrees) between the _X-Z\nplane_ of the pointer and the screen. This property is typically only useful for a\npen/stylus pointer type.\n\nFor an illustration of this property, see [Figure 3 in the specification](https://w3c.github.io/pointerevents/#dom-pointerevent-tilty).",
      "twist": "\n\nThe **`twist`** read-only property of the\n[PointerEvent] interface represents the clockwise rotation of the pointer\n(e.g., pen stylus) around its major axis, in degrees.",
      "width": "\n\nThe **`width`** read-only property of the\n[PointerEvent] interface represents the width of the pointer's contact\ngeometry along the x-axis, measured in CSS pixels. Depending on the source of the\npointer device (such as a finger), for a given pointer, each event may produce a\ndifferent value.\n\nIf the input hardware cannot report the contact geometry to the browser, the width\ndefaults to `1`."
    }
  },
  "popstateevent": {
    "docs": "\n\n**`PopStateEvent`** is an interface for the [`popstate`](/en-US/docs/Web/API/Window/popstate_event) event.\n\nA `popstate` event is dispatched to the window every time the active history\nentry changes between two history entries for the same document. If the history entry\nbeing activated was created by a call to `history.pushState()` or was\naffected by a call to `history.replaceState()`, the `popstate`\nevent's `state` property contains a copy of the history entry's state object.\n\n",
    "properties": {
      "state": "\n\nThe **`state`** read-only property of the [PopStateEvent] interface represents the state stored when the event was created.\n\nPractically it is a value provided by the call to [history.pushState] or [history.replaceState]"
    }
  },
  "positionsensorvrdevice": {
    "docs": "\n\nThe **`PositionSensorVRDevice`** interface of the [WebVR API](/en-US/docs/Web/API/WebVR_API) represents VR hardware's position sensor. You can access information such as the current position and orientation of the sensor in relation to the head mounted display through the [PositionSensorVRDevice.getState] method.",
    "properties": {
      "getimmediatestate": "\n\nThe **`getImmediateState()`** method of the [VRDisplay] interface returns the current instantaneous position sensor state. This is intended to only be used rarely, for certain special uses, for example sampling the immediate position of a hand orientation sensor — or at least it will be, in the future.\n\nFor most standard uses, you'll probably want to use [PositionSensorVRDevice.getState] instead.",
      "getstate": "\n\nThe **`getState()`** method of the [PositionSensorVRDevice] interface returns the current state of the position sensor for the current frame (e.g. within the current [window.requestAnimationFrame] callback) or for the previous frame, contained with a [VRPose] object. This is the method you'd normally want to use, vs. [PositionSensorVRDevice.getImmediateState].",
      "resetsensor": "\n\nThe **`resetSensor()`** method of the [VRDisplay] interface _can be used to reset the sensor if desired, returning the_ position and orientation values to zero."
    }
  },
  "presentation": {
    "docs": "\n\nThe **`Presentation`** can be defined as two possible user agents in the context: _Controlling user agent_ and _Receiving user agent_.\n\nIn controlling browsing context, the `Presentation` interface provides a mechanism to override the browser default behavior of launching presentation to external screen. In receiving browsing context, `Presentation` interface provides the access to the available presentation connections.",
    "properties": {
      "defaultrequest": "\n\nIn a [controlling user agent](https://www.w3.org/TR/presentation-api/#dfn-controlling-user-agent), the **`defaultRequest`** attribute _MUST_ return the [default presentation request](https://www.w3.org/TR/presentation-api/#dfn-default-presentation-request) if any, otherwise `null`. In a [receiving browsing context](https://www.w3.org/TR/presentation-api/#dfn-receiving-browsing-context), it _MUST_ return `null`.\n\nIf set by the [controller](https://www.w3.org/TR/presentation-api/#dfn-controller), the value of the `defaultRequest` attribute _SHOULD_ be used by the [controlling user agent](https://www.w3.org/TR/presentation-api/#dfn-controlling-user-agent) as the _default presentation request_ for that [controlling browsing context](https://www.w3.org/TR/presentation-api/#dfn-controlling-browsing-context). If the document object's [active sandboxing flag set](https://www.w3.org/TR/presentation-api/#dfn-active-sandboxing-flag-set) has the [sandboxed presentation browsing context flag](https://www.w3.org/TR/presentation-api/#sandboxed-presentation-browsing-context-flag) set, the [controlling user agent](https://www.w3.org/TR/presentation-api/#dfn-controlling-user-agent) _SHOULD_ act as if the default request is not set for that browsing context. When the [controlling user agent](https://www.w3.org/TR/presentation-api/#dfn-controlling-user-agent) wishes to initiate a [PresentationConnection] on the behalf of that browsing context, it _MUST_ [start a presentation](https://www.w3.org/TR/presentation-api/#dfn-start-a-presentation) using the [default presentation request](https://www.w3.org/TR/presentation-api/#dfn-default-presentation-request) for the [controller](https://www.w3.org/TR/presentation-api/#dfn-controller) (as if the controller had called [PresentationRequest.start]).\n\nThe [controlling user agent](https://www.w3.org/TR/presentation-api/#dfn-controlling-user-agent) _SHOULD_ initiate presentation using the [default presentation request](https://www.w3.org/TR/presentation-api/#dfn-default-presentation-request), only when the user has expressed an intention to do so via a user gesture. For example, by clicking a button in the browser.\n\n> **Note:** Some [controlling user agents](https://www.w3.org/TR/presentation-api/#dfn-controlling-user-agent) may allow the user to initiate a default [presentation connection](https://www.w3.org/TR/presentation-api/#dfn-presentation-connection) and select a [presentation display](https://www.w3.org/TR/presentation-api/#dfn-presentation-display) with the same user gesture. For example, the browser chrome could allow the user to pick a display from a menu, or allow the user to tap on an [Near Field Communications (NFC)](https://nfc-forum.org/) enabled display. In this case, when the [controlling user agent](https://www.w3.org/TR/presentation-api/#dfn-controlling-user-agent) asks for permission while [starting a presentation](https://www.w3.org/TR/presentation-api/#dfn-start-a-presentation), the browser could offer that display as the default choice, or consider the gesture as granting permission for the display and bypass display selection entirely.\n\n> **Note:** If a [controlling user agent](https://www.w3.org/TR/presentation-api/#dfn-controlling-user-agent) does not support initiation of a [presentation connection](https://www.w3.org/TR/presentation-api/#dfn-presentation-connection) from the browser chrome, setting `defaultRequest` will have no effect.",
      "receiver": "\n\nThe **read-only** [Presentation] attribute\n`receiver`, which is only available in browser contexts which are\n**receiving** a presentation, returns the\n[PresentationReceiver] object which can be used to access and communicate\nwith the browser context which controls the presentation. This property is always\n`null` when accessed from outside a browser context which is receiving a\npresentation."
    }
  },
  "presentationavailability": {
    "docs": "\n\nA **`PresentationAvailability`** object is associated with available [presentation displays](https://www.w3.org/TR/presentation-api/#dfn-presentation-display) and represents the _presentation display availability_ for a presentation request. If the [controlling user agent](https://www.w3.org/TR/presentation-api/#dfn-controlling-user-agent) can [monitor the list of available presentation displays](https://www.w3.org/TR/presentation-api/#dfn-monitor-the-list-of-available-presentation-displays) in the background (without a pending request to `start()`), the `PresentationAvailability` object _MUST_ be implemented in a [controlling browsing context](https://www.w3.org/TR/presentation-api/#dfn-controlling-browsing-context).\n\nThe `value` attribute _MUST_ return the last value it was set to. The value is updated by the [monitor the list of available presentation displays](https://www.w3.org/TR/presentation-api/#dfn-monitor-the-list-of-available-presentation-displays) algorithm.\n\nThe `onchange` attribute is an [event handler](https://www.w3.org/TR/presentation-api/#dfn-event-handler) whose corresponding [event handler event type](https://www.w3.org/TR/presentation-api/#dfn-event-handler-event-type) is `change`.\n\n",
    "properties": {
      "value": "\n\nThe **`value`** attribute _MUST_ return the last value from which it was set. The value is updated by the [monitor the list of available presentation displays](https://www.w3.org/TR/presentation-api/#dfn-monitor-the-list-of-available-presentation-displays) algorithm.\n\nThe `onchange` attribute is an [event handler](https://www.w3.org/TR/presentation-api/#dfn-event-handler) whose corresponding [event handler event type](https://www.w3.org/TR/presentation-api/#dfn-event-handler-event-type) is `change`."
    }
  },
  "presentationconnection": {
    "docs": "\n\nThe **`PresentationConnection`** interface of the [Presentation API](/en-US/docs/Web/API/Presentation_API) provides methods and properties for managing a single presentation. Each [presentation connection](https://www.w3.org/TR/presentation-api/#dfn-presentation-connection) is represented by a `PresentationConnection` object. Both the [controlling user agent](https://www.w3.org/TR/presentation-api/#dfn-controlling-user-agent) and [receiving user agent](https://www.w3.org/TR/presentation-api/#dfn-receiving-user-agent) _MUST_ implement `PresentationConnection`.\n\n",
    "properties": {
      "binarytype": "\n\nWhen a [PresentationConnection] object is created, its `binaryType` IDL attribute _MUST_ be set to the string `\"arraybuffer\"`. Upon getting, the attribute _MUST_ return its most recent value (the value it was last set as). Upon setting, the user agent _MUST_ set the IDL attribute to the new value.\n\n> **Note:** The `binaryType` attribute allows authors to control how binary data is exposed to scripts. By setting the attribute to `\"blob\"`, binary data is returned in `Blob` form; by setting it to `\"arraybuffer\"`, it is returned in `ArrayBuffer` form. The attribute defaults to `\"arraybuffer\"`. This attribute has no effect on data sent in a string form.",
      "close": "\n\nWhen the `close()` method is called on a [PresentationConnection], the  begins the process of closing the connection by sending an empty `closeMessage` with the `closeReason` set to `closed`.",
      "id": "\n\nThe **`id`** attribute specifies the [presentation identifier](https://www.w3.org/TR/presentation-api/#dfn-presentation-identifier) of a [presentation connection](https://www.w3.org/TR/presentation-api/#dfn-presentation-connection).",
      "send": "\n\nThe **`send()`** method of the\n[PresentationConnection] interface tells a controlling browsing context to\nsend binary or text data to a presenting browsing context.",
      "state": "\n\nThe **`state`** attribute reflects the [presentation connection](https://www.w3.org/TR/presentation-api/#dfn-presentation-connection)'s current state. Depending on the current [`PresentationConnectionState`](https://www.w3.org/TR/presentation-api/#idl-def-presentationconnectionstate), the `state` attribute can hold one of the following values.\n\n- **`connecting`**: The user agent is attempting to [establish a presentation connection](https://www.w3.org/TR/presentation-api/#dfn-establish-a-presentation-connection) with the [destination browsing context](https://www.w3.org/TR/presentation-api/#dfn-destination-browsing-context). This is the initial state when a [`PresentationConnection`](https://www.w3.org/TR/presentation-api/#idl-def-presentationconnection) object is created.\n- **`connected`**: The [presentation connection](https://www.w3.org/TR/presentation-api/#dfn-presentation-connection) is established and communication is possible.\n- **`closed`**: The [presentation connection](https://www.w3.org/TR/presentation-api/#dfn-presentation-connection) has been closed or could not be opened. The connection may be reopened by calling [`reconnect()`](https://www.w3.org/TR/presentation-api/#dom-presentationrequest-reconnect). No communication is possible in this state.\n- **`terminated`**: The [receiving browsing context](https://www.w3.org/TR/presentation-api/#dfn-receiving-browsing-context) has terminated. Any [presentation connection](https://www.w3.org/TR/presentation-api/#dfn-presentation-connection) to that [presentation](https://www.w3.org/TR/presentation-api/#dfn-presentation) has also terminated and cannot be reopened. No communication is possible.",
      "terminate": "\n\nWhen the `terminate()` method is called on a [PresentationConnection], the  begins the process of terminating the presentation. The exact process differs depending on whether `terminate()` is called in the controlling or the presenting context.",
      "url": "`Presentation API`\n\nThe **`url`** readonly property of the\n[PresentationConnection] interface returns the URL used to create or\nreconnect to the presentation."
    }
  },
  "presentationconnectionavailableevent": {
    "docs": "\n\nThe **`PresentationConnectionAvailableEvent`** interface of the [Presentation API](/en-US/docs/Web/API/Presentation_API) is fired on a [PresentationRequest] when a connection associated with the object is created.\n\nA [controlling user agent](https://www.w3.org/TR/presentation-api/#dfn-controlling-user-agent) [fires](https://www.w3.org/TR/presentation-api/#dfn-firing-an-event) a [trusted event](https://www.w3.org/TR/presentation-api/#dfn-trusted-event) named [`connectionavailable`](https://www.w3.org/TR/presentation-api/#dfn-connectionavailable) on a [`PresentationRequest`](https://www.w3.org/TR/presentation-api/#idl-def-presentationrequest) when a connection associated with the object is created. It is fired at the `PresentationRequest` instance, using the [`PresentationConnectionAvailableEvent`](https://www.w3.org/TR/presentation-api/#idl-def-presentationconnectionavailableevent) interface, with the [`connection`](https://www.w3.org/TR/presentation-api/#idl-def-presentationconnectionavailableevent-connection) attribute set to the [`PresentationConnection`](https://www.w3.org/TR/presentation-api/#idl-def-presentationconnection) object that was created. The event is fired for each connection that is created for the [controller](https://www.w3.org/TR/presentation-api/#dfn-controller), either by the [controller](https://www.w3.org/TR/presentation-api/#dfn-controller) calling `start()` or `reconnect()`, or by the [controlling user agent](https://www.w3.org/TR/presentation-api/#dfn-controlling-user-agent) creating a connection on the controller's behalf via [`defaultRequest`](https://www.w3.org/TR/presentation-api/#dom-presentation-defaultrequest).\n\n",
    "properties": {
      "connection": "\n\nWhen an incoming connection is created, a [receiving user agent](https://www.w3.org/TR/presentation-api/#dfn-receiving-user-agent) [fires](https://www.w3.org/TR/presentation-api/#dfn-firing-an-event) a [trusted event](https://www.w3.org/TR/presentation-api/#dfn-trusted-event), named [`connectionavailable`](https://www.w3.org/TR/presentation-api/#dfn-connectionavailable), on a [`PresentationReceiver`](https://www.w3.org/TR/presentation-api/#idl-def-presentationreceiver). The [trusted event](https://www.w3.org/TR/presentation-api/#dfn-trusted-event) is fired at the [presentation controller's monitor](https://www.w3.org/TR/presentation-api/#dfn-presentation-controllers-monitor), using the [`PresentationConnectionAvailableEvent`](https://www.w3.org/TR/presentation-api/#idl-def-presentationconnectionavailableevent) interface, with the [`connection`](https://www.w3.org/TR/presentation-api/#idl-def-presentationconnectionavailableevent-connection) attribute set to the [`PresentationConnection`](https://www.w3.org/TR/presentation-api/#idl-def-presentationconnection) object that was created.\n\nThe event is fired for all connections that are created when [monitoring incoming presentation connections](https://www.w3.org/TR/presentation-api/#dfn-monitoring-incoming-presentation-connections)."
    }
  },
  "presentationconnectioncloseevent": {
    "docs": "\n\nThe **`PresentationConnectionCloseEvent`** interface of the [Presentation API](/en-US/docs/Web/API/Presentation_API) is fired on a [PresentationConnection] when it is closed.\n\n"
  },
  "presentationconnectionlist": {
    "docs": "\n\n`PresentationConnectionList` is the collection of incoming presentation connections.\n\n"
  },
  "presentationreceiver": {
    "docs": "\n\nThe **`PresentationReceiver`** interface of the [Presentation API](/en-US/docs/Web/API/Presentation_API) provides a means for a receiving browsing context to access controlling browsing contexts and communicate with them."
  },
  "presentationrequest": {
    "docs": "\n\nA `PresentationRequest` object is used to initiate or reconnect to a presentation made by a [controlling browsing context](https://www.w3.org/TR/presentation-api/#dfn-controlling-browsing-context). The `PresentationRequest` object _MUST_ be implemented in a [controlling browsing context](https://www.w3.org/TR/presentation-api/#dfn-controlling-browsing-context) provided by a [controlling user agent](https://www.w3.org/TR/presentation-api/#dfn-controlling-user-agent).\n\nWhen a `PresentationRequest` is constructed, the given `urls` _MUST_ be used as the list of _presentation request URLs_ which are each a possible [presentation URL](https://www.w3.org/TR/presentation-api/#dfn-presentation-url) for the `PresentationRequest` instance.\n\n",
    "properties": {
      "getavailability": "\n\nWhen the `getAvailability()` method is called, the user agent _MUST_ run the following steps:\n\n- Input\n  - : _presentationUrls_, a list of [presentation request URLs](https://www.w3.org/TR/presentation-api/#dfn-presentation-request-urls)\n- Output\n  - : _P_, a [Promise](https://www.w3.org/TR/presentation-api/#dfn-promise)\n\n1. If one of the following conditions is true:\n\n   - The result of running the [prohibits mixed security contexts algorithm](https://www.w3.org/TR/presentation-api/#dfn-prohibits-mixed-security-contexts-algorithm) on the document's [settings object](https://www.w3.org/TR/presentation-api/#dfn-settings-object) is `\"Prohibits Mixed Security Contexts\"` and _presentationUrl_ is an [a priori unauthenticated URL](https://www.w3.org/TR/presentation-api/#dfn-a-priori-unauthenticated-url).\n   - The document object's [active sandboxing flag set](https://www.w3.org/TR/presentation-api/#dfn-active-sandboxing-flag-set) has the [sandboxed presentation browsing context flag](https://www.w3.org/TR/presentation-api/#sandboxed-presentation-browsing-context-flag) set.\n\n   Run the following substeps:\n\n   1. Return a [Promise](https://www.w3.org/TR/presentation-api/#dfn-promise) rejected with a `SecurityError` [DOMException].\n   2. Abort these steps.\n\n2. Let _P_ be a new [Promise](https://www.w3.org/TR/presentation-api/#dfn-promise).\n3. Return _P_, but continue running these steps [in parallel](https://www.w3.org/TR/presentation-api/#dfn-in-parallel).\n4. If the user agent is unable to [monitor the list of available presentation displays](https://www.w3.org/TR/presentation-api/#dfn-monitor-the-list-of-available-presentation-displays) for the entire duration of the [controlling browsing context](https://www.w3.org/TR/presentation-api/#dfn-controlling-browsing-context) (e.g., because the user has disabled this feature), then:\n\n   1. [Resolve](https://www.w3.org/TR/presentation-api/#dfn-resolving-a-promise) _P_ with a new `PresentationAvailability` object with its `value` property set to `false`.\n   2. Abort all the remaining steps.\n\n5. If the user agent is unable to continuously [monitor the list of available presentation displays](https://www.w3.org/TR/presentation-api/#dfn-monitor-the-list-of-available-presentation-displays) but can find presentation displays in order to start a connection, then:\n\n   1. [Reject](https://www.w3.org/TR/presentation-api/#dfn-rejecting-a-promise) _P_ with a `NotSupportedError` [DOMException].\n   2. Abort all the remaining steps.\n\n6. If there exists a tuple (_A_, _presentationUrls_) in the [set of availability objects](https://www.w3.org/TR/presentation-api/#dfn-set-of-availability-objects), then:\n\n   1. [Resolve](https://www.w3.org/TR/presentation-api/#dfn-resolving-a-promise) _P_ with _A_.\n   2. Abort all the remaining steps.\n\n7. Let _A_ be a new `PresentationAvailability` object with its `value` property set as follows:\n\n   1. `false` if the [list of available presentation displays](https://www.w3.org/TR/presentation-api/#dfn-list-of-available-presentation-displays) is empty.\n   2. `true` if there is at least one [compatible presentation display](https://www.w3.org/TR/presentation-api/#dfn-compatible-presentation-display) for some member of _presentationUrls_. Meaning there is an entry _(presentationUrl, display)_ in the [list of available presentation displays](https://www.w3.org/TR/presentation-api/#dfn-list-of-available-presentation-displays) for some _presentationUrl_ in _presentationUrls_.\n   3. `false` otherwise.\n\n8. Create a tuple (_A_, _presentationUrls_) and add it to the [set of availability objects](https://www.w3.org/TR/presentation-api/#dfn-set-of-availability-objects).\n9. Run the algorithm to [monitor the list of available presentation displays](https://www.w3.org/TR/presentation-api/#dfn-monitor-the-list-of-available-presentation-displays).\n10. [Resolve](https://www.w3.org/TR/presentation-api/#dfn-resolving-a-promise) _P_ with _A_.",
      "reconnect": "\n\nWhen the `reconnect(presentationId)` method is called on a `PresentationRequest` _presentationRequest_, the [user agent](https://www.w3.org/TR/presentation-api/#dfn-user-agents) _MUST_ run the following steps to _reconnect to a presentation_:",
      "start": "`Presentation API`\n\nThe **`start()`** property of the [PresentationRequest] interface returns a `Promise` that resolves with a [PresentationConnection] after the user agent prompts the user to select a display and grant permission to use that display."
    }
  },
  "processinginstruction": {
    "docs": "\n\nThe **`ProcessingInstruction`** interface represents a [processing instruction](https://www.w3.org/TR/xml/#sec-pi); that is, a [Node] which embeds an instruction targeting a specific application but that can be ignored by any other applications which don't recognize the instruction.\n\n> **Warning:** `ProcessingInstruction` nodes are only supported in XML documents, not in HTML documents. In these, a process instruction will be considered as a comment and be represented as a [Comment] object in the tree.\n\nA processing instruction may be different than the [XML declaration](/en-US/docs/Web/XML/XML_introduction#xml_declaration).\n\n> **Note:** User-defined processing instructions cannot begin with \"`xml`\", as `xml`-prefixed processing-instruction target names are reserved by the XML specification for particular, standard uses (see, for example, `<?xml-stylesheet ?>`.\n\nFor example:\n\n```html\n<?xml version=\"1.0\"?>\n```\n\nis a processing instruction whose `target` is `xml`.\n\n",
    "properties": {
      "sheet": "\n\nThe read-only **`sheet`** property of the [ProcessingInstruction] interface\ncontains the stylesheet associated to the `ProcessingInstruction`.\n\nThe `xml-stylesheet` processing instruction is used to associate a stylesheet in an XML file.",
      "target": "\n\nThe read-only **`target`** property of the [ProcessingInstruction] interface\nrepresent the application to which the `ProcessingInstruction` is targeted.\n\nFor example:\n\n```html\n<?xml version=\"1.0\"?>\n```\n\nis a processing instruction whose `target` is `xml`."
    }
  },
  "progressevent": {
    "docs": "\n\nThe **`ProgressEvent`** interface represents events measuring progress of an underlying process, like an HTTP request (for an `XMLHttpRequest`, or the loading of the underlying resource of an `img`, `audio`, `video`, `style` or `link`).\n\n",
    "properties": {
      "lengthcomputable": "\n\nThe\n**`ProgressEvent.lengthComputable`** read-only property is a\nboolean flag indicating if the resource concerned by the\n[ProgressEvent] has a length that can be calculated. If not, the\n[ProgressEvent.total] property has no significant value.",
      "loaded": "\n\nThe **`ProgressEvent.loaded`** read-only property is an integer\nrepresenting the amount of work already performed by the underlying process. The ratio\nof work done can be calculated with the property and `ProgressEvent.total`.\nWhen downloading a resource using HTTP, this value is specified in bytes (not bits), and only represents the part of the content\nitself, not headers and other overhead.",
      "total": "\n\nThe **`ProgressEvent.total`** read-only property is an unsigned\n64-bit integer value indicating the total size of the data being processed or\ntransmitted. In the case of an HTTP transmission, this is the size of the body of the\nmessage (the `Content-Length`), and does not include headers and other\noverhead.\n\nIf the event's [ProgressEvent.lengthComputable]\nproperty is `false`, this value is meaningless and should be ignored."
    }
  },
  "promiserejectionevent": {
    "docs": "\n\nThe **`PromiseRejectionEvent`** interface represents events which are sent to the global script context when JavaScript `Promise`s are rejected. These events are particularly useful for telemetry and debugging purposes.\n\nFor details, see [Promise rejection events](/en-US/docs/Web/JavaScript/Guide/Using_promises#promise_rejection_events).\n\n",
    "properties": {
      "promise": "\n\nThe [PromiseRejectionEvent] interface's\n**`promise`** read-only property indicates the JavaScript\n`Promise` which was rejected. You can examine the event's\n[PromiseRejectionEvent.reason] property to learn why the promise was\nrejected.",
      "reason": "\n\nThe [PromiseRejectionEvent] **`reason`** read-only\nproperty is any JavaScript value or `Object` which provides the reason\npassed into `Promise.reject()`. This in theory provides information about\nwhy the promise was rejected."
    }
  },
  "publickeycredential": {
    "docs": "\n\nThe **`PublicKeyCredential`** interface provides information about a public key / private key pair, which is a credential for logging in to a service using an un-phishable and data-breach resistant asymmetric key pair instead of a password. It inherits from [Credential], and is part of the [Web Authentication API](/en-US/docs/Web/API/Web_Authentication_API) extension to the [Credential Management API](/en-US/docs/Web/API/Credential_Management_API).\n\n> **Note:** This API is restricted to top-level contexts. Use from within an `iframe` element will not have any effect.",
    "properties": {
      "authenticatorattachment": "\n\nThe **`authenticatorAttachment`** read-only property of the [PublicKeyCredential] interface is a string that indicates the general category of authenticator used during the associated [CredentialsContainer.create] or [CredentialsContainer.get] call.",
      "getclientextensionresults": "\n\nThe **`getClientExtensionResults()`** method of the\n[PublicKeyCredential] interface returns a map between the identifiers of extensions requested during credential creation or authentication, and their results after processing by the user agent.\n\nDuring the creation or fetching of a `PublicKeyCredential` (via\n[CredentialsContainer.create] and\n[CredentialsContainer.get] respectively), it is possible\nto request \"custom\" processing by the client for different extensions, specified in the `publicKey` option's `extensions` property. You can find more information about requesting the different extensions in [Web Authentication extensions](/en-US/docs/Web/API/Web_Authentication_API/WebAuthn_extensions).\n\n> **Note:** `getClientExtensionResults()` only returns the results from extensions processed by the user agent (client). The results from extensions processed by the authenticator can be found in the [authenticator data](/en-US/docs/Web/API/Web_Authentication_API/Authenticator_data) available in [AuthenticatorAssertionResponse.authenticatorData].",
      "id": "\n\nThe **`id`** read-only property of the\n[PublicKeyCredential] interface is a string, inherited\nfrom [Credential], which represents the identifier of the current\n`PublicKeyCredential` instance.\n\nThis property is a [base64url encoded](/en-US/docs/Glossary/Base64) version of [PublicKeyCredential.rawId].\n\n> **Note:** This property may only be used in top-level contexts and will\n> not be available in an `iframe` for example.",
      "isconditionalmediationavailable": "\n\nThe **`isConditionalMediationAvailable()`** static method of the [PublicKeyCredential] interface returns a `Promise` which resolves to `true` if conditional mediation is available.\n\nConditional mediation, if available, results in any discovered credentials being presented to the user in a non-modal dialog box along with an indication of the origin requesting credentials. This is requested by including `mediation: 'conditional'` in your `get()` call. In practice, this means autofilling available credentials; you need to include `autocomplete=\"webauthn\"` on your form fields so that they will show the WebAuthn sign-in options.\n\nA conditional `get()` call does not show the browser UI and remains pending until the user picks an account to sign-in with from available autofill suggestions:\n\n- If the user makes a gesture outside of the dialog, it closes without resolving or rejecting the Promise and without causing a user-visible error condition.\n- If the user selects a credential, that credential is returned to the caller.\n\nThe prevent silent access flag (see [CredentialsContainer.preventSilentAccess]) is treated as being `true` regardless of its actual value: the conditional behavior always involves user mediation of some sort if applicable credentials are discovered.\n\n> **Note:** If no credentials are discovered, the non-modal dialog will not be visible, and the user agent can prompt the user to take action in a way that depends on the type of credential (for example, to insert a device containing credentials).",
      "isuserverifyingplatformauthenticatoravailable_static": "\n\nThe **`isUserVerifyingPlatformAuthenticatorAvailable()`** static method of the [PublicKeyCredential] interface returns a `Promise` which resolves to `true` if a user-verifying platform authenticator is present.\n\nA user-verifying platform authenticator is a kind of multi-factor authenticator that is part of the client device (it is generally not removable) and that involves an action from the user in order to identify them. Common user-verifying platform authenticators include:\n\n- Touch ID or Face ID (macOS and iOS)\n- Windows Hello (Windows)\n- Device unlock (fingerprint, face, PIN, etc.) on Android\n\n> **Note:** This method may only be used in top-level contexts and will not be available in an `iframe` for example.",
      "parsecreationoptionsfromjson_static": " \n\nThe **`parseCreationOptionsFromJSON()`** static method of the [PublicKeyCredential] interface converts a  into its corresponding [`publicKey` create credentials options object structure](/en-US/docs/Web/API/CredentialsContainer/create#publickey_object_structure).\n\nThe method is a convenience function for converting credential options information provided by a relying party server to the form that a web app can use to [create a credential](/en-US/docs/Web/API/Web_Authentication_API#creating_a_key_pair_and_registering_a_user).",
      "parserequestoptionsfromjson_static": " \n\nThe **`parseRequestOptionsFromJSON()`** static method of the [PublicKeyCredential] interface converts a  into its corresponding [`publicKey` request credentials options object structure](/en-US/docs/Web/API/CredentialsContainer/get#publickey_object_structure).\n\nThe method is a convenience function for converting information provided by a relying server to a web app in order to request an existing credential.",
      "rawid": "\n\nThe **`rawId`** read-only property of the\n[PublicKeyCredential] interface is an `ArrayBuffer` object\ncontaining the identifier of the credentials.\n\nThe [PublicKeyCredential.id] property is a [base64url encoded](/en-US/docs/Glossary/Base64) version of this identifier.\n\n> **Note:** This property may only be used in top-level contexts and will\n> not be available in an `iframe` for example.",
      "response": "\n\nThe **`response`** read-only property of the\n[PublicKeyCredential] interface is an [AuthenticatorResponse]\nobject which is sent from the authenticator to the user agent for the creation/fetching\nof credentials. The information contained in this response will be used by the relying\nparty's server to verify the demand is legitimate.\n\nAn `AuthenticatorResponse` is either:\n\n- an [AuthenticatorAttestationResponse] (when the\n  `PublicKeyCredential` is created via\n  [CredentialsContainer.create])\n- an [AuthenticatorAssertionResponse] (when the\n  `PublicKeyCredential` is obtained via\n  [CredentialsContainer.get]).\n\nIn order to validate the _creation_ of credentials, a relying party's server\nneeds both:\n\n- this response\n- the extensions of the client (given by\n  [PublicKeyCredential.getClientExtensionResults]) to validate the\n  demand.\n\n> **Note:** When validating the fetching of existing credentials, the\n> whole `PublicKeyCredential` object and the client extensions are necessary\n> for the relying party's server.\n\n> **Note:** This property may only be used in top-level contexts and will\n> not be available in an `iframe` for example.",
      "tojson": " \n\nThe **`toJSON()`** method of the [PublicKeyCredential] interface returns a  of a [PublicKeyCredential].\n\nThe properties of the returned object depend on whether the credential is returned by [`navigator.credentials.create()`](/en-US/docs/Web/API/CredentialsContainer/create) when [creating a key pair and registering a user](/en-US/docs/Web/API/Web_Authentication_API#creating_a_key_pair_and_registering_a_user), or [`navigator.credentials.get()`](/en-US/docs/Web/API/CredentialsContainer/get) when [authenticating a user](/en-US/docs/Web/API/Web_Authentication_API#authenticating_a_user).\n\nThis method is automatically invoked when web app code calls [`JSON.stringify()`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify) to serialize a [PublicKeyCredential] so that it can be sent to relying party server when registering or authenticating a user.\nIt not intended to be called directly in web app code."
    }
  },
  "pushevent": {
    "docs": "\n\nThe **`PushEvent`** interface of the [Push API](/en-US/docs/Web/API/Push_API) represents a push message that has been received. This event is sent to the [global scope](/en-US/docs/Web/API/ServiceWorkerGlobalScope) of a [ServiceWorker]. It contains the information sent from an application server to a [PushSubscription].\n\n",
    "properties": {
      "data": "\n\nThe `data` read-only property of the **`PushEvent`** interface returns a reference to a [PushMessageData] object containing data sent to the [PushSubscription]."
    }
  },
  "pushmanager": {
    "docs": "\n\nThe **`PushManager`** interface of the [Push API](/en-US/docs/Web/API/Push_API) provides a way to receive notifications from third-party servers as well as request URLs for push notifications.\n\nThis interface is accessed via the [ServiceWorkerRegistration.pushManager] property.",
    "properties": {
      "getsubscription": "\n\nThe **`PushManager.getSubscription()`** method of the [PushManager] interface retrieves an existing push subscription.\n\nIt returns a `Promise` that resolves to a [PushSubscription] object containing details of an existing subscription. If no existing subscription exists, this resolves to a `null` value.",
      "haspermission": "\n\nThe **`PushManager.hasPermission()`** method of the [PushManager] interface returns a `Promise` that resolves to the `PushPermissionStatus` of the requesting webapp, which will be one of `granted`, `denied`, or `default`.\n\n> **Note:** This feature has been superseded by the [PushManager.permissionState] method.",
      "permissionstate": "\n\nThe **`permissionState()`** method of the\n[PushManager] interface returns a `Promise` that resolves to a\nstring indicating the permission state of the push manager. Possible\nvalues are `'prompt'`, `'denied'`, or `'granted'`.\n\n> **Note:** As of Firefox 44, the permissions for [Notifications](/en-US/docs/Web/API/Notifications_API) and [Push](/en-US/docs/Web/API/Push_API) have been merged. If permission is\n> granted for notifications, push will also be enabled.",
      "register": "\n\nThe **`register`** method is used to ask the system to request\na new endpoint for notifications.\n\n> **Note:** This method has been superseded by [PushManager.subscribe].",
      "registrations": "\n\nThe **`registrations`** method is used to ask the system about\nexisting push endpoint registrations.\n\n> **Note:** This method has been superseded by the [PushManager.getSubscription] method.",
      "subscribe": "\n\nThe **`subscribe()`** method of the [PushManager]\ninterface subscribes to a push service.\n\nIt returns a `Promise` that resolves to a [PushSubscription]\nobject containing details of a push subscription. A new push subscription is created if\nthe current service worker does not have an existing subscription.",
      "supportedcontentencodings_static": "\n\nThe **`supportedContentEncodings`** read-only static property of the\n[PushManager] interface returns an array of supported content codings that\ncan be used to encrypt the payload of a push message.",
      "unregister": "\n\nThe **`unregister()`** method was used to ask the system to\nunregister and delete the specified endpoint.\n\n> **Note:** In the updated API, a subscription can be unregistered via the [PushSubscription.unsubscribe] method."
    }
  },
  "pushmessagedata": {
    "docs": "\n\nThe **`PushMessageData`** interface of the [Push API](/en-US/docs/Web/API/Push_API) provides methods which let you retrieve the push data sent by a server in various formats.\n\nUnlike the similar methods in the [Fetch API](/en-US/docs/Web/API/Fetch_API), which only allow the method to be invoked once, these methods can be called multiple times.\n\nMessages received through the Push API are sent encrypted by push services and then automatically decrypted by browsers before they are made accessible through the methods of the `PushMessageData` interface.",
    "properties": {
      "arraybuffer": "\n\nThe **`arrayBuffer()`** method of the [PushMessageData] interface extracts push message data as an `ArrayBuffer` object.",
      "blob": "\n\nThe **`blob()`** method of the [PushMessageData] interface extracts push message data as a [Blob] object.",
      "json": "\n\nThe **`json()`** method of the [PushMessageData] interface extracts push message data by parsing it as a [JSON](/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON) string and returning the result.",
      "text": "\n\nThe **`text()`** method of the [PushMessageData] interface extracts push message data as a plain text string."
    }
  },
  "pushsubscription": {
    "docs": "\n\nThe `PushSubscription` interface of the [Push API](/en-US/docs/Web/API/Push_API) provides a subscription's URL endpoint and allows unsubscribing from a push service.\n\nAn instance of this interface can be serialized.",
    "properties": {
      "endpoint": "\n\nThe **`endpoint`** read-only property of the\n[PushSubscription] interface returns a string containing\nthe endpoint associated with the push subscription.\n\nThe endpoint takes the form of a custom URL pointing to a push server, which can be\nused to send a push message to the particular service worker instance that subscribed to\nthe push service. For this reason, it is a good idea to keep your endpoint a secret, so\nothers do not hijack it and abuse the push functionality.",
      "expirationtime": "\n\nThe **`expirationTime`** read-only property of the\n[PushSubscription] interface returns a [DOMHighResTimeStamp]\nof the subscription expiration time associated with the push subscription, if there is\none, or `null` otherwise.",
      "getkey": "\n\nThe `getKey()` method of the [PushSubscription] interface\nreturns an `ArrayBuffer` representing a client public key, which can then\nbe sent to a server and used in encrypting push message data.",
      "options": "\n\nThe **`options`** read-only property\nof the [PushSubscription] interface is an object containing the options\nused to create the subscription.",
      "subscriptionid": "\n\nThe **`subscriptionId`** read-only property of the\n[PushSubscription] interface returns a string containing\nthe subscription ID associated with the push subscription.\n\n> **Warning:** Instead of this feature, use the [PushSubscription.endpoint] property on the same interface.",
      "tojson": "\n\nThe `toJSON()` method of the [PushSubscription] interface is a\nstandard serializer: it returns a JSON representation of the subscription properties,\nproviding a useful shortcut.",
      "unsubscribe": "\n\nThe `unsubscribe()` method of the [PushSubscription] interface\nreturns a `Promise` that resolves to a boolean value when the\ncurrent subscription is successfully unsubscribed."
    }
  },
  "pushsubscriptionoptions": {
    "docs": "`Push API`\n\nThe **`PushSubscriptionOptions`** interface of the [Push API] represents the options associated with a push subscription.\n\nThe read-only `PushSubscriptionOptions` object is returned by calling [PushSubscription.options] on a [PushSubscription]. This interface has no constructor of its own.",
    "properties": {
      "applicationserverkey": "`Push API`\n\nThe **`applicationServerKey`** read-only property of the [PushSubscriptionOptions] interface contains the public key used by the push server.",
      "uservisibleonly": "`Push API`\n\nThe **`userVisibleOnly`** read-only property of the [PushSubscriptionOptions] interface indicates if the returned push subscription will only be used for messages whose effect is made visible to the user."
    }
  },
  "radionodelist": {
    "docs": "\n\nThe **`RadioNodeList`** interface represents a collection of elements in a `form` or a `fieldset` element, returned by a call to [HTMLFormControlsCollection.namedItem].\n\n",
    "properties": {
      "value": "\n\nIf the underlying element collection contains radio buttons, the\n**`RadioNodeList.value`** property represents the checked radio\nbutton. On retrieving the `value` property, the `value` of the\ncurrently `checked` radio button is returned as a string. If the collection\ndoes not contain any radio buttons or none of the radio buttons in the collection is in\n`checked` state, the empty string is returned. On setting the\n`value` property, the first radio button input element whose\n`value` property is equal to the new value will be set to\n`checked`."
    }
  },
  "range": {
    "docs": "\n\nThe **`Range`** interface represents a fragment of a document that can contain nodes and parts of text nodes.\n\nA range can be created by using the [Document.createRange] method. Range objects can also be retrieved by using the [Selection/getRangeAt] method of the [Selection] object or the [Document/caretRangeFromPoint] method of the [Document] object.\n\nThere also is the [Range.Range] constructor available.\n\n",
    "properties": {
      "clonecontents": "\n\nThe **`Range.cloneContents()`** returns a [DocumentFragment] copying the objects of type [Node]\nincluded in the [Range].\n\nEvent listeners added using [EventTarget.addEventListener]\nare not copied during cloning. HTML attribute events are duplicated as they are\nfor the [Node.cloneNode] method. HTML `id` attributes\nare also cloned, which can lead to an invalid document through cloning.\n\nPartially selected nodes include the parent tags necessary to make the document\nfragment valid.",
      "clonerange": "\n\nThe **`Range.cloneRange()`** method returns a\n[Range] object with boundary points identical to the cloned\n[Range].\n\nThe returned clone is copied by value, not reference, so a change in either\n[Range] does not affect the other.",
      "collapse": "\n\nThe **`Range.collapse()`** method collapses the\n[Range] to one of its boundary points.\n\nA collapsed [Range] is empty, containing no content, specifying a\nsingle-point in a DOM tree. To determine if a [Range] is already collapsed,\nsee the [Range.collapsed] property.",
      "collapsed": "\n\nThe **`Range.collapsed`** read-only property returns a\nboolean flag indicating whether the start and end points of the\n[Range] are at the same position. It returns `true` if the start\nand end boundary points of the [Range] are the same point in the DOM,\n`false` if not.\n\nA collapsed [Range] is empty (containing no content), and specifies a\nsingle point in a DOM tree. To collapse a range, see the [Range.collapse]\nmethod.",
      "commonancestorcontainer": "\n\nThe **`Range.commonAncestorContainer`** read-only property\nreturns the deepest — or furthest down the document tree — [Node] that\ncontains both [boundary points](https://www.w3.org/TR/DOM-Level-2-Traversal-Range/ranges.html#Level-2-Range-Position-h3) of the [Range]. This means that if\n[Range.startContainer] and [Range.endContainer] both refer to\nthe same node, this node is the **common ancestor container**.\n\nSince a `Range` need not be continuous, and may also partially select nodes,\nthis is a convenient way to find a `Node` which encloses a\n`Range`.\n\nThis property is read-only. To change the ancestor container of a `Node`,\nconsider using the various methods available to set the start and end positions of the\n`Range`, such as [Range.setStart] and\n[Range.setEnd].",
      "compareboundarypoints": "\n\nThe\n**`Range.compareBoundaryPoints()`** method compares the\nboundary points of the [Range] with those of another range.",
      "comparenode": "\n\nThe **`Range.compareNode()`** returns a constant indicating the\nposition of the [Node].\n\nThe possible values are:\n\n- `NODE_BEFORE` (`0`)\n  - : Node starts before the Range\n- `NODE_AFTER` (`1`)\n  - : Node ends after the Range\n- `NODE_BEFORE_AND_AFTER` (`2`)\n  - : Node starts before and ends after the Range\n- `NODE_INSIDE` (`3`)\n  - : Node starts after and ends before the Range, i.e. the Node is completely selected by\n    the Range.\n\n> **Warning:** This method [has been removed](/en-US/docs/Mozilla/Firefox/Releases/3/Site_compatibility) from [Gecko 1.9](/en-US/docs/Mozilla/Firefox/Releases/3) and\n> will not exist in future versions of Firefox, which was the only browser implementing\n> it; you should switch to [Range.compareBoundaryPoints] as soon as\n> possible.\n\nThe following function can be used as replacement:\n\n```js\nfunction rangeCompareNode(range, node) {\n  const nodeRange = node.ownerDocument.createRange();\n  try {\n    nodeRange.selectNode(node);\n  } catch (e) {\n    nodeRange.selectNodeContents(node);\n  }\n  const nodeIsBefore =\n    range.compareBoundaryPoints(Range.START_TO_START, nodeRange) === 1;\n  const nodeIsAfter =\n    range.compareBoundaryPoints(Range.END_TO_END, nodeRange) === -1;\n\n  if (nodeIsBefore && !nodeIsAfter) return 0;\n  if (!nodeIsBefore && nodeIsAfter) return 1;\n  if (nodeIsBefore && nodeIsAfter) return 2;\n\n  return 3;\n}\n```",
      "comparepoint": "\n\nThe **`Range.comparePoint()`** method returns `-1`,\n`0`, or `1` depending on whether the `referenceNode` is\nbefore, the same as, or after the [Range].\n\nIf the _reference node_ is a [Node] of type [Text],\n[Comment], or [CDATASection], then offset is the number of\ncharacters from the start of _reference node_. For other [Node]\ntypes, offset is the number of child nodes between the start of the _reference\nnode_.",
      "createcontextualfragment": "\n\nThe **`Range.createContextualFragment()`** method returns a\n[DocumentFragment] by invoking the HTML fragment parsing algorithm or the\nXML fragment parsing algorithm with the start of the range (the _parent_ of the\nselected node) as the context node. The HTML fragment parsing algorithm is used if the\nrange belongs to a `Document` whose HTMLness bit is set. In the HTML case, if\nthe context node would be `html`, for historical reasons the fragment parsing\nalgorithm is invoked with `body` as the context instead.",
      "deletecontents": "\n\nThe **`Range.deleteContents()`** method removes the contents of\nthe [Range] from the [Document].\n\nUnlike [Range.extractContents], this method does not return a\n[DocumentFragment] containing the deleted content.",
      "detach": "\n\nThe **`Range.detach()`** method does nothing. It used to\ndisable the [Range] object and enable the browser to release associated\nresources. The method has been kept for compatibility.",
      "endcontainer": "\n\nThe **`Range.endContainer`** read-only property returns the\n[Node] within which the [Range] ends. To change the end\nposition of a node, use the [Range.setEnd] method or a similar one.",
      "endoffset": "\n\nThe **`Range.endOffset`** read-only property returns a number\nrepresenting where in the [Range.endContainer] the [Range]\nends.\n\nIf the `endContainer` is a [Node] of type [Text],\n[Comment], or [CDATASection], then the offset is the number of\ncharacters from the start of the `endContainer` to the boundary point of the\n[Range]. For other [Node] types, the `endOffset` is\nthe number of child nodes between the start of the `endContainer` and the\nboundary point of the [Range]. This property is read-only. To change the\n`endOffset` of a [Range], use one of the\n[Range.setEnd] methods.",
      "extractcontents": "\n\nThe **`Range.extractContents()`** method moves contents of the\n[Range] from the document tree into a [DocumentFragment].\n\nEvent listeners added using DOM Events are not retained during extraction. HTML\nattribute events are retained or duplicated as they are for the\n[Node.cloneNode] method. HTML `id` attributes are also cloned,\nwhich can lead to an invalid document if a partially-selected node is extracted and\nappended to the document.\n\nPartially selected nodes are cloned to include the parent tags necessary to make the\ndocument fragment valid.",
      "getboundingclientrect": "\n\nThe **`Range.getBoundingClientRect()`** method returns a [DOMRect] object that bounds the contents of the range; this is a rectangle\nenclosing the union of the bounding rectangles for all the elements in the range.\n\nThis method is useful for determining the viewport coordinates of the cursor or\nselection inside a text box. See [Element.getBoundingClientRect] for\ndetails on the returned value.",
      "getclientrects": "\n\nThe **`Range.getClientRects()`** method returns a list of [DOMRect] objects representing the area of the screen occupied by the [range](/en-US/docs/Web/API/Range). This is created by aggregating the results of calls to\n[Element.getClientRects] for all the elements in the range.",
      "insertnode": "\n\nThe **`Range.insertNode()`** method inserts a node at the start\nof the [Range].\n\nThe new node is inserted at the start boundary point of the `Range`. If the\nnew node is to be added to a text [Node], that `Node` is split\nat the insertion point, and the insertion occurs between the two text nodes.\n\nIf the new node is a document fragment, the children of the document fragment are\ninserted instead.",
      "intersectsnode": "\n\nThe **`Range.intersectsNode()`** method returns a boolean\nindicating whether the given [Node] intersects the [Range].",
      "ispointinrange": "\n\nThe **`Range.isPointInRange()`** method returns a boolean\nindicating whether the given point is in the [Range]. It returns\n`true` if the point (cursor position) at `offset` within\n`ReferenceNode` is within this range.",
      "selectnode": "\n\nThe **`Range.selectNode()`** method sets the\n[Range] to contain the [Node] and its contents. The parent\n[Node] of the start and end of the [Range] will be the same as\nthe parent of the _referenceNode_.",
      "selectnodecontents": "\n\nThe **`Range.selectNodeContents()`** method sets the [Range] to contain the contents of a [Node].\n\nThe parent `Node` of the start and end of the `Range` will be the\nreference node. The `startOffset` is 0, and the `endOffset` is the\nnumber of child `Node`s or number of characters contained in the reference\nnode.",
      "setend": "\n\nThe **`Range.setEnd()`** method sets the end position of a [Range] to be located at the given offset into the specified node x.Setting\nthe end point above (higher in the document) than the start point will result in a\ncollapsed range with the start and end points both set to the specified end position.",
      "setendafter": "\n\nThe **`Range.setEndAfter()`** method sets the end position of a\n[Range] relative to another [Node]. The parent\n`Node` of end of the `Range` will be the same as that for the\n`referenceNode`.",
      "setendbefore": "\n\nThe **`Range.setEndBefore()`** method sets the end position of\na `Range` relative to another [Node]. The parent\n`Node` of end of the `Range` will be the same as that for the\n`referenceNode`.",
      "setstart": "\n\nThe **`Range.setStart()`** method sets the start position of a\n[Range].\n\nIf the `startNode` is a [Node] of type [Text],\n[Comment], or [CDataSection], then `startOffset` is\nthe number of characters from the start of `startNode`. For other\n`Node` types, `startOffset` is the number of child nodes between\nthe start of the `startNode`.\n\nSetting the start point below (lower in the document) the end point will result in a\ncollapsed range with the start and end points both set to the specified start position.",
      "setstartafter": "\n\nThe **`Range.setStartAfter()`** method sets the start position\nof a [Range] relative to a [Node]. The parent\n[Node] of the start of the [Range] will be the same as that\nfor the `referenceNode`.",
      "setstartbefore": "\n\nThe **`Range.setStartBefore()`** method sets the start position\nof a [Range] relative to another [Node]. The parent\n[Node] of the start of the [Range] will be the same as that\nfor the `referenceNode`.",
      "startcontainer": "\n\nThe **`Range.startContainer`** read-only property returns the\n[Node] within which the `Range` starts. To change the start\nposition of a node, use one of the [Range.setStart] methods.",
      "startoffset": "\n\nThe **`Range.startOffset`** read-only property returns a number\nrepresenting where in the `startContainer` the `Range` starts.\n\nIf the `startContainer` is a [Node] of type\n[Text], [Comment], or [CDATASection], then the\noffset is the number of characters from the start of the `startContainer` to\nthe boundary point of the [Range]. For other [Node] types, the\n`startOffset` is the number of child nodes between the start of the\n`startContainer` and the boundary point of the [Range].\n\nTo change the `startOffset` of a [Range], use the\n[Range.setStart] method.",
      "surroundcontents": "\n\nThe **`Range.surroundContents()`** method moves content of the\n[Range] into a new node, placing the new node at the start of the\nspecified range.\n\nThis method is nearly equivalent to\n`newNode.appendChild(range.extractContents()); range.insertNode(newNode)`.\nAfter surrounding, the boundary points of the `range` include\n`newNode`.\n\nAn exception will be thrown, however, if the [Range] splits a non-[Text] node with only one of its boundary points. That is, unlike the\nalternative above, if there are partially selected nodes, they will not be cloned and\ninstead the operation will fail.",
      "tostring": "\n\nThe **`Range.toString()`** method is a  returning\nthe text of the [Range].\n\nAlerting the contents of a [Range] makes an implicit\n`toString()` call, so comparing range and text through an alert dialog is\nineffective."
    }
  },
  "readablebytestreamcontroller": {
    "docs": "\n\nThe **`ReadableByteStreamController`** interface of the [Streams API](/en-US/docs/Web/API/Streams_API) represents a controller for a [readable byte stream](/en-US/docs/Web/API/Streams_API/Using_readable_byte_streams).\nIt allows control of the state and internal queue of a [ReadableStream] with an underlying byte source, and enables efficient zero-copy transfer of data from the underlying source to a consumer when the stream's internal queue is empty.\n\nAn instance of this controller type is created if an `underlyingSource` object with the property `type=\"bytes\"` is passed as an argument to the [`ReadableStream()` constructor](/en-US/docs/Web/API/ReadableStream/ReadableStream#type).\nThe `underlyingSource` object may also define [`start()`](/en-US/docs/Web/API/ReadableStream/ReadableStream#start) and [`pull()`](/en-US/docs/Web/API/ReadableStream/ReadableStream#pull) callback functions.\nThese are called with the controller as a parameter, in order to set up the underlying source, and request data when needed.\n\nThe underlying source uses the controller to supply data to the stream via its [`byobRequest`](#readablebytestreamcontroller.byobrequest) property or [`enqueue()`](#readablebytestreamcontroller.enqueue) method.\n[`byobRequest`](#readablebytestreamcontroller.byobrequest) is a [ReadableStreamBYOBRequest] object that represents a pending request from a consumer to make a zero-copy transfer of data direct to a consumer.\n`byobRequest` must be used to copy data if it exists (do not use `enqueue()` in this case)!\nIf the underlying source needs to pass data to the stream and `byobRequest` is `null` then the source can call [`enqueue()`](#readablebytestreamcontroller.enqueue) to add the data to the stream's internal queues.\n\nNote that the [`byobRequest`](#readablebytestreamcontroller.byobrequest) is only created in \"BYOB mode\" when there is a request from a reader and the stream's internal queue is empty.\n\"BYOB mode\" is enabled when using a [ReadableStreamBYOBReader] (typically constructed by calling [ReadableStream.getReader] with the argument `{ mode: 'byob' }`).\nIt is also enabled when using a default reader and [`autoAllocateChunkSize`](/en-US/docs/Web/API/ReadableStream/ReadableStream#autoallocatechunksize) is specified in the [`ReadableController()` constructor](/en-US/docs/Web/API/ReadableStream/ReadableStream#autoallocatechunksize).\n\nAn underlying byte source can also use the controller to [`close()`](#readablebytestreamcontroller.close) the stream when all the data has been sent and report errors from the underlying source using [`error()`](#readablebytestreamcontroller.error).\nThe controller's [`desiredSize`](#readablebytestreamcontroller.desiredsize) property is used to apply \"backpressure\", informing the underlying source of the size of the internal queue (small values indicate that the queue is filling up, hinting to the underlying source that it is be desirable to pause or throttle the inflow).\n\nNote that even though the controller is primarily used by the underlying byte source, there is no reason it cannot be stored used by other parts of the system to signal the stream.",
    "properties": {
      "byobrequest": "\n\nThe **`byobRequest`** read-only property of the [ReadableByteStreamController] interface returns the current BYOB request, or `null` if there are no pending requests.\n\nAn underlying byte source should check this property, and use it to write data to the stream if it exists (rather than using [ReadableByteStreamController.enqueue]).\nThis will result in an efficient zero-byte transfer of the data to the consumer.",
      "close": "\n\nThe **`close()`** method of the [ReadableByteStreamController] interface closes the associated stream.\n\nThis might be called by the underlying source when its data source has been exhausted/completed.\n\n> **Note:** Readers will still be able to read any previously-enqueued chunks from the stream, but once those are read, the stream will become closed.\n> However if there is an outstanding and partially written [ReadableByteStreamController.byobRequest] when `close()` is called, the stream will be errored.",
      "desiredsize": "\n\nThe **`desiredSize`** read-only property of the [ReadableByteStreamController] interface returns the number of bytes required to fill the stream's internal queue to its \"desired size\".\n\nThe value is used by the stream to indicate a preferred flow rate to the underlying source.\nSources that support throttling or pausing their inflow of data (not all do!) should control the inflow such that `desiredSize` of the stream buffer is kept positive and as close to zero as possible.\n\nThe `desiredSize` is used to apply [backpressure](/en-US/docs/Web/API/Streams_API/Concepts#backpressure) from downstream consumers.",
      "enqueue": "\n\nThe **`enqueue()`** method of the [ReadableByteStreamController] interface enqueues a given chunk on the associated readable byte stream (the chunk is copied into the stream's internal queues).\n\nThis should only be used to transfer data to the queue when [ReadableByteStreamController.byobRequest] is `null`.",
      "error": "\n\nThe **`error()`** method of the [ReadableByteStreamController] interface causes any future interactions with the associated stream to error with the specified reason.\n\nThis is commonly called by an underlying source to surface an error from the interface where it gets its data (such as a file-read or socket error).\nIt can also be called from elsewhere to trigger a stream error, for example if another part of the system that the stream relies on fails."
    }
  },
  "readablestream": {
    "docs": "\n\nThe `ReadableStream` interface of the [Streams API](/en-US/docs/Web/API/Streams_API) represents a readable stream of byte data. The [Fetch API](/en-US/docs/Web/API/Fetch_API) offers a concrete instance of a `ReadableStream` through the [Response.body] property of a [Response] object.\n\n`ReadableStream` is a [transferable object](/en-US/docs/Web/API/Web_Workers_API/Transferable_objects).",
    "properties": {
      "cancel": "\n\nThe **`cancel()`** method of the\n[ReadableStream] interface returns a `Promise` that\nresolves when the stream is canceled.\n\nCancel is used when you've completely finished with the stream and don't need any more\ndata from it, even if there are chunks enqueued waiting to be read. That data is lost\nafter cancel is called, and the stream is not readable any more. To read those chunks\nstill and not completely get rid of the stream, you'd use\n[ReadableStreamDefaultController.close].",
      "from_static": "\n\nThe **`ReadableStream.from()`** static method returns a [ReadableStream] from a provided iterable or async iterable object.\n\nThe method can be used to wrap iterable and async iterable objects as readable streams, including arrays, sets, arrays of promises, async generators, `ReadableStreams`, Node.js `readable` streams, and so on.",
      "getreader": "\n\nThe **`getReader()`** method of the [ReadableStream] interface creates a reader and locks the stream to it.\nWhile the stream is locked, no other reader can be acquired until this one is released.",
      "locked": "\n\nThe **`locked`** read-only property of the [ReadableStream] interface returns whether or not the readable stream is locked to a reader.\n\nA readable stream can have at most one active reader at a time, and is locked to that reader until it is released.\nA reader might be obtained using [`ReadableStream.getReader()`](/en-US/docs/Web/API/ReadableStream/getReader) and released using the reader's `releaseLock()` method.",
      "pipethrough": "\n\nThe **`pipeThrough()`** method of the [ReadableStream] interface provides a chainable way of piping the current stream through a transform stream or any other writable/readable pair.\n\nPiping a stream will generally lock it for the duration of the pipe, preventing other readers from locking it.",
      "pipeto": "\n\nThe **`pipeTo()`** method of the [ReadableStream] interface pipes the current `ReadableStream` to a given [WritableStream] and returns a `Promise` that fulfills when the piping process completes successfully, or rejects if any errors were encountered.\n\nPiping a stream will generally [lock](/en-US/docs/Web/API/ReadableStream/locked) it for the duration of the pipe, preventing other readers from locking it.",
      "tee": "\n\nThe **`tee()`** method of the\n[ReadableStream] interface [tees](https://streams.spec.whatwg.org/#tee-a-readable-stream) the current readable stream, returning a\ntwo-element array containing the two resulting branches as\nnew [ReadableStream] instances.\n\nThis is useful for allowing two readers to read a stream sequentially or simultaneously,\nperhaps at different speeds.\nFor example, you might do this in a ServiceWorker if you want to fetch\na response from the server and stream it to the browser, but also stream it to the\nServiceWorker cache. Since a response body cannot be consumed more than once, you'd need\ntwo copies to do this.\n\nA teed stream will partially signal backpressure at the rate of the _faster_ consumer\nof the two `ReadableStream` branches,\nand unread data is enqueued internally on the slower consumed `ReadableStream`\nwithout any limit or backpressure.\nThat is, when _both_ branches have an unread element in their internal queue,\nthen the original `ReadableStream`'s controller's internal queue will start to fill up,\nand once its [ReadableStreamDefaultController.desiredSize] ≤ 0\nor byte stream controller [ReadableByteStreamController.desiredSize] ≤ 0,\nthen the controller will stop calling `pull(controller)` on the\nunderlying source passed to [ReadableStream.ReadableStream].\nIf only one branch is consumed, then the entire body will be enqueued in memory.\nTherefore, you should not use the built-in `tee()` to read very large streams\nin parallel at different speeds.\nInstead, search for an implementation that fully backpressures\nto the speed of the _slower_ consumed branch.\n\nTo cancel the stream you then need to cancel both resulting branches. Teeing a stream\nwill generally lock it for the duration, preventing other readers from locking it."
    }
  },
  "readablestreambyobreader": {
    "docs": "\n\nThe `ReadableStreamBYOBReader` interface of the [Streams API](/en-US/docs/Web/API/Streams_API) defines a reader for a [ReadableStream] that supports zero-copy reading from an underlying byte source.\nIt is used for efficient copying from underlying sources where the data is delivered as an \"anonymous\" sequence of bytes, such as files.\n\nAn instance of this reader type should usually be obtained by calling [ReadableStream.getReader] on the stream, specifying `mode: \"byob\"` in the options parameter.\nThe readable stream must have an _underlying byte source_. In other words, it must have been [constructed](/en-US/docs/Web/API/ReadableStream/ReadableStream) specifying an underlying source with [`type: \"bytes\"`](/en-US/docs/Web/API/ReadableStream/ReadableStream#type)).\n\nUsing this kind of reader, a [`read()`](#readablestreambyobreader.read) request when the readable stream's internal queues are empty will result in a zero copy transfer from the underlying source (bypassing the stream's internal queues).\nIf the internal queues are not empty, a `read()` will satisfy the request from the buffered data.\n\nNote that the methods and properties are similar to those for the default reader ([ReadableStreamDefaultReader]).\nThe `read()` method differs in that it provide a view into which data should be written.",
    "properties": {
      "cancel": "\n\nThe **`cancel()`** method of the [ReadableStreamBYOBReader] interface returns a `Promise` that resolves when the stream is canceled.\nCalling this method signals a loss of interest in the stream by a consumer.\n\n> **Note:** If the reader is active, the `cancel()` method behaves the same as that for the associated stream ([ReadableStream.cancel]).",
      "closed": "\n\nThe **`closed`** read-only property of the [ReadableStreamBYOBReader] interface returns a `Promise` that fulfills when the stream closes, or rejects if the stream throws an error or the reader's lock is released.\n\nThis property enables you to write code that responds to an end to the streaming process.",
      "read": "\n\nThe **`read()`** method of the [ReadableStreamBYOBReader] interface is used to read data into a view on a user-supplied buffer from an associated [readable byte stream](/en-US/docs/Web/API/Streams_API/Using_readable_byte_streams).\nA request for data will be satisfied from the stream's internal queues if there is any data present.\nIf the stream queues are empty, the request may be supplied as a zero-copy transfer from the underlying byte source.\n\nThe method takes as an argument a view on a buffer that supplied data is to be read into, and returns a `Promise`.\nThe promise fulfills with an object that has properties `value` and `done` when data comes available, or if the stream is cancelled.\nIf the stream is errored, the promise will be rejected with the relevant error object.\n\nIf a chunk of data is supplied, the `value` property will contain a new view.\nThis will be a view over the same buffer/backing memory (and of the same type) as the original `view` passed to the `read()` method, now populated with the new chunk of data.\nNote that once the promise fulfills, the original `view` passed to the method will be detached and no longer usable.\nThe promise will fulfill with a `value: undefined` if the stream has been cancelled.\nIn this case the backing memory region of `view` is discarded and not returned to the caller (all previously read data in the view's buffer is lost).\n\nThe `done` property indicates whether or not more data is expected.\nThe value is set `true` if the stream is closed or cancelled, and `false` otherwise.",
      "releaselock": "\n\nThe **`releaseLock()`** method of the [ReadableStreamBYOBReader] interface releases the reader's lock on the stream.\nAfter the lock is released, the reader is no longer active.\n\nThe reader will appear errored if the associated stream is errored when the lock is released; otherwise, the reader will appear closed.\n\nIf the reader's lock is released while it still has pending read requests then the promises returned by the reader's [ReadableStreamBYOBReader.read] method are immediately rejected with a `TypeError`.\nUnread chunks remain in the stream's internal queue and can be read later by acquiring a new reader."
    }
  },
  "readablestreambyobrequest": {
    "docs": "\n\nThe **`ReadableStreamBYOBRequest`** interface of the [Streams API](/en-US/docs/Web/API/Streams_API) represents a \"pull request\" for data from an underlying source that will made as a zero-copy transfer to a consumer (bypassing the stream's internal queues).\n\n`ReadableStreamBYOBRequest` objects are created in \"BYOB mode\" when a consumer makes a request for data and the stream's internal queue is _empty_.\n(The stream will resolve the consumer's request directly if it already has buffered data).\nAn underlying byte source can access active BYOB requests through its controller's [ReadableByteStreamController.byobRequest] property, which will be set to `null` if there is no outstanding request.\n\nAn underlying source that supports \"BYOB mode\" should check for [ReadableByteStreamController.byobRequest] and must use it for transferring data, if present.\nIf data arrives from the underlying source when [ReadableByteStreamController.byobRequest] is `null`, it can be queued using [ReadableByteStreamController.enqueue].\nThis might happen when an underlying push source receives new data when the stream's internal buffers are not empty.\n\nAn underlying source uses the request by writing data to the BYOB request's [`view`](#readablestreambyobrequest.view) and then calling [`respond()`](#readablestreambyobrequest.respond), or by calling [`respondWithNewView()`](#readablestreambyobrequest.respondwithnewview) and passing a new view as an argument.\nNote that the \"new view\" must actually be a view over the _same_ buffer as the original `view`, starting at the same offset.\nThis might be used to return a shorter buffer if the underlying source is unable to fill the entire original view.\n\nNote that a [ReadableByteStreamController] is only created for underlying sources when `type=\"bytes\"` is specified for the source in the [`ReadableStream()` constructor](/en-US/docs/Web/API/ReadableStream/ReadableStream#type).\n\"BYOB mode\" is enabled when either [`autoAllocateChunkSize`](/en-US/docs/Web/API/ReadableStream/ReadableStream#autoallocatechunksize) is specified in the [`ReadableController()` constructor](/en-US/docs/Web/API/ReadableStream/ReadableStream#autoallocatechunksize) or when using a [ReadableStreamBYOBReader] (typically constructed by calling [ReadableStream.getReader] with the argument `{ mode: 'byob' }`).",
    "properties": {
      "respond": "\n\nThe **`respond()`** method of the [ReadableStreamBYOBRequest] interface is used to signal to the associated [readable byte stream](/en-US/docs/Web/API/Streams_API/Using_readable_byte_streams) that the specified number of bytes were written into the [ReadableStreamBYOBRequest.view].\n\nAfter this method is called, the [ReadableStreamBYOBRequest/view] will be transferred and no longer modifiable.",
      "respondwithnewview": "\n\nThe **`respondWithNewView()`** method of the [ReadableStreamBYOBRequest] interface specifies a new view that the consumer of the associated readable byte stream should write to instead of [ReadableStreamBYOBRequest.view].\n\nThe new view must be a `TypedArray` or a `DataView` that provides a view onto the same backing memory region as [ReadableStreamBYOBRequest.view].\nAfter this method is called, the view that was passed into the method will be transferred and no longer modifiable.\n\nThe method is intended for use cases where an underlying byte source needs to transfer a `byobRequest.view` internally before finishing its response.\nFor example, the source may transfer the BYOB view to a separate worker thread, and wait for the worker to transfer it back once it has been filled.",
      "view": "\n\nThe **`view`** getter property of the [ReadableStreamBYOBRequest] interface returns the current view."
    }
  },
  "readablestreamdefaultcontroller": {
    "docs": "\n\nThe **`ReadableStreamDefaultController`** interface of the [Streams API](/en-US/docs/Web/API/Streams_API) represents a controller allowing control of a [ReadableStream]'s state and internal queue. Default controllers are for streams that are not byte streams.",
    "properties": {
      "close": "\n\nThe **`close()`** method of the\n[ReadableStreamDefaultController] interface closes the associated stream.\n\nReaders will still be able to read any previously-enqueued chunks from the stream,\nbut once those are read, the stream will become closed. If you want to completely get\nrid of the stream and discard any enqueued chunks, you'd use\n[ReadableStream.cancel] or\n[ReadableStreamDefaultReader.cancel].",
      "desiredsize": "\n\nThe **`desiredSize`** read-only property of the\n[ReadableStreamDefaultController] interface returns the desired size\nrequired to fill the stream's internal queue.",
      "enqueue": "\n\nThe **`enqueue()`** method of the\n[ReadableStreamDefaultController] interface enqueues a given chunk in the\nassociated stream.",
      "error": "\n\nThe **`error()`** method of the\n[ReadableStreamDefaultController] interface causes any future interactions\nwith the associated stream to error.\n\n> **Note:** The `error()` method can be called\n> more than once, and can be called when the stream is not readable."
    }
  },
  "readablestreamdefaultreader": {
    "docs": "\n\nThe **`ReadableStreamDefaultReader`** interface of the [Streams API](/en-US/docs/Web/API/Streams_API) represents a default reader that can be used to read stream data supplied from a network (such as a fetch request).\n\nA `ReadableStreamDefaultReader` can be used to read from a [ReadableStream] that has an underlying source of any type (unlike a [ReadableStreamBYOBReader], which can only be used with readable streams that have an _underlying byte source_).\n\nNote however that zero-copy transfer from an underlying source is only supported for underlying byte sources that autoallocate buffers.\nIn other words, the stream must have been [constructed](/en-US/docs/Web/API/ReadableStream/ReadableStream) specifying both [`type=\"bytes\"`](/en-US/docs/Web/API/ReadableStream/ReadableStream#type) and [`autoAllocateChunkSize`](/en-US/docs/Web/API/ReadableStream/ReadableStream#autoallocatechunksize).\nFor any other underlying source, the stream will always satisfy read requests with data from internal queues.",
    "properties": {
      "cancel": "\n\nThe **`cancel()`** method of the\n[ReadableStreamDefaultReader] interface returns a `Promise` that resolves when the stream is canceled. Calling this method signals a loss of interest in the stream by a consumer.\n\nCancel is used when you've completely finished with the stream and don't need any more\ndata from it, even if there are chunks enqueued waiting to be read. That data is lost\nafter cancel is called, and the stream is not readable any more. To read those chunks\nstill and not completely get rid of the stream, you'd use\n[ReadableStreamDefaultController.close].\n\n> **Note:** If the reader is active, the\n> `cancel()` method behaves the same as that for the associated stream\n> ([ReadableStream.cancel]).",
      "closed": "\n\nThe **`closed`** read-only property of the\n[ReadableStreamDefaultReader] interface returns a\n`Promise` that fulfills when the stream closes, or rejects if the\nstream throws an error or the reader's lock is released. This property enables you\nto write code that responds to an end to the streaming process.",
      "read": "\n\nThe **`read()`** method of the [ReadableStreamDefaultReader] interface returns a `Promise` providing access to the next chunk in the stream's internal queue.",
      "releaselock": "\n\nThe **`releaseLock()`** method of the [ReadableStreamDefaultReader] interface releases the reader's lock on the stream.\n\nIf the associated stream is errored when the lock is released, the reader will appear errored in that same way subsequently; otherwise, the reader will appear closed.\n\nIf the reader's lock is released while it still has pending read requests then the promises returned by the reader's [ReadableStreamDefaultReader.read] method are immediately rejected with a `TypeError`.\nUnread chunks remain in the stream's internal queue and can be read later by acquiring a new reader."
    }
  },
  "relativeorientationsensor": {
    "docs": "\n\nThe **`RelativeOrientationSensor`** interface of the [Sensor APIs](/en-US/docs/Web/API/Sensor_APIs) describes the device's physical orientation without regard to the Earth's reference coordinate system.\n\nTo use this sensor, the user must grant permission to the `'accelerometer'`, and `'gyroscope'` device sensors through the [Permissions API](/en-US/docs/Web/API/Permissions_API). In addition, this feature may be blocked by a [Permissions Policy](/en-US/docs/Web/HTTP/Permissions_Policy) set on your server.\n\n"
  },
  "remoteplayback": {
    "docs": "\n\nThe **`RemotePlayback`** interface of the [Remote Playback API] allows the page to detect availability of remote playback devices, then connect to and control playing on these devices.\n\n",
    "properties": {
      "cancelwatchavailability": "\n\nThe **`cancelWatchAvailability()`** method of the [RemotePlayback] interface cancels the request to watch for one or all available devices.",
      "connect_event": "\n\nThe **`connect`** event of the [RemotePlayback] interface fires when the user agent connects to the remote device.",
      "connecting_event": "\n\nThe **`connecting`** event of the [RemotePlayback] interface fires when the user agent initiates remote playback.",
      "disconnect_event": "\n\nThe **`disconnect`** event of the [RemotePlayback] interface fires when the user agent disconnects from the remote device.",
      "prompt": "\n\nThe **`prompt()`** method of the [RemotePlayback] interface prompts the user to select an available remote playback device and give permission for the current media to be played using that device.\n\nIf the user gives permission, the [RemotePlayback.state] will be set to `connecting` and the user agent will connect to the device to initiate playback.\n\nIf the user chooses to instead disconnect from the device, the [RemotePlayback.state] will be set to `disconnected` and user agent will disconnect from this device.",
      "state": "\n\nThe **`state`** read-only property of the [RemotePlayback] interface returns the current state of the `RemotePlayback` connection.",
      "watchavailability": "\n\nThe **`watchAvailability()`** method of the [RemotePlayback] interface watches the list of available remote playback devices and returns a `Promise` that resolves with the `callbackId` of a remote playback device."
    }
  },
  "report": {
    "docs": "\n\nThe `Report` interface of the [Reporting API](/en-US/docs/Web/API/Reporting_API) represents a single report.\n\nReports can be accessed in a number of ways:\n\n- Via the [ReportingObserver.takeRecords] method — this returns all reports in an observer's report queue, and then empties the queue.\n- Via the `reports` parameter of the callback function passed into the [`ReportingObserver()`](/en-US/docs/Web/API/ReportingObserver/ReportingObserver) constructor upon creation of a new observer instance. This contains the list of reports currently contained in the observer's report queue.\n- By sending requests to the endpoints defined via the  HTTP header.",
    "properties": {
      "body": "\n\nThe **`body`** read-only property of the [Report]\ninterface returns the body of the report, which is a `ReportBody` object\ncontaining the detailed report information.",
      "type": "\n\nThe **`type`** read-only property of the [Report]\ninterface returns the type of report generated, e.g. `deprecation` or\n`intervention`.",
      "url": "\n\nThe **`url`** read-only property of the [Report]\ninterface returns the URL of the document that generated the report."
    }
  },
  "reportbody": {
    "docs": "\n\nThe **`ReportBody`** interface of the [Reporting API] represents the body of a report. Individual report types inherit from this interface, adding specific attributes relevant to the particular report.\n\n### Reports that inherit from `ReportBody`\n\n- [CSPViolationReportBody]\n- [DeprecationReportBody]\n- [InterventionReportBody]\n\nAn instance of `ReportBody` is returned as the value of [Report.body]. The interface has no constructor.",
    "properties": {
      "tojson": "\n\nThe **`toJSON()`** method of the [ReportBody] interface is a _serializer_, and returns a JSON representation of the `ReportBody` object."
    }
  },
  "reportingobserver": {
    "docs": "\n\nThe `ReportingObserver` interface of the [Reporting API](/en-US/docs/Web/API/Reporting_API) allows you to collect and access reports.",
    "properties": {
      "disconnect": "\n\nThe **`disconnect()`** method of the\n[ReportingObserver] interface stops a reporting observer that had\npreviously started observing from collecting reports.\n\nAfter calling `disconnect()`, neither\n[ReportingObserver.takeRecords] nor the `records` parameter of\nthe\n[`ReportingObserver()`](/en-US/docs/Web/API/ReportingObserver/ReportingObserver)\ncallback will return any reports. The associated observer will no longer be active.",
      "observe": "\n\nThe **`observe()`** method of the\n[ReportingObserver] interface instructs a reporting observer to start\ncollecting reports in its report queue.",
      "takerecords": "\n\nThe **`takeRecords()`** method of the\n[ReportingObserver] interface returns the current list of reports contained\nin the observer's report queue, and empties the queue."
    }
  },
  "request": {
    "docs": "\n\nThe **`Request`** interface of the [Fetch API](/en-US/docs/Web/API/Fetch_API) represents a resource request.\n\nYou can create a new `Request` object using the [Request.Request] constructor, but you are more likely to encounter a `Request` object being returned as the result of another API operation, such as a service worker [FetchEvent.request].",
    "properties": {
      "arraybuffer": "\n\nThe **`arrayBuffer()`** method of the [Request] interface\nreads the request body and returns it as a promise that resolves with an `ArrayBuffer`.",
      "blob": "\n\nThe **`blob()`** method of the [Request] interface\nreads the request body and returns it as a promise that resolves with a [Blob].",
      "body": "\n\nThe read-only **`body`** property of the [Request]\ninterface contains a [ReadableStream] with the body contents\nthat have been added to the request. Note that a request using the\n`GET` or `HEAD` method cannot have a body\nand `null` is returned in these cases.",
      "bodyused": "\n\nThe read-only **`bodyUsed`** property of the\n[Request] interface is a boolean value that indicates\nwhether the request body has been read yet.",
      "cache": "\n\nThe **`cache`** read-only property of the [Request] interface contains the cache mode of the request. It controls how the request will interact with the browser's [HTTP cache](/en-US/docs/Web/HTTP/Caching).",
      "clone": "\n\nThe **`clone()`** method of the [Request] interface creates a copy of the current `Request` object.\n\nLike the underlying [ReadableStream.tee] api,\nthe [Request.body] of a cloned `Response`\nwill signal backpressure at the rate of the _faster_ consumer of the two bodies,\nand unread data is enqueued internally on the slower consumed `body`\nwithout any limit or backpressure.\nBeware when you construct a `Request` from a stream and then `clone` it.\n\n`clone()` throws a `TypeError` if the request body has already been used. In fact, the main reason `clone()` exists is to allow multiple uses of body objects (when they are one-use only.)\n\nIf you intend to modify the request, you may prefer the [Request] constructor.",
      "credentials": "\n\nThe **`credentials`** read-only property of the [Request] interface indicates whether the user agent should send or receive cookies from the other domain in the case of cross-origin requests.",
      "destination": "\n\nThe **`destination`** read-only\nproperty of the **[Request]** interface returns a string\ndescribing the type of content being requested.\n\nThe string must be one of the `audio`, `audioworklet`,\n`document`, `embed`, `font`, `frame`,\n`iframe`, `image`, `manifest`, `object`,\n`paintworklet`, `report`, `script`, `sharedworker`,\n`style`, `track`, `video`, `worker`\nor `xslt` strings, or the empty string, which is the default value.\n\nThe `destination` is used by the  to, for example,\nhelp determine which set of rules to follow for CORS purposes, or how to navigate any\ncomplicated code paths that affect how specific types of request get handled.\n\nThese destinations vary substantially in how they operate. Some are data receptacles,\nwhere the received data is stored for processing later. Others are script-based, in\nwhich case the received data is delivered to a script by calling it and passing the data\nalong. Script-based destinations include `script` elements, as well as\nany of the [Worklet]-based destinations\n(including subclasses like [AudioWorklet]), and the\n[Worker]-based destinations, including [ServiceWorker]\nand [SharedWorker].",
      "formdata": "\n\nThe **`formData()`** method of the [Request] interface\nreads the request body and returns it as a promise that resolves with a [FormData] object.",
      "headers": "\n\nThe **`headers`** read-only property of the\n[Request] interface contains the [Headers] object associated\nwith the request.",
      "integrity": "\n\nThe **`integrity`** read-only property of the [Request] interface contains the [subresource integrity](/en-US/docs/Web/Security/Subresource_Integrity) value of the request.",
      "json": "\n\nThe **`json()`** method of the [Request] interface\nreads the request body and returns it as a promise that resolves with the result of parsing the body text as `JSON`.\n\nNote that despite the method being named `json()`, the result is not JSON but is instead the result of taking JSON as input and parsing it to produce a JavaScript object.",
      "method": "\n\nThe **`method`** read-only property of the\n[Request] interface contains the request's method (`GET`,\n`POST`, etc.)",
      "mode": "\n\nThe **`mode`** read-only property of the [Request]\ninterface contains the mode of the request (e.g., `cors`,\n`no-cors`, `same-origin`, `navigate` or `websocket`.) This is used\nto determine if cross-origin requests lead to valid responses, and which properties of the response are readable.",
      "redirect": "\n\nThe **`redirect`** read-only property of the [Request] interface contains the mode for how redirects are handled.",
      "referrer": "\n\nThe **`referrer`** read-only property of the\n[Request] interface is set by the user agent to be the referrer of the\nRequest. (e.g., `client`, `no-referrer`, or a URL.)\n\n> **Note:** If `referrer`'s value is `no-referrer`,\n> it returns an empty string.",
      "referrerpolicy": "\n\nThe **`referrerPolicy`** read-only property of the\n[Request] interface returns the referrer policy, which governs what\nreferrer information, sent in the `Referer` header, should be included\nwith the request.",
      "signal": "\n\nThe read-only **`signal`** property of the [Request] interface returns the [AbortSignal] associated with the request.",
      "text": "\n\nThe **`text()`** method of the [Request] interface\nreads the request body and returns it as a promise that resolves with a `String`.\nThe response is _always_ decoded using UTF-8.",
      "url": "\n\nThe **`url`** read-only property of the [Request]\ninterface contains the URL of the request."
    }
  },
  "resizeobserver": {
    "docs": "\n\nThe **`ResizeObserver`** interface reports changes to the dimensions of an [Element]'s content or border box, or the bounding box of an [SVGElement].\n\n> **Note:** The content box is the box in which content can be placed, meaning the border box minus the padding and border width. The border box encompasses the content, padding, and border. See [The box model](/en-US/docs/Learn/CSS/Building_blocks/The_box_model) for further explanation.",
    "properties": {
      "disconnect": "\n\nThe **`disconnect()`** method of the\n[ResizeObserver] interface unobserves all observed [Element]\nor [SVGElement] targets.",
      "observe": "\n\nThe **`observe()`** method of the\n[ResizeObserver] interface starts observing the specified\n[Element] or [SVGElement].",
      "unobserve": "\n\nThe **`unobserve()`** method of the\n[ResizeObserver] interface ends the observing of a specified\n[Element] or [SVGElement]."
    }
  },
  "resizeobserverentry": {
    "docs": "\n\nThe **`ResizeObserverEntry`** interface represents the object passed to the [ResizeObserver.ResizeObserver] constructor's callback function, which allows you to access the new dimensions of the [Element] or [SVGElement] being observed.",
    "properties": {
      "borderboxsize": "\n\nThe **`borderBoxSize`** read-only property of\nthe [ResizeObserverEntry] interface returns an array containing the new\nborder box size of the observed element when the callback is run.",
      "contentboxsize": "\n\nThe **`contentBoxSize`** read-only property of\nthe [ResizeObserverEntry] interface returns an array containing the new\ncontent box size of the observed element when the callback is run.",
      "contentrect": "\n\nThe `contentRect` read-only property of the\n[ResizeObserverEntry] interface returns a [DOMRectReadOnly]\nobject containing the new size of the observed element when the callback is run. Note\nthat this is better supported than [ResizeObserverEntry.borderBoxSize] or\n[ResizeObserverEntry.contentBoxSize], but it is left over from an earlier\nimplementation of the Resize Observer API, is still included in the spec for web compat\nreasons, and may be deprecated in future versions.",
      "devicepixelcontentboxsize": "\n\nThe **`devicePixelContentBoxSize`** read-only property of\nthe [ResizeObserverEntry] interface returns an array containing the size in device pixels of the observed element when the callback is run.",
      "target": "\n\nThe **`target`** read-only property of the\n[ResizeObserverEntry] interface returns a reference to the\n[Element] or [SVGElement] that is being observed."
    }
  },
  "resizeobserversize": {
    "docs": "`Resize Observer API`\n\nThe **`ResizeObserverSize`** interface of the [Resize Observer API] is used by the [ResizeObserverEntry] interface to access the box sizing properties of the element being observed.\n\n> **Note:** In [multi-column layout](/en-US/docs/Web/CSS/CSS_multicol_layout), which is a fragmented context, the sizing returned by `ResizeObserverSize` will be the size of the first column.",
    "properties": {
      "blocksize": "`Resize Observer API`\n\nThe **`blockSize`** read-only property of the [ResizeObserverSize] interface returns the length of the observed element's border box in the block dimension. For boxes with a horizontal , this is the vertical dimension, or height; if the writing-mode is vertical, this is the horizontal dimension, or width.\n\n> **Note:** For more explanation of writing modes and block and inline dimensions, read [Handling different text directions](/en-US/docs/Learn/CSS/Building_blocks/Handling_different_text_directions).",
      "inlinesize": "`Resize Observer API`\n\nThe **`inlineSize`** read-only property of the [ResizeObserverSize] interface returns the length of the observed element's border box in the inline dimension. For boxes with a horizontal , this is the horizontal dimension, or width; if the writing-mode is vertical, this is the vertical dimension, or height.\n\n> **Note:** For more explanation of writing modes and block and inline dimensions, read [Handling different text directions](/en-US/docs/Learn/CSS/Building_blocks/Handling_different_text_directions)."
    }
  },
  "response": {
    "docs": "\n\nThe **`Response`** interface of the [Fetch API](/en-US/docs/Web/API/Fetch_API) represents the response to a request.\n\nYou can create a new `Response` object using the [Response.Response] constructor, but you are more likely to encounter a `Response` object being returned as the result of another API operation—for example, a service worker [FetchEvent.respondWith], or a simple [fetch].",
    "properties": {
      "arraybuffer": "\n\nThe **`arrayBuffer()`** method of the [Response] interface\ntakes a [Response] stream and reads it to completion. It returns a promise\nthat resolves with an `ArrayBuffer`.",
      "blob": "\n\nThe **`blob()`** method of the [Response] interface takes\na [Response] stream and reads it to completion. It returns a promise that\nresolves with a [Blob].",
      "body": "\n\nThe **`body`** read-only property of the [Response] interface is a [ReadableStream] of the body contents.",
      "bodyused": "\n\nThe **`bodyUsed`** read-only property of the [Response] interface is a boolean value that indicates whether the body has been read yet.",
      "clone": "\n\nThe **`clone()`** method of the [Response] interface creates a clone of a response object, identical in every way, but stored in a different variable.\n\nLike the underlying [ReadableStream.tee] api,\nthe [Response.body] of a cloned `Response`\nwill signal backpressure at the rate of the _faster_ consumer of the two bodies,\nand unread data is enqueued internally on the slower consumed `body`\nwithout any limit or backpressure.\nBackpressure refers to the mechanism by which the streaming consumer of data\n(in this case, the code that reads the body)\nslows down the producer of data (such as the TCP server)\nso as not to load large amounts of data in memory\nthat is waiting to be used by the application.\nIf only one cloned branch is consumed, then the entire body will be buffered in memory.\nTherefore, `clone()` is one way to read a response twice in sequence,\nbut you should not use it to read very large bodies\nin parallel at different speeds.\n\n`clone()` throws a `TypeError` if the response body has already been used.\nIn fact, the main reason `clone()` exists is to allow multiple uses of body objects (when they are one-use only.)",
      "error_static": "\n\nThe **`error()`** static method of the [Response] interface returns a new `Response` object associated with a network error.\n\nThis is mainly useful when writing service workers: it enables a service worker to send a response from a [ServiceWorkerGlobalScope.fetch_event] event handler that will cause the [fetch] call in the main app code to reject the promise.\n\nAn error response has its [Response.type] set to `error`.",
      "formdata": "\n\nThe **`formData()`** method of the [Response] interface\ntakes a [Response] stream and reads it to completion. It returns a promise\nthat resolves with a [FormData] object.\n\n> **Note:** This is mainly relevant to [service workers](/en-US/docs/Web/API/Service_Worker_API). If a user submits\n> a form and a service worker intercepts the request, you could for example call\n> `formData()` on it to obtain a key-value map, modify some fields, then send\n> the form onwards to the server (or use it locally).",
      "headers": "\n\nThe **`headers`** read-only property of the\n[Response] interface contains the [Headers] object associated\nwith the response.",
      "json": "\n\nThe **`json()`** method of the [Response] interface takes\na [Response] stream and reads it to completion. It returns a promise which\nresolves with the result of parsing the body text as `JSON`.\n\nNote that despite the method being named `json()`, the result is not JSON but is instead the result of taking JSON as input and parsing it to produce a JavaScript object.",
      "json_static": "\n\nThe **`json()`** static method of the [Response] interface returns a `Response` that contains the provided JSON data as body, and a  header which is set to `application/json`.\nThe response status, status message, and additional headers can also be set.\n\nThe method makes it easy to create `Response` objects for returning JSON encoded data.\n[Service workers](/en-US/docs/Web/API/Service_Worker_API), for example, intercept fetch requests made by a browser, and might use `json()` to construct a `Response` from cached JSON data to return to the main thread.\nThe `json()` method can also be used in server code to return JSON data for [single page applications](/en-US/docs/Glossary/SPA), and any other applications where a JSON response is expected.",
      "ok": "\n\nThe **`ok`** read-only property of the [Response] interface contains a Boolean stating whether the response was successful (status in the range 200-299) or not.",
      "redirect_static": "\n\nThe **`redirect()`** static method of the [Response] interface returns a `Response` resulting in a redirect to the specified URL.\n\n> **Note:** This can be used alongside the [ServiceWorker API](/en-US/docs/Web/API/Service_Worker_API).\n> A controlling service worker could intercept a page's request and redirect it as desired.\n> This will actually lead to a real redirect if a service worker sends it upstream.",
      "redirected": "\n\nThe read-only **`redirected`** property of the [Response] interface indicates whether or not the response is the result of a request you made which was redirected.\n\n> **Note:** Relying on redirected to filter out redirects makes it easy for a forged redirect to prevent your content from working as expected.\n> Instead, you should do the filtering when you call [fetch].\n> See the example [Disallowing redirects](#disallowing_redirects), which shows this being done.",
      "status": "\n\nThe **`status`** read-only property of the [Response] interface contains the [HTTP status codes](/en-US/docs/Web/HTTP/Status) of the response.\n\nFor example, `200` for success, `404` if the resource could not be found.",
      "statustext": "\n\nThe **`statusText`** read-only property of the [Response] interface contains the status message corresponding to the HTTP status code in [Response.status].\n\nFor example, this would be `OK` for a status code `200`, `Continue` for `100`, `Not Found` for `404`.",
      "text": "\n\nThe **`text()`** method of the [Response] interface takes a [Response] stream and reads it to completion.\nIt returns a promise that resolves with a `String`.\nThe response is _always_ decoded using UTF-8.",
      "type": "\n\nThe **`type`** read-only property of the [Response] interface contains the type of the response.\nIt can be one of the following:\n\n- `basic`: Normal, same origin response, with all headers exposed except \"Set-Cookie\".\n- `cors`: Response was received from a valid cross-origin request. [Certain headers and the body](https://fetch.spec.whatwg.org/#concept-filtered-response-cors) may be accessed.\n- `error`: Network error.\n  No useful information describing the error is available.\n  The Response's status is 0, headers are empty and immutable.\n  This is the type for a Response obtained from `Response.error()`.\n- `opaque`: Response for \"no-cors\" request to cross-origin resource.\n  [Severely restricted](https://fetch.spec.whatwg.org/#concept-filtered-response-opaque).\n- `opaqueredirect`: The fetch request was made with `redirect: \"manual\"`.\n  The Response's status is 0, headers are empty, body is null and trailer is empty.\n\n> **Note:** An \"error\" Response never really gets exposed to script: such a response to a [fetch] would reject the promise.",
      "url": "\n\nThe **`url`** read-only property of the [Response] interface contains the URL of the response.\nThe value of the `url` property will be the final URL obtained after any redirects."
    }
  },
  "rsahashedimportparams": {
    "docs": "\n\nThe **`RsaHashedImportParams`** dictionary of the [Web Crypto API](/en-US/docs/Web/API/Web_Crypto_API) represents the object that should be passed as the `algorithm` parameter into [SubtleCrypto.importKey] or [SubtleCrypto.unwrapKey], when importing any RSA-based key pair: that is, when the algorithm is identified as any of [RSASSA-PKCS1-v1_5](/en-US/docs/Web/API/SubtleCrypto/sign#rsassa-pkcs1-v1_5), [RSA-PSS](/en-US/docs/Web/API/SubtleCrypto/sign#rsa-pss), or [RSA-OAEP](/en-US/docs/Web/API/SubtleCrypto/encrypt#rsa-oaep)."
  },
  "rsahashedkeygenparams": {
    "docs": "\n\nThe **`RsaHashedKeyGenParams`** dictionary of the [Web Crypto API](/en-US/docs/Web/API/Web_Crypto_API) represents the object that should be passed as the `algorithm` parameter into [SubtleCrypto.generateKey], when generating any RSA-based key pair: that is, when the algorithm is identified as any of [RSASSA-PKCS1-v1_5](/en-US/docs/Web/API/SubtleCrypto/sign#rsassa-pkcs1-v1_5), [RSA-PSS](/en-US/docs/Web/API/SubtleCrypto/sign#rsa-pss), or [RSA-OAEP](/en-US/docs/Web/API/SubtleCrypto/encrypt#rsa-oaep)."
  },
  "rsaoaepparams": {
    "docs": "\n\nThe **`RsaOaepParams`** dictionary of the [Web Crypto API](/en-US/docs/Web/API/Web_Crypto_API) represents the object that should be passed as the `algorithm` parameter into [SubtleCrypto.encrypt], [SubtleCrypto.decrypt], [SubtleCrypto.wrapKey], or [SubtleCrypto.unwrapKey], when using the [RSA_OAEP](/en-US/docs/Web/API/SubtleCrypto/encrypt#rsa-oaep) algorithm."
  },
  "rsapssparams": {
    "docs": "\n\nThe **`RsaPssParams`** dictionary of the [Web Crypto API](/en-US/docs/Web/API/Web_Crypto_API) represents the object that should be passed as the `algorithm` parameter into [SubtleCrypto.sign] or [SubtleCrypto.verify], when using the [RSA-PSS](/en-US/docs/Web/API/SubtleCrypto/sign#rsa-pss) algorithm."
  },
  "rtcaudiosourcestats": {
    "docs": "\n\nThe [WebRTC API](/en-US/docs/Web/API/WebRTC_API)'s **`RTCAudioSourceStats`** dictionary provides information about an audio track that is attached to one or more senders.\n\nThese statistics can be obtained by iterating the [RTCStatsReport] returned by [RTCRtpSender.getStats] or [RTCPeerConnection.getStats] until you find a report with the [`type`](#type) of `media-source` and a [`kind`](#kind) of `audio`.\n\n> **Note:** For audio information about remotely sourced tracks (that are being received), see [RTCInboundRtpStreamStats].",
    "properties": {
      "audiolevel": "\n\nThe [RTCAudioSourceStats] dictionary's **`audioLevel`** property represents the audio level of the media source.\n\nThe level is averaged over some small implementation-dependent interval.\nUsers can alternatively calculate the average audio level over some arbitrary duration using the algorithm described in the [`RTCAudioSourceStats` description](/en-US/docs/Web/API/RTCAudioSourceStats#description).\n\n> **Note:** For audio levels of remotely sourced tracks, see [RTCInboundRtpStreamStats.audioLevel].",
      "id": "\n\nThe **`id`** property of the [RTCAudioSourceStats] dictionary is a string which uniquely identifies the object for which this object provides statistics.\n\nUsing the `id`, you can correlate this statistics object with others, in order to monitor statistics over time for a given WebRTC object, such as an [RTCPeerConnection], or an [RTCDataChannel].",
      "kind": "\n\nThe [RTCAudioSourceStats] dictionary's **`kind`** property is a string value that is used to differentiate `audio` and `video` media sources.\n\nAlong with the [RTCAudioSourceStats.type], this identifies the object as an [RTCAudioSourceStats] object when iterating the [RTCStatsReport] returned by [RTCRtpSender.getStats] or [RTCPeerConnection.getStats].",
      "timestamp": "\n\nThe **`timestamp`** property of the [RTCAudioSourceStats] dictionary is a [DOMHighResTimeStamp] object specifying the time at which the data in the object was sampled.\n\nThe time is given in milliseconds elapsed since the first moment of January 1, 1970, UTC (also known as [Unix time](/en-US/docs/Glossary/Unix_time)).",
      "totalaudioenergy": "\n\nThe [RTCAudioSourceStats] dictionary's **`totalAudioEnergy`** property represents the total audio energy of the media source over the lifetime of this stats object.\n\nThe total energy across a particular duration can be determined by subtracting the value of this property returned by two different `getStats()` calls.\n\n> **Note:** For audio energy of remotely sourced tracks, see [RTCInboundRtpStreamStats.totalAudioEnergy].",
      "totalsamplesduration": "\n\nThe [RTCAudioSourceStats] dictionary's **`totalSamplesDuration`** property represents the combined duration of all samples produced by the media source over the lifetime of this stats object, in seconds.\nIt does not include samples dropped before reaching this media source. <!-- Dropped samples in `droppedSamplesDuration`; not implemented -->\n\nThis can be used with [RTCAudioSourceStats.totalAudioEnergy] to compute an [average audio level over different intervals](/en-US/docs/Web/API/RTCAudioSourceStats#description).\n\n> **Note:** For audio duration of remotely sourced tracks, see [RTCInboundRtpStreamStats.totalSamplesDuration].",
      "trackidentifier": "\n\nThe [RTCAudioSourceStats] dictionary's property **`trackIdentifier`** contains the `id` attribute of the associated [`MediaStreamTrack`](/en-US/docs/Web/API/MediaStreamTrack).",
      "type": "\n\nThe [RTCAudioSourceStats] dictionary's property **`type`** is a string with value `media-source`.\n\nThe type of `media-source` identifies the type of statistics as either [RTCAudioSourceStats] or [RTCVideoSourceStats] when iterating the [RTCStatsReport] returned by [RTCRtpSender.getStats] or [RTCPeerConnection.getStats].\nThe type of stats can further be differentiated using the [RTCAudioSourceStats.kind], which will be `audio` for `RTCAudioSourceStats`."
    }
  },
  "rtccertificate": {
    "docs": "\n\nThe **`RTCCertificate`** interface of the [WebRTC API](/en-US/docs/Web/API/WebRTC_API) provides an object representing a certificate that an [RTCPeerConnection] uses to authenticate.\n\n`RTCCertificate` is a , so it can be cloned with [structuredClone] or copied between [Workers](/en-US/docs/Web/API/Worker) using [Worker/postMessage].",
    "properties": {
      "expires": "\n\nThe read-only **`expires`** property of the [RTCCertificate] interface returns the expiration date of the certificate.\n\nBy default a new certificate is configured with `expires` set to a value of 2592000000 milliseconds, or 30 days.\nThe expiration time cannot exceed 31536000000 milliseconds, or 365 days.\nIt's also useful to note that browsers may further restrict the expiration time of certificates if they choose.",
      "getfingerprints": "\n\nThe **`getFingerprints()`** method of the **[RTCCertificate]** interface is used to get an array of certificate fingerprints.\n\nAn application can use this method to compare the client certificate fingerprints with the certificate fingerprints from the server.\nThe server and client may support different sets of algorithms: all fingerprint values for the set of algorithms supported by both client and server should match."
    }
  },
  "rtccertificatestats": {
    "docs": "`WebRTC`\n\nThe **`RTCCertificateStats`** dictionary of the [WebRTC API](/en-US/docs/Web/API/WebRTC_API) is used to report information about a certificate used by an [RTCDtlsTransport] and its underlying [RTCIceTransport].\n\nThe report can be obtained by iterating the [RTCStatsReport] returned by [RTCPeerConnection.getStats] until you find an entry with the [`type`](#type) of `certificate`.",
    "properties": {
      "base64certificate": "\n\nThe **`base64Certificate`** property of the [RTCCertificateStats] dictionary is a string containing the base-64 representation of the DER-encoded certificate.\n\nThis is essentially an encoding of the original certificate as a string that can safely serialized and deserialized when sent over an IP network.",
      "fingerprint": "\n\nThe **`fingerprint`** property of the [RTCCertificateStats] dictionary is a string containing the fingerprint value of the associated [RTCCertificate].",
      "fingerprintalgorithm": "\n\nThe **`fingerprintAlgorithm`** property of the [RTCCertificateStats] dictionary is a string containing the name of the hash function used to generate the [RTCCertificateStats.fingerprint] value in the associated [RTCCertificate].",
      "id": "\n\nThe **`id`** property of the [RTCCertificateStats] dictionary is a string that uniquely identifies the object for which this object provides statistics.\n\nUsing the `id`, you can correlate this statistics object with others, in order to monitor statistics over time for a given WebRTC object, such as an [RTCPeerConnection], or an [RTCDataChannel].",
      "timestamp": "\n\nThe **`timestamp`** property of the [RTCCertificateStats] dictionary is a [DOMHighResTimeStamp] object specifying the time at which the data in the object was sampled.",
      "type": "\n\nThe **`type`** property of the [RTCCertificateStats] dictionary is a string with the value `\"certificate\"`.\n\nDifferent statistics are obtained by iterating the [RTCStatsReport] object returned by a call to [RTCPeerConnection.getStats].\nThe type indicates the set of statistics available through the object in a particular iteration step.\nA value of `\"certificate\"` indicates that the statistics available in the current step are those defined in [RTCCertificateStats]."
    }
  },
  "rtcdatachannel": {
    "docs": "\n\nThe **`RTCDataChannel`** interface represents a network channel which can be used for bidirectional peer-to-peer transfers of arbitrary data. Every data channel is associated with an [RTCPeerConnection], and each peer connection can have up to a theoretical maximum of 65,534 data channels (the actual limit may vary from browser to browser).\n\nTo create a data channel and ask a remote peer to join you, call the [RTCPeerConnection]'s [RTCPeerConnection.createDataChannel] method. The peer being invited to exchange data receives a [RTCPeerConnection.datachannel_event] event (which has type [RTCDataChannelEvent]) to let it know the data channel has been added to the connection.\n\n`RTCDataChannel` is a [transferable object](/en-US/docs/Web/API/Web_Workers_API/Transferable_objects).\n\n",
    "properties": {
      "binarytype": "\n\nThe property **`binaryType`** on the\n[RTCDataChannel] interface is a string which specifies\nthe type of object which should be used to represent binary data received\non the [RTCDataChannel]. Values allowed by the\n[WebSocket.binaryType] property are also permitted here:\n`blob` if [Blob] objects are being used or\n`arraybuffer` if `ArrayBuffer` objects are being used. The\ndefault is `blob`.\n\nWhen a binary message is received on the data channel, the resulting\n[RTCDataChannel.message_event] event's [MessageEvent.data] property is an object of\nthe type specified by the `binaryType`.",
      "bufferedamount": "\n\nThe read-only `RTCDataChannel` property\n**`bufferedAmount`** returns the number of bytes of data\ncurrently queued to be sent over the data channel. The queue may build up as a\nresult of calls to the [RTCDataChannel.send] method. This only\nincludes data buffered by the user agent itself; it doesn't include any framing overhead\nor buffering done by the operating system or network hardware.\n\nThe user agent may implement the process of actually sending data in any way it\nchooses; this may be done periodically during the event loop or truly asynchronously. As\nmessages are actually sent, this value is reduced accordingly.\n\n> **Note:** Closing the data channel doesn't reset this count, even though the user agent purges\n> the queued messages. However, even after closing the channel, attempts to send\n> messages continue to add to the `bufferedAmount` value, even though the\n> messages are neither sent nor buffered.\n\nWhenever this value decreases to fall to or below the value specified in the\n[RTCDataChannel.bufferedAmountLowThreshold]\nproperty, the user agent fires the [RTCDataChannel.bufferedamountlow_event] event. This event may\nbe used, for example, to implement code which queues more messages to be sent whenever\nthere's room to buffer them.",
      "bufferedamountlow_event": "\n\nA **`bufferedamountlow`** event is sent to an [RTCDataChannel] when the number of bytes currently in the outbound data transfer buffer falls below the threshold specified in [RTCDataChannel.bufferedAmountLowThreshold]. `bufferedamountlow` events aren't sent if `bufferedAmountLowThreshold` is 0.\n\nThis event is not cancelable and does not bubble.",
      "bufferedamountlowthreshold": "\n\nThe `RTCDataChannel` property\n**`bufferedAmountLowThreshold`** is used to specify the number\nof bytes of buffered outgoing data that is considered \"low.\" The default value is\n0\\. When the number of buffered outgoing bytes, as indicated by the\n[RTCDataChannel.bufferedAmount] property, falls to or\nbelow this value, a [RTCDataChannel.bufferedamountlow_event] event is fired. This event may be\nused, for example, to implement code which queues more messages to be sent whenever\nthere's room to buffer them. Listeners may be added with\n[RTCDataChannel.bufferedamountlow_event] or\n[EventTarget.addEventListener].\n\nThe user agent may implement the process of actually sending data in any way it\nchooses; this may be done periodically during the event loop or truly asynchronously. As\nmessages are actually sent, this value is reduced accordingly.\n\n> **Note:** `bufferedamountlow` events are not fired after the data channel is closed.",
      "close": "\n\nThe **`RTCDataChannel.close()`** method closes the\n[RTCDataChannel]. Either peer is permitted to call this method to initiate\nclosure of the channel.\n\nClosure of the data channel is not instantaneous. Most of the process of closing the\nconnection is handled asynchronously; you can detect when the channel has finished\nclosing by watching for a [RTCDataChannel.close_event] event on the data channel.\n\nThe sequence of events which occurs in response to this method being called:\n\n1. [RTCDataChannel.readyState] is set to `closing`.\n2. A background task is established to handle the remainder of the steps below, and\n   `close()` returns to the caller.\n3. The transport layer deals with any buffered messages; the protocol layer decides\n   whether to send them or discard them.\n4. The underlying data transport is closed.\n5. The [RTCDataChannel.readyState] property is set to\n   `closed`.\n6. If the transport was closed with an error,\n   the `RTCDataChannel` is sent\n   an [RTCDataChannel.error_event] event\n   with its [DOMException.name] set to `NetworkError`.\n7. A [RTCDataChannel.close_event] event is sent to the channel.",
      "close_event": "\n\nThe **`close`** event is sent to the [RTCDataChannel.close_event] event handler on an [RTCDataChannel] instance when the data transport for the data channel has closed. Before any further data can be transferred using `RTCDataChannel`, a new 'RTCDataChannel' instance must be created.\n\nThis event is not cancelable and does not bubble.",
      "closing_event": "\n\nThe **`closing`** event is sent to an [RTCDataChannel] just before the channel begins the process of shutting down its underlying data transport.\n\nThis event is not cancelable and does not bubble.",
      "error_event": "\n\nA WebRTC [RTCDataChannel.error_event] event is sent to an [RTCDataChannel] object's `onerror` event handler when an error occurs on the data channel.\n\nThe [RTCErrorEvent] object provides details about the error that occurred; see that article for details.\n\nThis event is not cancelable and does not bubble.",
      "id": "\n\nThe read-only `RTCDataChannel` property\n**`id`** returns an ID number (between 0 and 65,534) which\nuniquely identifies the [RTCDataChannel]. This ID is set at the\ntime the data channel is created, either by the user agent (if\n[RTCDataChannel.negotiated] is `false`) or by the site or app\nscript (if `negotiated` is `true`).\n\nEach [RTCPeerConnection] can therefore have up to a theoretical maximum of\n65,534 data channels on it, although the actual maximum may vary from browser to\nbrowser.",
      "label": "\n\nThe read-only `RTCDataChannel` property **`label`**\nreturns a string containing a name describing the data channel. These\nlabels are not required to be unique.\n\nYou may use the label as you wish; you could use it to identify all the channels that\nare being used for the same purpose, by giving them all the same name. Or you could give\neach channel a unique label for tracking purposes. It's entirely up to the design\ndecisions made when building your site or app.\n\nA unique ID can be found in the [RTCDataChannel.id] property.\n\n> **Note:** A data channel's label is set when the channel is created by calling\n> [RTCPeerConnection.createDataChannel]. It cannot be changed after that.",
      "maxpacketlifetime": "\n\nThe read-only `RTCDataChannel` property\n**`maxPacketLifeTime`** returns the amount of time, in\nmilliseconds, the browser is allowed to take to attempt to transmit a message, as set\nwhen the data channel was created, or `null`. This limits how long\nthe browser can continue to attempt to transmit and retransmit the message before giving\nup.",
      "maxretransmits": "\n\nThe read-only `RTCDataChannel` property\n**`maxRetransmits`** returns the maximum number of times the\nbrowser should try to retransmit a message before giving up, as set when the data\nchannel was created, or `null`, which indicates that there is no\nmaximum. This can only be set when the [RTCDataChannel] is created\nby calling [RTCPeerConnection.createDataChannel], using the\n`maxRetransmits` field in the specified `options`.",
      "message_event": "\n\nThe WebRTC **`message`** event is sent to the [RTCDataChannel.message_event] event handler on an [RTCDataChannel] object when a message has been received from the remote peer.\n\n> **Note:** The `message` event uses as its event object type the [MessageEvent] interface defined by the HTML specification.\n\nThis event is not cancelable and does not bubble.",
      "negotiated": "\n\nThe read-only `RTCDataChannel` property\n**`negotiated`** indicates whether the\n[RTCDataChannel]'s connection was negotiated by the Web app\n(`true`) or by the WebRTC layer (`false`). **The\ndefault is `false`.**\n\nSee [Creating a data channel](/en-US/docs/Web/API/WebRTC_API/Using_data_channels#creating_a_data_channel) for further information about this property.",
      "open_event": "\n\nThe WebRTC **`open`** event is sent to an [RTCDataChannel] object's `onopen` event handler when the underlying transport used to send and receive the data channel's messages is opened or reopened.\n\nThis event is not cancelable and does not bubble.",
      "ordered": "\n\nThe read-only `RTCDataChannel` property **`ordered`** indicates\nwhether or not the data channel guarantees in-order delivery of messages;\nthe default is `true`,\nwhich indicates that the data channel is indeed ordered.\nThis is set when the [RTCDataChannel] is created,\nby setting the `ordered` property\non the object passed as [RTCPeerConnection.createDataChannel]'s `options` parameter.",
      "protocol": "\n\nThe read-only `RTCDataChannel` property\n**`protocol`** returns a string containing the\nname of the subprotocol in use. If no protocol was specified when the data channel was\ncreated, then this property's value is the empty string (`\"\"`).\n\n> **Note:** The permitted values of this property are defined by the website or app using the\n> data channel.\n\nThe ability for each channel to have a defined subprotocol lets your app, for example,\nuse JSON objects as messages on one channel while another channel is plaintext and\nanother is raw binary or even some other format.",
      "readystate": "\n\nThe read-only `RTCDataChannel` property **`readyState`** returns a string which indicates the state of the data channel's underlying data connection.",
      "reliable": "\n\nThe read-only `RTCDataChannel` property\n**`reliable`** indicates whether or not the data channel is\nreliable.\n\n> **Warning:** This property is obsolete. Use [RTCDataChannel.ordered] instead in any\n> new code, and update existing code as soon as possible.",
      "send": "\n\nThe **`send()`** method of the\n[RTCDataChannel] interface sends data across the data channel to the\nremote peer.\nThis can be done any time except during the initial process of\ncreating the underlying transport channel. Data sent before connecting is buffered if\npossible (or an error occurs if it's not possible), and is also buffered if sent while\nthe connection is closing or closed.\n\n> **Note:** Different browsers have different limitations on the size of the message you can\n> send. Specifications exist to define how to automatically fragment large messages, but\n> not all browsers implement them, and those that do have various additional\n> restrictions. This will get less complicated over time, but for now, if you have\n> questions, see [Understanding message size limits](/en-US/docs/Web/API/WebRTC_API/Using_data_channels#understanding_message_size_limits)."
    }
  },
  "rtcdatachannelevent": {
    "docs": "\n\nThe **`RTCDataChannelEvent`** interface\nrepresents an event related to a specific [RTCDataChannel].\n\n",
    "properties": {
      "channel": "\n\nThe read-only property **`RTCDataChannelEvent.channel`**\nreturns the [RTCDataChannel] associated with the event."
    }
  },
  "rtcdtlstransport": {
    "docs": "\n\nThe **`RTCDtlsTransport`** interface provides access to information about the Datagram Transport Layer Security (****) transport over which a [RTCPeerConnection]'s  and  packets are sent and received by its [RTCRtpSender] and [RTCRtpReceiver] objects.\n\nA `RTCDtlsTransport` object is also used to provide information about  packets transmitted and received by a connection's [data channels](/en-US/docs/Web/API/RTCDataChannel).\n\nFeatures of the DTLS transport include the addition of security to the underlying transport; the `RTCDtlsTransport` interface can be used to obtain information about the underlying transport and the security added to it by the DTLS layer.\n\n",
    "properties": {
      "error_event": "\n\nAn [RTCDtlsTransport] receives an `error` event when a transport-level error occurs on the [RTCPeerConnection].\n\nThis event is not cancelable and does not bubble.",
      "icetransport": "\n\nThe read-only **[RTCDtlsTransport]**\nproperty **`iceTransport`** contains a reference\nto the underlying [RTCIceTransport].",
      "state": "\n\nThe **`state`** read-only property of the\n[RTCDtlsTransport] interface provides information which describes a\nDatagram Transport Layer Security (****) transport state."
    }
  },
  "rtcdtmfsender": {
    "docs": "\n\nThe **`RTCDTMFSender`** interface provides a mechanism for transmitting  codes on a [WebRTC](/en-US/docs/Web/API/WebRTC_API) [RTCPeerConnection]. You gain access to the connection's `RTCDTMFSender` through the [RTCRtpSender.dtmf] property on the audio track you wish to send DTMF with.\n\nThe primary purpose for WebRTC's DTMF support is to allow WebRTC-based communication clients to be connected to a [public-switched telephone network (PSTN)](https://en.wikipedia.org/wiki/Public_switched_telephone_network) or other legacy telephone service, including extant voice over IP (VoIP) services. For that reason, DTMF can't be used between two WebRTC-based devices, because there is no mechanism provided by WebRTC for receiving DTMF codes.\n\n",
    "properties": {
      "insertdtmf": "\n\nThe **`insertDTMF()`** method on the [RTCDTMFSender] interface\nstarts sending  tones to the remote peer over the\n[RTCPeerConnection].\n\nSending of the tones is performed asynchronously,\nwith [`tonechange`](/en-US/docs/Web/API/RTCDTMFSender/tonechange_event) events sent to the `RTCDTMFSender` every time\na tone starts or ends.\n\nAs long as the connection is active, you can send tones at any time. Calling\n`insertDTMF()` replaces any already-pending tones from the `toneBuffer`.\nYou can abort sending queued tones by specifying an empty string (`\"\"`) as the set of tones to play.\nSince `insertDTMF()` replaces the tone buffer, in order to add to the DTMF tones being played, it is necessary to call\n`insertDTMF` with a string containing both the remaining tones (stored in the `toneBuffer`) and the new tones appended together.",
      "tonebuffer": "\n\nThe [RTCDTMFSender] interface's toneBuffer property returns a string\ncontaining a list of the  tones currently queued for sending to the\nremote peer over the [RTCPeerConnection]. To place tones into the buffer,\ncall [RTCDTMFSender.insertDTMF].\n\nTones are removed from the string as they're played, so only upcoming tones are listed.",
      "tonechange_event": "\n\nThe **`tonechange`** event is sent to an [RTCDTMFSender] by the [WebRTC API](/en-US/docs/Web/API/WebRTC_API) to indicate when  tones previously queued for sending (by calling [RTCDTMFSender.insertDTMF]) begin and end.\n\nTo determine what tone started playing, or if a tone stopped playing, check the value of the event's [RTCDTMFToneChangeEvent.tone] property.\n\nThis event is not cancelable and does not bubble."
    }
  },
  "rtcdtmftonechangeevent": {
    "docs": "\n\nThe **`RTCDTMFToneChangeEvent`** interface represents events sent to indicate that  tones have started or finished playing. This interface is used by the [`tonechange`](/en-US/docs/Web/API/RTCDTMFSender/tonechange_event) event.\n\n",
    "properties": {
      "tone": "\n\nThe read-only property **`RTCDTMFToneChangeEvent.tone`**\nreturns the DTMF character which has just begun to play, or an empty string\n(`\"\"`). if all queued tones have finished playing (that is,\n[RTCDTMFSender.toneBuffer] is empty)."
    }
  },
  "rtcencodedaudioframe": {
    "docs": "\n\nThe **`RTCEncodedAudioFrame`** of the [WebRTC API](/en-US/docs/Web/API/WebRTC_API) represents an encoded audio frame in the WebRTC receiver or sender pipeline, which may be modified using a [WebRTC Encoded Transform](/en-US/docs/Web/API/WebRTC_API/Using_Encoded_Transforms).\n\nThe interface provides methods and properties to get metadata about the frame, allowing its format and order in the sequence of frames to be determined.\nThe `data` property gives access to the encoded frame data as a buffer, which might be encrypted, or otherwise modified by a transform.\n\n> **Note:** This feature is available in [_Dedicated_ Web Workers](/en-US/docs/Web/API/Web_Workers_API#worker_types).",
    "properties": {
      "data": "\n\nThe **`data`** property of the [RTCEncodedAudioFrame] interface returns a buffer containing the data for an encoded frame.",
      "getmetadata": "\n\nThe **`getMetadata()`** method of the [RTCEncodedAudioFrame] interface returns an object containing the metadata associated with the frame.\n\nThis includes information about the frame, including the audio encoding used, the synchronization source and contributing sources, and the sequence number (for incoming frames).",
      "timestamp": "\n\nThe readonly **`timestamp`** property of the [RTCEncodedAudioFrame] interface indicates the time at which frame sampling started."
    }
  },
  "rtcencodedvideoframe": {
    "docs": "\n\nThe **`RTCEncodedVideoFrame`** of the [WebRTC API](/en-US/docs/Web/API/WebRTC_API) represents an encoded video frame in the WebRTC receiver or sender pipeline, which may be modified using a [WebRTC Encoded Transform](/en-US/docs/Web/API/WebRTC_API/Using_Encoded_Transforms).\n\n> **Note:** This feature is available in [_Dedicated_ Web Workers](/en-US/docs/Web/API/Web_Workers_API#worker_types).",
    "properties": {
      "data": "\n\nThe **`data`** property of the [RTCEncodedVideoFrame] interface returns a buffer containing the frame data.",
      "getmetadata": "\n\nThe **`getMetadata()`** method of the [RTCEncodedVideoFrame] interface returns an object containing the metadata associated with the frame.\n\nThis includes information about the frame, including its size, video encoding, other frames needed to construct a full image, timestamp, and other information.",
      "timestamp": "\n\nThe readonly **`timestamp`** property of the [RTCEncodedVideoFrame] interface indicates the time at which frame sampling started.",
      "type": "\n\nThe readonly **`type`** property of the [RTCEncodedVideoFrame] interface indicates whether this frame is a key frame, delta frame, or empty frame."
    }
  },
  "rtcerror": {
    "docs": "`WebRTC`\n\nThe **`RTCError`** interface describes an error which has occurred while handling [WebRTC](/en-US/docs/Web/API/WebRTC_API) operations. It's based upon the standard [DOMException] interface that describes general DOM errors.\n\n",
    "properties": {
      "errordetail": "\n\nThe [RTCError] interface's read-only\n**`errorDetail`** property is a string indicating the [WebRTC](/en-US/docs/Web/API/WebRTC_API)-specific error code that occurred.",
      "receivedalert": "\n\nThe [RTCError] read-only property\n**`receivedAlert`** specifies the fatal \nerror which resulted in an alert being received from the remote peer.",
      "sctpcausecode": "\n\nThe read-only **`sctpCauseCode`** property in an\n[RTCError] object provides the  cause code explaining\nwhy the SCTP negotiation failed, if the `RTCError` represents an SCTP error.",
      "sdplinenumber": "\n\nThe [RTCError] interface's read-only property\n**`sdpLineNumber`** specifies the line number within the\n at which a syntax error occurred while parsing it.",
      "sentalert": "\n\nThe read-only **`sentAlert`** property in an\n[RTCError] object specifies the  alert number occurred\nwhile sending data to the remote peer, if the error represents an outbound DTLS error."
    }
  },
  "rtcerrorevent": {
    "docs": "`WebRTC`\n\nThe WebRTC API's **`RTCErrorEvent`** interface represents an error sent to a WebRTC object. It's based on the standard [Event] interface, but adds RTC-specific information describing the error, as shown below.\n\n",
    "properties": {
      "error": "`WebRTC`\n\nThe read-only [RTCErrorEvent] property **`error`**\ncontains an [RTCError] object describing the details of the error which the\nevent is announcing."
    }
  },
  "rtcicecandidate": {
    "docs": "\n\nThe **`RTCIceCandidate`** interface—part of the [WebRTC API](/en-US/docs/Web/API/WebRTC_API)—represents a candidate Interactive Connectivity Establishment () configuration which may be used to establish an [RTCPeerConnection].\n\nAn ICE candidate describes the protocols and routing needed for WebRTC to be able to communicate with a remote device. When starting a WebRTC peer connection, typically a number of candidates are proposed by each end of the connection, until they mutually agree upon one which describes the connection they decide will be best. WebRTC then uses that candidate's details to initiate the connection.\n\nFor details on how the ICE process works, see [Lifetime of a WebRTC session](/en-US/docs/Web/API/WebRTC_API/Session_lifetime). The article [WebRTC connectivity](/en-US/docs/Web/API/WebRTC_API/Connectivity) provides additional useful details.",
    "properties": {
      "address": "\n\nThe **[RTCIceCandidate]** interface's read-only **`address`** property is a string providing the IP address of the device which is the source of the candidate.\nThe `address` is `null` by default if not otherwise specified.\n\nThe `address` field's value is set from the `candidateInfo` options object passed to the [RTCIceCandidate.RTCIceCandidate] constructor.\nYou can't specify the value of `address` directly in the options object, but its value is automatically extracted from the object's `candidate` a-line, if it's formatted properly.",
      "candidate": "\n\nThe read-only property **`candidate`** on the [RTCIceCandidate] interface returns a string describing the candidate in detail.\nMost of the other properties of `RTCIceCandidate` are actually extracted from this string.\n\nThis property can be configured using the `candidate` property of the object passed into the [RTCIceCandidate.RTCIceCandidate] or [RTCPeerConnection.addIceCandidate].",
      "component": "\n\nThe read-only **`component`** property\non the [RTCIceCandidate] interface is a string which indicates whether\nthe candidate is an [RTP](/en-US/docs/Web/API/WebRTC_API/Intro_to_RTP) or\nan RTCP candidate.\n\nIf a candidate represents both RTP and RTCP multiplexed together, it is reported as an\nRTP candidate.",
      "foundation": "\n\nThe **[RTCIceCandidate]**\ninterface's read-only **`foundation`** property is a string\nwhich uniquely identifies the candidate across multiple transports.\n\nThe `foundation` can therefore be used to correlate candidates that are present on\nmultiple [RTCIceTransport] objects",
      "port": "\n\nThe **[RTCIceCandidate]** interface's read-only **`port`** property contains the port\nnumber on the device at the address given by [RTCIceCandidate.address] at which the candidate's peer can be reached.\n\nThe `port` field's value is set from the `candidateInfo` options object passed to the [RTCIceCandidate.RTCIceCandidate] constructor.\nYou can't specify the value of `port` directly in the options object, but its value is automatically extracted from the object's `candidate` a-line, if it's formatted properly.",
      "priority": "\n\nThe **[RTCIceCandidate]** interface's read-only **`priority`** property specifies the candidate's priority according to the remote peer; the higher this value is, the better the remote peer considers the candidate to be.\n\nThe `priority` field's value is set from the `candidateInfo` options object passed to the [RTCIceCandidate.RTCIceCandidate] constructor.\nYou can't specify the value of `priority` directly in the options object, but its value is automatically extracted from the object's `candidate` a-line, if it's formatted properly.",
      "protocol": "\n\nThe **[RTCIceCandidate]** interface's read-only **`protocol`** property is a string\nwhich indicates whether the candidate uses  or  as its transport protocol.\n\nThe `protocol` field's value is set from the `candidateInfo` options object passed to the [RTCIceCandidate.RTCIceCandidate] constructor.\nYou can't specify the value of `protocol` directly in the options object, but its value is automatically extracted from the object's `candidate` a-line, if it's formatted properly.\n\n`protocol` is `null` by default if not specified properly in the SDP, but this is an error condition and will result in a thrown exception when you call [RTCPeerConnection.addIceCandidate].",
      "relatedaddress": "\n\nThe **[RTCIceCandidate]** interface's read-only **`relatedAddress`** property is a\nstring indicating the **related address** of a relay or reflexive candidate.\n\nIf the candidate is a host candidate (that is, its [RTCIceCandidate/address] is in fact the real IP address of the remote peer), `relatedAddress` is `null`.\n\nThe `relatedAddress` field's value is set from the `candidateInfo` options object passed to the [RTCIceCandidate.RTCIceCandidate] constructor.\nYou can't specify the value of `relatedAddress` directly in the options object, but its value is automatically extracted from the object's `candidate` a-line if it's formatted properly(the `rel-address` field).\n\nThe related address and port ([RTCIceCandidate.relatedPort]) are not used at all by  itself; they are provided\nfor analysis and diagnostic purposes only, and their inclusion may be blocked by security systems, so do not rely on them having non-`null` values.",
      "relatedport": "\n\nThe **[RTCIceCandidate]** interface's read-only **`relatedPort`** property indicates the port number of reflexive or relay candidates.\n\nIf the candidate is a host candidate (that is, its [RTCIceCandidate/address] is in fact the real IP address of the remote peer), `relatedPort` is `null`.\n\nThe `relatedPort` field's value is set from the `candidateInfo` options object passed to the [RTCIceCandidate.RTCIceCandidate] constructor.\nYou can't specify the value of `relatedPort` directly in the options object, but its value is automatically extracted from the object's `candidate` a-line, if it's formatted properly (the `rel-port` field).\n\nThe related address ([RTCIceCandidate.relatedAddress]) and port are not used at all by  itself; they are provided for\nanalysis and diagnostic purposes only, and their inclusion may be blocked by security systems, so do not rely on them having non-`null` values.",
      "sdpmid": "\n\nThe read-only property **`sdpMid`** on the [RTCIceCandidate] interface returns a string\nspecifying the media stream identification tag of the media component with which the candidate is associated.\nThis ID uniquely identifies a given stream for the component with which the candidate is associated.\n\nThis property can be configured by specifying the value of the `sdpMid` property in the `candidateInfo` options object that is passed to the [RTCIceCandidate.RTCIceCandidate] constructor.\nIf you call the constructor with an m-line string instead of the options object, the value of `sdpMid` is extracted from the specified candidate m-line string.",
      "sdpmlineindex": "\n\nThe read-only **`sdpMLineIndex`** property on the [RTCIceCandidate] interface\nis a zero-based index of the m-line describing the media associated with the candidate.\n\nThis property can be configured by specifying the value of the `sdpMLineIndex` property in the `candidateInfo` options object that is passed to the [RTCIceCandidate.RTCIceCandidate] constructor.\nIf you call the constructor with an m-line string instead of the options object, the value of `sdpMLineIndex` is extracted from the specified candidate m-line string.",
      "tcptype": "\n\nThe **[RTCIceCandidate]** interface's read-only **`tcpType`** property is included on TCP candidates to provide additional details about the candidate type.\n\nThe `tcpType` field's value is set from the `candidateInfo` options object passed to the [RTCIceCandidate.RTCIceCandidate] constructor.\nYou can't specify the value of `tcpType` directly in the options object, but its value is automatically extracted from the object's `candidate` a-line, if it's formatted properly.",
      "tojson": "\n\nThe [RTCIceCandidate] method **`toJSON()`** converts the `RTCIceCandidate` on which it's called into JSON.\n\nA stringified version of the object can then be obtained by calling `stringify()` on the returned object.",
      "type": "\n\nThe **[RTCIceCandidate]** interface's read-only **`type`** specifies the type of candidate the object represents.\n\nThe `type` field's value is set from the `candidateInfo` options object passed to the [RTCIceCandidate.RTCIceCandidate] constructor.\nYou can't specify the value of `type` directly in the options object, but its value is automatically extracted from the object's `candidate` a-line (the `cand-type` field), if it's formatted properly.",
      "usernamefragment": "\n\nThe read-only **`usernameFragment`** property on the [RTCIceCandidate] interface is a string indicating the\nusername fragment (\"ufrag\") that uniquely identifies a single ICE interaction session.\n\nThis value is specified using the `usernameFragment` property in the `candidateInfo` options object that is passed to the [RTCIceCandidate.RTCIceCandidate] constructor.\nIf you call the constructor with an m-line string instead of the options object, the value of `usernameFragment` is extracted from the specified candidate m-line string.\n\nNote that 24 bits of the username fragment are required to be randomized by the browser. See [Randomization](#randomization) below for details."
    }
  },
  "rtcicecandidatepair": {
    "docs": "\n\nThe **`RTCIceCandidatePair`** dictionary describes a pair of ICE candidates which together comprise a description of a viable connection between two WebRTC endpoints. It is used as the return value from [RTCIceTransport.getSelectedCandidatePair] to identify the currently-selected candidate pair identified by the ICE agent.",
    "properties": {
      "local": "\n\nThe **`local`** property of the\n**[RTCIceCandidatePair]** dictionary specifies the\n[RTCIceCandidate] which describes the configuration of the local end of a\nviable WebRTC connection.",
      "remote": "\n\nThe **`remote`** property of the\n**[RTCIceCandidatePair]** dictionary specifies the\n[RTCIceCandidate] describing the configuration of the remote end of a\nviable WebRTC connection."
    }
  },
  "rtcicecandidatepairstats": {
    "docs": "\n\nThe **`RTCIceCandidatePairStats`** dictionary of the [WebRTC API](/en-US/docs/Web/API/WebRTC_API) is used to report statistics that provide insight into the quality and performance of an [RTCPeerConnection] while connected and configured as described by the specified pair of  candidates.\n\nThe statistics can be obtained by iterating the [RTCStatsReport] returned by [RTCPeerConnection.getStats] until you find an entry with the [`type`](#type) of `\"candidate-pair\"`.",
    "properties": {
      "availableincomingbitrate": "\n\nThe [RTCIceCandidatePairStats] property\n**`availableIncomingBitrate`** returns a value indicative of\nthe available inbound capacity of the network connection represented by the candidate\npair. The higher the value, the more bandwidth you can assume is available for\nincoming data.\n\nYou can get the outgoing available bitrate from\n[RTCIceCandidatePairStats.availableoutgoingBitrate].",
      "availableoutgoingbitrate": "\n\nThe [RTCIceCandidatePairStats] property\n**`availableOutgoingBitrate`** returns a value indicative of\nthe available outbound capacity of the network connection represented by the candidate\npair. The higher the value, the more bandwidth you can assume is available for\noutgoing data.\n\nYou can get the incoming available bitrate from\n[RTCIceCandidatePairStats.availableIncomingBitrate].",
      "bytesreceived": "\n\nThe [RTCIceCandidatePairStats] property\n**`bytesReceived`** indicates the total number of payload\nbytes—that is, bytes which aren't overhead such as headers or padding—that have been\nreceived to date on the connection described by the candidate pair.\n\nThe [RTCIceCandidatePairStats.bytesSent] property reports the\nnumber of bytes sent so far on the described connection.",
      "bytessent": "\n\nThe [RTCIceCandidatePairStats] property\n**`bytesSent`** indicates the total number of payload\nbytes—that is, bytes which aren't overhead such as headers or padding—that have been\nsent so far on the connection described by the candidate pair.\n\nThe [RTCIceCandidatePairStats.bytesReceived] property\nreports the number of bytes received so far on the described connection.",
      "currentroundtriptime": "\n\nThe [RTCIceCandidatePairStats] property\n**`currentRoundTripTime`** is a floating-point value\nindicating the number of seconds it takes for data to be sent by this peer to the\nremote peer and back over the connection described by this pair of \ncandidates.",
      "id": "\n\nThe **`id`** property of the [RTCIceCandidatePairStats] dictionary is a string that uniquely identifies the object for which this object provides statistics.\n\nUsing the `id`, you can correlate this statistics object with others, in order to monitor statistics over time for a given WebRTC object, such as an [RTCPeerConnection], or an [RTCDataChannel].",
      "lastpacketreceivedtimestamp": "\n\nThe [RTCIceCandidatePairStats] property\n**`lastPacketReceivedTimestamp`** indicates the time at which\nthe connection described by the candidate pair last received a packet.\n packets are not included.",
      "lastpacketsenttimestamp": "\n\nThe [RTCIceCandidatePairStats] property\n**`lastPacketSentTimestamp`** indicates the time at which the\nconnection described by the candidate pair last sent a packet, not including\n packets.",
      "localcandidateid": "\n\nThe [RTCIceCandidatePairStats] property\n**`localCandidateId`** is a string that uniquely identifies\nthe local  candidate which was analyzed to generate the\n[RTCIceCandidateStats] used to compute the statistics for this pair of\ncandidates.",
      "nominated": "\n\nThe [RTCIceCandidatePairStats] property\n**`nominated`** specifies whether or not the candidate pair\ndescribed by the underlying `RTCIceCandidatePair` has been nominated to be\nused as the configuration for the WebRTC connection.",
      "priority": "\n\nThe _obsolete_ [RTCIceCandidatePairStats]\nproperty **`priority`** reports the priority of the candidate\npair as an integer value. The higher the value, the more likely the WebRTC\nlayer is to select the candidate pair when the time comes to establish (or re-establish)\na connection between the two peers.",
      "readable": "\n\nThe _obsolete_ [RTCIceCandidatePairStats]\nproperty **`readable`** reports whether or not the connection\ndescribed by the candidate pair has received at least one valid incoming ICE\nrequest.",
      "remotecandidateid": "\n\nThe [RTCIceCandidatePairStats] property\n**`remoteCandidateId`** is a string that uniquely identifies\nthe remote  candidate which was analyzed to generate the\n[RTCIceCandidateStats] used to compute the statistics for this pair of\ncandidates.",
      "requestsreceived": "\n\nThe [RTCIceCandidatePairStats] dictionary's\n**`requestsReceived`** property indicates the total number of\n connectivity check requests that have been received so far on the\nconnection described by this pairing of candidates.",
      "requestssent": "\n\nThe [RTCIceCandidatePairStats] dictionary's\n**`requestsSent`** property indicates the total number of\n connectivity check requests that have been sent so far on the\nconnection described by this pair of candidates.",
      "responsesreceived": "\n\nThe **`responsesReceived`** property\nin the [RTCIceCandidatePairStats] dictionary indicates the total number\nof  connectivity check responses that have been received on the\nconnection described by this pair of candidates.",
      "responsessent": "\n\nThe [RTCIceCandidatePairStats] dictionary's\n**`responsesSent`** property indicates the total number of\n connectivity check responses that have been sent so far on the\nconnection described by this pair of candidates.",
      "selected": "\n\nThe _non-standard_, Firefox-specific [RTCIceCandidatePairStats] property **`selected`** indicates whether or not the candidate pair described by the object is the one currently being used to communicate with the remote peer.",
      "state": "\n\nThe **`state`** property is a string that indicates the state of the checklist of which the candidate pair is a member.",
      "timestamp": "\n\nThe **`timestamp`** property of the [RTCIceCandidatePairStats] dictionary is a [DOMHighResTimeStamp] object specifying the time at which the data in the object was sampled.",
      "totalroundtriptime": "\n\nThe [RTCIceCandidatePairStats] dictionary's\n**`totalRoundTripTime`** property is the total time that has\nelapsed between sending  requests and receiving the responses, for\nall such requests that have been made so far on the pair of candidates described by\nthis `RTCIceCandidatePairStats` object. This value includes both\nconnectivity check and consent check requests.",
      "transportid": "\n\nThe **`transportId`** property\nuniquely identifies the [RTCIceTransport] that was inspected to obtain\nthe transport-related statistics contained in the\n[RTCIceCandidatePairStats] object.",
      "type": "\n\nThe **`type`** property of the [RTCIceCandidatePairStats] dictionary is a string with the value `\"candidate-pair\"`.\n\nDifferent statistics are obtained by iterating the [RTCStatsReport] object returned by a call to [RTCPeerConnection.getStats].\nThe type indicates the set of statistics available through the object in a particular iteration step.\nA value of `\"candidate-pair\"` indicates that the statistics available in the current step are those defined in [RTCIceCandidatePairStats].",
      "writable": "\n\nThe _obsolete_ [RTCIceCandidatePairStats]\nproperty **`writable`** reports whether or not the connection\ndescribed by the candidate pair is writable."
    }
  },
  "rtcicecandidatestats": {
    "docs": "\n\nThe **`RTCIceCandidateStats`** dictionary of the [WebRTC API](/en-US/docs/Web/API/WebRTC_API) is used to report statistics related to an [RTCIceCandidate].\n\nThe statistics can be obtained by iterating the [RTCStatsReport] returned by [RTCPeerConnection.getStats] until you find a report with the [`type`](#type) of `local-candidate`.",
    "properties": {
      "address": "\n\nThe **`address`** property of the\n[RTCIceCandidateStats] dictionary indicates the address of the\n candidate. While it's preferred that the address be specified as\nan IPv4 or IPv6 numeric address, a fully-qualified domain name can be used as\nwell.\n\nWhen a domain name is specified, the first IP address selected for that\naddress is used, even if the domain name maps to multiple IP addresses.",
      "candidatetype": "\n\nThe [RTCIceCandidateStats] interface's\n**`candidateType`** property is a string that indicates the\ntype of  candidate the object represents.",
      "deleted": "\n\nThe [RTCIceCandidateStats] dictionary's\n**`deleted`** property indicates whether or not the candidate\nhas been deleted or released.",
      "id": "\n\nThe **`id`** property of the [RTCIceCandidateStats] dictionary is a string that uniquely identifies the object for which this object provides statistics.\n\nUsing the `id`, you can correlate this statistics object with others, in order to monitor statistics over time for a given WebRTC object, such as an [RTCPeerConnection], or an [RTCDataChannel].",
      "port": "\n\nThe [RTCIceCandidateStats] dictionary's **`port`**\nproperty specifies the network port used by the candidate.",
      "priority": "\n\nThe [RTCIceCandidateStats] dictionary's\n**`priority`** property is a positive integer value\nindicating the priority (or desirability) of the described candidate.\n\nDuring  negotiation while setting up a WebRTC peer connection, the\npriority values reported to the remote peer by a  are used\nto determine which candidates are considered \"more desirable\". The higher the value,\nthe more desirable the candidate is.",
      "protocol": "\n\nThe [RTCIceCandidateStats] dictionary's\n**`protocol`** property specifies the protocol the specified\ncandidate would use for communication with the remote peer.",
      "relayprotocol": "\n\nThe [RTCIceCandidateStats] dictionary's\n**`relayProtocol`** property specifies the protocol being used\nby a local  candidate to communicate with the \nserver.\n\nThe ICE protocol being used by the candidate otherwise can be obtained from the\n[RTCIceCandidateStats.protocol] property.",
      "timestamp": "\n\nThe **`timestamp`** property of the [RTCIceCandidateStats] dictionary is a [DOMHighResTimeStamp] object specifying the time at which the data in the object was sampled.",
      "transportid": "\n\nThe [RTCIceCandidateStats] dictionary's\n**`transportId`** property is a string that uniquely\nidentifies the transport that produced the [RTCTransportStats] from which\ninformation about this candidate was taken.",
      "type": "\n\nThe **`type`** property of the [RTCIceCandidateStats] dictionary is a string with the value `\"local-candidate\"`.\n\nDifferent statistics are obtained by iterating the [RTCStatsReport] object returned by a call to [RTCPeerConnection.getStats].\nThe type indicates the set of statistics available through the object in a particular iteration step.\nA value of `\"local-candidate\"` indicates that the statistics available in the current step are those defined in [RTCIceCandidateStats].",
      "url": "\n\nThe [RTCIceCandidateStats] dictionary's\n**`url`** property specifies the URL of the\n server from which the described candidate was obtained. This\nproperty is _only_ available for local candidates."
    }
  },
  "rtciceparameters": {
    "docs": "\n\nThe **`RTCIceParameters`** dictionary specifies the username fragment and password assigned to an  session.\n\nDuring ICE negotiation, each peer's username fragment and password are recorded in an `RTCIceParameters` object, which can be obtained from the [RTCIceTransport] by calling its [RTCIceTransport.getLocalParameters] or [RTCIceTransport.getRemoteParameters] method, depending on which end interests you.",
    "properties": {
      "password": "\n\nThe **[RTCIceParameters]**\ndictionary's **`password`** property specifies the ICE\npassword that, in tandem with the [RTCIceParameters.usernameFragment], uniquely identifies an ICE session for its entire\nduration.",
      "usernamefragment": "\n\nThe **[RTCIceParameters]** dictionary's\n**`usernameFragment`** property specifies the username fragment\n(\"ufrag\") that uniquely identifies the corresponding ICE session for the duration of the\ncurrent ICE session."
    }
  },
  "rtcicetransport": {
    "docs": "\n\nThe **`RTCIceTransport`** interface provides access to information about the  transport layer over which the data is being sent and received.\nThis is particularly useful if you need to access state information about the connection.\n\n",
    "properties": {
      "component": "\n\nThe read-only **[RTCIceTransport]**\nproperty **`component`** specifies whether the object is\nserving to transport  or .",
      "gatheringstate": "\n\nThe read-only property **`gatheringState`** property of the [RTCIceTransport] interface returns a string that indicates the current gathering state of the ICE agent: `\"new\"`, `\"gathering\"`, or `\"complete\"`.",
      "gatheringstatechange_event": "\n\nA **`gatheringstatechange`** event is sent to an [RTCIceTransport] when its  candidate gathering state changes.\n\nThe gathering state, whose actual status can be found in the transport object's [RTCIceTransport.gatheringState] property, indicates whether or not the ICE agent has begun gathering candidates, and if so, if it has finished doing so.\n\nThe key difference between `gatheringstatechange` and [RTCPeerConnection.icegatheringstatechange_event] is that the latter represents the overall state of the connection including every [RTCIceTransport] used by every [RTCRtpSender] and every [RTCRtpReceiver] on the entire connection. In contrast, `gatheringstatechange` represents changes to the candidate gathering state for a single transport.\n\nThis event is not cancelable and does not bubble.",
      "getlocalcandidates": "\n\nThe **[RTCIceTransport]** method\n**`getLocalCandidates()`** returns an array of\n[RTCIceCandidate] objects, one for each of the candidates that have been\ngathered by the local device during the current  agent\nsession.\n\nThe local candidates are placed in this list by the ICE agent prior to being delivered\nto the local client's code in an [RTCPeerConnection.icecandidate_event] event so that the client can\nforward the candidates to the remote peer.",
      "getlocalparameters": "\n\nThe **[RTCIceTransport]** method\n**`getLocalParameters()`** returns an\n[RTCIceParameters] object which provides information uniquely identifying\nthe local peer for the duration of the ICE session.\n\nThe local peer's parameters are obtained during ICE signaling and delivered to the\ntransport when the client calls [RTCPeerConnection.setLocalDescription].",
      "getremotecandidates": "\n\nThe **[RTCIceTransport]** method\n**`getRemoteCandidates()`** returns an array which contains\none [RTCIceCandidate] for each of the candidates that have been received\nfrom the remote peer so far during the current  gathering\nsession.\n\nEach time your signaling code calls [RTCPeerConnection.addIceCandidate]\nto add a received candidate to the ICE session, the ICE agent places it in the list\nreturned by this function.",
      "getremoteparameters": "\n\nThe **[RTCIceTransport]** method\n**`getRemoteParameters()`** returns an\n[RTCIceParameters] object which provides information uniquely\nidentifying the remote peer for the duration of the ICE session.\n\nThe remote peer's parameters are received during ICE signaling and delivered to the\ntransport when the client calls\n[RTCPeerConnection.setRemoteDescription].",
      "getselectedcandidatepair": "\n\nThe [RTCIceTransport] method\n**`getSelectedCandidatePair()`** returns an\n[RTCIceCandidatePair] object containing the current best-choice pair\nof  candidates describing the configuration of the endpoints of the transport.",
      "role": "\n\nThe read-only **[RTCIceTransport]**\nproperty **`role`** indicates which  role\nthe transport is fulfilling: that of the controlling agent, or the agent that is being\ncontrolled.\n\nYou can learn more about ICE roles in\n[Choosing a candidate pair](/en-US/docs/Web/API/WebRTC_API/Connectivity#choosing_a_candidate_pair).",
      "selectedcandidatepairchange_event": "\n\nA **`selectedcandidatepairchange`** event is sent to an [RTCIceTransport] when the  agent selects a new pair of candidates that describe the endpoints of a viable connection.\n\nThe pair of candidates is in turn described by an [RTCIceCandidatePair] object which contains one [RTCIceCandidate] representing the local end of the connection, and another representing the remote end of the connection.\n\nTogether, the candidates can be used to establish a connection to be used by the [RTCIceTransport], and, by extension, by an [RTCPeerConnection].\n\nThis event is not cancelable and does not bubble.",
      "state": "\n\nThe read-only **[RTCIceTransport]**\nproperty **`state`** returns the current state of the ICE\ntransport, so you can determine the state of ICE gathering in which the ICE agent\ncurrently is operating.\n\nThis differs from the [RTCIceTransport.gatheringState],\nwhich only indicates whether or not ICE gathering is currently underway.",
      "statechange_event": "\n\nA **`statechange`** event occurs when the [RTCIceTransport] changes state. The [RTCIceTransport.state] can be used to determine how far through the process of examining, verifying, and selecting a valid candidate pair is prior to successfully connecting the two peers for WebRTC communications.\n\nThis event is not cancelable and does not bubble."
    }
  },
  "rtcidentityassertion": {
    "docs": "\n\nThe **`RTCIdentityAssertion`** interface of the [WebRTC API](/en-US/docs/Web/API/WebRTC_API) represents the identity of a remote peer of the current connection. If no peer has yet been set and verified, then this interface returns `null`. Once set it can't be changed."
  },
  "rtcinboundrtpstreamstats": {
    "docs": "\n\nThe **`RTCInboundRtpStreamStats`** dictionary of the [WebRTC API](/en-US/docs/Web/API/WebRTC_API) is used to report statistics related to the receiving end of an RTP stream on the local end of the [RTCPeerConnection].\n\nThe statistics can be obtained by iterating the [RTCStatsReport] returned by [RTCPeerConnection.getStats] or [RTCRtpReceiver.getStats] until you find a report with the [`type`](#type) of `inbound-rtp`.",
    "properties": {
      "averagertcpinterval": "\n\nThe **`averageRtcpInterval`** property\nof the [RTCInboundRtpStreamStats] dictionary is a floating-point value\nindicating the average  transmission interval, in seconds.\n\nThe RTCP interval is the amount of time that should elapse between transmissions of RTCP\npackets.",
      "bytesreceived": "\n\nThe [RTCInboundRtpStreamStats] dictionary's\n**`bytesReceived`** property is an integer value which\nindicates the total number of bytes received so far from this synchronization source\n(SSRC).",
      "fecpacketsdiscarded": "\n\nThe **`fecPacketsDiscarded`** property\nof the [RTCInboundRtpStreamStats] dictionary is a numeric value\nindicating the number of  Forward Error Correction (FEC) packets\nthat have been discarded.",
      "fecpacketsreceived": "\n\nThe **`fecPacketsReceived`** property\nof the [RTCInboundRtpStreamStats] dictionary indicates how many\nForward Error Correction (FEC) packets have been received by this RTP receiver\nfrom the remote peer.\n\nAn FEC packet provides parity information which can\nbe used to attempt to reconstruct RTP data packets which have been corrupted in\ntransit.",
      "fircount": "\n\nThe **`firCount`** property of the\n[RTCInboundRtpStreamStats] dictionary indicates the number of\n**Full Intra Request** (**FIR**) packets have been sent by\nthe receiver to the sender.\n\nThe receiver sends a FIR packet when the stream\nfalls behind and needs to skip frames in order to catch up.",
      "framesdecoded": "\n\nThe **`framesDecoded`** property of\nthe [RTCInboundRtpStreamStats] dictionary indicates the total number of\nframes which have been decoded successfully for this media source.",
      "id": "\n\nThe **`id`** property of the [RTCInboundRtpStreamStats] dictionary is a string that uniquely identifies the object for which this object provides statistics.\n\nUsing the `id`, you can correlate this statistics object with others, in order to monitor statistics over time for a given WebRTC object, such as an [RTCPeerConnection], or an [RTCDataChannel].",
      "lastpacketreceivedtimestamp": "\n\nThe **`lastPacketReceivedTimestamp`** property of the [RTCInboundRtpStreamStats] dictionary indicates the time at which the most recently received packet arrived from this source.",
      "nackcount": "\n\nThe **`nackCount`** property of the\n[RTCInboundRtpStreamStats] dictionary is a numeric value indicating the\nnumber of times the receiver sent a **NACK** packet to the sender.\n\nA NACK (Negative ACKnowledgement, also called \"Generic NACK\") packet tells the sender\nthat one or more of the  packets it sent were lost in transport.",
      "packetsduplicated": "\n\nThe **`packetsDuplicated`** property\nof the [RTCInboundRtpStreamStats] dictionary indicates the total number\nof packets discarded because they were duplicates of previously-received\npackets.\n\nThese packets are not counted by the\n[RTCInboundRtpStreamStats.packetsDiscarded] property.",
      "packetsfaileddecryption": "\n\nThe **`packetsFailedDecryption`**\nproperty of the [RTCInboundRtpStreamStats] dictionary indicates the total\nnumber of  packets which failed to be decrypted successfully after\nbeing received by the local end of the connection during this session.",
      "perdscppacketsreceived": "\n\nThe **`perDscpPacketsReceived`**\nproperty of the [RTCInboundRtpStreamStats] dictionary is a record\ncomprised of key/value pairs in which each key is a string representation of a\nDifferentiated Services Code Point and the value is the number of packets received for\nthat DCSP.\n\n> **Note:** Not all operating systems make data available on a per-DSCP\n> basis, so this property shouldn't be relied upon on those systems.",
      "plicount": "\n\nThe **`pliCount`** property of the\n[RTCInboundRtpStreamStats] dictionary states the number of times the\n[RTCRtpReceiver] described by these statistics sent a **Picture\nLoss Indication** (**PLI**) packet to the sender.\n\nA PLI\npacket indicates that some amount of encoded video data has been lost for one or more\nframes.",
      "qpsum": "\n\nThe **`qpSum`** property of the\n[RTCInboundRtpStreamStats] dictionary is a value generated by adding the\n**Quantization Parameter** (**QP**) values for every frame\nsent or received to date on the video track corresponding to this\n`RTCInboundRtpStreamStats` object.\n\nIn general, the higher this\nnumber is, the more heavily compressed the video data is.",
      "receiverid": "\n\nThe **`receiverId`** property of the [RTCInboundRtpStreamStats] dictionary specifies the [RTCInboundRtpStreamStats.id] of the [RTCAudioReceiverStats] or [RTCVideoReceiverStats] object representing the [RTCRtpReceiver] receiving the stream.",
      "remoteid": "\n\nThe **`remoteId`** property of the\n[RTCInboundRtpStreamStats] dictionary specifies the [RTCInboundRtpStreamStats.id] of the [RTCRemoteOutboundRtpStreamStats] object representing the remote peer's [RTCRtpSender] which is sending the media to the local peer.",
      "slicount": "\n\nThe **`sliCount`** property of the\n[RTCInboundRtpStreamStats] dictionary indicates how many **Slice\nLoss Indication** (**SLI**) packets the\n[RTCRtpReceiver] for which this object provides statistics sent to the\nremote [RTCRtpSender].\n\nAn SLI packet is used by a decoder to let\nthe encoder know that it's detected corruption of one or more consecutive macroblocks\n(in scan order) in the received media.\n\nIn general, what's usually of interest is that the higher this number is, the more the\nstream data is becoming corrupted between the sender and the receiver, requiring resends\nor dropping frames.",
      "timestamp": "\n\nThe **`timestamp`** property of the [RTCInboundRtpStreamStats] dictionary is a [DOMHighResTimeStamp] object specifying the time at which the data in the object was sampled.",
      "trackid": " \n\nThe **`trackId`** property of the [RTCInboundRtpStreamStats] dictionary indicates the [RTCInboundRtpStreamStats.id] of the [RTCReceiverAudioTrackAttachmentStats] or [RTCReceiverVideoTrackAttachmentStats] object representing the [MediaStreamTrack] which is receiving the incoming media.",
      "type": "\n\nThe **`type`** property of the [RTCInboundRtpStreamStats] dictionary is a string with the value `\"inbound-rtp\"`.\n\nDifferent statistics are obtained by iterating the [RTCStatsReport] object returned by a call to [RTCPeerConnection.getStats].\nThe type indicates the set of statistics available through the object in a particular iteration step.\nA value of `\"inbound-rtp\"` indicates that the statistics available in the current step are those defined in [RTCInboundRtpStreamStats]."
    }
  },
  "rtcoutboundrtpstreamstats": {
    "docs": "\n\nThe **`RTCOutboundRtpStreamStats`** dictionary of the [WebRTC API](/en-US/docs/Web/API/WebRTC_API) is used to report metrics and statistics related to an outbound  stream being sent by an [RTCRtpSender].\n\nThe statistics can be obtained by iterating the [RTCStatsReport] returned by [RTCPeerConnection.getStats] or [RTCRtpSender.getStats] until you find a report with the [`type`](#type) of `outbound-rtp`.",
    "properties": {
      "averagertcpinterval": "\n\nThe **`averageRtcpInterval`** property\nof the [RTCOutboundRtpStreamStats] dictionary is a floating-point value\nindicating the average time that should pass between transmissions of\n packets on this stream.",
      "fircount": "\n\nThe **`firCount`** property of the\n[RTCOutboundRtpStreamStats] dictionary indicates the number of\n**Full Intra Request** (**FIR**) that the remote\n[RTCRtpReceiver] has sent to this [RTCRtpSender].\n\nA FIR packet is sent when the receiver finds that it has fallen behind and needs to skip\nframes in order to catch up; the sender should respond by sending a full frame instead\nof a delta frame.\n\nAvailable only on video media.",
      "framesencoded": "\n\nThe **`framesEncoded`** property of\nthe [RTCOutboundRtpStreamStats] dictionary indicates the total number of\nframes that have been encoded by this [RTCRtpSender] for this media\nsource.",
      "id": "\n\nThe **`id`** property of the [RTCOutboundRtpStreamStats] dictionary is a string that uniquely identifies the object for which this object provides statistics.\n\nUsing the `id`, you can correlate this statistics object with others, in order to monitor statistics over time for a given WebRTC object, such as an [RTCPeerConnection], or an [RTCDataChannel].",
      "nackcount": "\n\nThe **`nackCount`** property of the\n[RTCOutboundRtpStreamStats] dictionary is a numeric value indicating the\nnumber of times the [RTCRtpSender] described by this object received a\n**NACK** packet from the remote receiver.\n\nA NACK (Negative\nACKnowledgement, also called \"Generic NACK\") packet is used by the\n[RTCRtpReceiver] to inform the sender that one or more \npackets it sent were lost in transport.",
      "perdscppacketssent": "\n\nThe **`perDscpPacketsSent`** property\nof the [RTCOutboundRtpStreamStats] dictionary is a record comprised of\nkey/value pairs in which each key is a string representation of a Differentiated\nServices Code Point and the value is the number of packets sent for that DCSP.\n\n> **Note:** Not all operating systems make data available on a per-DSCP\n> basis, so this property shouldn't be relied upon on those systems.",
      "plicount": "\n\nThe **`pliCount`** property of the\n[RTCOutboundRtpStreamStats] dictionary states the number of times the\nremote peer's [RTCRtpReceiver] sent a **Picture Loss\nIndication** (**PLI**) packet to the [RTCRtpSender]\nfor which this object provides statistics.\n\nA PLI packet indicates that some\namount of encoded video data has been lost for one or more frames.",
      "qpsum": "\n\nThe **`qpSum`** property of the [RTCOutboundRtpStreamStats] dictionary is a value generated by adding the **Quantization Parameter** (**QP**) values for every frame this sender has produced to date on the video track corresponding to this `RTCOutboundRtpStreamStats` object.\n\nIn general, the higher this number is, the more heavily compressed the video data is.",
      "qualitylimitationreason": "\n\nThe **`qualityLimitationReason`**\nproperty of the [RTCOutboundRtpStreamStats] dictionary is a string\nindicating the reason why the media quality in the stream is currently being reduced\nby the codec during encoding, or `none` if no quality reduction is being\nperformed.\n\nThis quality reduction may include changes such as reduced frame\nrate or resolution, or an increase in compression factor.\n\nThe amount of time the encoded media has had its quality reduced in each of the\npotential ways that can be done can be found in\n[RTCOutboundRtpStreamStats.qualityLimitationDurations].",
      "remoteid": "\n\nThe **`remoteId`** property of the\n[RTCOutboundRtpStreamStats] dictionary specifies the\n[RTCOutboundRtpStreamStats.id] of the [RTCRemoteInboundRtpStreamStats]\nobject representing the remote peer's [RTCRtpReceiver] which is sending\nthe media to the local peer for this SSRC.",
      "slicount": "\n\nThe **`sliCount`** property of the\n[RTCOutboundRtpStreamStats] dictionary indicates how many **Slice\nLoss Indication** (**SLI**) packets the\n[RTCRtpSender] received from the remote [RTCRtpReceiver] for\nthe RTP stream described by this object.\n\nAn SLI packet is used by a decoder to let the encoder (the sender) know that it's\ndetected corruption of one or more consecutive macroblocks, in scan order, in the\nreceived media. In general, what's usually of interest is that the higher this number is,\nthe more the stream data is becoming corrupted between the sender and the receiver,\ncausing the receiver to request retransmits or to drop frames entirely.",
      "timestamp": "\n\nThe **`timestamp`** property of the [RTCOutboundRtpStreamStats] dictionary is a [DOMHighResTimeStamp] object specifying the time at which the data in the object was sampled.",
      "trackid": "\n\nThe **`trackId`** property of the [RTCOutboundRtpStreamStats] dictionary indicates the [RTCOutboundRtpStreamStats.id] of the [RTCSenderAudioTrackAttachmentStats] or [RTCSenderVideoTrackAttachmentStats] object representing the [MediaStreamTrack] which is being sent on this stream.",
      "type": "\n\nThe **`type`** property of the [RTCOutboundRtpStreamStats] dictionary is a string with the value `\"outbound-rtp\"`.\n\nDifferent statistics are obtained by iterating the [RTCStatsReport] object returned by a call to [RTCPeerConnection.getStats].\nThe type indicates the set of statistics available through the object in a particular iteration step.\nA value of `\"outbound-rtp\"` indicates that the statistics available in the current step are those defined in [RTCOutboundRtpStreamStats]."
    }
  },
  "rtcpeerconnection": {
    "docs": "\n\nThe **`RTCPeerConnection`** interface represents a WebRTC connection between the local computer and a remote peer.\nIt provides methods to connect to a remote peer, maintain and monitor the connection, and close the connection once it's no longer needed.\n\n",
    "properties": {
      "addicecandidate": "\n\nWhen a website or app using [RTCPeerConnection] receives a new ICE candidate from the remote peer over its signaling channel, it delivers the newly-received candidate to the browser's  agent by calling **`RTCPeerConnection.addIceCandidate()`**.\nThis adds this new remote candidate to the `RTCPeerConnection`'s remote description, which describes the state of the remote end of the connection.\n\nIf the `candidate` parameter is missing or a value of `null` is given when calling `addIceCandidate()`, the added ICE candidate is an \"end-of-candidates\" indicator.\nThe same is the case if the value of the specified object's [RTCIceCandidate.candidate] is either missing or an empty string (`\"\"`), it signals that all remote candidates have been delivered.\n\nThe end-of-candidates notification is transmitted to the remote peer using a candidate with an a-line value of `end-of-candidates`.\n\nDuring negotiation, your app will likely receive many candidates which you'll deliver to the ICE agent in this way, allowing it to build up a list of potential connection methods.\nThis is covered in more detail in the articles [WebRTC connectivity](/en-US/docs/Web/API/WebRTC_API/Connectivity) and\n[Signaling and video calling](/en-US/docs/Web/API/WebRTC_API/Signaling_and_video_calling).",
      "addstream": "\n\nThe _obsolete_ [RTCPeerConnection] method\n**`addStream()`** adds a [MediaStream] as a local\nsource of audio or video. Instead of using this obsolete method, you should instead use\n[RTCPeerConnection.addTrack] once for each track you wish to\nsend to the remote peer.\n\nIf the [RTCPeerConnection.signalingState] is set to\n`closed`, an `InvalidStateError` is raised. If the\n[RTCPeerConnection.signalingState] is set to\n`stable`, the event [RTCPeerConnection/negotiationneeded_event] is sent on the\n[RTCPeerConnection] to indicate that  negotiation must\nbe repeated to consider the new stream.",
      "addstream_event": "\n\nThe obsolete **`addstream`** event is sent to an [RTCPeerConnection] when new media, in the form of a [MediaStream] object, has been added to it.\n\n> **Warning:** This event has been removed from the WebRTC specification. You should instead watch for the [RTCPeerConnection.track_event] event, which is sent for each media track added to the `RTCPeerConnection`.\n\nYou can, similarly, watch for streams to be removed from the connection by monitoring the [RTCPeerConnection.removestream_event] event.\n\nThis event is not cancelable and does not bubble.",
      "addtrack": "\n\nThe [RTCPeerConnection] method **`addTrack()`** adds a new media track to the set of tracks which will be transmitted to the other peer.\n\n> **Note:** Adding a track to a connection triggers renegotiation by firing a [RTCPeerConnection/negotiationneeded_event] event.\n> See [Starting negotiation](/en-US/docs/Web/API/WebRTC_API/Signaling_and_video_calling#starting_negotiation) for details.",
      "addtransceiver": "\n\nThe [RTCPeerConnection] method **`addTransceiver()`** creates a new [RTCRtpTransceiver] and adds it to the set of transceivers associated with the `RTCPeerConnection`.\nEach transceiver represents a bidirectional stream, with both an [RTCRtpSender] and an [RTCRtpReceiver] associated with it.",
      "cantrickleicecandidates": "\n\nThe read-only **[RTCPeerConnection]** property **`canTrickleIceCandidates`**\nreturns a boolean value which indicates whether or not the remote peer can accept\n[trickled ICE candidates](https://datatracker.ietf.org/doc/html/draft-ietf-mmusic-trickle-ice).\n\n**ICE trickling** is the process of continuing to send candidates after\nthe initial offer or answer has already been sent to the other peer.\n\nThis property is only set after having called\n[RTCPeerConnection.setRemoteDescription]. Ideally, your signaling\nprotocol provides a way to detect trickling support, so that you don't need to rely on\nthis property. A WebRTC browser will always support trickle ICE. If trickling isn't\nsupported, or you aren't able to tell, you can check for a falsy value for this\nproperty and then wait until the value of\n[RTCPeerConnection.iceGatheringState] changes to\n`\"completed\"` before creating and sending the initial offer. That way, the\noffer contains all of the candidates.",
      "close": "\n\nThe **`RTCPeerConnection.close()`** method closes the current\npeer connection.",
      "connectionstate": "\n\nThe read-only **`connectionState`** property of the [RTCPeerConnection] interface indicates the current state of the peer connection by returning one of the following string values: `new`, `connecting`, `connected`, `disconnected`, `failed`, or `closed`.\n\nThis state essentially represents the aggregate state of all ICE transports (which are of type [RTCIceTransport] or [RTCDtlsTransport]) being used by the connection.\n\nWhen this property's value changes, a [RTCPeerConnection.connectionstatechange_event] event is sent to the [RTCPeerConnection] instance.",
      "connectionstatechange_event": "\n\nThe **`connectionstatechange`** event is sent to the `onconnectionstatechange` event handler on an [RTCPeerConnection] object after a new track has been added to an [RTCRtpReceiver] which is part of the connection.\nThe new connection state can be found in [RTCPeerConnection.connectionState], and is one of the string values: `new`, `connecting`, `connected`, `disconnected`, `failed`, or `closed`.\n\nThis event is not cancelable and does not bubble.",
      "createanswer": "\n\nThe **`createAnswer()`** method on the\n[RTCPeerConnection] interface creates an  answer to an\noffer received from a remote peer during the offer/answer negotiation of a WebRTC\nconnection. The answer contains information about any media already attached to the\nsession, codecs and options supported by the browser, and any \ncandidates already gathered. The answer is delivered to the returned\n`Promise`, and should then be sent to the source of the offer to continue\nthe negotiation process.",
      "createdatachannel": "\n\nThe **`createDataChannel()`** method\non the [RTCPeerConnection] interface\ncreates a new channel linked with the remote peer,\nover which any kind of data may be transmitted.\nThis can be useful for back-channel content,\nsuch as images, file transfer, text chat, game update\npackets, and so forth.\n\nIf the new data channel is the first one added to the connection, renegotiation is\nstarted by delivering a [RTCPeerConnection/negotiationneeded_event] event.",
      "createoffer": "\n\nThe **`createOffer()`** method\nof the [RTCPeerConnection] interface\ninitiates the creation of an  offer\nfor the purpose of starting a new WebRTC connection to a remote peer.\nThe SDP offer includes information\nabout any [MediaStreamTrack] objects\nalready attached to the WebRTC session, codec, and options supported by the browser,\nand any candidates already gathered by the  agent,\nfor the purpose of being sent over the signaling channel\nto a potential peer\nto request a connection\nor to update the configuration of an existing connection.\n\nThe return value is a `Promise` which, when the offer has been created, is\nresolved with a [RTCSessionDescription] object containing the newly-created\noffer.",
      "currentlocaldescription": "\n\nThe read-only property\n**`RTCPeerConnection.currentLocalDescription`** returns an\n[RTCSessionDescription] object describing the local end of the connection\nas it was most recently successfully negotiated since the last time the\n[RTCPeerConnection] finished negotiating and connecting to a remote peer.\nAlso included is a list of any ICE candidates that may already have been generated by\nthe ICE agent since the offer or answer represented by the description was first\ninstantiated.\n\nTo change the `currentLocalDescription`, call\n[RTCPeerConnection.setLocalDescription], which triggers a series of\nevents which leads to this value being set. For details on what exactly happens and why\nthe change isn't necessarily instantaneous, see\n[Pending and current descriptions](/en-US/docs/Web/API/WebRTC_API/Connectivity#pending_and_current_descriptions) in the WebRTC Connectivity page.\n\n> **Note:** Unlike [RTCPeerConnection.localDescription], this value represents the\n> actual current state of the local end of the connection; `localDescription`\n> may specify a description which the connection is currently in the process of\n> switching over to.",
      "currentremotedescription": "\n\nThe read-only property\n**`RTCPeerConnection.currentRemoteDescription`** returns an\n[RTCSessionDescription] object describing the remote end of the connection\nas it was most recently successfully negotiated since the last time the\n[RTCPeerConnection] finished negotiating and connecting to a remote peer.\nAlso included is a list of any ICE candidates that may already have been generated by\nthe ICE agent since the offer or answer represented by the description was first\ninstantiated.\n\nTo change the `currentRemoteDescription`, call\n[RTCPeerConnection.setRemoteDescription], which triggers a series of\nevents which leads to this value being set. For details on what exactly happens and why\nthe change isn't necessarily instantaneous, see\n[Pending and current descriptions](/en-US/docs/Web/API/WebRTC_API/Connectivity#pending_and_current_descriptions) in the WebRTC Connectivity page.\n\n> **Note:** Unlike [RTCPeerConnection.remoteDescription], this value represents the\n> actual current state of the local end of the connection;\n> `remoteDescription` may specify a description which the connection is\n> currently in the process of switching over to.",
      "datachannel_event": "\n\nA **`datachannel`** event is sent to an [RTCPeerConnection] instance when an [RTCDataChannel] has been added to the connection, as a result of the remote peer calling [RTCPeerConnection.createDataChannel].\n\n> **Note:** This event is _not_ dispatched when the local end of the connection creates the channel.\n\nThis event is not cancelable and does not bubble.",
      "generatecertificate_static": "\n\nThe static **`RTCPeerConnection.generateCertificate()`**\nfunction creates an X.509 certificate and corresponding private key, returning a promise\nthat resolves with the new [RTCCertificate] once it's generated.",
      "getconfiguration": "\n\nThe **`RTCPeerConnection.getConfiguration()`** method returns\nan object which indicates the current configuration of\nthe [RTCPeerConnection] on which the method is called.\n\nThe returned configuration is the last configuration applied via\n[RTCPeerConnection.setConfiguration], or if\n`setConfiguration()` hasn't been called, the configuration the\n`RTCPeerConnection` was constructed with. The configuration includes a list\nof the ICE servers used by the connection, information about transport policies, and\nidentity information.",
      "getidentityassertion": "\n\nThe **`RTCPeerConnection.getIdentityAssertion()`** method\ninitiates the gathering of an identity assertion. This has an effect only if the\n[RTCPeerConnection.signalingState] is not\n`\"closed\"`.\n\nThe method returns a JavaScript `Promise` which resolves to an\nidentity assertion encoded as a string.\n\nIt is not expected for the application dealing with the `RTCPeerConnection`:\nthis is automatically done; an explicit call only allows to anticipate the need.",
      "getreceivers": "\n\nThe **`RTCPeerConnection.getReceivers()`** method returns an array of [RTCRtpReceiver] objects, each of which represents one RTP receiver.\nEach RTP receiver manages the reception and decoding of data for a [MediaStreamTrack] on an [RTCPeerConnection].",
      "getsenders": "\n\nThe [RTCPeerConnection] method **`getSenders()`** returns an array of [RTCRtpSender] objects, each of which represents the RTP sender responsible for transmitting one track's data.\nA sender object provides methods and properties for examining and controlling the encoding and transmission of the track's data.",
      "getstats": "\n\nThe [RTCPeerConnection] method\n**`getStats()`** returns a promise which resolves with data\nproviding statistics about either the overall connection or about the specified\n[MediaStreamTrack].",
      "gettransceivers": "\n\nThe [RTCPeerConnection] interface's **`getTransceivers()`** method returns a list of the [RTCRtpTransceiver] objects being used to send and receive data on the connection.",
      "icecandidate_event": "\n\nAn **`icecandidate`** event is sent to an [RTCPeerConnection] when:\n\n- An [RTCIceCandidate] has been identified and added to the local peer by a call to [RTCPeerConnection.setLocalDescription],\n- Every [RTCIceCandidate] correlated with a particular username fragment and password combination (a **generation**) has been so identified and added, and\n- All ICE gathering on all transports is complete.\n\nIn the first two cases, the event handler should transmit the candidate to the remote peer over the signaling channel so the remote peer can add it to its set of remote candidates.\n\nThis event is not cancelable and does not bubble.",
      "icecandidateerror_event": "\n\nThe [WebRTC API](/en-US/docs/Web/API/WebRTC_API) event **`icecandidateerror`** is sent to an [RTCPeerConnection] if an error occurs while performing ICE negotiations through a  or  server. The event object is of type [RTCPeerConnectionIceErrorEvent], and contains information describing the error in some amount of detail.\n\nThis event is not cancelable and does not bubble.",
      "iceconnectionstate": "\n\nThe read-only property **`RTCPeerConnection.iceConnectionState`** returns\na string which state of the  agent associated with the [RTCPeerConnection]:\n`new`, `checking`, `connected`, `completed`,\n`failed`, `disconnected`, and `closed`.\n\nIt describes the current state of the ICE agent\nand its connection to the ICE server;\nthat is, the  or  server.\n\nYou can detect when this value has changed by watching for the\n[RTCPeerConnection.iceconnectionstatechange_event] event.",
      "iceconnectionstatechange_event": "\n\nAn **`iceconnectionstatechange`** event is sent to an [RTCPeerConnection] object each time the  connection state changes during the negotiation process.\nThe new ICE connection state is available in the object's [RTCPeerConnection.iceConnectionState] property.\n\nOne common task performed by the `iceconnectionstatechange` event listener is to trigger [ICE restart](/en-US/docs/Web/API/WebRTC_API/Session_lifetime#ice_restart) when the state changes to `failed`.\n\nThis event is not cancelable and does not bubble.",
      "icegatheringstate": "\n\nThe read-only property **`RTCPeerConnection.iceGatheringState`** returns a string\nthat describes the connection's ICE gathering state.\nThis lets you detect, for example, when collection of ICE candidates has finished.\n\nYou can detect when the value of this property changes by watching for an event of type\n[RTCPeerConnection/icegatheringstatechange_event].",
      "icegatheringstatechange_event": "\n\nThe **`icegatheringstatechange`** event is sent to the `onicegatheringstatechange` event handler on an [RTCPeerConnection] when the state of the  candidate gathering process changes.\nThis signifies that the value of the connection's [RTCPeerConnection.iceGatheringState] property has changed.\n\nWhen ICE first starts to gather connection candidates, the value changes from `new` to `gathering` to indicate that the process of collecting candidate configurations for the connection has begun. When the value changes to `complete`, all of the transports that make up the `RTCPeerConnection` have finished gathering ICE candidates.\n\n> **Note:** While you can determine that ICE candidate gathering is complete by watching for `icegatheringstatechange` events and checking for the value of [RTCPeerConnection.iceGatheringState] to become `complete`, you can also have your handler for the [RTCPeerConnection.icecandidate_event] event look to see if its [RTCPeerConnectionIceEvent.candidate] property is `null`. This also indicates that collection of candidates is finished.\n\nThis event is not cancelable and does not bubble.",
      "localdescription": "\n\nThe read-only property **`RTCPeerConnection.localDescription`** returns an [RTCSessionDescription] describing the session for the local end of the connection.\nIf it has not yet been set, this is `null`.",
      "negotiationneeded_event": "\n\nA **`negotiationneeded`** event is sent to the [RTCPeerConnection] when negotiation of the connection through the signaling channel is required.\nThis occurs both during the initial setup of the connection as well as any time a change to the communication environment requires reconfiguring the connection.\n\nThe `negotiationneeded` event is first dispatched to the [RTCPeerConnection] when media is first added to the connection. This starts the process of  negotiation by instructing your code to begin exchanging ICE candidates through the signaling server. See [Signaling transaction flow](/en-US/docs/Web/API/WebRTC_API/Signaling_and_video_calling#signaling_transaction_flow) for a description of the signaling process that begins with a `negotiationneeded` event.\n\nThis event is not cancelable and does not bubble.",
      "peeridentity": "\n\nThe read-only [RTCPeerConnection] property\n**`peerIdentity`** returns a JavaScript `Promise`\nthat resolves to an [RTCIdentityAssertion] which contains a\nstring identifying the remote peer. Once this promise\nresolves successfully, the resulting identity is the **target peer\nidentity** and cannot change for the duration of the connection.",
      "pendinglocaldescription": "\n\nThe read-only property\n**`RTCPeerConnection.pendingLocalDescription`** returns an\n[RTCSessionDescription] object describing a pending configuration change\nfor the local end of the connection. This does not describe the connection as it\ncurrently stands, but as it may exist in the near future. Use\n[RTCPeerConnection.currentLocalDescription] or\n[RTCPeerConnection.localDescription] to get the current state of the\nendpoint. For details on the difference, see\n[Pending and current descriptions](/en-US/docs/Web/API/WebRTC_API/Connectivity#pending_and_current_descriptions) in the WebRTC Connectivity page.",
      "pendingremotedescription": "\n\nThe read-only property\n**`RTCPeerConnection.pendingRemoteDescription`** returns an\n[RTCSessionDescription] object describing a pending configuration change\nfor the remote end of the connection. This does not describe the connection as it\ncurrently stands, but as it may exist in the near future. Use\n[RTCPeerConnection.currentRemoteDescription] or\n[RTCPeerConnection.remoteDescription] to get the current session\ndescription for the remote endpoint. For details on the difference, see\n[Pending and current descriptions](/en-US/docs/Web/API/WebRTC_API/Connectivity#pending_and_current_descriptions) in the WebRTC Connectivity page.",
      "remotedescription": "\n\nThe read-only property\n**`RTCPeerConnection.remoteDescription`** returns a\n[RTCSessionDescription] describing the session (which includes\nconfiguration and media information) for the remote end of the connection. If this\nhasn't been set yet, this is `null`.\n\nThe returned value typically reflects a remote description which has been received over\nthe signaling server (as either an offer or an answer) and then put into effect by your\ncode calling [RTCPeerConnection.setRemoteDescription] in response.",
      "removestream": "\n\nThe\n**`RTCPeerConnection.removeStream()`** method removes a\n[MediaStream] as a local source of audio or video. If the negotiation\nalready happened, a new one will be needed for the remote peer to be able to use it.\nBecause this method has been deprecated, you should instead use\n[RTCPeerConnection.removeTrack] if your target browser\nversions have implemented it.\n\nIf the [RTCPeerConnection.signalingState] is set to\n`\"closed\"`, an `InvalidStateError` is raised. If the\n[RTCPeerConnection.signalingState] is set to\n`\"stable\"`, the event [RTCPeerConnection/negotiationneeded_event] is sent on the\n[RTCPeerConnection].",
      "removestream_event": "\n\nThe obsolete **`removestream`** event was sent to an [RTCPeerConnection] to inform it that a [MediaStream] had been removed from the connection.\nYou can use the `RTCPeerConnection` interface's `onremovestream` property to set a handler for this event.\n\nThis is the counterpart to the [RTCPeerConnection.addstream_event] event, which is also obsolete.\n\n> **Warning:** This event has been removed from the WebRTC specification in favor of the existing [MediaStream/removetrack_event] event on the remote [MediaStream] and the corresponding event handler property of the remote [MediaStream]. The [RTCPeerConnection] API is now track-based, so having zero tracks in the remote stream is equivalent to the remote stream being removed, which caused a `removestream` event.\n\nThis event is not cancelable and does not bubble.",
      "removetrack": "\n\nThe\n**`RTCPeerConnection.removeTrack()`** method tells the local\nend of the connection to stop sending media from the specified track, without actually\nremoving the corresponding [RTCRtpSender] from the list of senders as\nreported by [RTCPeerConnection.getSenders]. If the track is\nalready stopped, or is not in the connection's senders list, this method has no effect.\n\nIf the connection has already been negotiated\n([RTCPeerConnection.signalingState] is set to\n`\"stable\"`), it is marked as needing to be negotiated again; the remote peer\nwon't experience the change until this negotiation occurs. A\n[RTCPeerConnection/negotiationneeded_event] event is sent to the [RTCPeerConnection] to\nlet the local end know this negotiation must occur.",
      "restartice": "\n\nThe [WebRTC](/en-US/docs/Web/API/WebRTC_API) API's\n[RTCPeerConnection] interface offers the\n**`restartIce()`** method to allow a web application to easily\nrequest that  candidate gathering be redone on both ends of the\nconnection.\nThis simplifies the process by allowing the same method to be used\nby either the caller or the receiver to trigger an ICE restart.\n\nAfter `restartIce()` returns, the offer returned by the next call to\n[RTCPeerConnection.createOffer] is automatically\nconfigured to trigger ICE restart on both the local peer (once the local peer has been\nset) and on the remote peer, once the offer is sent across your signaling mechanism and\nthe remote peer has set its description as well.\n\n`restartIce()` causes the\n[RTCPeerConnection.negotiationneeded_event] event to\nbe fired on the `RTCPeerConnection` to inform the application that it should\nperform negotiation using its signaling channel.\n\nIf negotiation fails to complete—either due to rollback or because incoming offers are\nin the process of being negotiated—the [RTCPeerConnection] will remember\nthat you requested ICE restart. The next time the connection's\n[RTCPeerConnection.signalingState] changes to\n`stable`, the connection will fire the\n[RTCPeerConnection.negotiationneeded_event] event.\nThis process continues until an ICE restart has been successfully completed.",
      "sctp": "\n\nThe read-only **`sctp`** property on the [RTCPeerConnection] interface returns an [RTCSctpTransport] describing the  transport over which SCTP data is being sent and\nreceived.\nIf SCTP hasn't been negotiated, this value is `null`.\n\nThe SCTP transport is used for transmitting and receiving data for any and all [RTCDataChannel]s on the peer connection.",
      "setconfiguration": "\n\nThe **`RTCPeerConnection.setConfiguration()`** method sets the\ncurrent configuration of the [RTCPeerConnection] based on the values\nincluded in the specified object. This lets you change\nthe ICE servers used by the connection and which transport policies to use.\n\nThe most common use case for this method (and even then, probably not a very common use\ncase) is to replace the set of ICE servers to be used. Two potential scenarios in which\nthis might be done:\n\n- The [RTCPeerConnection] was instantiated without specifying any ICE\n  servers. If, for example, the [RTCPeerConnection.RTCPeerConnection] constructor was called with no parameters, you would have to\n  then call `setConfiguration()` to add ICE servers before ICE negotiation could begin.\n- Renegotiation of the connection is needed, and a different set of ICE servers needs\n  to be used for some reason. Perhaps the user has moved into a new region, so using new\n  regional ICE servers is necessary, for example.\n  In this situation, one might call `setConfiguration()` to switch to new regional ICE servers, then initiate an [ICE restart](/en-US/docs/Web/API/WebRTC_API/Session_lifetime#ice_restart).\n\n> **Note:** You cannot change the identity information for a connection once it's already been set.",
      "setidentityprovider": "\n\nThe **`RTCPeerConnection.setIdentityProvider()`** method sets\nthe Identity Provider (IdP) to the triplet given in parameter: its name, the protocol\nused to communicate with it (optional) and an optional username. The IdP will be used\nonly when an assertion is needed.\n\nIf the [RTCPeerConnection.signalingState] is set to\n`\"closed\"`, an `InvalidStateError` is raised.",
      "setlocaldescription": "\n\nThe [RTCPeerConnection] method\n[RTCPeerConnection.setLocalDescription] changes\nthe local description associated with the connection. This description specifies the\nproperties of the local end of the connection, including the media format.\nThe method takes a single parameter—the session description—and it returns a\n`Promise` which is fulfilled once the description has been changed,\nasynchronously.\n\nIf `setLocalDescription()` is called while a connection is already in place,\nit means renegotiation is underway (possibly to adapt to changing network conditions).\nBecause descriptions will be exchanged until the two peers agree on a configuration, the\ndescription submitted by calling `setLocalDescription()` does not immediately\ntake effect. Instead, the current connection configuration remains in place until\nnegotiation is complete. Only then does the agreed-upon configuration take effect.",
      "setremotedescription": "\n\nThe [RTCPeerConnection]\nmethod **`setRemoteDescription()`** sets the specified\nsession description as the remote peer's current offer or answer. The description\nspecifies the properties of the remote end of the connection, including the media\nformat. The method takes a single parameter—the session description—and it\nreturns a `Promise` which is fulfilled once the description has been\nchanged, asynchronously.\n\nThis is typically called after receiving an offer or answer from another peer over the\nsignaling server. Keep in mind that if `setRemoteDescription()` is called\nwhile a connection is already in place, it means renegotiation is underway (possibly\nto adapt to changing network conditions).\n\nBecause descriptions will be exchanged until the two peers agree on a configuration,\nthe description submitted by calling `setRemoteDescription()` does not\nimmediately take effect. Instead, the current connection configuration remains in\nplace until negotiation is complete. Only then does the agreed-upon configuration take\neffect.",
      "signalingstate": "\n\nThe read-only **`signalingState`** property on the\n[RTCPeerConnection] interface returns a string value\ndescribing the state of the signaling process\non the local end of the connection\nwhile connecting or reconnecting to another peer.\nSee [Signaling](/en-US/docs/Web/API/WebRTC_API/Session_lifetime#signaling) in our WebRTC session lifetime page.\n\nBecause the signaling process is a state machine, being able to verify that your code\nis in the expected state when messages arrive can help avoid unexpected and avoidable\nfailures. For example, if you receive an answer while the `signalingState`\nisn't `\"have-local-offer\"`, you know that something is wrong, since you\nshould only receive answers after creating an offer but before an answer has been\nreceived and passed into [RTCPeerConnection.setLocalDescription]. Your\ncode will be more reliable if you watch for mismatched states like this and handle them\ngracefully.\n\nThis value may also be useful during debugging, for example.\n\nIn addition, when the value of this property changes, a\n[RTCPeerConnection/signalingstatechange_event] event is sent to the [RTCPeerConnection]\ninstance.",
      "signalingstatechange_event": "\n\nA **`signalingstatechange`** event is sent to an [RTCPeerConnection] to notify it that its signaling state, as indicated by the [RTCPeerConnection.signalingState] property, has changed.\n\nThis event is not cancelable and does not bubble.",
      "track_event": "\n\nThe **`track`** event is sent to the `ontrack` event handler on [RTCPeerConnection]s after a new track has been added to an [RTCRtpReceiver] which is part of the connection.\n\nBy the time this event is delivered, the new track has been fully added to the peer connection. See [Track event types](/en-US/docs/Web/API/RTCTrackEvent#track_event_types) for details.\n\nThis event is not cancellable and does not bubble."
    }
  },
  "rtcpeerconnectioniceerrorevent": {
    "docs": "`WebRTC API`\n\nThe **`RTCPeerConnectionIceErrorEvent`** interface—based upon the [Event] interface—provides details pertaining to an  error announced by sending an [RTCPeerConnection.icecandidateerror_event] event to the [RTCPeerConnection] object.\n\n",
    "properties": {
      "address": "`WebRTC`\n\nThe [RTCPeerConnectionIceErrorEvent] property\n**`address`** is a string which indicates the local IP address\nbeing used to communicate with the  or  server\nduring negotiations. The error which occurred involved this address."
    }
  },
  "rtcpeerconnectioniceevent": {
    "docs": "\n\nThe **`RTCPeerConnectionIceEvent`** interface represents events that occur in relation to  candidates with the target, usually an [RTCPeerConnection].\n\nOnly one event is of this type: [RTCPeerConnection.icecandidate_event].\n\n",
    "properties": {
      "candidate": "\n\nThe read-only **`candidate`** property\nof the [RTCPeerConnectionIceEvent] interface returns the\n[RTCIceCandidate] associated with the event."
    }
  },
  "rtcpeerconnectionstats": {
    "docs": "\n\nThe **`RTCPeerConnectionStats`** dictionary of the [WebRTC API](/en-US/docs/Web/API/WebRTC_API) provides information about the high level peer connection ([RTCPeerConnection]).\n\nIn particular, it provides the number of unique data channels that have been opened, and the number of opened channels that have been closed.\nThis allows the current number of open channels to be calculated.\n\nThese statistics can be obtained by iterating the [RTCStatsReport] returned by [RTCPeerConnection.getStats] until you find a report with the [`type`](#type) of `peer-connection`.",
    "properties": {
      "datachannelsclosed": "\n\nThe **`dataChannelsClosed`** property of the [RTCPeerConnectionStats] dictionary indicates the number of unique [RTCDataChannel] objects that have left the [`open`](/en-US/docs/Web/API/RTCDataChannel/readyState#open) state during their lifetime.\n\nA channel will leave the `open` state if either end of the connection or the underlying transport is closed.\nNote that channels that transition to [`closing`](/en-US/docs/Web/API/RTCDataChannel/readyState#closing) or [`closed`](/en-US/docs/Web/API/RTCDataChannel/readyState#closed) without ever being `open` are not counted in this number.",
      "datachannelsopened": "\n\nThe **`dataChannelsOpened`** property of the [RTCPeerConnectionStats] dictionary indicates the number of unique [RTCDataChannel] objects that have entered the [`open`](/en-US/docs/Web/API/RTCDataChannel/readyState#open) state during their lifetime.",
      "id": "\n\nThe **`id`** property of the [RTCPeerConnectionStats] dictionary is a string which uniquely identifies the object for which this object provides statistics.\n\nUsing the `id`, you can correlate this statistics object with others, in order to monitor statistics over time for a given WebRTC object, such as an [RTCPeerConnection], or an [RTCDataChannel].",
      "timestamp": "\n\nThe **`timestamp`** property of the [RTCPeerConnectionStats] dictionary is a [DOMHighResTimeStamp] object specifying the time at which the data in the object was sampled.",
      "type": "\n\nThe **`type`** property of the [RTCPeerConnectionStats] dictionary is a string with the value `\"peer-connection\"`.\n\nDifferent statistics are obtained by iterating the [RTCStatsReport] object returned by a call to [RTCPeerConnection.getStats].\nThe type indicates the set of statistics available through the object in a particular iteration step.\nA value of `\"peer-connection\"` indicates that the statistics available in the current step are those defined in [RTCPeerConnectionStats]."
    }
  },
  "rtcremoteoutboundrtpstreamstats": {
    "docs": "\n\nThe **`RTCRemoteOutboundRtpStreamStats`** dictionary of the [WebRTC API](/en-US/docs/Web/API/WebRTC_API) is used to report statistics from remote endpoint of its outbound RTP stream, which corresponds to an inbound stream that is currently received by an [RTCPeerConnection] object.\n\nThe statistics can be obtained by iterating the [RTCStatsReport] returned by [RTCPeerConnection.getStats] until you find a report with the [`type`](#type) of `remote-outbound-rtp`.",
    "properties": {
      "codecid": "\n\nThe **`codecId`** property of the [RTCRemoteOutboundRtpStreamStats] dictionary is a string that uniquely identifies the object that was inspected to produce the data in the [RTCCodecStats] for the  stream.",
      "id": "\n\nThe **`id`** property of the [RTCRemoteOutboundRtpStreamStats] dictionary is a string that uniquely identifies the object for which this object provides statistics.\n\nUsing the `id`, you can correlate this statistics object with others, in order to monitor statistics over time for a given WebRTC object, such as an [RTCPeerConnection], or an [RTCDataChannel].",
      "kind": "\n\nThe **`kind`** property of the [RTCRemoteOutboundRtpStreamStats] dictionary is a string indicating whether the described  stream contains audio or video media.",
      "localid": "\n\nThe [RTCRemoteOutboundRtpStreamStats] dictionary's **`localId`** property is a string which can be used to identify the [RTCInboundRtpStreamStats] object whose [RTCInboundRtpStreamStats.remoteId] matches this value.\n\nTogether, these two objects provide statistics about the inbound and outbound sides of the same synchronization source (SSRC).",
      "remotetimestamp": "\n\nThe [RTCRemoteOutboundRtpStreamStats] property **`remoteTimestamp`** indicates the timestamp on the remote peer at which these statistics were sent.\nThis differs from `timestamp`, which indicates the time at which the statistics were generated or received locally.",
      "ssrc": "\n\nThe **`ssrc`** property of the [RTCRemoteOutboundRtpStreamStats] dictionary provides the Synchronization Source (SSRC), an integer which uniquely identifies the source of the  packets whose statistics are covered by the [RTCStatsReport] that includes this `RTCRemoteOutboundRtpStreamStats` dictionary.",
      "timestamp": "\n\nThe **`timestamp`** property of the [RTCRemoteOutboundRtpStreamStats] dictionary is a [DOMHighResTimeStamp] object specifying the time at which the data in the object was sampled.",
      "transportid": "\n\nThe **`transportId`** property of the [RTCRemoteOutboundRtpStreamStats] dictionary is a string that uniquely identifies the object from which the statistics contained in the [RTCTransportStats] properties in the [RTCStatsReport].",
      "type": "\n\nThe **`type`** property of the [RTCRemoteOutboundRtpStreamStats] dictionary is a string with the value `\"remote-outbound-rtp\"`.\n\nDifferent statistics are obtained by iterating the [RTCStatsReport] object returned by a call to [RTCPeerConnection.getStats].\nThe type indicates the set of statistics available through the object in a particular iteration step.\nA value of `\"remote-outbound-rtp\"` indicates that the statistics available in the current step are those defined in [RTCRemoteOutboundRtpStreamStats]."
    }
  },
  "rtcrtpcodecparameters": {
    "docs": "\n\nThe [RTCRtpCodecParameters] dictionary, part of the WebRTC API, is used to describe the configuration parameters for a single media .\n\nIt's used in [RTCRtpSender.getParameters], [RTCRtpSender.setParameters] and [RTCRtpReceiver.getParameters].\nIts also use used when calling [RTCRtpTransceiver.setCodecPreferences] to configure a transceiver's codecs before beginning the offer/answer process to establish a WebRTC peer connection.\n\nMost of the fields in this property take values which are defined and maintained by the Internet Assigned Numbers Authority (IANA). References to relevant IANA documents are provided in the [see also](#see_also) section at the end of this article."
  },
  "rtcrtpreceiver": {
    "docs": "\n\nThe **`RTCRtpReceiver`** interface of the [WebRTC API](/en-US/docs/Web/API/WebRTC_API) manages the reception and decoding of data for a [MediaStreamTrack] on an [RTCPeerConnection].",
    "properties": {
      "getcapabilities_static": "`WebRTC`\n\nThe _static method_ **`RTCRtpReceiver.getCapabilities()`** returns an object describing the codec and header extension capabilities supported by [RTCRtpReceiver] objects on the current device.\n\nYou can, similarly, obtain the capabilities of [RTCRtpSender] objects by calling the static function [RTCRtpSender.getCapabilities_static].",
      "getcontributingsources": "\n\nThe **`getContributingSources()`** method of the [RTCRtpReceiver] interface returns an array of objects, each corresponding to one CSRC (contributing source) identifier received by the current `RTCRtpReceiver` in the last ten seconds.",
      "getparameters": "\n\nThe **`getParameters()`** method of the [RTCRtpReceiver] interface returns an object describing the current configuration for the encoding and transmission of media on the receiver's [RTCRtpReceiver.track].",
      "getstats": "\n\nThe [RTCRtpReceiver] method **`getStats()`** asynchronously requests an [RTCStatsReport] object which provides statistics about incoming traffic on the owning [RTCPeerConnection], returning a `Promise` whose fulfillment handler will be called once the results are available.",
      "getsynchronizationsources": "\n\nThe **`getSynchronizationSources()`** method of the [RTCRtpReceiver] interface returns an array of objects, each corresponding to one SSRC (synchronization source) identifier received by the current `RTCRtpReceiver` in the last ten seconds.",
      "track": "\n\nThe **`track`** read-only property of the\n[RTCRtpReceiver] interface returns the [MediaStreamTrack]\nassociated with the current [RTCRtpReceiver] instance.",
      "transform": "\n\nThe **`transform`** property of the [RTCRtpReceiver] object is used to insert a transform stream ([TransformStream]) running in a worker thread into the receiver pipeline.\nThis allows stream transforms to be applied to encoded video and audio frames as they arrive from the packetizer (before they are played/rendered).\n\nThe transform that is to be added is defined using an [RTCRtpScriptTransform] and its associated [Worker].\nIf the transform is set in the peer connection [`track` event](/en-US/docs/Web/API/RTCPeerConnection/track_event) handler, the transform stream will receive the first full incoming frame for the track.\n\n### Value\n\nA [RTCRtpScriptTransform]<!-- or [SFrameTransform] -->, or `null` if the receiver has no associated transform stream.",
      "transport": "`WebRTC`\n\nThe read-only **`transport`** property of an\n[RTCRtpReceiver] object provides the [RTCDtlsTransport] object\nused to interact with the underlying transport over which the receiver is exchanging\nReal-time Transport Control Protocol () packets.\n\nThis transport is responsible for receiving the data for the media on the receiver's\n[RTCRtpReceiver.track]."
    }
  },
  "rtcrtpscripttransform": {
    "docs": "\n\nThe **`RTCRtpScriptTransform`** interface of the [WebRTC API](/en-US/docs/Web/API/WebRTC_API) is used to insert a [WebRTC Encoded Transform](/en-US/docs/Web/API/WebRTC_API/Using_Encoded_Transforms) (a [TransformStream] running in a worker thread) into the WebRTC sender and receiver pipelines."
  },
  "rtcrtpscripttransformer": {
    "docs": "\n\nThe **`RTCRtpScriptTransformer`** interface of the [WebRTC API](/en-US/docs/Web/API/WebRTC_API) provides a worker-side [Stream API](/en-US/docs/Web/API/Streams_API) interface that a [WebRTC Encoded Transform](/en-US/docs/Web/API/WebRTC_API/Using_Encoded_Transforms) can use to modify encoded media frames in the incoming and outgoing WebRTC pipelines.\n\n> **Note:** This feature is available in [_Dedicated_ Web Workers](/en-US/docs/Web/API/Web_Workers_API#worker_types).",
    "properties": {
      "generatekeyframe": "\n\nThe **`generateKeyFrame()`** method of the [RTCRtpScriptTransformer] interface causes a video encoder to generate a key frame.",
      "options": "\n\nThe **`options`** read-only property of the [RTCRtpScriptTransformer] interface returns the object that was (optionally) passed as the second argument [during construction](/en-US/docs/Web/API/RTCRtpScriptTransform/RTCRtpScriptTransform) of the corresponding [RTCRtpScriptTransform].",
      "readable": "\n\nThe **`readable`** read-only property of the [RTCRtpScriptTransformer] interface returns a [ReadableStream] instance is a source for encoded media frames.\n\nWhen the corresponding [RTCRtpScriptTransform] is inserted into the WebRTC sender and receiver pipelines, this stream may be enqueued with outgoing or incoming encoded media frames ([RTCEncodedVideoFrame] or [RTCEncodedAudioFrame]).\nA WebRTC encoded transform can read the frames, modify them as needed, and then send them back into the WebRTC pipeline by writing them to [RTCRtpScriptTransformer.writable].\nA common way to perform this operation is to pipe the frames through a [TransformStream].",
      "sendkeyframerequest": "\n\nThe **`sendKeyFrameRequest()`** method of the [RTCRtpScriptTransformer] interface may be called by a [WebRTC Encoded Transform](/en-US/docs/Web/API/WebRTC_API/Using_Encoded_Transforms) that is processing incoming encoded video frames, in order to request a key frame from the sender.\n\nThe method may only be called when receiving _video_ (not audio) frames and if, for whatever reason, a recipient will not be able to decode the video without a new key frame.\nNote that the user agent can decide that the request for a key frame is not necessary, in which case the returned promise will fulfill even though the request was not actually sent.\n\n> **Note:** It might be called, for example, if a new user joins a WebRTC conference, in order to reduce the time before they receive a key frame and can hence start displaying video.\n> For more information see [Triggering a key frame](/en-US/docs/Web/API/WebRTC_API/Using_Encoded_Transforms#triggering_a_key_frame) in Using WebRTC Encoded Transforms.",
      "writable": "\n\nThe **`writable`** read-only property of the [RTCRtpScriptTransformer] interface returns a [WritableStream] instance that can be used as a sink for encoded media frames enqueued on the corresponding [RTCRtpScriptTransformer.readable].\n\nWhen the corresponding [RTCRtpScriptTransform] is inserted into the WebRTC sender and receiver pipelines, encoded media frames ([RTCEncodedVideoFrame] or [RTCEncodedAudioFrame]) may be enqueued on the [RTCRtpScriptTransformer.readable].\nA WebRTC encoded transform can read the frames from `readable`, modify them as needed, and then send them back into the WebRTC pipeline by sending them to this `writable`.\nA common way to perform this operation is to pipe the frames through a [TransformStream]."
    }
  },
  "rtcrtpsender": {
    "docs": "\n\nThe **`RTCRtpSender`** interface provides the ability to control and obtain details about how a particular [MediaStreamTrack] is encoded and sent to a remote peer.\n\nWith it, you can configure the encoding used for the corresponding track, get information about the device's media capabilities, and so forth. You can also obtain access to an [RTCDTMFSender] which can be used to send  codes (to simulate the user pressing buttons on a telephone's dial pad) to the remote peer.",
    "properties": {
      "dtmf": "\n\nThe read-only **`dtmf`** property on the\n**[RTCRtpSender]** interface returns a\n[RTCDTMFSender] object which can be used to send  tones\nover the [RTCPeerConnection]. See [Using DTMF](/en-US/docs/Web/API/WebRTC_API/Using_DTMF) for details on how to\nmake use of the returned `RTCDTMFSender` object.",
      "getcapabilities_static": "`WebRTC`\n\nThe _static method_ **`RTCRtpSender.getCapabilities()`** returns an object describing the codec and header extension capabilities supported by the [RTCRtpSender].\n\nYou can, similarly, obtain the capabilities of [RTCRtpReceiver] objects on the device by calling the static function [RTCRtpReceiver.getCapabilities_static].",
      "getparameters": "`WebRTC`\n\nThe **`getParameters()`** method of the [RTCRtpSender] interface returns an object describing the current configuration for how the sender's [RTCRtpSender.track] will be encoded and transmitted to a remote [RTCRtpReceiver].",
      "getstats": "\n\nThe [RTCRtpSender] method **`getStats()`** asynchronously requests an [RTCStatsReport] object which provides statistics about outgoing traffic on the [RTCPeerConnection] which owns the sender, returning a `Promise` which is fulfilled when the results are available.",
      "replacetrack": "\n\nThe [RTCRtpSender] method\n**`replaceTrack()`** replaces the track currently being used\nas the sender's source with a new [MediaStreamTrack].\n\nThe new\ntrack must be of the same media kind (audio, video, etc.) and switching the track should\nnot require negotiation.\n\nAmong the use cases for `replaceTrack()` is the common need to switch\nbetween the rear- and front-facing cameras on a phone. With `replaceTrack()`,\nyou can have a track object for each camera and switch between the two as needed. See\nthe example [Switching cameras](#switching_cameras) below.",
      "setparameters": "\n\nThe **`setParameters()`** method of the [RTCRtpSender] interface applies changes the configuration of sender's [RTCRtpSender.track], which is the [MediaStreamTrack] for which the `RTCRtpSender` is responsible.\n\nIn other words, `setParameters()` updates the configuration of the  transmission as well as the encoding configuration for a specific outgoing media track on the [WebRTC](/en-US/docs/Web/API/WebRTC_API) connection.",
      "setstreams": "`WebRTC API`\n\nThe [RTCRtpSender] method **`setStreams()`** associates the sender's [RTCRtpSender.track] with the specified [MediaStream] objects.",
      "track": "\n\nThe **`track`** read-only property of\nthe [RTCRtpSender] interface returns the [MediaStreamTrack]\nwhich is being handled by the `RTCRtpSender`.",
      "transform": "\n\nThe **`transform`** property of the [RTCRtpSender] object is used to insert a transform stream ([TransformStream]) running in a worker thread into the sender pipeline.\nThis allows stream transforms to be applied to encoded video and audio frames after they are output by a codec, and before they are sent.\n\nThe transform that is to be added is defined using an [RTCRtpScriptTransform] and its associated [Worker].\nIf the transform is set synchronously immediately after creating the `RTCRtpSender` it will receive the first full frame generated by the sender's encoder.\n\n### Value\n\nA [RTCRtpScriptTransform]<!-- or [SFrameTransform] -->, or `null` if the sender has no associated transform stream.",
      "transport": "`WebRTC`\n\nThe read-only **`transport`** property of an\n[RTCRtpSender] object provides the [RTCDtlsTransport] object\nused to interact with the underlying transport over which the sender is exchanging\nReal-time Transport Control Protocol () packets.\n\nThis transport is responsible for receiving the data for the media on the sender's\n[RTCRtpReceiver.track]."
    }
  },
  "rtcrtpstreamstats": {
    "docs": "\n\nThe [RTCRtpStreamStats] dictionary is returned by the [RTCPeerConnection.getStats], [RTCRtpSender.getStats], and [RTCRtpReceiver.getStats] methods to provide detailed statistics about WebRTC connectivity.\n\nWhile the dictionary has a base set of properties that are present in each of these cases, there are also additional properties added depending on which interface the method is called on.\n\n`RTCRtpStreamStats` is the base class for all RTP-related statistics reports.\n\n> **Note:** This interface was called `RTCRTPStreamStats` until a specification update in the spring of 2017.\n> Check the [Browser compatibility](#browser_compatibility) table to know if and when the name change was implemented in specific browsers.",
    "properties": {
      "codecid": "\n\nThe [RTCRtpStreamStats] dictionary's\n**`codecId`** property is a string which uniquely identifies\nthe object that was inspected to produce the data in the [RTCCodecStats]\nfor the  stream.",
      "fircount": "\n\nThe **`firCount`** property of the\n[RTCRtpStreamStats] dictionary indicates the number of **Full Intra\nRequest** (**FIR**) packets have been sent by the receiver to\nthe sender.\n\nThis is a measure of how often the stream falls behind and has to\nskip frames in order to catch up.",
      "kind": "\n\nThe **`kind`** property of the\n[RTCRtpStreamStats] dictionary is a string indicating whether the\ndescribed  stream contains audio or video media.\n\nIts value\nis always either `\"audio\"` or `\"video\"`.\n\nThis property was previously called `mediaType`. The name was changed in the\nspecification in February, 2018. See [Browser compatibility](#browser_compatibility) below to\ndetermine how this affects the browsers you're targeting.",
      "nackcount": "\n\nThe **`nackCount`** property of the\n[RTCRtpStreamStats] dictionary is a numeric value indicating the number\nof times the receiver sent a **NACK packet** to the sender.\n\nA NACK\n(Negative ACKnowledgement, also called \"Generic NACK\") packet tells the sender that one\nor more of the  packets it sent were lost in transport.",
      "plicount": "\n\nThe **`pliCount`** property of the\n[RTCRtpStreamStats] dictionary states the number of times the stream's\nreceiving end sent a **Picture Loss Indication** (**PLI**)\npacket to the sender.\n\nA PLI packet indicates that some amount of encoded video\ndata has been lost for one or more frames.",
      "qpsum": "\n\nThe **`qpSum`** property of the\n[RTCRtpStreamStats] dictionary is a value generated by adding the\n**Quantization Parameter** (**QP**) values for every frame\nsent or received to date on the video track corresponding to this\n`RTCRtpStreamStats` object.\n\nIn general, the higher this number is,\nthe more heavily compressed the video data is.",
      "ssrc": "\n\nThe [RTCRtpStreamStats] dictionary's\n**`ssrc`** property provides the Synchronization Source\n(SSRC), an integer which uniquely identifies the source of the \npackets whose statistics are covered by the [RTCStatsReport] that\nincludes this `RTCRtpStreamStats` dictionary.",
      "trackid": "\n\nThe [RTCRtpStreamStats] dictionary's\n**`trackId`** property is a string which uniquely identifies\nthe [RTCMediaStreamTrackStats] object which contains the track statistics\nfor the [MediaStreamTrack] for which statistics are provided in this\nobject.",
      "transportid": "\n\nThe [RTCRtpStreamStats] dictionary's\n**`transportId`** property is a string which uniquely\nidentifies the object from which the statistics contained in the\n[RTCTransportStats] properties in the\n[RTCStatsReport]."
    }
  },
  "rtcrtptransceiver": {
    "docs": "\n\nThe WebRTC interface **`RTCRtpTransceiver`** describes a permanent pairing of an [RTCRtpSender] and an [RTCRtpReceiver], along with some shared state.\n\nEach  media section describes one bidirectional SRTP (\"Secure Real Time Protocol\") stream (excepting the media section for [RTCDataChannel], if present).\nThis pairing of send and receive SRTP streams is significant for some applications, so `RTCRtpTransceiver` is used to represent this pairing, along with other important state from the media section.\nEach non-disabled SRTP media section is always represented by exactly one transceiver.\n\nA transceiver is uniquely identified using its [RTCRtpTransceiver.mid] property, which is the same as the media ID (`mid`) of its corresponding m-line. An `RTCRtpTransceiver` is **associated** with an m-line if its `mid` is non-null; otherwise it's considered disassociated.",
    "properties": {
      "currentdirection": "\n\nThe read-only [RTCRtpTransceiver] property **`currentDirection`** is a string which indicates the current negotiated directionality of the transceiver.\n\nThe directionality indicates whether the transceiver will offer to send and/or receive  data, or whether it is inactive or stopped and won't send or receive data.\n\nThe transceiver's preferred directionality can be set and read using the [RTCRtpTransceiver.direction] property.\nChanging the `direction` triggers a renegotiation, which may eventually result in the `currentDirection` also changing.",
      "direction": "\n\nThe [RTCRtpTransceiver] property **`direction`** is a string that indicates the transceiver's _preferred_ directionality.\n\nThe directionality indicates whether the transceiver will offer to send and/or receive  data, or whether it is inactive or stopped (terminated).\nWhen setting the transceiver's direction, the value is not applied immediately.\nThe _current_ direction is indicated by the [RTCRtpTransceiver.currentDirection] property.",
      "mid": "\n\nThe read-only [RTCRtpTransceiver] interface's\n**`mid`** property specifies the negotiated media ID\n(`mid`) which the local and remote peers have agreed upon to uniquely\nidentify the stream's pairing of sender and receiver.",
      "receiver": "\n\nThe read-only **`receiver`** property\nof WebRTC's [RTCRtpTransceiver] interface indicates the\n[RTCRtpReceiver] responsible for receiving and decoding incoming media\ndata for the transceiver's stream.",
      "sender": "\n\nThe read-only **`sender`** property\nof WebRTC's [RTCRtpTransceiver] interface indicates the\n[RTCRtpSender] responsible for encoding and sending outgoing media data\nfor the transceiver's stream.",
      "setcodecpreferences": "\n\nThe [RTCRtpTransceiver] method **`setCodecPreferences()`** configures the transceiver's preferred list of codecs.\n\nThe specified set of codecs will be used for all future connections that include this transceiver until this method is called again.\n\nWhen preparing to open an [RTCPeerConnection], you can change the codec parameters from the  default configuration by calling `setCodecParameters()` _before_ calling either [RTCPeerConnection.createOffer] or [RTCPeerConnection.createAnswer].\n\nA guide to codecs supported by WebRTC—and each codec's positive and negative characteristics—can be found in [Codecs used by WebRTC](/en-US/docs/Web/Media/Formats/WebRTC_codecs).",
      "stop": "\n\nThe **`stop()`** method in the [RTCRtpTransceiver] interface permanently stops the transceiver by stopping both the associated [RTCRtpSender] and\n[RTCRtpReceiver].",
      "stopped": "\n\n> **Note:** Instead of using this deprecated property, compare [RTCRtpTransceiver.currentDirection] to `\"stopped\"`.\n\nThe read-only **`stopped`** property on the [RTCRtpTransceiver] interface indicates whether or not the transceiver's associated sender and receiver have both been stopped.\n\nThe transceiver is stopped if the [RTCRtpTransceiver.stop] method has been called or if a change to either the local or the remote description has caused the transceiver to be stopped for some reason."
    }
  },
  "rtcsctptransport": {
    "docs": "\n\nThe **`RTCSctpTransport`** interface provides information which describes a Stream Control Transmission Protocol (****) transport. This provides information about limitations of the transport, but also provides a way to access the underlying Datagram Transport Layer Security (****) transport over which SCTP packets for all of an [RTCPeerConnection]'s data channels are sent and received.\n\nYou don't create [RTCSctpTransport] objects yourself; instead, you get access to the `RTCSctpTransport` for a given `RTCPeerConnection` through its **[RTCPeerConnection.sctp]** property.\n\nPossibly the most useful property on this interface is its [`maxMessageSize`](#rtcsctptransport.maxmessagesize) property, which you can use to determine the upper limit on the size of messages you can send over a data channel on the peer connection.\n\n",
    "properties": {
      "maxchannels": "\n\nThe **`maxChannels`** read-only property of the [RTCSctpTransport] interface indicates the maximum number of [RTCDataChannel] objects that can be opened simultaneously.",
      "maxmessagesize": "\n\nThe **`maxMessageSize`** read-only property of the [RTCSctpTransport] interface indicates the maximum size of a message that can be sent using the [RTCDataChannel.send] method.",
      "state": "\n\nThe **`state`** read-only property of the [RTCSctpTransport] interface provides information which describes a Stream Control Transmission Protocol () transport state.",
      "statechange_event": "\n\nA **`statechange`** event is sent to an [RTCSctpTransport] to provide notification when the [RTCSctpTransport.state] property has changed.\n\n<!-- This event is not cancelable and does not bubble. -->",
      "transport": "\n\nThe **`transport`** read-only property of the [RTCSctpTransport] interface returns a [RTCDtlsTransport] object representing the  transport used for the transmission and receipt of data packets."
    }
  },
  "rtcsessiondescription": {
    "docs": "\n\nThe **`RTCSessionDescription`** interface describes one end of a connection—or potential connection—and how it's configured. Each `RTCSessionDescription` consists of a description [RTCSessionDescription.type] indicating which part of the offer/answer negotiation process it describes and of the  descriptor of the session.\n\nThe process of negotiating a connection between two peers involves exchanging `RTCSessionDescription` objects back and forth, with each description suggesting one combination of connection configuration options that the sender of the description supports. Once the two peers agree upon a configuration for the connection, negotiation is complete.",
    "properties": {
      "sdp": "\n\nThe property **`RTCSessionDescription.sdp`** is a read-only\nstring containing the  which describes the session.",
      "tojson": "\n\nThe **`RTCSessionDescription.toJSON()`** method generates a\n description of the object. Both properties,\n[RTCSessionDescription.type] and\n[RTCSessionDescription.sdp], are contained in the generated JSON.",
      "type": "\n\nThe property **`RTCSessionDescription.type`** is a read-only\nstring value which describes the description's type."
    }
  },
  "rtcstatsreport": {
    "docs": "\n\nThe **`RTCStatsReport`** interface of the [WebRTC API](/en-US/docs/Web/API/WebRTC_API) provides a statistics report for a [RTCPeerConnection], [RTCRtpSender], or [RTCRtpReceiver].\n\nAn `RTCStatsReport` instance is a read-only [`Map`-like object](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map#map-like_browser_apis), in which each key is an identifier for an object for which statistics are being reported, and the corresponding value is a dictionary object providing the statistics.",
    "properties": {
      "@@iterator": "\n\nThe **`[@@iterator]()`** method of the [RTCStatsReport] interface implements the [iterable protocol](/en-US/docs/Web/JavaScript/Reference/Iteration_protocols) and allows statistics reports to be consumed by most syntaxes expecting iterables, such as the [spread syntax](/en-US/docs/Web/JavaScript/Reference/Operators/Spread_syntax) and `for...of` loops.\nIt returns an [iterator object](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Iterator) that yields the key-value pairs of the report in insertion order.\n\nThe initial value of this property is the same function object as the initial value of the [RTCStatsReport.entries] method.\n\nThe method is otherwise the same as [`Map.prototype[@@iterator]()`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map/@@iterator).",
      "entries": "\n\nThe **`entries()`** method of the [RTCStatsReport] interface returns a new [iterator](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Iterator) object that can be used to iterate through the key/value pairs for each element in the `RTCStatsReport` object, in insertion order.\n\nThe keys are unique `id` values for monitored statistics objects from which the statistics are derived, and the associated values are [statistics dictionary objects](/en-US/docs/Web/API/RTCStatsReport#the_statistic_types).\n\nThe method is otherwise the same as `Map.prototype.entries()`.",
      "foreach": "\n\nThe **`forEach()`** method of the [RTCStatsReport] interface executes a provided function once for each key/value pair in the `RTCStatsReport` object, in insertion order.\n\nThe keys are unique `id` values for the monitored statistics objects from which the statistics are derived, and the associated values are [statistics dictionary objects](/en-US/docs/Web/API/RTCStatsReport#the_statistic_types).\n\nThe method is otherwise the same as `Map.prototype.forEach()`.",
      "get": "\n\nThe **`get()`** method of the [RTCStatsReport] interface returns a specified element from an `RTCStatsReport`.\n\nElements in the `RTCStatsReport` are identified by unique `id` values, which represent the monitored statistics objects from which the statistics are derived.\nThe element returned will be an instance of one of the [statistics dictionary objects](/en-US/docs/Web/API/RTCStatsReport#the_statistic_types), and it will contain statistics for the object with the given `id`.\nThe fetched value is a reference to the statistics dictionary, and any change made to that object will effectively modify it inside the `RTCStatsReport` object.\n\nThe method is otherwise the same as `Map.prototype.get()`.",
      "has": "\n\nThe **`has()`** method of the [RTCStatsReport] interface returns a boolean indicating whether a report contains a statistics dictionary with the specified id.\n\nThe method is otherwise the same as `Map.prototype.has()`.",
      "keys": "\n\nThe **`keys()`** method of the [RTCStatsReport] interface returns a new _[iterator](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Iterator)_ object that can be used to iterate through the keys for each element in the `RTCStatsReport` object, in insertion order.\n\nThe keys in the `RTCStatsReport` are unique string `id` values, which represent the monitored statistics objects from which the statistics are derived.\n\nThe method is otherwise the same as `Map.prototype.keys()`.",
      "size": "\n\nThe **`size`** read-only property of the [RTCStatsReport] interface returns the number of items in the current report.\n\nNote that each item consists of a key-value pair, where the keys are unique `id` values for monitored statistics objects from which the statistics are derived, and the associated values are [statistics dictionary objects](/en-US/docs/Web/API/RTCStatsReport#the_statistic_types).\n\nThis property is otherwise the same as `Map.prototype.size`.",
      "values": "\n\nThe **`values()`** method of the [RTCStatsReport] interface returns a new _[iterator](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Iterator)_ object that can be used to iterate through the values for each element in the `RTCStatsReport` object, in insertion order.\n\nThe values are [statistics dictionary objects](/en-US/docs/Web/API/RTCStatsReport#the_statistic_types).\n\nThe method is otherwise the same as `Map.prototype.values()`."
    }
  },
  "rtctrackevent": {
    "docs": "\n\nThe [WebRTC API](/en-US/docs/Web/API/WebRTC_API) interface **`RTCTrackEvent`** represents the [RTCPeerConnection.track_event] event, which is sent when a new [MediaStreamTrack] is added to an [RTCRtpReceiver] which is part of the [RTCPeerConnection].\n\nThe target is the `RTCPeerConnection` object to which the track is being added.\n\nThis event is sent by the WebRTC layer to the website or application, so you will not typically need to instantiate an `RTCTrackEvent` yourself.\n\n",
    "properties": {
      "receiver": "\n\nThe read-only **`receiver`** property\nof the [RTCTrackEvent] interface indicates the\n[RTCRtpReceiver] which is used to receive data containing media for the\n[RTCTrackEvent.track] to which the event refers.",
      "streams": "\n\nThe [WebRTC API](/en-US/docs/Web/API/WebRTC_API)\ninterface [RTCTrackEvent]'s read-only\n**`streams`** property specifies an array of\n[MediaStream] objects, one for each of the streams that comprise the\ntrack being added to the [RTCPeerConnection].",
      "track": "\n\nThe [WebRTC API](/en-US/docs/Web/API/WebRTC_API)\ninterface [RTCTrackEvent]'s read-only **`track`**\nproperty specifies the [MediaStreamTrack] that has been added to the\n[RTCPeerConnection].",
      "transceiver": "\n\nThe WebRTC API interface [RTCTrackEvent]'s\nread-only **`transceiver`** property indicates the\n[RTCRtpTransceiver] affiliated with the event's\n[RTCTrackEvent.track].\n\nThe transceiver pairs the track's\n[RTCTrackEvent.receiver] with an [RTCRtpSender]."
    }
  },
  "rtctransformevent": {
    "docs": "\n\nThe **`RTCTransformEvent`** of the [WebRTC API](/en-US/docs/Web/API/WebRTC_API) represent an event that is fired in a dedicated worker when an encoded frame has been queued for processing by a [WebRTC Encoded Transform](/en-US/docs/Web/API/WebRTC_API/Using_Encoded_Transforms).\n\nThe interface has a [RTCTransformEvent.transformer] property that exposes a readable stream and a writable stream.\nA worker should read encoded frames from `transformer.readable`, modify them as needed, and write them to `transformer.writable` in the same order and without any duplication.\n\nAt time of writing there is just one event based on `RTCTransformEvent`: [DedicatedWorkerGlobalScope.rtctransform_event].\n\n",
    "properties": {
      "transformer": "\n\nThe read-only **`transformer`** property of the [RTCTransformEvent] interface returns the [RTCRtpScriptTransformer] associated with the event.\n\nThe property exposes the WebRTC sender or receiver pipeline as a readable and writable stream of encoded media frames, which a [WebRTC Encoded Transform](/en-US/docs/Web/API/WebRTC_API/Using_Encoded_Transforms) can insert itself into in order to modify frames."
    }
  },
  "rtctransportstats": {
    "docs": "\n\nThe **`RTCTransportStats`** dictionary of the [WebRTC API](/en-US/docs/Web/API/WebRTC_API) provides information about the transport ([RTCDtlsTransport] and its underlying [RTCIceTransport]) used by a particular candidate pair.\n\nThe _BUNDLE_ feature is an SDP extension that allows negotiation to use a single transport for sending and receiving media described by multiple SDP media descriptions.\nIf the remote endpoint is aware of this feature, all [MediaStreamTrack] and data channels are bundled onto a single transport at the completion of negotiation.\nThis is true for current browsers, but if connecting to an older endpoint that is not BUNDLE-aware, then separate transports might be used for different media.\nThe policy to use in the negotiation is configured in the [`RTCPeerConnection` constructor](/en-US/docs/Web/API/RTCPeerConnection/RTCPeerConnection).\n\nThese statistics can be obtained by iterating the [RTCStatsReport] returned by [RTCPeerConnection.getStats] until you find a report with the [`type`](#type) of `transport`.",
    "properties": {
      "id": "\n\nThe **`id`** property of the [RTCTransportStats] dictionary is a string which uniquely identifies the object for which this object provides statistics.\n\nUsing the `id`, you can correlate this statistics object with others, in order to monitor statistics over time for a given WebRTC object, such as an [RTCDtlsTransport], or an [RTCPeerConnection].",
      "timestamp": "\n\nThe **`timestamp`** property of the [RTCTransportStats] dictionary is a [DOMHighResTimeStamp] object specifying the time at which the data in the object was sampled.",
      "type": "\n\nThe **`type`** property of the [RTCTransportStats] dictionary is a string with the value `\"transport\"`.\n\nDifferent statistics are obtained by iterating the [RTCStatsReport] object returned by a call to [RTCPeerConnection.getStats].\nThe type indicates the set of statistics available through the object in a particular iteration step.\nA value of `\"transport\"` indicates that the statistics available in the current step are those defined in [RTCTransportStats]."
    }
  },
  "sanitizer": {
    "docs": "\n\nThe **`Sanitizer`** interface of the [HTML Sanitizer API] is used to sanitize untrusted strings of HTML, [Document] and [DocumentFragment] objects.\nAfter sanitization, unwanted elements or attributes are removed, and the returned objects can safely be inserted into a document's DOM.\n\nA **`Sanitizer`** object is also used by the [Element.setHTML] method to parse and sanitize a string of HTML, and immediately insert it into an element.\n\nThe default configuration strips out XSS-relevant input by default, including `script` tags, custom elements, and comments.\nThis configuration may be customized using constructor options.",
    "properties": {
      "sanitize": "\n\nThe **`sanitize()`** method of the [Sanitizer] interface is used to sanitize a tree of DOM nodes, removing any unwanted elements or attributes.\n\nIt should be used when the data to be sanitized is already available as DOM nodes.\nFor example when sanitizing a `Document` instance in a frame.\n\nThe default `Sanitizer()` configuration strips out XSS-relevant input by default, including `script` tags, custom elements, and comments.\nThe sanitizer configuration may be customized using [Sanitizer.Sanitizer] constructor options.\n\n> **Note:** To sanitize strings, instead use [Element.setHTML].\n> See [HTML Sanitizer API] for more information."
    }
  },
  "scheduler": {
    "docs": "\n\nThe **`Scheduler`** interface of the [Prioritized Task Scheduling API](/en-US/docs/Web/API/Prioritized_Task_Scheduling_API) provides the [Scheduler.postTask] method that can be used for adding prioritized tasks to be scheduled.\n\nA `Scheduler` can be accessed from the global object [Window] or [WorkerGlobalScope] (`this.scheduler`).",
    "properties": {
      "posttask": "\n\nThe **`postTask()`** method of the [Scheduler] interface is used for adding tasks to be [scheduled](/en-US/docs/Web/API/Prioritized_Task_Scheduling_API) according to their [priority](/en-US/docs/Web/API/Prioritized_Task_Scheduling_API#task_priorities).\n\nThe method allows users to optionally specify a minimum delay before the task will run, a priority for the task, and a signal that can be used to modify the task priority and/or abort the task.\nIt returns a promise that is resolved with the result of the task callback function, or rejected with the abort reason or an error thrown in the task.\n\nTask priority can be [mutable or immutable](/en-US/docs/Web/API/Prioritized_Task_Scheduling_API#mutable_and_immutable_task_priority).\nIf the task priority will never need to change then it should be set using the `options.priority` parameter (any priority set through a signal will then be ignored).\nYou can still pass an [AbortSignal] (which has no priority) or [TaskSignal] to the `options.signal` parameter for aborting the task.\n\nIf the task priority might need to be changed the `options.priority` parameter must not be set.\nInstead a [TaskController] should be created and its [TaskSignal] should be passed to `options.signal`.\nThe task priority will be initialized from the signal priority, and can later be modified using the signal's associated [TaskController].\n\nIf no priority is set then the task priority defaults to [`\"user-visible\"`](/en-US/docs/Web/API/Prioritized_Task_Scheduling_API#user-visible).\n\nIf a delay is specified and greater than 0, then the execution of the task will be delayed for at least that many milliseconds.\nOtherwise the task is immediately scheduled for prioritization."
    }
  },
  "scheduling": {
    "docs": "\n\nThe **`Scheduling`** object provides methods and properties to control scheduling tasks within the current document.",
    "properties": {
      "isinputpending": "\n\nThe **`isInputPending()`** method of the [Scheduling] interface allows you to check whether there are pending input events in the event queue, indicating that the user is attempting to interact with the page.\n\nThis feature is useful in situations where you have a queue of tasks to run, and you want to yield to the main thread regularly to allow user interaction to occur so that the app is kept as responsive and performant as possible. `isInputPending()` allows you to yield only when there is input pending, rather than having to do it at arbitrary intervals.\n\n`isInputPending()` is called using `navigator.scheduling.isInputPending()`."
    }
  },
  "screen": {
    "docs": "\n\nThe `Screen` interface represents a screen, usually the one on which the current window is being rendered, and is obtained using [window.screen].\n\nNote that browsers determine which screen to report as current by detecting which screen has the center of the browser window.\n\n",
    "properties": {
      "availheight": "\n\nThe read-only [Screen] interface's\n**`availHeight`** property returns the height, in CSS pixels, of\nthe space available for Web content on the screen. Since [Screen] is\nexposed on the [Window] interface's [Window.screen] property, you access `availHeight` using\n`window.screen.availHeight`.\n\nYou can similarly use [Screen.availWidth] to get the number of pixels\nwhich are horizontally available to the browser for its use.",
      "availwidth": "\n\nThe **`Screen.availWidth`** property returns the amount of\nhorizontal space (in pixels) available to the window.",
      "change_event": "\n\nThe **`change`** event of the [Screen] interface is fired on a specific screen when one or more of the following properties change on it:\n\n- [Screen.width]\n- [Screen.height]\n- [Screen.availWidth]\n- [Screen.availHeight]\n- [Screen.colorDepth]\n- [Screen.orientation]",
      "colordepth": "\n\nThe **`Screen.colorDepth`** read-only property returns the\ncolor depth of the screen. Per the CSSOM, some implementations return `24`\nfor compatibility reasons. See the browser compatibility section for those that don't.",
      "height": "\n\nThe **`Screen.height`** read-only property returns the height\nof the screen in pixels.",
      "isextended": "\n\nThe **`isExtended`** read-only property of the\n[Screen] interface returns `true` if the user's device has multiple screens, and `false` if not.\n\nThis property is typically accessed via `window.screen.isExtended`, and can be used to test whether multiple screens are available before attempting to create a multi-window, multi-screen layout using the [Window Management API](/en-US/docs/Web/API/Window_Management_API).",
      "lockorientation": "\n\nThe **`lockOrientation()`** method of the [Screen]\ninterface locks the screen into a specified orientation.\n\n> **Warning:** This feature is deprecated and should be avoided. Use the [ScreenOrientation.lock] method instead.\n\n> **Note:** This method only works for installed Web apps or for Web pages\n> in [fullscreen mode](/en-US/docs/Web/API/Fullscreen_API).",
      "mozbrightness": "\n\nIndicates how bright the screen's backlight is, on a scale from 0 (very dim) to 1 (full\nbrightness); this value is a double-precision float.\n\nYou can read and write this attribute even when the screen is disabled, but the\nbacklight is off while the screen is disabled. If you write a value of X into this\nattribute, the attribute may not have the same value X when you later read it. Most\nscreens don't support as many different brightness levels as there are doubles between 0\nand 1. The value's precision might be reduced before storing it.",
      "mozenabled": "\n\nThis Boolean attribute controls the device's screen. Setting it to `false`\nwill turn off the screen.",
      "orientation": "\n\nThe **`orientation`** read-only property of the\n[Screen] interface returns the current orientation of the screen.",
      "orientationchange_event": "\n\nThe `orientationchange` event fires when the device's orientation has changed.",
      "pixeldepth": "\n\nReturns the bit depth of the screen. Per the CSSOM, some implementations\nreturn `24` for compatibility reasons. See the [browser compatibility](#browser_compatibility) section for those that don't.",
      "unlockorientation": "\n\nThe **`Screen.unlockOrientation()`** method removes all the\nprevious screen locks set by the page/app. The [ScreenOrientation.unlock]\nmethod should be used instead.\n\n> **Warning:** This feature is deprecated and should be avoided. Use the [ScreenOrientation.unlock] method instead.\n\n> **Note:** This method only works for installed Web apps or for Web pages\n> in [fullscreen mode](/en-US/docs/Web/API/Fullscreen_API).",
      "width": "\n\nThe **`Screen.width`** read-only property returns the width of\nthe screen in CSS pixels."
    }
  },
  "screendetailed": {
    "docs": "\n\nThe **`ScreenDetailed`** interface of the [Window Management API](/en-US/docs/Web/API/Window_Management_API) represents detailed information about one specific screen available to the user's device.\n\n`ScreenDetailed` objects can be accessed via the [ScreenDetails.screens] and [ScreenDetails.currentScreen] properties.\n\n",
    "properties": {
      "availleft": "\n\nThe **`availLeft`** read-only property of the\n[ScreenDetailed] interface is a number representing the x-coordinate (left-hand edge) of the available screen area inside the OS virtual screen arrangement, relative to the [multi-screen origin](/en-US/docs/Web/API/Window_Management_API/Multi-screen_origin).\n\nThis is equal to the [ScreenDetailed.left] property, plus the width of any OS UI element drawn on the left of the screen. Windows cannot be placed in those areas, so `availLeft` is useful for giving you the left boundary of the actual area available to open or place windows.\n\n> **Note:** A non-standard implementation of the `availLeft` property is available on the `Screen` interface in all browsers. See the [Non-standard example](#non-standard_example) below for usage details, and see the [`Screen`](/en-US/docs/Web/API/Screen#browser_compatibility) reference page for browser support information relating to the non-standard implementation.",
      "availtop": "\n\nThe **`availTop`** read-only property of the\n[ScreenDetailed] interface is a number representing the y-coordinate (top edge) of the available screen area inside the OS virtual screen arrangement, relative to the [multi-screen origin](/en-US/docs/Web/API/Window_Management_API/Multi-screen_origin).\n\nThis is equal to the [ScreenDetailed.top] property, plus the height of any OS UI element drawn at the top of the screen. Windows cannot be placed in those areas, so `availTop` is useful for giving you the top boundary of the actual area available to open or place windows.\n\n> **Note:** A non-standard implementation of the `availTop` property is available on the `Screen` interface in all browsers. See the [Non-standard example](#non-standard_example) below for usage details, and see the [`Screen`](/en-US/docs/Web/API/Screen#browser_compatibility) reference page for browser support information relating to the non-standard implementation.",
      "devicepixelratio": "\n\nThe **`devicePixelRatio`** read-only property of the\n[ScreenDetailed] interface is a number representing the screen's device pixel ratio.\n\nThis is the same as the value returned by [Window.devicePixelRatio], except that `Window.devicePixelRatio`:\n\n- always returns the device pixel ratio for the [ScreenDetails.currentScreen].\n- also includes scaling of the window itself, i.e. page zoom (at least on some browser implementations).",
      "isinternal": "\n\nThe **`isInternal`** read-only property of the\n[ScreenDetailed] interface is a boolean indicating whether the screen is internal to the device or external. External devices are generally manufactured separately from the device they are attached to and can be connected and disconnected as needed, whereas internal screens are part of the device and not intended to be disconnected.",
      "isprimary": "\n\nThe **`isPrimary`** read-only property of the\n[ScreenDetailed] interface is a boolean indicating whether the screen is set as the operating system (OS) primary screen or not.\n\nThe OS hosting the browser will have one primary screen, and one or more secondary screens. The primary screen can usually be specified by the user via OS settings, and generally contains OS UI features such as the taskbar/icon dock. The primary screen may change for a number of reasons, such as a screen being unplugged.",
      "label": "\n\nThe **`label`** read-only property of the\n[ScreenDetailed] interface is a string providing a descriptive label for the screen, for example \"Built-in Retina Display\".\n\nThis is useful for constructing a list of options to display to the user if you want them to choose a screen to display content on.",
      "left": "\n\nThe **`left`** read-only property of the\n[ScreenDetailed] interface is a number representing the x-coordinate (left-hand edge) of the total screen area inside the OS virtual screen arrangement, relative to the [multi-screen origin](/en-US/docs/Web/API/Window_Management_API/Multi-screen_origin).\n\nThis is equal to the true left-hand edge, ignoring any OS UI element drawn at the left of the screen. Windows cannot be placed in those areas; to get the left-hand coordinate of the screen area that windows can be placed in, use [ScreenDetailed.availLeft].\n\n> **Note:** In Firefox, a non-standard implementation of the `left` property is available on the `Screen` interface. See the [Non-standard example](#non-standard_example) below for usage details, and see the [`Screen`](/en-US/docs/Web/API/Screen#browser_compatibility) reference page for browser support information relating to the non-standard implementation.",
      "top": "\n\nThe **`top`** read-only property of the\n[ScreenDetailed] interface is a number representing the y-coordinate (top edge) of the total screen area inside the OS virtual screen arrangement, relative to the [multi-screen origin](/en-US/docs/Web/API/Window_Management_API/Multi-screen_origin).\n\nThis is equal to the true top edge, ignoring any OS UI element drawn at the top of the screen. Windows cannot be placed in those areas; to get the top coordinate of the screen area that windows can be placed in, use [ScreenDetailed.availTop].\n\n> **Note:** In Firefox, a non-standard implementation of the `top` property is available on the `Screen` interface. See the [Non-standard example](#non-standard_example) below for usage details, and see the [`Screen`](/en-US/docs/Web/API/Screen#browser_compatibility) reference page for browser support information relating to the non-standard implementation."
    }
  },
  "screendetails": {
    "docs": "\n\nThe **`ScreenDetails`** interface of the [Window Management API](/en-US/docs/Web/API/Window_Management_API) represents the details of all the screens available to the user's device.\n\nThis information is accessed via the [Window.getScreenDetails] method.\n\n> **Note:** `ScreenDetails` is a live object, meaning that it updates as the available screens change. You can therefore keep querying the same object to get updated values, rather than repeatedly calling `getScreenDetails()`.\n\n",
    "properties": {
      "currentscreen": "\n\nThe **`currentScreen`** read-only property of the\n[ScreenDetails] interface contains a single [ScreenDetailed] object representing detailed information about the screen that the current browser window is displayed in.",
      "currentscreenchange_event": "\n\nThe **`currentscreenchange`** event of the [ScreenDetails] interface is fired when the [ScreenDetails.currentScreen] changes in one of the following ways:\n\n- The current screen changes to a different screen, i.e., the current browser window is moved to a different screen.\n- One or more of the following properties change on the current screen:\n  - [Screen.width]\n  - [Screen.height]\n  - [Screen.availWidth]\n  - [Screen.availHeight]\n  - [Screen.colorDepth]\n  - [Screen.orientation]\n- One or more of the following values change:\n  - The screen's **position** ((x,y) coordinates of the top-left corner) inside the OS virtual screen arrangement, relative to the [multi-screen origin](/en-US/docs/Web/API/Window_Management_API/Multi-screen_origin)\n  - The screen's **available position** ((x,y) coordinates of the top-left corner) inside the OS virtual screen arrangement, relative to the [multi-screen origin](/en-US/docs/Web/API/Window_Management_API/Multi-screen_origin). This is equal to the screen position, plus the width/height of any OS UI elements drawn on the top-left of the screen — windows cannot be placed in those areas\n  - [ScreenDetailed.devicePixelRatio]\n  - [ScreenDetailed.label]\n  - The screen's designation as primary or secondary (see [ScreenDetailed.isPrimary])\n  - The screen's designation as internal or external (see [ScreenDetailed.isInternal])",
      "screens": "\n\nThe **`screens`** read-only property of the\n[ScreenDetails] interface contains an array of [ScreenDetailed] objects, each one representing detailed information about one specific screen available to the user's device.",
      "screenschange_event": "\n\nThe **`screenschange`** event of the [ScreenDetails] interface is fired when the set of screens available to the system has changed: that is, a new screen has become available or an existing screen has become unavailable. This will be reflected in a change in the [ScreenDetails.screens] array."
    }
  },
  "screenorientation": {
    "docs": "\n\nThe **`ScreenOrientation`** interface of the [Screen Orientation API](/en-US/docs/Web/API/Screen_Orientation_API) provides information about the current orientation of the document.\n\nA **`ScreenOrientation`** instance object can be retrieved using the [screen.orientation] property.\n\n",
    "properties": {
      "angle": "\n\nThe **`angle`** read-only property of the\n[ScreenOrientation] interface returns the document's current orientation\nangle.",
      "change_event": "\n\nThe **`change`** event of the [ScreenOrientation] interface fires when the orientation of the screen has changed, for example when a user rotates their mobile phone.",
      "lock": "\n\nThe **`lock()`** property of the [ScreenOrientation] interface locks the orientation of the containing document to the specified orientation.\n\nTypically orientation locking is only enabled on mobile devices, and when the browser context is full screen.\nIf locking is supported, then it must work for all the parameter values listed below.",
      "type": "\n\nThe **`type`** read-only property of the\n[ScreenOrientation] interface returns the document's current orientation\ntype, one of `portrait-primary`, `portrait-secondary`, `landscape-primary`, or\n`landscape-secondary`.",
      "unlock": "\n\nThe **`unlock()`** property of the\n[ScreenOrientation] interface unlocks the orientation of the containing\ndocument from its default orientation."
    }
  },
  "scriptprocessornode": {
    "docs": "\n\nThe `ScriptProcessorNode` interface allows the generation, processing, or analyzing of audio using JavaScript.\n\n> **Note:** This feature was replaced by [AudioWorklets](/en-US/docs/Web/API/AudioWorklet) and the [AudioWorkletNode] interface.\n\nThe `ScriptProcessorNode` interface is an [AudioNode] audio-processing module that is linked to two buffers, one containing the input audio data, one containing the processed output audio data. An event, implementing the [AudioProcessingEvent] interface, is sent to the object each time the input buffer contains new data, and the event handler terminates when it has filled the output buffer with data.\n\n![The ScriptProcessorNode stores the input in a buffer, send the audioprocess event. The EventHandler takes the input buffer and fill the output buffer which is sent to the output by the ScriptProcessorNode.](webaudioscriptprocessingnode.png)\n\nThe size of the input and output buffer are defined at the creation time, when the [BaseAudioContext.createScriptProcessor] method is called (both are defined by [BaseAudioContext.createScriptProcessor]'s `bufferSize` parameter). The buffer size must be a power of 2 between `256` and `16384`, that is `256`, `512`, `1024`, `2048`, `4096`, `8192` or `16384`. Small numbers lower the _latency_, but large number may be necessary to avoid audio breakup and glitches.\n\nIf the buffer size is not defined, which is recommended, the browser will pick one that its heuristic deems appropriate.\n\n<table class=\"properties\">\n  <tbody>\n    <tr>\n      <th scope=\"row\">Number of inputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Number of outputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count mode</th>\n      <td><code>\"max\"</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count</th>\n      <td><code>2</code> (not used in the default count mode)</td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel interpretation</th>\n      <td><code>\"speakers\"</code></td>\n    </tr>\n  </tbody>\n</table>",
    "properties": {
      "audioprocess_event": "\n\nThe `audioprocess` event of the [ScriptProcessorNode] interface is fired when an input buffer of a script processor is ready to be processed.\n\n> **Note:** This feature was replaced by [AudioWorklets](/en-US/docs/Web/API/AudioWorklet) and the [AudioWorkletNode] interface.\n\nThis event is not cancelable and does not bubble.",
      "buffersize": "\n\nThe `bufferSize` property of the [ScriptProcessorNode] interface returns an integer representing both the input and output buffer size, in sample-frames. Its value can be a power of 2 value in the range `256` – `16384`.\n\n> **Note:** This feature was replaced by [AudioWorklets](/en-US/docs/Web/API/AudioWorklet) and the [AudioWorkletNode] interface."
    }
  },
  "scrolltimeline": {
    "docs": "\n\nThe **`ScrollTimeline`** interface of the [Web Animations API] represents a scroll progress timeline (see [CSS scroll-driven animations](/en-US/docs/Web/CSS/CSS_scroll-driven_animations) for more details).\n\nPass a `ScrollTimeline` instance to the [Animation.Animation] constructor or the [Element.animate] method to specify it as the timeline that will control the progress of the animation.\n\n",
    "properties": {
      "axis": "\n\nThe **`axis`** read-only property of the\n[ScrollTimeline] interface returns an enumerated value representing the scroll axis that is driving the progress of the timeline.",
      "source": "\n\nThe **`source`** read-only property of the\n[ScrollTimeline] interface returns a reference to the scrollable element (_scroller_) whose scroll position is driving the progress of the timeline and therefore the animation."
    }
  },
  "securepaymentconfirmationrequest": {
    "docs": "\n\nThe **`SecurePaymentConfirmationRequest`** dictionary describes input to the [Payment Request API](/en-US/docs/Web/API/Payment_Request_API) when used to authenticate a user during an e-commerce transaction [using SPC with Payment Request API](/en-US/docs/Web/API/Payment_Request_API/Using_secure_payment_confirmation).\n\nAn instance of this dictionary must be passed into the [PaymentRequest.PaymentRequest] constructor as the value of the [`data`](/en-US/docs/Web/API/PaymentRequest/PaymentRequest#data) field corresponding to a [`supportedMethods`](/en-US/docs/Web/API/PaymentRequest/PaymentRequest#supportedmethods) value of `\"secure-payment-confirmation\"`."
  },
  "securitypolicyviolationevent": {
    "docs": "\n\nThe **`SecurityPolicyViolationEvent`** interface inherits from [Event], and represents the event object of an event sent on a document or worker when its content security policy is violated.\n\n",
    "properties": {
      "blockeduri": "\n\nThe **`blockedURI`** read-only property of the\n[SecurityPolicyViolationEvent] interface is a string\nrepresenting the URI of the resource that was blocked because it violates a policy.",
      "columnnumber": "\n\nThe **`columnNumber`** read-only property of the\n[SecurityPolicyViolationEvent] interface is the column number in the\ndocument or worker at which the violation occurred.",
      "disposition": "\n\nThe **`disposition`** read-only property of the\n[SecurityPolicyViolationEvent] interface indicates how the violated policy\nis configured to be treated by the user agent.",
      "documenturi": "\n\nThe **`documentURI`** read-only property of the\n[SecurityPolicyViolationEvent] interface is a string\nrepresenting the URI of the document or worker in which the violation was found.",
      "effectivedirective": "\n\nThe **`effectiveDirective`** read-only property of the\n[SecurityPolicyViolationEvent] interface is a string\nrepresenting the directive whose enforcement uncovered the violation.",
      "linenumber": "\n\nThe **`lineNumber`** read-only property of the\n[SecurityPolicyViolationEvent] interface is the line number in the document\nor worker at which the violation occurred.",
      "originalpolicy": "\n\nThe **`originalPolicy`** read-only property of the\n[SecurityPolicyViolationEvent] interface is a string\ncontaining the policy whose enforcement uncovered the violation.",
      "referrer": "\n\nThe **`referrer`** read-only property of the\n[SecurityPolicyViolationEvent] interface is a string\nrepresenting the referrer of the resources whose policy was violated. This will be a URL\nor `null`.",
      "sample": "\n\nThe **`sample`** read-only property of the\n[SecurityPolicyViolationEvent] interface is a string\nrepresenting a sample of the resource that caused the violation.",
      "sourcefile": "\n\nThe **`sourceFile`** read-only property of the\n[SecurityPolicyViolationEvent] interface is a string\nrepresenting the URI of the document or worker in which the violation was found.",
      "statuscode": "\n\nThe **`statusCode`** read-only property of the\n[SecurityPolicyViolationEvent] interface is a number representing the HTTP\nstatus code of the document or worker in which the violation occurred.",
      "violateddirective": "\n\nThe **`violatedDirective`** read-only property of the\n[SecurityPolicyViolationEvent] interface is a string\nrepresenting the directive whose enforcement uncovered the violation."
    }
  },
  "selection": {
    "docs": "\n\nA **`Selection`** object represents the range of text selected by the user or the current position of the caret. To obtain a `Selection` object for examination or manipulation, call [window.getSelection].\n\nA user may make a selection from left to right (in document order) or right to left (reverse of document order). The **_anchor_** is where the user began the selection and the **_focus_** is where the user ends the selection. If you make a selection with a desktop mouse, the anchor is placed where you pressed the mouse button, and the focus is placed where you released the mouse button.\n\n> **Note:** _Anchor_ and _focus_ should not be confused with the _start_ and _end_ positions of a selection. The anchor can be placed before the focus or vice versa, depending on the direction you made your selection.",
    "properties": {
      "addrange": "\n\nThe **`Selection.addRange()`** method adds a\n[Range] to a [Selection].",
      "anchornode": "\n\nThe **`Selection.anchorNode`** read-only property returns the\n[Node] in which the selection begins.\n\nA user may make a selection from left to right (in document order) or right to left\n(reverse of document order). The anchor is where the user began the selection. This can\nbe visualized by holding the Shift key and pressing the arrow keys on your keyboard. The\nselection's anchor does not move, but the selection's focus, the other end of the\nselection, does move.",
      "anchoroffset": "\n\nThe **`Selection.anchorOffset`** read-only property returns the\nnumber of characters that the selection's anchor is offset within the\n[Selection.anchorNode].\n\nThis number is zero-based. If the selection begins with the first character in the\n[Selection.anchorNode], `0` is returned.",
      "collapse": "\n\nThe **`Selection.collapse()`** method collapses the current selection to a single point. The document is not modified. If the content is focused and editable, the caret will blink there.\n\n> **Note:** This method is an alias for the [Selection.setPosition] method.",
      "collapsetoend": "\n\nThe **`Selection.collapseToEnd()`** method collapses the\nselection to the end of the last range in the selection. If the content of the selection\nis focused and editable, the caret will blink there.",
      "collapsetostart": "\n\nThe **`Selection.collapseToStart()`** method collapses the\nselection to the start of the first range in the selection. If the content of the\nselection is focused and editable, the caret will blink there.",
      "containsnode": "\n\nThe **`Selection.containsNode()`** method indicates whether a\nspecified node is part of the selection.",
      "deletefromdocument": "\n\nThe **`deleteFromDocument()`** method of the\n[Selection] interface deletes the selected text from the document's DOM.",
      "empty": "\n\nThe **`Selection.empty()`** method removes all ranges from the selection, leaving the [Selection.anchorNode] and [Selection.focusNode] properties equal to `null` and nothing selected. When this method is called, a [Document/selectionchange_event] event is fired at the document.\n\n> **Note:** This method is an alias for the [Selection.removeAllRanges] method.",
      "extend": "\n\nThe **`Selection.extend()`** method moves the focus of the\nselection to a specified point. The anchor of the selection does not move. The selection\nwill be from the anchor to the new focus, regardless of direction.",
      "focusnode": "\n\nThe **`Selection.focusNode`** read-only property returns the\n[Node] in which the selection ends.\n\nA user may make a selection from left to right (in document order) or right to left\n(reverse of document order). The focus is where the user ended the selection. This can\nbe visualized by holding the <kbd>Shift</kbd> key and pressing the arrow keys on your\nkeyboard to modify the current selection. The selection's focus moves, but the\nselection's anchor, the other end of the selection, does not move.",
      "focusoffset": "\n\nThe **`Selection.focusOffset`** read-only property returns the\nnumber of characters that the selection's focus is offset within the\n[Selection.focusNode].\n\nThis number is zero-based. If the selection ends with the first character in the\n[Selection.focusNode], `0` is returned.",
      "getrangeat": "\n\nThe **`Selection.getRangeAt()`** method returns a range object\nrepresenting one of the ranges currently selected.",
      "iscollapsed": "\n\nThe **`Selection.isCollapsed`** read-only property returns a\nboolean value which indicates whether or not there is currently any text\nselected. No text is selected when the selection's start and end points are at the same\nposition in the content.\n\nKeep in mind that a collapsed selection may still have one (or more, in Gecko)\n[Range]s, so [Selection.rangeCount] may not be zero. In that\nscenario, calling a [Selection] object's [Selection.getRangeAt] method may return a `Range` object which is collapsed.",
      "modify": "\n\nThe **`Selection.modify()`** method applies a change to the\ncurrent selection or cursor position, using simple textual commands.",
      "rangecount": "\n\nThe **`Selection.rangeCount`** read-only property returns the\nnumber of ranges in the selection.\n\nBefore the user has clicked a freshly loaded page, the `rangeCount` is\n`0`. After the user clicks on the page, `rangeCount` is\n`1`, even if no selection is visible.\n\nA user can normally only select one range at a time, so the `rangeCount`\nwill usually be `1`. Scripting can be used to make the selection contain more\nthan one range.\n\nGecko browsers allow multiple selections across table cells. Firefox allows to select\nmultiple ranges in the document by using Ctrl+click (unless the click occurs within an\nelement that has the `display: table-cell` CSS property assigned).",
      "removeallranges": "\n\nThe **`Selection.removeAllRanges()`** method removes all ranges from the selection, leaving the [Selection.anchorNode] and [Selection.focusNode] properties equal to `null` and nothing selected. When this method is called, a [Document/selectionchange_event] event is fired at the document.\n\n> **Note:** This method is an alias for the [Selection.empty] method.",
      "removerange": "\n\nThe **`Selection.removeRange()`** method removes a range from a\nselection.",
      "selectallchildren": "\n\nThe **`Selection.selectAllChildren()`** method adds all the\nchildren of the specified node to the selection. Previous selection is lost.",
      "setbaseandextent": "\n\nThe **`setBaseAndExtent()`** method of the\n[Selection] interface sets the selection to be a range including all or\nparts of two specified DOM nodes, and any content located between them.",
      "setposition": "\n\nThe **`Selection.setPosition()`** method collapses the current selection to a single point. The document is not modified. If the content is focused and editable, the caret will blink there.\n\n> **Note:** This method is an alias for the [Selection.collapse] method.",
      "tostring": "\n\nThe **`Selection.toString()`** method returns a string\ncurrently being represented by the selection object, i.e. the currently selected text.",
      "type": "\n\nThe **`type`** read-only property of the\n[Selection] interface returns a string describing the\ntype of the current selection."
    }
  },
  "sensor": {
    "docs": "\n\nThe **`Sensor`** interface of the [Sensor APIs](/en-US/docs/Web/API/Sensor_APIs) is the base class for all the other sensor interfaces. This interface cannot be used directly. Instead it provides properties, event handlers, and methods accessed by interfaces that inherit from it.\n\nThis feature may be blocked by a [Permissions Policy](/en-US/docs/Web/HTTP/Permissions_Policy) set on your server.\n\nWhen initially created, the `Sensor` object is _idle_, meaning it does not take measures. Once the [Sensor.start] method is called, it prepares itself to read data and, once ready, the [Sensor/activate_event] event is sent and the sensor becomes _activated_. It then sends a [Sensor/reading_event] event each time new data is available.\n\nIn case of an error, the [Sensor/error_event] event is sent, reading stops, and the `Sensor` object becomes _idle_ again. The [Sensor.start] method needs to be called again before it can read further data.",
    "properties": {
      "activate_event": "\n\nThe **`activate`** event is fired when a sensor becomes activated. It means that it will start obtaining readings.\n\nThe [Sensor] interface is a base class, `onactivate` and the `activate` event may only be used\non one of the [derived classes](/en-US/docs/Web/API/Sensor#interfaces_based_on_sensor).",
      "activated": "\n\nThe **`activated`** read-only property\nof the [Sensor] interface returns a boolean value indicating\nwhether the sensor is active.\n\nBecause [Sensor] is a base class, `activated` may only be read\nfrom one of its derived classes.",
      "error_event": "\n\nThe **`error`** event is fired when an exception occurs on a sensor.\n\nThe [Sensor] interface is a base class, `onerror` and the `error` event may only be used\non one of the [derived classes](/en-US/docs/Web/API/Sensor#interfaces_based_on_sensor).\n\nAfter this event has occurred, the [Sensor] object becomes idle. If the sensor was reading values, it will stop until it restarts.",
      "hasreading": "\n\nThe **`hasReading`** read-only\nproperty of the [Sensor] interface returns a boolean value\nindicating whether the sensor has a reading.\n\nBecause [Sensor] is a base class, `hasReading` may only be read\nfrom one of its derived classes.",
      "reading_event": "\n\nThe **`reading`** event is fired when a new reading is available on a sensor.\n\nThe [Sensor] interface is a base class, `onreading` and the `reading` event may only be used\non one of the [derived classes](/en-US/docs/Web/API/Sensor#interfaces_based_on_sensor).",
      "start": "\n\nThe **`start`** method activates one\nof the sensors based on `Sensor`.",
      "stop": "\n\nThe **`stop`** method of the\n[Sensor] interface deactivates the current sensor.",
      "timestamp": "\n\nThe **`timestamp`** read-only property\nof the [Sensor] interface returns the timestamp of the latest sensor\nreading.\n\nBecause [Sensor] is a base class, `timestamp` may only be read\nfrom one of its derived classes."
    }
  },
  "sensorerrorevent": {
    "docs": "\n\nThe **`SensorErrorEvent`** interface of the [Sensor APIs](/en-US/docs/Web/API/Sensor_APIs) provides information about errors thrown by a [Sensor] or derived interface.\n\n",
    "properties": {
      "error": "\n\nThe **`error`** read-only property of\nthe [SensorErrorEvent] interface returns the [DOMException]\nobject passed in the event's constructor."
    }
  },
  "serial": {
    "docs": "\n\nThe `Serial` interface of the [Web_Serial_API] provides attributes and methods for finding and connecting to serial ports from a web page.\n\n",
    "properties": {
      "getports": "\n\nThe **`getPorts()`** method of the [Serial] interface returns a `Promise` that resolves with an array of [SerialPort] objects representing serial ports connected to the host which the origin has permission to access.",
      "requestport": "\n\nThe **`Serial.requestPort()`** method of the [Serial] interface returns a `Promise` that resolves with an instance of [SerialPort] representing the device chosen by the user or rejects if no device was selected."
    }
  },
  "serialport": {
    "docs": "\n\nThe `SerialPort` interface of the [Web_Serial_API] provides access to a serial port on the host device.\n\n",
    "properties": {
      "close": "\n\nThe **`SerialPort.close()`** method of the [SerialPort] interface returns a `Promise` that resolves when the port closes.",
      "connect_event": "\n\nThe **`connect`** event of the [SerialPort] interface is fired when a port has connected to the device. This event is only fired for ports associated with removable devices such as those connected via USB.\n\nThis event bubbles to the instance of [Serial] that returned this interface.",
      "disconnect_event": "\n\nThe **`disconnect`** event of the [SerialPort] interface is fired when the port has disconnected from the device. This event is only fired for ports associated with removable devices such as those connected via USB.\n\nThis event bubbles to the instance of [Serial] that returned this interface.",
      "forget": "\n\nThe **`SerialPort.forget()`** method of the [SerialPort] interface returns a `Promise` that resolves when the serial port is closed and is forgotten.",
      "getinfo": "\n\nThe **`getInfo()`** method of the [SerialPort] interface returns an object whose properties are the vendor ID and product ID of the device.",
      "getsignals": "\n\nThe **`SerialPort.getSignals()`** method of the [SerialPort] interface returns a `Promise` that resolves with an object containing the current state of the port's control signals.",
      "open": "\n\nThe **`open()`** method of the [SerialPort] interface returns a `Promise` that resolves when the port is opened. By default the port is opened with 8 data bits, 1 stop bit and no parity checking. The `baudRate` parameter is required.",
      "readable": "\n\nThe **`readable`** read-only property of the [SerialPort] interface returns a [ReadableStream] for receiving data from the device connected to the port. Chunks read from this stream are instances of `Uint8Array`. This property is non-null as long as the port is open and has not encountered a fatal error.",
      "setsignals": "\n\nThe **`setSignals()`** method of the [SerialPort] interface sets control signals on the port and returns a `Promise` that resolves when they are set.",
      "writable": "\n\nThe **`writable`** read-only property of the [SerialPort] interface returns a [WritableStream] for sending data to the device connected to the port. Chunks written to this stream must be instances of `ArrayBuffer`, `TypedArray`, or `DataView`. This property is non-null as long as the port is open and has not encountered a fatal error."
    }
  },
  "serviceworker": {
    "docs": "\n\nThe **`ServiceWorker`** interface of the [Service Worker API](/en-US/docs/Web/API/Service_Worker_API) provides a reference to a service worker. Multiple  (e.g. pages, workers, etc.) can be associated with the same service worker, each through a unique `ServiceWorker` object.\n\nA `ServiceWorker` object is available via a number of properties:\n\n- [ServiceWorkerRegistration.active]\n- [ServiceWorkerGlobalScope.serviceWorker]\n- [ServiceWorkerContainer.controller] — when the service worker is in `activating` or `activated` state\n- [ServiceWorkerRegistration.installing] — when the service worker is in `installing` state\n- [ServiceWorkerRegistration.waiting] — when the service worker is in `installed` state\n\nThe `ServiceWorker` interface is dispatched a set of lifecycle events — `install` and `activate` — and functional events including `fetch`. A `ServiceWorker` object has an associated [ServiceWorker.state], related to its lifecycle.\n\nService workers allow static import of [ECMAScript modules](/en-US/docs/Web/JavaScript/Guide/Modules), if supported, using [`import`](/en-US/docs/Web/JavaScript/Reference/Statements/import).\nDynamic import is disallowed by the specification — calling [`import()`](/en-US/docs/Web/JavaScript/Reference/Operators/import) will throw.\n\n",
    "properties": {
      "error_event": "\n\nThe `error` event fires whenever an error occurs in the service worker.",
      "postmessage": "\n\nThe **`postMessage()`** method of the [ServiceWorker] interface sends a message to the worker. This accepts a single parameter, which is the data to send to the worker. The data may be any JavaScript object which can be handled by the [structured clone algorithm](/en-US/docs/Web/API/Web_Workers_API/Structured_clone_algorithm).\n\nThe service worker can send back information to its clients by using the [Client.postMessage] method. The message will not be sent back to this `ServiceWorker` object but to the associated [ServiceWorkerContainer] available via [navigator.serviceWorker].",
      "scripturl": "\n\nReturns the `ServiceWorker` serialized script URL defined as part of [`ServiceWorkerRegistration`](/en-US/docs/Web/API/ServiceWorkerRegistration).\nMust be on the same origin as the document that registers the\n`ServiceWorker`.",
      "state": "\n\nThe **`state`** read-only property of the\n[ServiceWorker] interface returns a string representing the current state\nof the service worker. It can be one of the following values: `parsed`, `installing`,\n`installed`, `activating`, `activated`, or\n`redundant`.",
      "statechange_event": "\n\nThe `statechange` event fires anytime the [ServiceWorker.state] changes."
    }
  },
  "serviceworkercontainer": {
    "docs": "\n\nThe **`ServiceWorkerContainer`** interface of the [Service Worker API](/en-US/docs/Web/API/Service_Worker_API) provides an object representing the service worker as an overall unit in the network ecosystem, including facilities to register, unregister and update service workers, and access the state of service workers and their registrations.\n\nMost importantly, it exposes the [ServiceWorkerContainer.register] method used to register service workers, and the [ServiceWorkerContainer.controller] property used to determine whether or not the current page is actively controlled.\n\n",
    "properties": {
      "controller": "\n\nThe **`controller`** read-only\nproperty of the [ServiceWorkerContainer] interface returns a\n[ServiceWorker] object if its state is `activating` or\n`activated` (the same object returned by\n[ServiceWorkerRegistration.active]). This property returns\n`null` if the request is a force refresh (_Shift_ + refresh) or if\nthere is no active worker.",
      "controllerchange_event": "\n\nThe **`controllerchange`** event of the [ServiceWorkerContainer] interface fires when the document's associated [ServiceWorkerRegistration] acquires a new [ServiceWorkerRegistration.active] worker.",
      "error_event": "\n\nThe `error` event fires when an error occurs in the service worker.",
      "getregistration": "\n\nThe **`getRegistration()`** method of the\n[ServiceWorkerContainer] interface gets a\n[ServiceWorkerRegistration] object whose scope URL matches the provided\nclient URL. The method returns a `Promise` that resolves to\na [ServiceWorkerRegistration] or `undefined`.",
      "getregistrations": "\n\nThe **`getRegistrations()`** method of the\n[ServiceWorkerContainer] interface gets all\n[ServiceWorkerRegistration]s associated with a\n`ServiceWorkerContainer`, in an array. The method returns a\n`Promise` that resolves to an array of\n[ServiceWorkerRegistration].",
      "message_event": "\n\nThe **`message`** event is used in a page controlled by a service worker to receive messages from the service worker.\n\nThis event is not cancelable and does not bubble.",
      "messageerror_event": "\n\nThe **`messageerror`** event is fired to the [ServiceWorkerContainer] when an incoming message sent to the associated worker can't be deserialized.\n\nThis event is not cancelable and does not bubble.",
      "ready": "\n\nThe **`ready`** read-only property of\nthe [ServiceWorkerContainer] interface provides a way of delaying code\nexecution until a service worker is active. It returns a `Promise` that\nwill never reject, and which waits indefinitely until\nthe [ServiceWorkerRegistration] associated with the current page has\nan [ServiceWorkerRegistration.active] worker. Once that\ncondition is met, it resolves with\nthe [ServiceWorkerRegistration].",
      "register": "\n\nThe **`register()`** method of the\n[ServiceWorkerContainer] interface creates or updates a\n[ServiceWorkerRegistration] for the given `scriptURL`.\n\nIf successful, a service worker registration ties the provided script URL to a\n_scope_, which is subsequently used for navigation matching. You can call this\nmethod unconditionally from the controlled page. I.e., you don't need to first check\nwhether there's an active registration.\n\nThere is frequent confusion surrounding the meaning and use of _scope_. Since a\nservice worker can't have a scope broader than its own location, only use the\n`scope` option when you need a scope that is narrower than the default.",
      "startmessages": "\n\nThe **`startMessages()`** method of\nthe [ServiceWorkerContainer] interface explicitly starts the flow of\nmessages being dispatched from a service worker to pages under its control (e.g. sent\nvia [Client.postMessage]). This can be used to react to sent messages\nearlier, even before that page's content has finished loading."
    }
  },
  "serviceworkerglobalscope": {
    "docs": "\n\nThe **`ServiceWorkerGlobalScope`** interface of the [Service Worker API](/en-US/docs/Web/API/Service_Worker_API) represents the global execution context of a service worker.\n\nDevelopers should keep in mind that the ServiceWorker state is not persisted across the termination/restart cycle, so each event handler should assume it's being invoked with a bare, default global state.\n\nOnce successfully registered, a service worker can and will be terminated when idle to conserve memory and processor power. An active service worker is automatically restarted to respond to events, such as [ServiceWorkerGlobalScope.fetch_event] or [ServiceWorkerGlobalScope.message_event].\n\nAdditionally, synchronous requests are not allowed from within a service worker — only asynchronous requests, like those initiated via the [fetch] method, can be used.\n\nThis interface inherits from the [WorkerGlobalScope] interface, and its parent [EventTarget].\n\n",
    "properties": {
      "activate_event": "\n\nThe **`activate`** event of the [ServiceWorkerGlobalScope] interface is fired when a [ServiceWorkerRegistration] acquires a new [ServiceWorkerRegistration.active] worker.\n\nThis event is not cancelable and does not bubble.",
      "backgroundfetchabort_event": "\n\nThe **`backgroundfetchabort`** event of the [ServiceWorkerGlobalScope] interface is fired when the user or the app itself cancels a [background fetch](/en-US/docs/Web/API/Background_Fetch_API) operation.\n\nThis event is not cancelable and does not bubble.",
      "backgroundfetchclick_event": "\n\nThe **`backgroundfetchclick`** event of the [ServiceWorkerGlobalScope] interface is fired when the user clicks on the UI that the browser provides to show the user the progress of the [background fetch](/en-US/docs/Web/API/Background_Fetch_API) operation.\n\nThis event is not cancelable and does not bubble.",
      "backgroundfetchfail_event": "\n\nThe **`backgroundfetchfail`** event of the [ServiceWorkerGlobalScope] interface is fired when a [background fetch](/en-US/docs/Web/API/Background_Fetch_API) operation has failed: that is, when at least one network request in the fetch has failed to complete successfully.\n\nThis event is not cancelable and does not bubble.",
      "backgroundfetchsuccess_event": "\n\nThe **`backgroundfetchsuccess`** event of the [ServiceWorkerGlobalScope] interface is fired when a [background fetch](/en-US/docs/Web/API/Background_Fetch_API) operation has completed successfully: that is, when all network requests in the fetch have completed successfully.\n\nThis event is not cancelable and does not bubble.",
      "canmakepayment_event": "\n\nThe **`canmakepayment`** event of the [ServiceWorkerGlobalScope] interface is fired on a payment app's service worker to check whether it is ready to handle a payment. Specifically, it is fired when the merchant website calls [PaymentRequest.PaymentRequest].",
      "clients": "\n\nThe **`clients`** read-only property of the\n[ServiceWorkerGlobalScope] interface returns the [`Clients`](/en-US/docs/Web/API/Clients)\nobject associated with the service worker.",
      "contentdelete_event": "\n\nThe **`contentdelete`** event of the [ServiceWorkerGlobalScope] interface is fired when an item is removed from the indexed content via the user agent.\n\nThis event is not cancelable and does not bubble.",
      "cookiechange_event": "\n\nThe **`cookiechange`** event of the [ServiceWorkerGlobalScope] interface is fired when a cookie change occurs that matches the service worker's cookie change subscription list.\n\nThis event is not cancelable and does not bubble.",
      "fetch_event": "\n\nThe **`fetch`** event is fired in the service worker's global scope when the main app thread makes a network request. It enables the service worker to intercept network requests and send customized responses (for example, from a local cache).\n\nThis event is not cancelable and does not bubble.",
      "install_event": "\n\nThe **`install`** event of the [ServiceWorkerGlobalScope] interface is fired when a [ServiceWorkerRegistration] acquires a new [ServiceWorkerRegistration.installing] worker.\n\nThis event is not cancelable and does not bubble.",
      "message_event": "\n\nThe **`message`** event of the [ServiceWorkerGlobalScope] interface occurs when incoming messages are received. Controlled pages can use the [ServiceWorker.postMessage] method to send messages to service workers.\nThe service worker can optionally send a response back via the [Client.postMessage], corresponding to the controlled page.\n\nThis event is not cancelable and does not bubble.",
      "messageerror_event": "\n\nThe **`messageerror`** event of the [ServiceWorkerGlobalScope] interface occurs when incoming messages can't be deserialized.\n\nThis event is not cancelable and does not bubble.",
      "notificationclick_event": "\n\nThe **`notificationclick`** event is fired to indicate that a system notification spawned by [ServiceWorkerRegistration.showNotification] has been clicked.\n\nThis event is not cancelable and does not bubble.",
      "notificationclose_event": "\n\nThe **`notificationclose`** event fires when a user closes a displayed notification spawned by [ServiceWorkerRegistration.showNotification].\n\nNotifications created on the main thread or in workers which aren't service workers\nusing the [Notification.Notification] constructor will\ninstead receive a [Notification/close_event] event on the `Notification` object\nitself.\n\n> **Note:** Trying to create a notification inside the\n> [ServiceWorkerGlobalScope] using the\n> [Notification.Notification] constructor will throw an\n> error.\n\nThis event is not cancelable and does not bubble.",
      "paymentrequest_event": "\n\nThe **`paymentrequest`** event of the [ServiceWorkerGlobalScope] interface is fired on a payment app when a payment flow has been initiated on the merchant website via the [PaymentRequest.show] method.",
      "periodicsync_event": "\n\nThe **`periodicsync`** event of the [ServiceWorkerGlobalScope] interface is fired at timed intervals, specified when registering a [PeriodicSyncManager].\n\nThis event is not cancelable and does not bubble.",
      "push_event": "\n\nThe **`push`** event is sent to a service worker's global scope (represented by the [ServiceWorkerGlobalScope] interface) when the service worker has received a push message.\n\nThis event is not cancelable and does not bubble.",
      "pushsubscriptionchange_event": "\n\nThe **`pushsubscriptionchange`** event is sent to the [global scope](/en-US/docs/Web/API/ServiceWorkerGlobalScope) of a [ServiceWorker] to indicate a change in push subscription that was triggered outside the application's control.\n\nThis may occur if the subscription was refreshed by the browser, but it may also happen if the subscription has been revoked or lost.\n\nThis event is not cancelable and does not bubble.",
      "registration": "\n\nThe **`registration`** read-only property of the [ServiceWorkerGlobalScope] interface returns a reference to the [ServiceWorkerRegistration] object, which represents the service worker's registration.",
      "serviceworker": "\n\nThe **`serviceWorker`** read-only property of the [ServiceWorkerGlobalScope] interface returns a reference to the [ServiceWorker] object, which represents the service worker.",
      "skipwaiting": "\n\nThe **`ServiceWorkerGlobalScope.skipWaiting()`** method of the [ServiceWorkerGlobalScope] forces the waiting service worker to become the active service worker.\n\nUse this method with [Clients.claim] to ensure that updates to the underlying service worker take effect immediately for both the current client and all other active clients.",
      "sync_event": "`Background Sync`\n\nThe **`sync`** event of the [ServiceWorkerGlobalScope] interface is fired when the page (or worker) that registered the event with the [SyncManager] is running and as soon as network connectivity is available.\n\nThis event is not cancelable and does not bubble."
    }
  },
  "serviceworkerregistration": {
    "docs": "\n\nThe **`ServiceWorkerRegistration`** interface of the [Service Worker API](/en-US/docs/Web/API/Service_Worker_API) represents the service worker registration. You register a service worker to control one or more pages that share the same origin.\n\nThe lifetime of a service worker registration is beyond that of the `ServiceWorkerRegistration` objects that represent them within the lifetime of their corresponding service worker clients. The browser maintains a persistent list of active `ServiceWorkerRegistration` objects.\n\n> **Note:** This feature is available in [Web Workers](/en-US/docs/Web/API/Web_Workers_API).\n\n",
    "properties": {
      "active": "\n\nThe **`active`** property of the\n[ServiceWorkerRegistration] interface returns a service worker whose\n[ServiceWorker.state] is `activating` or `activated`.\nThis property is initially set to `null`.\n\nAn active worker controls a [Client] if the client's URL\nfalls within the scope of the registration (the `scope` option set when\n[ServiceWorkerContainer.register] is first called.)\n\n> **Note:** This feature is available in [Web Workers](/en-US/docs/Web/API/Web_Workers_API).\n\n> **Note:** Once an active worker is `activating`, neither a\n> runtime script error nor a force termination of the active worker prevents the active\n> worker from getting `activated`.",
      "backgroundfetch": "\n\nThe **`backgroundFetch`** property of the\n[ServiceWorkerRegistration] interface returns a reference to a\n[BackgroundFetchManager] object, which can be used to initiate background fetch operations.",
      "getnotifications": "\n\nThe **`getNotifications()`** method of\nthe [ServiceWorkerRegistration] interface returns a list of the\nnotifications in the order that they were created from the current origin via the\ncurrent service worker registration. Origins can have many active but\ndifferently-scoped service worker registrations. Notifications created by one service\nworker on the same origin will not be available to other active service workers on\nthat same origin.",
      "index": "\n\nThe **`index`** read-only property of the\n[ServiceWorkerRegistration] interface returns a reference to the\n[ContentIndex] interface, which allows for indexing of offline content.",
      "installing": "\n\nThe **`installing`** property of the\n[ServiceWorkerRegistration] interface returns a service worker whose\n[ServiceWorker.state] is `installing`. This property is\ninitially set to `null`.\n\n> **Note:** This feature is available in [Web Workers](/en-US/docs/Web/API/Web_Workers_API).",
      "navigationpreload": "\n\nThe **`navigationPreload`** read-only property of the [ServiceWorkerRegistration] interface returns the [NavigationPreloadManager] associated with the current service worker registration.\n\nThe returned object allows resources managed by a service worker to be preemptively downloaded in parallel with service worker boot up.",
      "paymentmanager": "\n\nThe **`paymentManager`** read-only property of the\n[ServiceWorkerRegistration] interface returns a payment app's [PaymentManager] instance, which is used to manage various payment app functionality.",
      "periodicsync": "\n\nThe **`periodicSync`** read-only property of\nthe [ServiceWorkerRegistration] interface returns a reference to the\n[PeriodicSyncManager] interface, which allows for registering of tasks to\nrun at specific intervals.",
      "pushmanager": "\n\nThe **`pushManager`** property of the\n[ServiceWorkerRegistration] interface returns a reference to the\n[PushManager] interface for managing push subscriptions; this includes\nsupport for subscribing, getting an active subscription, and accessing push permission\nstatus.",
      "scope": "\n\nThe **`scope`** read-only property of the\n[ServiceWorkerRegistration] interface returns a unique identifier for a\nservice worker registration. The service worker must be on the same origin as the\ndocument that registers the [ServiceWorker].\n\n> **Note:** This feature is available in [Web Workers](/en-US/docs/Web/API/Web_Workers_API).",
      "shownotification": "\n\nThe **`showNotification()`** method of the\n[ServiceWorkerRegistration] interface creates a notification on an active\nservice worker.\n\n> **Note:** This feature is available in [Web Workers](/en-US/docs/Web/API/Web_Workers_API).",
      "sync": "\n\nThe **`sync`** property of the\n[ServiceWorkerRegistration] interface returns a reference to the\n[SyncManager] interface, which manages background synchronization\nprocesses.",
      "unregister": "\n\nThe **`unregister()`** method of the\n[ServiceWorkerRegistration] interface unregisters the service worker\nregistration and returns a `Promise`. The promise will resolve to\n`false` if no registration was found, otherwise it resolves to\n`true` irrespective of whether unregistration happened or not (it may not\nunregister if someone else just called [ServiceWorkerContainer.register]\nwith the same scope.) The service worker will finish any ongoing operations before it is\nunregistered.\n\n> **Note:** This feature is available in [Web Workers](/en-US/docs/Web/API/Web_Workers_API).",
      "update": "\n\nThe **`update()`** method of the\n[ServiceWorkerRegistration] interface attempts to update the service\nworker. It fetches the worker's script URL, and if the new worker is not byte-by-byte\nidentical to the current worker, it installs the new worker. The fetch of the worker\nbypasses any browser caches if the previous fetch occurred over 24 hours ago.\n\n> **Note:** This feature is available in [Web Workers](/en-US/docs/Web/API/Web_Workers_API).",
      "updatefound_event": "\n\nThe **`updatefound`** event of the\n[ServiceWorkerRegistration] interface is fired any time the [ServiceWorkerRegistration.installing] property acquires a new service worker.",
      "updateviacache": "\n\nThe **`updateViaCache`** read-only property of the\n[ServiceWorkerRegistration] interface updates the cache using\nthe mode specified in the call to [ServiceWorkerContainer.register].\nRequests for `importScripts` still go via the HTTP cache. `updateViaCache` offers\ncontrol over this behavior.",
      "waiting": "\n\nThe **`waiting`** property of the\n[ServiceWorkerRegistration] interface returns a service worker whose\n[ServiceWorker.state] is `installed`. This property is initially\nset to `null`.\n\n> **Note:** This feature is available in [Web Workers](/en-US/docs/Web/API/Web_Workers_API)."
    }
  },
  "shadowroot": {
    "docs": "\n\nThe **`ShadowRoot`** interface of the Shadow DOM API is the root node of a DOM subtree that is rendered separately from a document's main DOM tree.\n\nYou can retrieve a reference to an element's shadow root using its [Element.shadowRoot] property, provided it was created using [Element.attachShadow] with the `mode` option set to `open`.\n\n",
    "properties": {
      "activeelement": "\n\nThe **`activeElement`** read-only property of the\n[ShadowRoot] interface returns the element within the shadow tree that has focus.",
      "adoptedstylesheets": "\n\nThe **`adoptedStyleSheets`** property of the [ShadowRoot] interface sets an array of constructed stylesheets to be used by the shadow DOM subtree.\n\n> **Note:** A constructed stylesheet is a stylesheet created programmatically using the [`CSSStyleSheet()` constructor](/en-US/docs/Web/API/CSSStyleSheet/CSSStyleSheet) (as compared to one created by a user-agent when importing a stylesheet from a script, imported using `style` and , or linked to via `link`).\n\nThe same constructed stylesheet can be adopted by multiple [ShadowRoot] instances, and by the parent document (using the [Document.adoptedStyleSheets] property).\nChanging an adopted stylesheet will affect all the adopting objects.\n\nStylesheets in the `adoptedStyleSheets` property are considered along with the shadow DOM's other stylesheets.\nFor the purpose of determining the final computed CSS of any element, they are considered to have been added _after_ the other stylesheets in the shadow DOM ([`ShadowRoot.styleSheets`](/en-US/docs/Web/API/ShadowRoot/styleSheets)).\n\nOnly stylesheets created using the [`CSSStyleSheet()` constructor](/en-US/docs/Web/API/CSSStyleSheet/CSSStyleSheet), and from within the same parent [Document] as the shadow root, may be adopted.",
      "delegatesfocus": "\n\nThe **`delegatesFocus`** read-only property of the [ShadowRoot] interface returns `true` if the shadow root delegates focus, and `false` otherwise.\n\nIf `true`, when a non-focusable part of the shadow DOM is clicked, or `.focus()` is called on the host element, the first focusable part is given focus, and the shadow host is given any available `:focus` styling.\n\nFocus is of particular importance for keyboard users (including those using screen readers). `delegatesFocus` default behavior is to focus the first focusable element — which may be undesirable if that element is not meant to be part of the tabbing order (for example, an element with `tabindex=\"-1\"`), or if a more 'important' focusable element should receive initial focus (for instance, the first text field rather than the 'close' button which precedes it). In such cases, the `autofocus` attribute can be specified on the element which should receive initial focus. Use the `autofocus` attribute with caution as it can introduce accessibility issues, such as bypassing important content which may go unnoticed due to focus being set to an element later in the DOM order.\n\nThe property value is set using the `delegatesFocus` property of the object passed to [Element.attachShadow]).",
      "fullscreenelement": "\n\nThe **`fullscreenElement`** read-only property of the\n[ShadowRoot] interface returns the element within the shadow tree that is currently displayed in full screen.",
      "getanimations": "\n\nThe **`getAnimations()`** method of the [ShadowRoot] interface\nreturns an array of all [Animation] objects currently in effect whose\ntarget elements are descendants of the shadow tree. This array includes [CSS Animations](/en-US/docs/Web/CSS/CSS_animations), [CSS Transitions](/en-US/docs/Web/CSS/CSS_transitions), and [Web Animations](/en-US/docs/Web/API/Web_Animations_API).",
      "host": "\n\nThe **`host`** read-only property of\nthe [ShadowRoot] returns a reference to the DOM element the\n`ShadowRoot` is attached to.",
      "innerhtml": "\n\nThe **`innerHTML`** property of the [ShadowRoot]\ninterface sets or returns a reference to the DOM tree inside the\n`ShadowRoot`.",
      "mode": "\n\nThe **`mode`** read-only property of the [ShadowRoot]\nspecifies its mode — either `open` or `closed`. This defines\nwhether or not the shadow root's internal features are accessible from JavaScript.\n\nWhen the `mode` of a shadow root is \"`closed`\", the shadow root's\nimplementation internals are inaccessible and unchangeable from JavaScript—in the same\nway the implementation internals of, for example, the `video` element\nare inaccessible and unchangeable from JavaScript.",
      "pictureinpictureelement": "\n\nThe **`pictureInPictureElement`** read-only property of the\n[ShadowRoot] interface returns the [Element] that is currently being\npresented in picture-in-picture mode in this shadow tree, or `null` if\npicture-in-picture mode is not currently in use.",
      "pointerlockelement": "\n\nThe **`pointerLockElement`** read-only property of the [ShadowRoot] interface provides the element set as the target for mouse events while the pointer is locked.\nIt is `null` if lock is pending, pointer is unlocked, or the target is in another tree.",
      "slotassignment": "\n\nThe read-only **`slotAssignment`** property of the [ShadowRoot] interface returns the _slot assignment mode_ for the shadow DOM tree. Nodes are either automatically assigned (`named`) or manually assigned (`manual`). The value of this property defined using the `slotAssignment` option when calling [Element.attachShadow].",
      "stylesheets": "\n\nThe **`styleSheets`** read-only property of the [ShadowRoot] interface\nreturns a [StyleSheetList] of [CSSStyleSheet] objects, for stylesheets explicitly linked into or embedded in a shadow tree."
    }
  },
  "sharedstorage": {
    "docs": "\n\nThe **`SharedStorage`** interface of the [Shared Storage API] represents the shared storage for a particular origin, defining methods to write data to the shared storage.\n\n`SharedStorage` is the base class for:\n\n- [WindowSharedStorage], accessed via [Window.sharedStorage].\n- [WorkletSharedStorage], accessed via [SharedStorageWorkletGlobalScope.sharedStorage].\n\n",
    "properties": {
      "append": "\n\nThe **`append()`** method of the [SharedStorage] interface appends a string to the value of an existing key-value pair in the current origin's shared storage.",
      "clear": "\n\nThe **`clear()`** method of the [SharedStorage] interface clears the current origin's shared storage, removing all data from it.",
      "delete": "\n\nThe **`delete()`** method of the [SharedStorage] interface deletes an existing key-value pair from the current origin's shared storage.",
      "set": "\n\nThe **`set()`** method of the [SharedStorage] interface either stores a new key-value pair in the current origin's shared storage or updates an existing one."
    }
  },
  "sharedstorageoperation": {
    "docs": "\n\nThe **`SharedStorageOperation`** interface of the [Shared Storage API] represents the base class for all output gate operation types.\n\nThe output gate types are detailed below:\n\n<table class=\"no-markdown\">\n  <thead>\n    <tr>\n      <th>Name</th>\n      <th>Description</th>\n      <th>Defined by</th>\n      <th>Invoked by</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>URL Selection</td>\n      <td>Used to select a URL to display to the user based on shared storage data.</td>\n      <td>[SharedStorageSelectURLOperation]</td>\n      <td>[WindowSharedStorage.selectURL]</td>\n    </tr>\n    <tr>\n      <td>Run</td>\n      <td>A generic way to process some shared storage data. Used, for example, by the <a href=\"https://developer.chrome.com/docs/privacy-sandbox/private-aggregation/\">Private Aggregation API</a> to process shared storage data and generate aggregated reports. </td>\n      <td>[SharedStorageRunOperation]</td>\n      <td>[WindowSharedStorage.run]</td>\n    </tr>\n  </tbody>\n</table>"
  },
  "sharedstoragerunoperation": {
    "docs": "\n\nThe **`SharedStorageRunOperation`** interface of the [Shared Storage API] represents a [Run output gate](/en-US/docs/Web/API/Shared_Storage_API#run) operation.\n\n",
    "properties": {
      "run": "\n\nThe **`run()`** method of the\n[SharedStorageRunOperation] interface defines the structure to which the `run()` method defined inside a Run output gate operation should conform."
    }
  },
  "sharedstorageselecturloperation": {
    "docs": "\n\nThe **`SharedStorageSelectURLOperation`** interface of the [Shared Storage API] represents a [URL Selection output gate](/en-US/docs/Web/API/Shared_Storage_API#url_selection) operation.\n\n",
    "properties": {
      "run": "\n\nThe **`run()`** method of the [SharedStorageSelectURLOperation] interface defines the structure to which the `run()` method defined inside a URL Selection output gate operation should conform."
    }
  },
  "sharedstorageworklet": {
    "docs": "\n\nThe **`SharedStorageWorklet`** interface of the [Shared Storage API] represents the shared storage worklet for the current origin.\n\n`SharedStorageWorklet` does not have its own properties or methods. Rather, it inherits the [Worklet.addModule] method from the [Worklet] interface. This method is used for adding a module.\n\nUnlike a regular [Worklet]:\n\n- If the calling site has not included the Shared Storage API in a [privacy sandbox enrollment process](/en-US/docs/Web/Privacy/Privacy_sandbox/Enrollment), calls to `sharedStorageWorklet.addModule()` will be rejected.\n- `SharedStorageWorklet` allows only a single module to be added, for privacy reasons. Even with a successful enrollment, repeated calls to `addModule()` on the same shared storage worklet will be rejected.\n\n`SharedStorageWorklet` is accessed via [WindowSharedStorage.worklet].\n\n"
  },
  "sharedstorageworkletglobalscope": {
    "docs": "\n\nThe **`SharedStorageWorkletGlobalScope`** interface of the [Shared Storage API] represents the global scope of a [SharedStorageWorklet] module.\n\n",
    "properties": {
      "register": "\n\nThe **`register()`** method of the\n[SharedStorageWorkletGlobalScope] interface registers an [SharedStorageOperation] defined inside the current worklet module.",
      "sharedstorage": "\n\nThe **`context`** read-only property of the\n[SharedStorageWorkletGlobalScope] interface contains a [WorkletSharedStorage] object instance, which represents the shared storage for a particular origin as exposed to a worklet context."
    }
  },
  "sharedworker": {
    "docs": "\n\nThe **`SharedWorker`** interface represents a specific kind of worker that can be _accessed_ from several browsing contexts, such as several windows, iframes or even workers. They implement an interface different than dedicated workers and have a different global scope, [SharedWorkerGlobalScope].\n\n> **Note:** If SharedWorker can be accessed from several browsing contexts, all those browsing contexts must share the exact same origin (same protocol, host and port).\n\n",
    "properties": {
      "error_event": "\n\nThe **`error`** event of the [SharedWorker] interface fires when an error occurs in the worker.",
      "port": "\n\nThe **`port`** property of the [SharedWorker]\ninterface returns a [MessagePort] object used to communicate and control\nthe shared worker."
    }
  },
  "sharedworkerglobalscope": {
    "docs": "\n\nThe **`SharedWorkerGlobalScope`** object (the [SharedWorker] global scope) is accessible through the [window.self] keyword. Some additional global functions, namespaces objects, and constructors, not typically associated with the worker global scope, but available on it, are listed in the [JavaScript Reference](/en-US/docs/Web/JavaScript/Reference). See the complete list of [functions available to workers](/en-US/docs/Web/API/Web_Workers_API/Functions_and_classes_available_to_workers).\n\n",
    "properties": {
      "close": "\n\nThe **`close()`** method of the [SharedWorkerGlobalScope] interface discards any tasks queued in the `SharedWorkerGlobalScope`'s event loop, effectively closing this particular scope.",
      "connect_event": "\n\nThe **`connect`** event is fired in shared workers at their [SharedWorkerGlobalScope] when a new client connects.\n\nThis event is not cancelable and does not bubble.",
      "name": "\n\nThe **`name`** read-only property of the\n[SharedWorkerGlobalScope] interface returns the name that the\n[SharedWorker] was (optionally) given when it was created. This is the name\nthat the [SharedWorker.SharedWorker] constructor can pass\nto get a reference to the [SharedWorkerGlobalScope]."
    }
  },
  "sourcebuffer": {
    "docs": "\n\nThe **`SourceBuffer`** interface represents a chunk of media to be passed into an [HTMLMediaElement] and played, via a [MediaSource] object. This can be made up of one or several media segments.\n\n",
    "properties": {
      "abort": "\n\nThe **`abort()`** method of the [SourceBuffer]\ninterface aborts the current segment and resets the segment parser.",
      "appendbuffer": "\n\nThe **`appendBuffer()`** method of the\n[SourceBuffer] interface appends media segment data from an\n`ArrayBuffer`, a `TypedArray` or a `DataView` object\nto the `SourceBuffer`.",
      "appendbufferasync": "\n\nThe **`appendBufferAsync()`** method\nof the [SourceBuffer] interface begins the process of asynchronously\nappending media segment data from an `ArrayBuffer`,\na `TypedArray` or a `DataView` object to the `SourceBuffer` object.\nIt returns a `Promise` which is fulfilled once the buffer has been appended.",
      "appendwindowend": "\n\nThe **`appendWindowEnd`** property of the\n[SourceBuffer] interface controls the timestamp for the end of the [append window](https://w3c.github.io/media-source/#append-window), a\ntimestamp range that can be used to filter what media data is appended to the\n`SourceBuffer`. Coded media frames with timestamps within this range will be\nappended, whereas those outside the range will be filtered out.\n\nThe default value of `appendWindowEnd` is positive infinity.",
      "appendwindowstart": "\n\nThe **`appendWindowStart`** property of the\n[SourceBuffer] interface controls the timestamp for the start of the [append window](https://w3c.github.io/media-source/#append-window), a\ntimestamp range that can be used to filter what media data is appended to the\n`SourceBuffer`. Coded media frames with timestamps within this range will be\nappended, whereas those outside the range will be filtered out.\n\nThe default value of `appendWindowStart` is the presentation start time,\nwhich is the beginning time of the playable media.",
      "audiotracks": "\n\nThe **`audioTracks`** read-only property of the\n[SourceBuffer] interface returns a list of the audio tracks currently\ncontained inside the `SourceBuffer`.",
      "buffered": "\n\nThe **`buffered`** read-only property of the\n[SourceBuffer] interface returns the time ranges that are currently\nbuffered in the `SourceBuffer` as a normalized [TimeRanges]\nobject.",
      "changetype": "\n\nThe **`changeType()`** method of the\n[SourceBuffer] interface sets the MIME type that future calls to\n[SourceBuffer.appendBuffer] should expect the new media\ndata to conform to. This makes it possible to change codecs or container type\nmid-stream.\n\nOne scenario in which this is helpful is to support adapting the media source to\nchanging bandwidth availability, by transitioning from one codec to another as resource\nconstraints change.",
      "mode": "\n\nThe **`mode`** property of the [SourceBuffer]\ninterface controls whether media segments can be appended to the\n`SourceBuffer` in any order, or in a strict sequence.\n\nThe two available values are:\n\n- `segments`: The media segment timestamps determine the order in which the\n  segments are played. The segments can be appended to the `SourceBuffer` in\n  any order.\n- `sequence`: The order in which the segments are appended to the\n  `SourceBuffer` determines the order in which they are played. Segment\n  timestamps are generated automatically for the segments that observe this order.\n\nThe mode value is initially set when the `SourceBuffer` is created using\n`MediaSource.addSourceBuffer()`. If timestamps already exist for the media\nsegments, then the value will be set to `segments`; if they don't, then the\nvalue will be set to `sequence`.\n\nIf you try to set the `mode` property value to `segments` when\nthe initial value is `sequence`, an exception will be thrown. The existing\nsegment order must be maintained in `sequence` mode. You can, however, change\nthe value from `segments` to `sequence`. It just means the play\norder will be fixed, and new timestamps generated to reflect this.\n\nThis property cannot be changed during while the `SourceBuffer` is\nprocessing either an [SourceBuffer.appendBuffer] or\n[SourceBuffer.remove] call.",
      "remove": "\n\nThe **`remove()`** method of the [SourceBuffer]\ninterface removes media segments within a specific time range from the\n`SourceBuffer`. This method can only be called when\n[SourceBuffer.updating] equals `false`. If\n`SourceBuffer.updating` is not equal to `false`, call\n[SourceBuffer.abort].",
      "removeasync": "\n\nThe **`removeAsync()`** method of the\n[SourceBuffer] interface starts the process of asynchronously removing\nfrom the `SourceBuffer` media segments found within a specific time\nrange. A `Promise` is returned, which is fulfilled when the buffers\nin the specified time range have been removed.\n\nThis method can only be called when [SourceBuffer.updating] is\n`false`. If that's not the case, call [SourceBuffer.abort] instead.",
      "texttracks": "\n\nThe **`textTracks`** read-only property of the\n[SourceBuffer] interface returns a list of the text tracks currently\ncontained inside the `SourceBuffer`.",
      "timestampoffset": "\n\nThe **`timestampOffset`** property of the\n[SourceBuffer] interface controls the offset applied to timestamps inside\nmedia segments that are appended to the `SourceBuffer`.\n\nThe initial value of `timestampOffset` is 0.",
      "updating": "\n\nThe **`updating`** read-only property of the\n[SourceBuffer] interface indicates whether the `SourceBuffer` is\ncurrently being updated — i.e. whether an [SourceBuffer.appendBuffer] or [SourceBuffer.remove]\noperation is currently in progress.",
      "videotracks": "\n\nThe **`videoTracks`** read-only property of the\n[SourceBuffer] interface returns a list of the video tracks currently\ncontained inside the `SourceBuffer`."
    }
  },
  "sourcebufferlist": {
    "docs": "\n\nThe **`SourceBufferList`** interface represents a simple container list for multiple [SourceBuffer] objects.\n\nThe source buffer list containing the `SourceBuffer`s appended to a particular `MediaSource` can be retrieved using the [MediaSource.sourceBuffers] property.\n\nThe individual source buffers can be accessed using the [bracket notation](/en-US/docs/Web/JavaScript/Reference/Operators/Property_accessors#bracket_notation) `[]`.\n\n",
    "properties": {
      "length": "\n\nThe **`length`** read-only property of the\n[SourceBufferList] interface returns the number of\n[SourceBuffer] objects in the list."
    }
  },
  "speechgrammar": {
    "docs": "\n\nThe **`SpeechGrammar`** interface of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) represents a set of words or patterns of words that we want the recognition service to recognize.\n\nGrammar is defined using [JSpeech Grammar Format](https://www.w3.org/TR/jsgf/) (**JSGF**.) Other formats may also be supported in the future.",
    "properties": {
      "src": "\n\nThe **`src`** property of the [SpeechGrammar]\ninterface sets and returns a string containing the grammar from within in the\n`SpeechGrammar` object.",
      "weight": "\n\nThe optional **`weight`** property of the\n[SpeechGrammar] interface sets and returns the weight of the\n`SpeechGrammar` object."
    }
  },
  "speechgrammarlist": {
    "docs": "\n\nThe **`SpeechGrammarList`** interface of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) represents a list of [SpeechGrammar] objects containing words or patterns of words that we want the recognition service to recognize.\n\nGrammar is defined using [JSpeech Grammar Format](https://www.w3.org/TR/jsgf/) (**JSGF**.) Other formats may also be supported in the future.",
    "properties": {
      "addfromstring": "\n\nThe **`addFromString()`** method of the\n[SpeechGrammarList] interface takes a grammar present in a specific\nstring within the code base (e.g. stored in a variable) and adds it to\nthe `SpeechGrammarList` as a new [SpeechGrammar] object.",
      "addfromuri": "\n\nThe **`addFromURI()`** method of the\n[SpeechGrammarList] interface takes a grammar present at a specific URI and\nadds it to the `SpeechGrammarList` as a new [SpeechGrammar]\nobject.\n\nNote that some speech recognition services may support built-in grammars that can be\nspecified by URI.",
      "item": "\n\nThe **`item`** getter of the [SpeechGrammarList]\ninterface is a standard getter — it allows individual [SpeechGrammar]\nobjects to be retrieved from the `SpeechGrammarList` using array syntax.",
      "length": "\n\nThe **`length`** read-only property of the\n[SpeechGrammarList] interface returns the number of\n[SpeechGrammar] objects contained in the [SpeechGrammarList]."
    }
  },
  "speechrecognition": {
    "docs": "\n\nThe **`SpeechRecognition`** interface of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) is the controller interface for the recognition service; this also handles the [SpeechRecognitionEvent] sent from the recognition service.\n\n> **Note:** On some browsers, like Chrome, using Speech Recognition on a web page involves a server-based recognition engine. Your audio is sent to a web service for recognition processing, so it won't work offline.\n\n",
    "properties": {
      "abort": "\n\nThe **`abort()`** method of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) stops the speech\nrecognition service from listening to incoming audio, and doesn't attempt to return a\n[SpeechRecognitionResult].",
      "audioend_event": "\n\nThe **`audioend`** event of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) is fired when the user agent has finished capturing audio for speech recognition.",
      "audiostart_event": "\n\nThe **`audiostart`** event of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) is fired when the user agent has started to capture audio for speech recognition.",
      "continuous": "\n\nThe **`continuous`** property of the\n[SpeechRecognition] interface controls whether continuous results are\nreturned for each recognition, or only a single result.\n\nIt defaults to single results (`false`.)",
      "end_event": "\n\nThe **`end`** event of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) [SpeechRecognition] object is fired when the speech recognition service has disconnected.",
      "error_event": "\n\nThe **`error`** event of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) [SpeechRecognition] object is fired when a speech recognition error occurs.",
      "grammars": "\n\nThe **`grammars`** property of the\n[SpeechRecognition] interface returns and sets a collection of\n[SpeechGrammar] objects that represent the grammars that will be understood\nby the current `SpeechRecognition`.",
      "interimresults": "\n\nThe **`interimResults`** property of the\n[SpeechRecognition] interface controls whether interim results should be\nreturned (`true`) or not (`false`.) Interim results are results\nthat are not yet final (e.g. the [SpeechRecognitionResult.isFinal] property\nis `false`.)\n\nThe default value for **`interimResults`** is `false`.",
      "lang": "\n\nThe **`lang`** property of the [SpeechRecognition]\ninterface returns and sets the language of the current `SpeechRecognition`.\nIf not specified, this defaults to the HTML [`lang`](/en-US/docs/Web/HTML/Element/html#lang) attribute\nvalue, or the user agent's language setting if that isn't set either.",
      "maxalternatives": "\n\nThe **`maxAlternatives`** property of the\n[SpeechRecognition] interface sets the maximum number of\n[SpeechRecognitionAlternative]s provided per\n[SpeechRecognitionResult].\n\nThe default value is 1.",
      "nomatch_event": "\n\nThe **`nomatch`** event of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) is fired when the speech recognition service returns a final result with no significant recognition.\n\nThis may involve some degree of recognition, which doesn't meet or exceed the [SpeechRecognitionAlternative.confidence] threshold.",
      "result_event": "\n\nThe **`result`** event of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) is fired when the speech recognition service returns a result — a word or phrase has been positively recognized and this has been communicated back to the app",
      "soundend_event": "\n\nThe **`soundend`** event of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) is fired when any sound — recognizable speech or not — has stopped being detected.",
      "soundstart_event": "\n\nThe **`soundstart`** event of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) is fired when any sound — recognizable speech or not — has been detected.",
      "speechend_event": "\n\nThe **`speechend`** event of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) is fired when speech recognized by the speech recognition service has stopped being detected.",
      "speechstart_event": "\n\nThe **`speechstart`** event of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) is fired when sound recognized by the speech recognition service as speech has been detected.",
      "start": "\n\nThe **`start()`** method of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) starts the speech\nrecognition service listening to incoming audio with intent to recognize grammars\nassociated with the current [SpeechRecognition].",
      "start_event": "\n\nThe **`start`** event of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) [SpeechRecognition] object is fired when the speech recognition service has begun listening to incoming audio with intent to recognize grammars associated with the current `SpeechRecognition`.",
      "stop": "\n\nThe **`stop()`** method of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) stops the speech\nrecognition service from listening to incoming audio, and attempts to return a\n[SpeechRecognitionResult] using the audio captured so far."
    }
  },
  "speechrecognitionalternative": {
    "docs": "\n\nThe **`SpeechRecognitionAlternative`** interface of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) represents a single word that has been recognized by the speech recognition service.",
    "properties": {
      "confidence": "\n\nThe **`confidence`** read-only property of the\n[SpeechRecognitionResult] interface returns a numeric estimate of how\nconfident the speech recognition system is that the recognition is correct.\n\n> **Note:** Mozilla's implementation of `confidence` is still\n> being worked on — at the moment, it always seems to return 1.",
      "transcript": "\n\nThe **`transcript`** read-only property of the\n[SpeechRecognitionResult] interface returns a string containing the\ntranscript of the recognized word(s).\n\nFor continuous recognition, leading or trailing whitespace will be included where\nnecessary so that concatenation of consecutive [SpeechRecognitionResult]s\nproduces a proper transcript of the session."
    }
  },
  "speechrecognitionerrorevent": {
    "docs": "\n\nThe **`SpeechRecognitionErrorEvent`** interface of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) represents error messages from the recognition service.\n\n",
    "properties": {
      "error": "\n\nThe **`error`** read-only property of the\n[SpeechRecognitionErrorEvent] interface returns the type of error raised.",
      "message": "\n\nThe **`message`** read-only property of the\n[SpeechRecognitionErrorEvent] interface returns a message describing the\nerror in more detail."
    }
  },
  "speechrecognitionevent": {
    "docs": "\n\nThe **`SpeechRecognitionEvent`** interface of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) represents the event object for the [SpeechRecognition.result_event] and [SpeechRecognition.nomatch_event] events, and contains all the data associated with an interim or final speech recognition result.\n\n",
    "properties": {
      "emma": "\n\nThe **`emma`** read-only property of the\n[SpeechRecognitionEvent] interface returns an Extensible\nMultiModal Annotation markup language (EMMA) — XML — representation of the\nresult.\n\n> **Note:** EMMA is defined in the specification [EMMA: Extensible MultiModal Annotation markup language](https://www.w3.org/TR/emma/). You can see multiple EMMA examples in the spec.",
      "interpretation": "\n\nThe **`interpretation`** read-only property of the\n[SpeechRecognitionEvent] interface returns the semantic meaning of what the\nuser said.\n\nThis might be determined, for instance, through the SISR specification of semantics in\na grammar (see\n[Semantic Interpretation for Speech Recognition (SISR) Version 1.0](https://www.w3.org/TR/semantic-interpretation/)\nfor specification and examples.)",
      "resultindex": "\n\nThe **`resultIndex`** read-only property of the\n[SpeechRecognitionEvent] interface returns the lowest index value result in\nthe [SpeechRecognitionResultList] \"array\" that has actually changed.\n\nThe [SpeechRecognitionResultList] object is not an array, but it has a\ngetter that allows it to be accessed by array syntax.",
      "results": "\n\nThe **`results`** read-only property of the\n[SpeechRecognitionEvent] interface returns a\n[SpeechRecognitionResultList] object representing all the speech\nrecognition results for the current session.\n\nSpecifically this object will contain all final results that have been returned,\nfollowed by the current best hypothesis for all interim results. When subsequent\n[SpeechRecognition.result_event] events are fired, interim results may be overwritten by a newer\ninterim result or by a final result — they may even be removed, if they are at the end\nof the \"results\" array and the array length decreases. Final results on the other hand\nwill not be overwritten or removed."
    }
  },
  "speechrecognitionresult": {
    "docs": "\n\nThe **`SpeechRecognitionResult`** interface of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) represents a single recognition match, which may contain multiple [SpeechRecognitionAlternative] objects.",
    "properties": {
      "isfinal": "\n\nThe **`isFinal`** read-only property of the\n[SpeechRecognitionResult] interface is a boolean value that states\nwhether this result is final (`true`) or not (`false`) — if so,\nthen this is the final time this result will be returned; if not, then this result is an\ninterim result, and may be updated later on.",
      "item": "\n\nThe **`item`** getter of the\n[SpeechRecognitionResult] interface is a standard getter that allows\n[SpeechRecognitionAlternative] objects within the result to be accessed via\narray syntax.",
      "length": "\n\nThe **`length`** read-only property of the\n[SpeechRecognitionResult] interface returns the length of the \"array\"\n— the number of [SpeechRecognitionAlternative] objects contained\nin the result (also referred to as \"n-best alternatives\".)\n\nThe number of alternatives contained in the result depends on what the\n[SpeechRecognition.maxAlternatives] property was set to when the speech\nrecognition was first initiated."
    }
  },
  "speechrecognitionresultlist": {
    "docs": "\n\nThe **`SpeechRecognitionResultList`** interface of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) represents a list of [SpeechRecognitionResult] objects, or a single one if results are being captured in  mode.",
    "properties": {
      "item": "\n\nThe **`item`** getter of the\n[SpeechRecognitionResultList] interface is a standard getter — it allows\n[SpeechRecognitionResult] objects in the list to be accessed via array\nsyntax.",
      "length": "\n\nThe **`length`** read-only property of the\n[SpeechRecognitionResultList] interface returns the length of the\n\"array\" — the number of [SpeechRecognitionResult] objects in the\nlist."
    }
  },
  "speechsynthesis": {
    "docs": "\n\nThe **`SpeechSynthesis`** interface of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) is the controller interface for the speech service; this can be used to retrieve information about the synthesis voices available on the device, start and pause speech, and other commands besides.\n\n",
    "properties": {
      "cancel": "\n\nThe **`cancel()`** method of the [SpeechSynthesis]\ninterface removes all utterances from the utterance queue.\n\nIf an utterance is currently being spoken, speaking will stop immediately.",
      "getvoices": "\n\nThe **`getVoices()`** method of the\n[SpeechSynthesis] interface returns a list of\n[SpeechSynthesisVoice] objects representing all the available voices on the\ncurrent device.",
      "pause": "\n\nThe **`pause()`** method of the [SpeechSynthesis]\ninterface puts the `SpeechSynthesis` object into a paused state.",
      "paused": "\n\nThe **`paused`** read-only property of the\n[SpeechSynthesis] interface is a boolean value that returns\n`true` if the `SpeechSynthesis` object is in a paused state, or `false` if not.\n\nIt can be set to [SpeechSynthesis.pause] even if nothing is\ncurrently being spoken through it. If\n[SpeechSynthesisUtterance] are then added to the utterance\nqueue, they will not be spoken until the `SpeechSynthesis` object is\nunpaused, using [SpeechSynthesis.resume].",
      "pending": "\n\nThe **`pending`** read-only property of the\n[SpeechSynthesis] interface is a boolean value that returns\n`true` if the utterance queue contains as-yet-unspoken utterances.",
      "resume": "\n\nThe **`resume()`** method of the [SpeechSynthesis]\ninterface puts the `SpeechSynthesis` object into a non-paused state:\nresumes it if it was already paused.",
      "speak": "\n\nThe **`speak()`** method of the [SpeechSynthesis]\ninterface adds an [SpeechSynthesisUtterance] to the utterance\nqueue; it will be spoken when any other utterances queued before it have been spoken.",
      "speaking": "\n\nThe **`speaking`** read-only property of the\n[SpeechSynthesis] interface is a boolean value that returns\n`true` if an utterance is currently in the process of being spoken — even\nif `SpeechSynthesis` is in a\n[SpeechSynthesis/pause] state.",
      "voiceschanged_event": "\n\nThe **`voiceschanged`** event of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) is fired when the list of [SpeechSynthesisVoice] objects that would be returned by the [SpeechSynthesis.getVoices] method has changed (when the `voiceschanged` event fires.)"
    }
  },
  "speechsynthesiserrorevent": {
    "docs": "\n\nThe **`SpeechSynthesisErrorEvent`** interface of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) contains information about any errors that occur while processing [SpeechSynthesisUtterance] objects in the speech service.\n\n",
    "properties": {
      "error": "\n\nThe **`error`** property of the\n[SpeechSynthesisErrorEvent] interface returns an error code indicating what has gone wrong with a speech synthesis attempt."
    }
  },
  "speechsynthesisevent": {
    "docs": "\n\nThe **`SpeechSynthesisEvent`** interface of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) contains information about the current state of [SpeechSynthesisUtterance] objects that have been processed in the speech service.\n\n",
    "properties": {
      "charindex": "\n\nThe **`charIndex`** read-only property of the [SpeechSynthesisUtterance] interface returns the index position of the character in [SpeechSynthesisUtterance.text] that was being spoken when the event was triggered.",
      "charlength": "\n\nThe read-only **`charLength`** property of the [SpeechSynthesisEvent] interface returns the number of characters left to be spoken after the character at the [SpeechSynthesisEvent.charIndex] position.\n\nIf the speech engine can't determine it, it returns 0.",
      "elapsedtime": "\n\nThe **`elapsedTime`** read-only property of the [SpeechSynthesisEvent] returns the elapsed time in seconds, after the [SpeechSynthesisUtterance.text] started being spoken, at which the [event](/en-US/docs/Web/API/SpeechSynthesisUtterance#events) was triggered.",
      "name": "\n\nThe **`name`** read-only property of the [SpeechSynthesisUtterance] interface returns the name associated with certain types of events occurring as the [SpeechSynthesisUtterance.text] is being spoken:\nthe name of the [SSML](https://www.w3.org/TR/speech-synthesis/#S3.3.2) marker reached in the case of a [SpeechSynthesisUtterance.mark_event] event, or the type of boundary reached in the case of a [SpeechSynthesisUtterance.boundary_event] event.",
      "utterance": "\n\nThe **`utterance`** read-only property of the [SpeechSynthesisUtterance] interface returns the [SpeechSynthesisUtterance] instance that the event was triggered on."
    }
  },
  "speechsynthesisutterance": {
    "docs": "\n\nThe **`SpeechSynthesisUtterance`** interface of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) represents a speech request.\nIt contains the content the speech service should read and information about how to read it (e.g. language, pitch and volume.)\n\n",
    "properties": {
      "boundary_event": "\n\nThe **`boundary`** event of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) is fired when the spoken utterance reaches a word or sentence boundary.",
      "end_event": "\n\nThe **`end`** event of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) [SpeechSynthesisUtterance] object is fired when the utterance has finished being spoken.",
      "error_event": "\n\nThe **`error`** event of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) [SpeechSynthesisUtterance] object is fired when an error occurs that prevents the utterance from being successfully spoken.",
      "lang": "\n\nThe **`lang`** property of the [SpeechSynthesisUtterance] interface gets and sets the language of the utterance.\n\nIf unset, the app's (i.e. the `html` [`lang`](/en-US/docs/Web/HTML/Element/html#lang) value) lang will be used, or the user-agent default if that is unset too.",
      "mark_event": "\n\nThe **`mark`** event of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) [SpeechSynthesisUtterance] object is fired when the spoken utterance reaches a named SSML \"mark\" tag.",
      "pause_event": "\n\nThe **`pause`** event of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) [SpeechSynthesisUtterance] object is fired when the utterance is paused part way through.",
      "pitch": "\n\nThe **`pitch`** property of the [SpeechSynthesisUtterance] interface gets and sets the pitch at which the utterance will be spoken at.\n\nIf unset, a default value of 1 will be used.",
      "rate": "\n\nThe **`rate`** property of the [SpeechSynthesisUtterance] interface gets and sets the speed at which the utterance will be spoken at.\n\nIf unset, a default value of 1 will be used.",
      "resume_event": "\n\nThe **`resume`** event of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) [SpeechSynthesisUtterance] object is fired when a paused utterance is resumed.",
      "start_event": "\n\nThe **`start`** event of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) [SpeechSynthesisUtterance] object is fired when the utterance has begun to be spoken.",
      "text": "\n\nThe **`text`** property of the\n[SpeechSynthesisUtterance] interface gets and sets the text that will be synthesized when the utterance is spoken.\n\nThe text may be provided as plain text, or a well-formed [SSML](https://www.w3.org/TR/speech-synthesis/) document.\nThe SSML tags will be stripped away by devices that don't support SSML.",
      "voice": "\n\nThe **`voice`** property of the [SpeechSynthesisUtterance] interface gets and sets the voice that will be used to speak the utterance.\n\nThis should be set to one of the [SpeechSynthesisVoice] objects returned by [SpeechSynthesis.getVoices].\nIf not set by the time the utterance is spoken, the voice used will be the most suitable default voice available for the utterance's [SpeechSynthesisUtterance.lang] setting.",
      "volume": "\n\nThe **`volume`** property of the [SpeechSynthesisUtterance] interface gets and sets the volume that the utterance will be spoken at.\n\nIf not set, the default value 1 will be used."
    }
  },
  "speechsynthesisvoice": {
    "docs": "\n\nThe **`SpeechSynthesisVoice`** interface of the [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) represents a voice that the system supports.\nEvery `SpeechSynthesisVoice` has its own relative speech service including information about language, name and URI.",
    "properties": {
      "default": "\n\nThe **`default`** read-only property of the\n[SpeechSynthesisVoice] interface returns a boolean value\nindicating whether the voice is the default voice for the current app\n(`true`), or not (`false`.)\n\n> **Note:** For some devices, it might be the default voice for the\n> voice's language. The spec is not very clear on which it should be, so some\n> implementations may differ.",
      "lang": "\n\nThe **`lang`** read-only property of the [SpeechSynthesisVoice] interface returns a BCP 47 language tag indicating the language of the voice.",
      "localservice": "\n\nThe **`localService`** read-only property of the\n[SpeechSynthesisVoice] interface returns a boolean value\nindicating whether the voice is supplied by a local speech synthesizer service\n(`true`), or a remote speech synthesizer service (`false`.)\n\nThis property is provided to allow differentiation in the case that some voice options\nare provided by a remote service; it is possible that remote voices might have extra\nlatency, bandwidth or cost associated with them, so such distinction may be useful.",
      "name": "\n\nThe **`name`** read-only property of the\n[SpeechSynthesisVoice] interface returns a human-readable name that\nrepresents the voice.",
      "voiceuri": "\n\nThe **`voiceURI`** read-only property of the\n[SpeechSynthesisVoice] interface returns the type of URI and location of\nthe speech synthesis service for this voice."
    }
  },
  "staticrange": {
    "docs": "\n\nThe [DOM](/en-US/docs/Web/API/Document_Object_Model) **`StaticRange`** interface extends [AbstractRange] to provide a method to specify a range of content in the DOM whose contents don't update to reflect changes which occur within the DOM tree.\n\nThis interface offers the same set of properties and methods as `AbstractRange`.\n\n`AbstractRange` and `StaticRange` are not available from [web workers](/en-US/docs/Web/API/Web_Workers_API).\n\n",
    "properties": {
      "collapsed": "\n\nThe **`collapsed`** read-only property\nof the [StaticRange] interface returns `true` if the range's\nstart position and end position are the same.",
      "endcontainer": "\n\nThe **`endContainer`** property of the [StaticRange] interface returns the end [Node] for the range.",
      "endoffset": "\n\nThe **`endOffset`** property of the [StaticRange]\ninterface returns the offset into the end node of the range's end position.",
      "startcontainer": "\n\nThe read-only **`startContainer`**\nproperty of the [StaticRange] interface returns the start\n[Node] for the range.",
      "startoffset": "\n\nThe read-only **`startOffset`**\nproperty of the [StaticRange] interface returns the offset into the start\nnode of the range's start position."
    }
  },
  "stereopannernode": {
    "docs": "\n\nThe `StereoPannerNode` interface of the [Web Audio API](/en-US/docs/Web/API/Web_Audio_API) represents a simple stereo panner node that can be used to pan an audio stream left or right. It is an [AudioNode] audio-processing module that positions an incoming audio stream in a stereo image using a low-cost equal-power [panning algorithm](https://webaudio.github.io/web-audio-api/#panning-algorithm).\n\nThe [StereoPannerNode.pan] property takes a unitless value between `-1` (full left pan) and `1` (full right pan). This interface was introduced as a much simpler way to apply a simple panning effect than having to use a full [PannerNode].\n\n![The Stereo Panner Node moved the sound's position from the center of two speakers to the left.](stereopannernode.png)\n\n<table class=\"properties\">\n  <tbody>\n    <tr>\n      <th scope=\"row\">Number of inputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Number of outputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count mode</th>\n      <td><code>\"clamped-max\"</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count</th>\n      <td><code>2</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel interpretation</th>\n      <td><code>\"speakers\"</code></td>\n    </tr>\n  </tbody>\n</table>",
    "properties": {
      "pan": "\n\nThe `pan` property of the [StereoPannerNode] interface is an [a-rate](/en-US/docs/Web/API/AudioParam#a-rate) [AudioParam] representing the amount of panning to apply. The value can range between `-1` (full left pan) and `1` (full right pan)."
    }
  },
  "storage": {
    "docs": "\n\nThe **`Storage`** interface of the [Web Storage API](/en-US/docs/Web/API/Web_Storage_API) provides access to a particular domain's session or local storage. It allows, for example, the addition, modification, or deletion of stored data items.\n\nTo manipulate, for instance, the session storage for a domain, a call to [Window.sessionStorage] is made; whereas for local storage the call is made to [Window.localStorage].",
    "properties": {
      "clear": "\n\nThe **`clear()`** method of the [Storage]\ninterface clears all keys stored in a given `Storage` object.",
      "getitem": "\n\nThe **`getItem()`** method of the [Storage]\ninterface, when passed a key name, will return that key's value, or `null` if\nthe key does not exist, in the given `Storage` object.",
      "key": "\n\nThe **`key()`** method of the [Storage] interface,\nwhen passed a number n, returns the name of the nth key in a given `Storage`\nobject. The order of keys is user-agent defined, so you should not rely on it.",
      "length": "\n\nThe **`length`** read-only property of the\n[Storage] interface returns the number of data items stored in a given\n`Storage` object.",
      "removeitem": "\n\nThe **`removeItem()`** method of the [Storage]\ninterface, when passed a key name, will remove that key from the given\n`Storage` object if it exists.\nThe **`Storage`** interface of the [Web Storage API](/en-US/docs/Web/API/Web_Storage_API) provides access to a\nparticular domain's session or local storage.\n\nIf there is no item associated with the given key, this method will do nothing.",
      "setitem": "\n\nThe **`setItem()`** method of the [Storage]\ninterface, when passed a key name and value, will add that key to the given\n`Storage` object, or update that key's value if it already exists."
    }
  },
  "storageevent": {
    "docs": "\n\nThe **`StorageEvent`** interface is implemented by the [Window/storage_event] event, which is\nsent to a window\nwhen a storage area the window has access to is changed within the context of another document.\n\n",
    "properties": {
      "initstorageevent": "\n\nThe **`StorageEvent.initStorageEvent()`** method is used to initialize the value of a [StorageEvent].",
      "key": "\n\nThe **`key`** property of the [StorageEvent] interface returns the key for the storage item that was changed.",
      "newvalue": "\n\nThe **`newValue`** property of the [StorageEvent] interface returns the new value of the storage item whose value was changed.",
      "oldvalue": "\n\nThe **`oldValue`** property of the [StorageEvent] interface returns the original value of the storage item whose value changed.",
      "storagearea": "\n\nThe **`storageArea`** property of the [StorageEvent] interface returns the storage object that was affected.",
      "url": "\n\nThe **`url`** property of the [StorageEvent] interface returns the URL of the document whose storage changed."
    }
  },
  "storagemanager": {
    "docs": "\n\nThe **`StorageManager`** interface of the [Storage API](/en-US/docs/Web/API/Storage_API) provides an interface for managing persistence permissions and estimating available storage. You can get a reference to this interface using either [navigator.storage] or [WorkerNavigator.storage].\n\n",
    "properties": {
      "estimate": "\n\nThe **`estimate()`** method of the [StorageManager] interface asks the Storage Manager for how much storage the current [origin](/en-US/docs/Glossary/Same-origin_policy) takes up (`usage`), and how much space is available (`quota`).\n\nThis method operates asynchronously, so it returns a `Promise` which resolves once the information is available. The promise's fulfillment handler is called with an object containing the usage and quota data.\n\n",
      "getdirectory": "\n\nThe **`getDirectory()`** method of the [StorageManager] interface is used to obtain a reference to a [FileSystemDirectoryHandle] object allowing access to a directory and its contents, stored in the [origin private file system](/en-US/docs/Web/API/File_System_API/Origin_private_file_system) (OPFS).\n\n",
      "persist": "\n\nThe **`persist()`** method of the [StorageManager] interface requests permission to use persistent storage, and returns a `Promise` that resolves to `true` if permission is granted and bucket mode is persistent, and `false` otherwise.\n\n> **Note:** This method is not available in [Web Workers](/en-US/docs/Web/API/Web_Workers_API), though the [StorageManager] interface is.",
      "persisted": "\n\nThe **`persisted()`** method of the [StorageManager] interface returns a `Promise` that resolves to `true` if your site's storage bucket is persistent.\n\n"
    }
  },
  "stylepropertymap": {
    "docs": "\n\nThe **`StylePropertyMap`** interface of the [CSS Typed Object Model API](/en-US/docs/Web/API/CSS_Object_Model#css_typed_object_model_experimental) provides a representation of a CSS declaration block that is an alternative to [CSSStyleDeclaration].\n\n",
    "properties": {
      "append": "\n\nThe **`append()`** method of the\n[StylePropertyMap] interface adds the passed CSS value to the\n`StylePropertyMap` with the given property.",
      "clear": "\n\nThe **`clear()`** method of the [StylePropertyMap]\ninterface removes all declarations in the `StylePropertyMap`.",
      "delete": "\n\nThe **`delete()`** method of the\n[StylePropertyMap] interface removes the CSS declaration with the given\nproperty.",
      "set": "\n\nThe **`set()`** method of the [StylePropertyMap]\ninterface changes the CSS declaration with the given property."
    }
  },
  "stylepropertymapreadonly": {
    "docs": "\n\nThe **`StylePropertyMapReadOnly`** interface of the [CSS Typed Object Model API](/en-US/docs/Web/API/CSS_Object_Model#css_typed_object_model) provides a read-only representation of a CSS declaration block that is an alternative to [CSSStyleDeclaration]. Retrieve an instance of this interface using [Element.computedStyleMap].",
    "properties": {
      "entries": "\n\nThe **`StylePropertyMapReadOnly.entries()`** method returns an\narray of a given object's own enumerable property `[key, value]` pairs, in\nthe same order as that provided by a `for...in` loop\n(the difference being that a for-in loop enumerates properties in the prototype chain as\nwell).",
      "foreach": "\n\nThe **`StylePropertyMapReadOnly.forEach()`** method executes a\nprovided function once for each element of [StylePropertyMapReadOnly].",
      "get": "\n\nThe **`get()`** method of the\n[StylePropertyMapReadOnly] interface returns a [CSSStyleValue]\nobject for the first value of the specified property.",
      "getall": "\n\nThe **`getAll()`** method of the\n[StylePropertyMapReadOnly] interface returns an array of\n[CSSStyleValue] objects containing the values for the provided property.",
      "has": "\n\nThe **`has()`** method of the\n[StylePropertyMapReadOnly] interface indicates whether the specified\nproperty is in the `StylePropertyMapReadOnly` object.",
      "keys": "\n\nThe **`StylePropertyMapReadOnly.keys()`** method returns a new\n_array iterator_ containing the keys for each item\nin `StylePropertyMapReadOnly`",
      "size": "\n\nThe **`size`** read-only property of the\n[StylePropertyMapReadOnly] interface returns an unsigned long integer\ncontaining the size of the `StylePropertyMapReadOnly` object.",
      "values": "\n\nThe **`StylePropertyMapReadOnly.values()`** method returns a\nnew _array iterator_ containing the values for each index in the\n`StylePropertyMapReadOnly` object."
    }
  },
  "stylesheet": {
    "docs": "\n\nAn object implementing the `StyleSheet` interface represents a single style sheet. CSS style sheets will further implement the more specialized [CSSStyleSheet] interface.",
    "properties": {
      "disabled": "\n\nThe **`disabled`** property of the\n[StyleSheet] interface determines whether the style sheet is prevented from\napplying to the document.\n\nA style sheet may be disabled by manually setting this property to `true` or\nif it's an inactive [alternative style sheet](/en-US/docs/Web/CSS/Alternative_style_sheets). Note that `disabled === false` does not guarantee the style\nsheet is applied (it could be removed from the document, for instance).",
      "href": "\n\nThe **`href`** property of the [StyleSheet]\ninterface returns the location of the style sheet.\n\nThis property is read-only.",
      "media": "\n\nThe **`media`** property of the [StyleSheet] interface specifies the intended destination media for style information. It is a read-only, array-like `MediaList` object and can be removed with `deleteMedium()` and added with `appendMedium()`.",
      "ownernode": "\n\nThe **`ownerNode`** property of the\n[StyleSheet] interface returns the node that associates this style sheet\nwith the document.\n\nThis is usually an HTML\n[`<link>`](/en-US/docs/Web/HTML/Element/link) or\n[`<style>`](/en-US/docs/Web/HTML/Element/style) element, but\ncan also return a [processing instruction node](/en-US/docs/Web/API/ProcessingInstruction) in the case of `<?xml-stylesheet ?>`.",
      "parentstylesheet": "\n\nThe **`parentStyleSheet`** property of the\n[StyleSheet] interface returns the style sheet, if any, that is including\nthe given style sheet.",
      "title": "\n\nThe **`title`** property of the [StyleSheet] interface returns the advisory title of the current style sheet.\n\nThe title is often specified in the [StyleSheet/OwnerNode].",
      "type": "\n\nThe **`type`** property of the [StyleSheet]\ninterface specifies the style sheet language for the given style sheet."
    }
  },
  "stylesheetlist": {
    "docs": "\n\nThe `StyleSheetList` interface represents a list of [CSSStyleSheet] objects. An instance of this object can be returned by [Document.styleSheets].\n\nIt is an array-like object but can't be iterated over using `Array` methods. However it can be iterated over in a standard `for` loop over its indices, or converted to an `Array`.\n\n> **Note:** This interface was an [attempt to create an unmodifiable list](https://stackoverflow.com/questions/74630989/why-use-domstringlist-rather-than-an-array/74641156#74641156) and only continues to be supported to not break code that's already using it. Modern APIs use types that wrap around ECMAScript array types instead, so you can treat them like ECMAScript arrays, and at the same time impose additional semantics on their usage (such as making their items read-only).",
    "properties": {
      "item": "\n\nThe **`item()`** method of the [StyleSheetList] interface returns a single [CSSStyleSheet] object.",
      "length": "\n\nThe **`length`** read-only property of the [StyleSheetList] interface returns the number of [CSSStyleSheet] objects in the collection."
    }
  },
  "submitevent": {
    "docs": "\n\nThe **`SubmitEvent`** interface defines the object used to represent an  form's [HTMLFormElement.submit_event] event. This event is fired at the `form` when the form's submit action is invoked.\n\n",
    "properties": {
      "submitter": "\n\nThe read-only **`submitter`** property found on\nthe [SubmitEvent] interface specifies the submit button or other element\nthat was invoked to cause the form to be submitted."
    }
  },
  "subtlecrypto": {
    "docs": "\n\nThe **`SubtleCrypto`** interface of the [Web Crypto API](/en-US/docs/Web/API/Web_Crypto_API) provides a number of low-level cryptographic functions. Access to the features of `SubtleCrypto` is obtained through the [Crypto.subtle] property of the [Crypto] object you get from the [crypto_property] property.\n\n> **Warning:** This API provides a number of low-level cryptographic primitives. It's very easy to misuse them, and the pitfalls involved can be very subtle.\n>\n> Even assuming you use the basic cryptographic functions correctly, secure key management and overall security system design are extremely hard to get right, and are generally the domain of specialist security experts.\n>\n> Errors in security system design and implementation can make the security of the system completely ineffective.\n>\n> Please learn and experiment, but don't guarantee or imply the security of your work before an individual knowledgeable in this subject matter thoroughly reviews it. The [Crypto 101 Course](https://www.crypto101.io/) can be a great place to start learning about the design and implementation of secure systems.",
    "properties": {
      "decrypt": "\n\nThe **`decrypt()`** method of the [SubtleCrypto] interface decrypts some encrypted data.\nIt takes as arguments a  to decrypt with, some optional extra parameters, and the data to decrypt (also known as \"ciphertext\").\nIt returns a `Promise` which will be fulfilled with the decrypted data (also known as \"plaintext\").",
      "derivebits": "\n\nThe **`deriveBits()`** method of the\n[SubtleCrypto] interface can be used to derive an array of bits from a base\nkey.\n\nIt takes as its arguments the base key, the derivation algorithm to use, and the length\nof the bits to derive. It returns a [`Promise`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise)\nwhich will be fulfilled with an\n[`ArrayBuffer`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/ArrayBuffer)\ncontaining the derived bits.\n\nThis method is very similar to\n[`SubtleCrypto.deriveKey()`](/en-US/docs/Web/API/SubtleCrypto/deriveKey),\nexcept that `deriveKey()` returns a\n[`CryptoKey`](/en-US/docs/Web/API/CryptoKey) object rather than an\n`ArrayBuffer`. Essentially `deriveKey()` is composed of\n`deriveBits()` followed by\n[`importKey()`](/en-US/docs/Web/API/SubtleCrypto/importKey).\n\nThis function supports the same derivation algorithms as `deriveKey()`:\nECDH, HKDF, and PBKDF2. See [Supported algorithms](/en-US/docs/Web/API/SubtleCrypto/deriveKey#supported_algorithms)\nfor some more detail on these algorithms.",
      "derivekey": "\n\nThe **`deriveKey()`** method of the [SubtleCrypto]\ninterface can be used to derive a secret key from a master key.\n\nIt takes as arguments some initial key material, the derivation algorithm to use, and\nthe desired properties for the key to derive. It returns a [`Promise`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise)\nwhich will be fulfilled with a [CryptoKey] object representing the new key.\n\nIt's worth noting that the three key derivation algorithms you can use have quite\ndifferent characteristics and are appropriate in quite different situations. See [Supported algorithms](#supported_algorithms) for some more detail on this.",
      "digest": "\n\nThe **`digest()`** method of the [SubtleCrypto]\ninterface generates a  of the given data. A digest is a short\nfixed-length value derived from some variable-length input. Cryptographic digests should\nexhibit collision-resistance, meaning that it's hard to come up with two different\ninputs that have the same digest value.\n\nIt takes as its arguments an identifier for the digest algorithm to use and the data to\ndigest. It returns a `Promise` which will be fulfilled with the digest.\n\nNote that this API does not support streaming input: you must read the entire input into memory before passing it into the digest function.",
      "encrypt": "\n\nThe **`encrypt()`** method of the [SubtleCrypto] interface encrypts data.\n\nIt takes as its arguments a  to encrypt with, some algorithm-specific parameters, and the data to encrypt (also known as \"plaintext\").\nIt returns a `Promise` which will be fulfilled with the encrypted data (also known as \"ciphertext\").",
      "exportkey": "\n\nThe **`exportKey()`** method of the [SubtleCrypto]\ninterface exports a key: that is, it takes as input a [CryptoKey] object\nand gives you the key in an external, portable format.\n\nTo export a key, the key must have [CryptoKey.extractable] set to\n`true`.\n\nKeys can be exported in several formats: see [Supported formats](/en-US/docs/Web/API/SubtleCrypto/importKey#supported_formats) in the\n[`SubtleCrypto.importKey()`](/en-US/docs/Web/API/SubtleCrypto/importKey)\npage for details.\n\nKeys are not exported in an encrypted format: to encrypt keys when exporting them use\nthe\n[`SubtleCrypto.wrapKey()`](/en-US/docs/Web/API/SubtleCrypto/wrapKey)\nAPI instead.",
      "generatekey": "\n\nUse the **`generateKey()`** method of the\n[SubtleCrypto] interface to generate a new key (for symmetric algorithms)\nor key pair (for public-key algorithms).",
      "importkey": "\n\nThe **`importKey()`** method of the [SubtleCrypto]\ninterface imports a key: that is, it takes as input a key in an external, portable\nformat and gives you a [CryptoKey] object that you can use in the [Web Crypto API](/en-US/docs/Web/API/Web_Crypto_API).\n\nThe function accepts several import formats: see [Supported formats](#supported_formats) for details.",
      "sign": "\n\nThe **`sign()`** method of the [SubtleCrypto]\ninterface generates a digital .\n\nIt takes as its arguments a  to sign with, some algorithm-specific\nparameters, and the data to sign. It returns a `Promise` which will be\nfulfilled with the signature.\n\nYou can use the corresponding [SubtleCrypto.verify] method to verify the\nsignature.",
      "unwrapkey": "\n\nThe **`unwrapKey()`** method of the [SubtleCrypto] interface \"unwraps\" a key.\nThis means that it takes as its input a key that has been exported and then encrypted (also called \"wrapped\").\nIt decrypts the key and then imports it, returning a [CryptoKey] object that can be used in the [Web Crypto API](/en-US/docs/Web/API/Web_Crypto_API).\n\nAs with [`SubtleCrypto.importKey()`](/en-US/docs/Web/API/SubtleCrypto/importKey), you specify the key's [import format](/en-US/docs/Web/API/SubtleCrypto/importKey#supported_formats) and other attributes of the key to import details such as whether it is extractable, and which operations it can be used for.\n\nBut because `unwrapKey()` also decrypts the key to be imported, you also need to pass in the key that must be used to decrypt it.\nThis is sometimes called the \"unwrapping key\".\n\nThe inverse of `unwrapKey()` is [SubtleCrypto.wrapKey]: while `unwrapKey` is composed of decrypt + import, `wrapKey` is composed of encrypt + export.",
      "verify": "\n\nThe **`verify()`** method of the [SubtleCrypto]\ninterface verifies a digital .\n\nIt takes as its arguments a  to verify the signature with, some\nalgorithm-specific parameters, the signature, and the original signed data. It returns a\n`Promise` which will be fulfilled with a boolean value\nindicating whether the signature is valid.",
      "wrapkey": "\n\nThe **`wrapKey()`** method of the [SubtleCrypto] interface \"wraps\" a key.\nThis means that it exports the key in an external, portable format, then encrypts the exported key.\nWrapping a key helps protect it in untrusted environments, such as inside an otherwise unprotected data store or in transmission over an unprotected network.\n\nAs with [SubtleCrypto.exportKey], you specify an [export format](/en-US/docs/Web/API/SubtleCrypto/importKey#supported_formats) for the key.\nTo export a key, it must have [CryptoKey.extractable] set to `true`.\n\nBut because `wrapKey()` also encrypts the key to be exported, you also need to pass in the key that must be used to encrypt it.\nThis is sometimes called the \"wrapping key\".\n\nThe inverse of `wrapKey()` is [SubtleCrypto.unwrapKey]: while `wrapKey` is composed of export + encrypt, `unwrapKey` is composed of import + decrypt."
    }
  },
  "svgaelement": {
    "docs": "\n\nThe **`SVGAElement`** interface provides access to the properties of an  element, as well as methods to manipulate them.\n\n",
    "properties": {
      "target": "\n\nThe **`SVGAElement.target`** read-only property of [SVGAElement] returns an [SVGAnimatedString] object that specifies the portion of a target window, frame, pane into which a document is to be opened when a link is activated.\n\nThis property is used when there are multiple possible targets for the ending resource, like when the parent document is a multi-frame HTML or XHTML document."
    }
  },
  "svgangle": {
    "docs": "\n\nThe `SVGAngle` interface is used to represent a value that can be an  or  value. An `SVGAngle` reflected through the `animVal` attribute is always read only.\n\nAn `SVGAngle` object can be designated as read only, which means that attempts to modify the object will result in an exception being thrown.\n\nAn `SVGAngle` object can be associated with a particular element. The associated element is used to determine which element's content attribute to update if the object reflects an attribute. Unless otherwise described, an `SVGAngle` object is not associated with any element.\n\nEvery `SVGAngle` object operates in one of two modes:\n\n1. **_Reflect the base value_** of a reflected animatable attribute (being exposed through the `baseVal` member of an [SVGAnimatedAngle]),\n2. **_Be detached_,** which is the case for `SVGAngle` objects created with [SVGSVGElement.createSVGAngle]."
  },
  "svganimatecolorelement": {
    "docs": "\n\nThe **`SVGAnimateColorElement`** interface corresponds to the `<animateColor>` element.\n\n"
  },
  "svganimatedangle": {
    "docs": ""
  },
  "svganimatedboolean": {
    "docs": ""
  },
  "svganimatedenumeration": {
    "docs": "\n\nThe **`SVGAnimatedEnumeration`** interface describes attribute values which are constants from a particular enumeration and which can be animated.",
    "properties": {
      "animval": "\n\nThe **`animVal`** property of the [SVGAnimatedEnumeration] interface contains the current value of an SVG enumeration. If there is no animation, it is the same value as the [SVGAnimatedEnumeration.baseVal].",
      "baseval": "\n\nThe **`baseVal`** property of the [SVGAnimatedEnumeration] interface contains the initial value of an SVG enumeration."
    }
  },
  "svganimatedinteger": {
    "docs": ""
  },
  "svganimatedlength": {
    "docs": "\n\nThe **`SVGAnimatedLength`** interface represents attributes of type [\\<length>](/en-US/docs/Web/SVG/Content_type#length) which can be animated.",
    "properties": {
      "animval": "\n\nThe **`animVal`** property of the [SVGAnimatedLength] interface contains the current value of an SVG enumeration. If there is no animation, it is the same value as the [SVGAnimatedLength.baseVal].",
      "baseval": "\n\nThe **`baseVal`** property of the [SVGAnimatedLength] interface contains the initial value of an SVG enumeration."
    }
  },
  "svganimatedlengthlist": {
    "docs": ""
  },
  "svganimatednumber": {
    "docs": ""
  },
  "svganimatednumberlist": {
    "docs": ""
  },
  "svganimatedpreserveaspectratio": {
    "docs": ""
  },
  "svganimatedrect": {
    "docs": "\n\nThe `SVGAnimatedRect` interface is used for attributes of basic [SVGRect] which can be animated.\n\n### Interface overview\n\n<table class=\"no-markdown\">\n  <tbody>\n    <tr>\n      <th scope=\"row\">Also implement</th>\n      <td><em>None</em></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Methods</th>\n      <td><em>None</em></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Properties</th>\n      <td>\n        <ul>\n          <li>\n            readonly [SVGRect] <code>baseVal</code>\n          </li>\n          <li>\n            readonly [SVGRect] <code>animVal</code>\n          </li>\n        </ul>\n      </td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Normative document</th>\n      <td>\n        <a\n          href=\"https://www.w3.org/TR/SVG11/types.html#InterfaceSVGAnimatedRect\"\n          >SVG 1.1 (2nd Edition)</a\n        >\n      </td>\n    </tr>\n  </tbody>\n</table>"
  },
  "svganimatedstring": {
    "docs": "\n\nThe **`SVGAnimatedString`** interface represents string attributes which can be animated from each SVG declaration. You need to create SVG attribute before doing anything else, everything should be declared inside this.",
    "properties": {
      "animval": "\n\nAnimVal attribute or animVal property contains the same value as the [SVGAnimatedString.baseVal] property. If the given attribute or property is being animated, contains the current animated value of the attribute or property. If the given attribute or property is not currently being animated, then it contains the same value as baseVal\n\n> **Note:** The **animVal** property is a read only property.",
      "baseval": "\n\nBaseVal gets or sets the base value of the given attribute before any animations are applied. The base value of the given attribute before applying any animations. Setter throws DOMException."
    }
  },
  "svganimatedtransformlist": {
    "docs": ""
  },
  "svganimateelement": {
    "docs": "\n\nThe **`SVGAnimateElement`** interface corresponds to the  element.\n\n"
  },
  "svganimatemotionelement": {
    "docs": "\n\nThe **`SVGAnimateMotionElement`** interface corresponds to the  element.\n\n"
  },
  "svganimatetransformelement": {
    "docs": "\n\nThe `SVGAnimateTransformElement` interface corresponds to the  element.\n\n"
  },
  "svganimationelement": {
    "docs": "\n\nThe **`SVGAnimationElement`** interface is the base interface for all of the animation element interfaces: [SVGAnimateElement], [SVGSetElement], [SVGAnimateColorElement], [SVGAnimateMotionElement] and [SVGAnimateTransformElement].\n\n",
    "properties": {
      "beginevent_event": "\n\nThe **`beginEvent`** event of the [SVGAnimationElement] interface is fired when the element local timeline begins to play. It will be raised each time the element begins the active duration (i.e., when it restarts, but not when it repeats).\n\nIt may be raised both in the course of normal (i.e. scheduled or interactive) timeline play, as well as in the case that the element was begun with a DOM method.\n\nThis event is not cancelable and does not bubble.",
      "endevent_event": "\n\nThe **`endEvent`** event of the [SVGAnimationElement] interface is fired when at the active end of the animation is reached.\n\n> **Note:** This event is not raised at the simple end of each animation repeat. This event may be raised both in the course of normal (i.e. scheduled or interactive) timeline play, as well as in the case that the element was ended with a DOM method.\n\nThis event is not cancelable and does not bubble.",
      "repeatevent_event": "\n\nThe **`repeatEvent`** event of the [SVGAnimationElement] interface is fired when the element's local timeline repeats. It will be fired each time the element repeats, after the first iteration.\n\n> **Note:** Associated with the `repeatEvent` event is an integer that indicates which repeat iteration is beginning; this can be found in the `detail` property of the event object. The value is a 0-based integer, but the repeat event is not raised for the first iteration and so the observed values will be >= 1. This is supported in Firefox, but not in Chrome.\n\nThis event is not cancelable and does not bubble.",
      "targetelement": "\n\nThe **`SVGAnimationElement.targetElement`** property refers to\nthe element which is being animated. If no target element is being animated (for\nexample, because the `href` attribute specifies an unknown element), the\nvalue returned is `null`."
    }
  },
  "svgcircleelement": {
    "docs": "\n\nThe **`SVGCircleElement`** interface is an interface for the  element.\n\n",
    "properties": {
      "cx": "\n\nThe **`cx`** read-only property of the [SVGCircleElement] interface reflects the `cx` attribute of a  element and by that defines the x-coordinate of the circle's center.<\n\nIf unspecified, the effect is as if the value is set to `0`.",
      "cy": "\n\nThe **`cy`** read-only property of the [SVGCircleElement] interface reflects the `cy` attribute of a  element and by that defines the y-coordinate of the circle's center.\n\nIf unspecified, the effect is as if the value is set to `0`.",
      "r": "\n\nThe **`r`** read-only property of the [SVGCircleElement] interface reflects the `r` attribute of a  element and by that defines the radius of the circle.\n\nIf unspecified, the effect is as if the value is set to `0`."
    }
  },
  "svgclippathelement": {
    "docs": "\n\nThe **`SVGClipPathElement`** interface provides access to the properties of  elements, as well as methods to manipulate them.\n\n",
    "properties": {
      "clippathunits": "\n\nThe read-only **`clipPathUnits`** property of the [SVGClipPathElement] interface reflects the `clipPathUnits` attribute of a  element which defines the coordinate system to use for the content of the element.\n\n> **Note:** Although this property is read-only, it is merely a container for two values you can modify, [SVGAnimatedEnumeration.baseVal] and [SVGAnimatedEnumeration.animVal].",
      "transform": "\n\nThe read-only **`transform`** property of the [SVGClipPathElement] interface reflects the `transform` attribute of a  element, that is a list of transformations applied to the element."
    }
  },
  "svgcomponenttransferfunctionelement": {
    "docs": "\n\nThe **`SVGComponentTransferFunctionElement`** interface defines a base interface used by the component transfer function interfaces.\n\n"
  },
  "svgcursorelement": {
    "docs": "\n\nThe **`SVGCursorElement`** interface provides access to the properties of  elements, as well as methods to manipulate them.\n\n"
  },
  "svgdefselement": {
    "docs": "\n\nThe **`SVGDefsElement`** interface corresponds to the  element.\n\n"
  },
  "svgdescelement": {
    "docs": "\n\nThe **`SVGDescElement`** interface corresponds to the  element.\n\n"
  },
  "svgelement": {
    "docs": "\n\nAll of the SVG DOM interfaces that correspond directly to elements in the SVG language derive from the `SVGElement` interface.\n\n",
    "properties": {
      "error_event": "\n\nThe `error` event is fired when an SVG element does not load properly or when an error occurs during script execution.\n\nThis basically implements the standard `error` DOM event.\n\nThis event is not cancelable.",
      "load_event": "\n\nThe `load` event fires on an `SVGElement` when it is loaded in the browser, e.g. in the DOM in the case of an embedded `<svg>`. It is basically the same as the standard `load` DOM event.\n\nThis event is not cancelable and does not bubble.",
      "style": "\n\nThe read-only **`style`** property of the [SVGElement] returns the _inline_ style of an element in the form of a live [CSSStyleDeclaration] object that contains a list of all styles properties for that element with values assigned only for the attributes that are defined in the element's inline [`style`](/en-US/docs/Web/HTML/Global_attributes/style) attribute.\n\nShorthand properties are expanded. If you set `style=\"border-top: 1px solid black\"`, the longhand properties (, , and ) are set instead.\n\nThis property is read-only, meaning it is not possible to assign a [CSSStyleDeclaration] object to it. Nevertheless, it is possible to set an inline style by assigning a _string_ directly to the `style` property. In this case the string is forwarded to [CSSStyleDeclaration.cssText]. Using `style` in this manner will completely overwrite all inline styles on the element.\n\nTherefore, to add specific styles to an element without altering other style values, it is generally preferable to set individual properties on the [CSSStyleDeclaration] object. For example, you can write `element.style.backgroundColor = \"red\"`.\n\nA style declaration is reset by setting it to `null` or an empty string, e.g., `elt.style.color = null`.\n\n> **Note:** CSS property names are converted to JavaScript identifier with these rules:\n>\n> - If the property is made of one word, it remains as it is: `height` stays as is (in lowercase).\n> - If the property is made of several words, separated by dashes, the dashes are removed and it is converted to : `background-attachment` becomes `backgroundAttachment`.\n> - The property `float`, being a reserved JavaScript keyword, is converted to `cssFloat`.\n>\n> The `style` property has the same priority in the CSS cascade as an inline style declaration set via the `style` attribute."
    }
  },
  "svgellipseelement": {
    "docs": "\n\nThe **`SVGEllipseElement`** interface provides access to the properties of  elements.\n\n"
  },
  "svgevent": {
    "docs": "\n\nThe [SVGEvent] interface represents the event object for most SVG-related events."
  },
  "svgfeblendelement": {
    "docs": "\n\nThe **`SVGFEBlendElement`** interface corresponds to the  element.\n\n"
  },
  "svgfecolormatrixelement": {
    "docs": "\n\nThe **`SVGFEColorMatrixElement`** interface corresponds to the  element.\n\n"
  },
  "svgfecomponenttransferelement": {
    "docs": "\n\nThe **`SVGFEComponentTransferElement`** interface corresponds to the  element.\n\n"
  },
  "svgfecompositeelement": {
    "docs": "\n\nThe **`SVGFECompositeElement`** interface corresponds to the  element.\n\n"
  },
  "svgfeconvolvematrixelement": {
    "docs": "\n\nThe **`SVGFEConvolveMatrixElement`** interface corresponds to the  element.\n\n"
  },
  "svgfediffuselightingelement": {
    "docs": "\n\nThe **`SVGFEDiffuseLightingElement`** interface corresponds to the  element.\n\n"
  },
  "svgfedisplacementmapelement": {
    "docs": "\n\nThe **`SVGFEDisplacementMapElement`** interface corresponds to the  element.\n\n"
  },
  "svgfedistantlightelement": {
    "docs": "\n\nThe **`SVGFEDistantLightElement`** interface corresponds to the  element.\n\n"
  },
  "svgfedropshadowelement": {
    "docs": "\n\nThe **`SVGFEDropShadowElement`** interface corresponds to the  element.\n\n"
  },
  "svgfefloodelement": {
    "docs": "\n\nThe **`SVGFEFloodElement`** interface corresponds to the  element.\n\n"
  },
  "svgfefuncaelement": {
    "docs": "\n\nThe **`SVGFEFuncAElement`** interface corresponds to the  element.\n\n"
  },
  "svgfefuncbelement": {
    "docs": "\n\nThe **`SVGFEFuncBElement`** interface corresponds to the  element.\n\n"
  },
  "svgfefuncgelement": {
    "docs": "\n\nThe **`SVGFEFuncGElement`** interface corresponds to the  element.\n\n"
  },
  "svgfefuncrelement": {
    "docs": "\n\nThe **`SVGFEFuncRElement`** interface corresponds to the  element.\n\n"
  },
  "svgfegaussianblurelement": {
    "docs": "\n\nThe **`SVGFEGaussianBlurElement`** interface corresponds to the  element.\n\n"
  },
  "svgfeimageelement": {
    "docs": "\n\nThe **`SVGFEImageElement`** interface corresponds to the  element.\n\n"
  },
  "svgfemergeelement": {
    "docs": "\n\nThe **`SVGFEMergeElement`** interface corresponds to the  element.\n\n"
  },
  "svgfemergenodeelement": {
    "docs": "\n\nThe **`SVGFEMergeNodeElement`** interface corresponds to the  element.\n\n"
  },
  "svgfemorphologyelement": {
    "docs": "\n\nThe **`SVGFEMorphologyElement`** interface corresponds to the  element.\n\n"
  },
  "svgfeoffsetelement": {
    "docs": "\n\nThe **`SVGFEOffsetElement`** interface corresponds to the  element.\n\n"
  },
  "svgfepointlightelement": {
    "docs": "\n\nThe **`SVGFEPointLightElement`** interface corresponds to the  element.\n\n"
  },
  "svgfespecularlightingelement": {
    "docs": "\n\nThe **`SVGFESpecularLightingElement`** interface corresponds to the  element.\n\n"
  },
  "svgfespotlightelement": {
    "docs": "\n\nThe **`SVGFESpotLightElement`** interface corresponds to the  element.\n\n"
  },
  "svgfetileelement": {
    "docs": "\n\nThe **`SVGFETileElement`** interface corresponds to the  element.\n\n"
  },
  "svgfeturbulenceelement": {
    "docs": "\n\nThe **`SVGFETurbulenceElement`** interface corresponds to the  element.\n\n"
  },
  "svgfilterelement": {
    "docs": "\n\nThe **`SVGFilterElement`** interface provides access to the properties of  elements, as well as methods to manipulate them.\n\n"
  },
  "svgfontelement": {
    "docs": "\n\nThe **`SVGFontElement`** interface corresponds to the  elements.\n\nObject-oriented access to the attributes of the  element via the SVG DOM is not possible.\n\n"
  },
  "svgfontfaceelement": {
    "docs": "\n\nThe **`SVGFontFaceElement`** interface corresponds to the  elements.\n\nObject-oriented access to the attributes of the  element via the SVG DOM is not possible.\n\n"
  },
  "svgfontfaceformatelement": {
    "docs": "\n\nThe **`SVGFontFaceFormatElement`** interface corresponds to the  elements.\n\nObject-oriented access to the attributes of the  element via the SVG DOM is not possible.\n\n"
  },
  "svgfontfacenameelement": {
    "docs": "\n\nThe **`SVGFontFaceNameElement`** interface corresponds to the  elements.\n\nObject-oriented access to the attributes of the  element via the SVG DOM is not possible.\n\n"
  },
  "svgfontfacesrcelement": {
    "docs": "\n\nThe **`SVGFontFaceSrcElement`** interface corresponds to the  elements.\n\nObject-oriented access to the attributes of the  element via the SVG DOM is not possible.\n\n"
  },
  "svgfontfaceurielement": {
    "docs": "\n\nThe **`SVGFontFaceUriElement`** interface corresponds to the  elements.\n\nObject-oriented access to the attributes of the  element via the SVG DOM is not possible.\n\n"
  },
  "svgforeignobjectelement": {
    "docs": "\n\nThe **`SVGForeignObjectElement`** interface provides access to the properties of  elements, as well as methods to manipulate them.\n\n"
  },
  "svggelement": {
    "docs": "\n\nThe **`SVGGElement`** interface corresponds to the  element.\n\n"
  },
  "svggeometryelement": {
    "docs": "\n\nThe `SVGGeometryElement` interface represents SVG elements whose rendering is defined by geometry with an equivalent path, and which can be filled and stroked. This includes paths and the basic shapes.\n\n",
    "properties": {
      "getpointatlength": "\n\nThe\n**`SVGGeometryElement.getPointAtLength()`** method returns the\npoint at a given distance along the path.",
      "gettotallength": "\n\nThe **`SVGGeometryElement.getTotalLength()`** method returns\nthe user agent's computed value for the total length of the path in user units.",
      "ispointinfill": "\n\nThe **`SVGGeometryElement.isPointInFill()`** method determines\nwhether a given point is within the fill shape of an element. Normal hit testing rules\napply; the value of the  property on the element determines\nwhether a point is considered to be within the fill. The `point` argument is\ninterpreted as a point in the local coordinate system of the element.",
      "ispointinstroke": "\n\nThe **`SVGGeometryElement.isPointInStroke()`** method\ndetermines whether a given point is within the stroke shape of an element. Normal hit\ntesting rules apply; the value of the  property on the\nelement determines whether a point is considered to be within the stroke. The\n`point` argument is interpreted as a point in the local coordinate system of\nthe element.",
      "pathlength": "\n\nThe **`SVGGeometryElement.pathLength`** property reflects the\n`pathLength` attribute and returns the total length of the path, in user units."
    }
  },
  "svgglyphelement": {
    "docs": "\n\nThe **`SVGGlyphElement`** interface corresponds to the  element.\n\nObject-oriented access to the attributes of the `<glyph>` element via the SVG DOM is not possible.\n\n> **Warning:** This interface was removed in the SVG 2 specification."
  },
  "svgglyphrefelement": {
    "docs": "\n\nThe **`SVGGlyphRefElement`** interface corresponds to the  elements.\n\n"
  },
  "svggradientelement": {
    "docs": "\n\nThe **`SVGGradient`** interface is a base interface used by [SVGLinearGradientElement] and [SVGRadialGradientElement].\n\n"
  },
  "svggraphicselement": {
    "docs": "\n\nThe **`SVGGraphicsElement`** interface represents SVG elements whose primary purpose is to directly render graphics into a group.\n\n",
    "properties": {
      "copy_event": "\n\nThe **`copy`** event fires on [SVGGraphicsElement] when the user initiates a copy action through the browser's user interface.\n\nThe event's default action is to copy the selection (if any) to the clipboard.\n\nA handler for this event can _modify_ the clipboard contents by calling [DataTransfer.setData] on the event's [ClipboardEvent.clipboardData] property, and cancelling the event's default action using [`event.preventDefault()`](/en-US/docs/Web/API/Event/preventDefault).\n\nHowever, the handler cannot _read_ the clipboard data.\n\nIt's possible to construct and dispatch a [synthetic](/en-US/docs/Web/Events/Creating_and_triggering_events) `copy` event, but this will not affect the system clipboard.",
      "cut_event": "\n\nThe **`cut`** event is fired on an [SVGGraphicsElement] when the user has initiated a \"cut\" action through the browser's user interface.\n\nIf the user attempts a cut action on uneditable content, the `cut` event still fires but the event object contains no data.\n\nThe event's default action is to copy the current selection (if any) to the system clipboard and remove it from the document.\n\nA handler for this event can _modify_ the clipboard contents by calling [`setData(format, data)`](/en-US/docs/Web/API/DataTransfer/setData) on the event's [`ClipboardEvent.clipboardData`](/en-US/docs/Web/API/ClipboardEvent/clipboardData) property, and cancelling the default action using [`event.preventDefault()`](/en-US/docs/Web/API/Event/preventDefault).\n\nNote though that cancelling the default action will also prevent the document from being updated. So an event handler which wants to emulate the default action for \"cut\" while modifying the clipboard must also manually remove the selection from the document.\n\nThe handler cannot _read_ the clipboard data.\n\nIt's possible to construct and dispatch a [synthetic](/en-US/docs/Web/Events/Creating_and_triggering_events) `cut` event, but this will not affect the system clipboard or the document's contents.",
      "getbbox": "\n\nThe **`SVGGraphicsElement.getBBox()`** method allows us to determine\nthe coordinates of the smallest rectangle in which the object fits. The coordinates\nreturned are with respect to the current SVG space (after the application of all\ngeometry attributes on all the elements contained in the target element).\n\n> **Note:** `getBBox()` must return the actual bounding box at\n> the time the method was called—even in case the element has not yet been rendered. It\n> also does not account for any transformation applied to the element or its parents.\n\n> **Note:** `getBBox` returns different values than\n> [Element.getBoundingClientRect], as the\n> latter returns value relative to the viewport",
      "paste_event": "\n\nThe **`paste`** event is fired on an [SVGGraphicsElement] when the user has initiated a \"paste\" action through the browser's user interface.\n\nIf the cursor is in an editable context (for example, in a `textarea` or an element with [`contenteditable`](/en-US/docs/Web/HTML/Global_attributes/contenteditable) attribute set to `true`) then the default action is to insert the contents of the clipboard into the document at the cursor position.\n\nA handler for this event can access the clipboard contents by calling [DataTransfer/getData] on the event's `clipboardData` property.\n\nTo override the default behavior (for example to insert some different data or a transformation of the clipboard contents) an event handler must cancel the default action using [Event/preventDefault], and then insert its desired data manually.\n\nIt's possible to construct and dispatch a [synthetic](/en-US/docs/Web/Events/Creating_and_triggering_events) `paste` event, but this will not affect the document's contents."
    }
  },
  "svghkernelement": {
    "docs": "\n\nThe **`SVGHKernElement`** interface corresponds to the  elements.\n\nObject-oriented access to the attributes of the  element via the SVG DOM is not possible.\n\n"
  },
  "svgimageelement": {
    "docs": "\n\nThe **`SVGImageElement`** interface corresponds to the  element.\n\n",
    "properties": {
      "decode": "\n\nThe **`decode()`** method of the\n[SVGImageElement] interface initiates asynchronous decoding of an image,\nreturning a `Promise` that resolves once the image is decoded and it is safe to append\nit to the DOM.",
      "decoding": "\n\nThe **`decoding`** property of the [SVGImageElement] interface provides a hint to the browser as to whether it should perform image decoding synchronously or asynchronously.",
      "height": "\n\nThe **`height`** read-only property of the\n[SVGImageElement] interface returns an [SVGAnimatedLength]\ncorresponding to the `height` attribute of the given\n element.",
      "preserveaspectratio": "\n\nThe **`preserveAspectRatio`** read-only\nproperty of the [SVGImageElement] interface returns an\n[SVGAnimatedPreserveAspectRatio] corresponding to the\n`preserveAspectRatio` attribute of the given \nelement.",
      "width": "\n\nThe **`width`** read-only property of the\n[SVGImageElement] interface returns an [SVGAnimatedLength]\ncorresponding to the `width` attribute of the given \nelement.",
      "x": "\n\nThe **`x`** read-only property of the\n[SVGImageElement] interface returns an [SVGAnimatedLength]\ncorresponding to the `x` attribute of the given \nelement.",
      "y": "\n\nThe **`y`** read-only property of the\n[SVGImageElement] interface returns an [SVGAnimatedLength]\ncorresponding to the `y` attribute of the given \nelement."
    }
  },
  "svglength": {
    "docs": ""
  },
  "svglengthlist": {
    "docs": ""
  },
  "svglineargradientelement": {
    "docs": "\n\nThe **`SVGLinearGradientElement`** interface corresponds to the  element.\n\n"
  },
  "svglineelement": {
    "docs": "\n\nThe **`SVGLineElement`** interface provides access to the properties of  elements, as well as methods to manipulate them.\n\n"
  },
  "svgmarkerelement": {
    "docs": "\n\nThe **`SVGMarkerElement`** interface provides access to the properties of  elements, as well as methods to manipulate them. The  element defines the graphics used for drawing marks on a shape.\n\nThe following properties and methods all return, or act on the attributes of the  element represented by `SVGMarkerElement`.",
    "properties": {
      "markerheight": "\n\nThe **`markerHeight`** read-only property of the [SVGMarkerElement] interface returns an [SVGAnimatedLength] object containing the height of the  viewport as defined by the `markerHeight` attribute.",
      "markerunits": "\n\nThe **`markerUnits`** read-only property of the [SVGMarkerElement] interface returns an [SVGAnimatedEnumeration] object. This object returns an integer which represents the keyword values that the `markerUnits` attribute accepts.",
      "markerwidth": "\n\nThe **`markerWidth`** read-only property of the [SVGMarkerElement] interface returns an [SVGAnimatedLength] object containing the width of the  viewport as defined by the `markerWidth` attribute.",
      "orientangle": "\n\nThe **`orientAngle`** read-only property of the [SVGMarkerElement] interface returns an [SVGAnimatedAngle] object containing the angle of the `orient` attribute.",
      "orienttype": "\n\nThe **`orientType`** read-only property of the [SVGMarkerElement] interface returns an [SVGAnimatedEnumeration] object indicating whether the `orient` attribute is `auto`, an angle value, or something else.\n\nThis _something else_ is most likely to be the keyword `auto-start-reverse` however the spec leaves it open for this to be other values. Unsupported values will generally be thrown away by the parser, leaving the value the default of `auto`.",
      "preserveaspectratio": "\n\nThe **`preserveAspectRatio`** read-only property of the [SVGMarkerElement] interface returns an [SVGAnimatedPreserveAspectRatio] object containing the value of the `preserveAspectRatio` attribute of the .",
      "refx": "\n\nThe **`refX`** read-only property of the [SVGMarkerElement] interface returns an [SVGAnimatedLength] object containing the value of the `refX` attribute of the .",
      "refy": "\n\nThe **`refY`** read-only property of the [SVGMarkerElement] interface returns an [SVGAnimatedLength] object containing the value of the `refY` attribute of the .",
      "setorienttoangle": "\n\nThe **`setOrientToAngle()`** method of the [SVGMarkerElement] interface sets the value of the `orient` attribute to the value in the [SVGAngle] passed in.",
      "setorienttoauto": "\n\nThe **`setOrientToAuto()`** method of the [SVGMarkerElement] interface sets the value of the `orient` attribute to `auto`.",
      "viewbox": "\n\nThe **`viewBox`** read-only property of the [SVGMarkerElement] interface returns an [SVGAnimatedRect] object which contains the values set by the `viewBox` attribute on the ."
    }
  },
  "svgmaskelement": {
    "docs": "\n\nThe **`SVGMaskElement`** interface provides access to the properties of  elements, as well as methods to manipulate them.\n\n",
    "properties": {
      "height": "\n\nThe read-only **`height`** property of the [SVGMaskElement] interface returns an [SVGAnimatedLength] object containing the value of the `height` attribute of the .\n\n> **Note:** Although this property is read-only, it is merely a container for two values you can modify, [SVGAnimatedLength.baseVal] and [SVGAnimatedLength.animVal].",
      "maskcontentunits": "\n\nThe read-only **`maskContentUnits`** property of the [SVGMaskElement] interface reflects the `maskContentUnits` attribute. It indicates which coordinate system to use for the contents of the  element.\n\n> **Note:** Although this property is read-only, it is merely a container for two values you can modify, [SVGAnimatedEnumeration.baseVal] and [SVGAnimatedEnumeration.animVal].",
      "maskunits": "\n\nThe read-only **`maskUnits`** property of the [SVGMaskElement] interface reflects the `maskUnits` attribute of a  element which defines the coordinate system to use for the mask of the element.\n\n> **Note:** Although this property is read-only, it is merely a container for two values you can modify, [SVGAnimatedEnumeration.baseVal] and [SVGAnimatedEnumeration.animVal].",
      "width": "\n\nThe read-only **`width`** property of the [SVGMaskElement] interface returns an [SVGAnimatedLength] object containing the value of the `width` attribute of the .\n\n> **Note:** Although this property is read-only, it is merely a container for two values you can modify, [SVGAnimatedLength.baseVal] and [SVGAnimatedLength.animVal].",
      "x": "\n\nThe read-only **`x`** property of the [SVGMaskElement] interface returns an [SVGAnimatedLength] object containing the value of the `x` attribute of the . It represents the x-axis coordinate of the _top-left_ corner of the masking area.\n\n> **Note:** Although this property is read-only, it is merely a container for two values you can modify, [SVGAnimatedLength.baseVal] and [SVGAnimatedLength.animVal].",
      "y": "\n\nThe read-only **`y`** property of the [SVGMaskElement] interface returns an [SVGAnimatedLength] object containing the value of the `y` attribute of the . It represents the y-axis coordinate of the _top-left_ corner of the masking area.\n\n> **Note:** Although this property is read-only, it is merely a container for two values you can modify, [SVGAnimatedLength.baseVal] and [SVGAnimatedLength.animVal]."
    }
  },
  "svgmetadataelement": {
    "docs": "\n\nThe **`SVGMetadataElement`** interface corresponds to the  element.\n\n"
  },
  "svgmissingglyphelement": {
    "docs": "\n\nThe **`SVGMissingGlyphElement`** interface corresponds to the  elements.\n\nObject-oriented access to the attributes of the  element via the SVG DOM is not possible.\n\n"
  },
  "svgmpathelement": {
    "docs": "\n\nThe **`SVGMPathElement`** interface corresponds to the  element.\n\n"
  },
  "svgnumber": {
    "docs": "\n\nThe **`SVGNumber`** interface corresponds to the  basic data type.\n\nAn `SVGNumber` object can be designated as read only, which means that attempts to modify the object will result in an exception being thrown."
  },
  "svgnumberlist": {
    "docs": ""
  },
  "svgpathelement": {
    "docs": "\n\nThe **`SVGPathElement`** interface corresponds to the  element.\n\n> **Note:** In SVG 2 the `getPathSegAtLength()` and `createSVGPathSeg*` methods were removed and the `pathLength` property and the `getTotalLength()` and `getPointAtLength()` methods were moved to [SVGGeometryElement]."
  },
  "svgpatternelement": {
    "docs": "\n\nThe **`SVGPatternElement`** interface corresponds to the  element.\n\n"
  },
  "svgpoint": {
    "docs": "\n\n> **Warning:** `SVGPoint` is deprecated.\n> Use [DOMPoint] or [DOMPointReadOnly] instead.\n\nAn `SVGPoint` represents a 2D or 3D point in the SVG coordinate system."
  },
  "svgpointlist": {
    "docs": "\n\nThe **`SVGPointList`** interface represents a list of [SVGPoint] objects.\n\nAn `SVGPointList` can be designated as read-only, which means that attempts to modify the object will result in an exception being thrown.",
    "properties": {
      "appenditem": "\n\nThe **`appendItem()`** method of the [SVGPointList] interface adds a [SVGPoint] to the end of the list.",
      "clear": "\n\nThe **`clear()`** method of the [SVGPointList] interface removes all items from the list.",
      "getitem": "\n\nThe **`getItem()`** method of the [SVGPointList] interface gets one item from the list at the specified index.",
      "initialize": "\n\nThe **`initialize()`** method of the [SVGPointList] interface clears the list then adds a single new [SVGPoint] object to the list.",
      "insertitembefore": "\n\nThe **`insertItemBefore()`** method of the [SVGPointList] interface inserts a [SVGPoint] before another item in the list.",
      "length": "\n\nThe **`length`** read-only property of the [SVGPointList] interface returns the number of items in the list.",
      "numberofitems": "\n\nThe **`numberOfItems`** read-only property of the [SVGPointList] interface returns the number of items in the list.",
      "removeitem": "\n\nThe **`removeItem()`** method of the [SVGPointList] interface removes a [SVGPoint] from the list.",
      "replaceitem": "\n\nThe **`replaceItem()`** method of the [SVGPointList] interface replaces a [SVGPoint] in the list."
    }
  },
  "svgpolygonelement": {
    "docs": "\n\nThe **`SVGPolygonElement`** interface provides access to the properties of  elements, as well as methods to manipulate them.\n\n"
  },
  "svgpolylineelement": {
    "docs": "\n\nThe **`SVGPolylineElement`** interface provides access to the properties of  elements, as well as methods to manipulate them.\n\n"
  },
  "svgpreserveaspectratio": {
    "docs": ""
  },
  "svgradialgradientelement": {
    "docs": "\n\nThe **`SVGRadialGradientElement`** interface corresponds to the  element.\n\n"
  },
  "svgrect": {
    "docs": "\n\nThe **`SVGRect`** represents a rectangle. Rectangles consist of an `x` and `y` coordinate pair identifying a minimum `x` value, a minimum `y` value, and a `width` and `height`, which are constrained to be non-negative.\n\nAn **`SVGRect`** object can be designated as read only, which means that attempts to modify the object will result in an exception being thrown.",
    "properties": {
      "the__x__property": "\n\nThe [x](https://svgwg.org/svg2-draft/geometry.html#XProperty) property describes the horizontal coordinate of the position of the element."
    }
  },
  "svgrectelement": {
    "docs": "\n\nThe `SVGRectElement` interface provides access to the properties of  elements, as well as methods to manipulate them.\n\n"
  },
  "svgrenderingintent": {
    "docs": "\n\nThe **`SVGRenderingIntent`** interface defines the enumerated list of possible values for  attributes or descriptors.\n\n> **Warning:** This interface was removed in the SVG 2 specification."
  },
  "svgscriptelement": {
    "docs": "\n\nThe **`SVGScriptElement`** interface corresponds to the SVG  element.\n\n"
  },
  "svgsetelement": {
    "docs": "\n\nThe **`SVGSetElement`** interface corresponds to the  element.\n\n"
  },
  "svgstopelement": {
    "docs": "\n\nThe **`SVGStopElement`** interface corresponds to the  element.\n\n"
  },
  "svgstringlist": {
    "docs": ""
  },
  "svgstyleelement": {
    "docs": "\n\nThe **`SVGStyleElement`** interface corresponds to the SVG  element.\n\n",
    "properties": {
      "disabled": "\n\nThe **`SVGStyleElement.disabled`** property can be used to get and set whether the stylesheet is disabled (`true`) or not (`false`).\n\nNote that there is no corresponding `disabled` attribute on the [SVG `<style>` element](/en-US/docs/Web/SVG/Element/style).",
      "media": "\n\nThe **`SVGStyleElement.media`** property is a media query string corresponding to the [`media`](/en-US/docs/Web/SVG/Element/style#media) attribute of the given SVG style element.\n\nThe query must be matched for the style to apply.",
      "sheet": "\n\nThe **`SVGStyleElement.sheet`** read-only property returns the [CSSStyleSheet] corresponding to the given SVG style element, or `null` if there is none.",
      "title": "\n\nThe **`SVGStyleElement.title`** property is a string corresponding to the [`title`](/en-US/docs/Web/SVG/Element/style#title) attribute of the given SVG style element.\nIt may be used to select between [alternate style sheets](/en-US/docs/Web/CSS/Alternative_style_sheets).",
      "type": " \n\nThe **`SVGStyleElement.type`** property returns the type of the current style.\nThe value reflects the associated SVG `<style>` element's [`type`](/en-US/docs/Web/SVG/Element/style#type) attribute.\n\nAuthors should not use this property or rely on the value."
    }
  },
  "svgsvgelement": {
    "docs": "\n\nThe **`SVGSVGElement`** interface provides access to the properties of  elements, as well as methods to manipulate them. This interface contains also various miscellaneous commonly-used utility methods, such as matrix operations and the ability to control the time of redraw on visual rendering devices.\n\n"
  },
  "svgswitchelement": {
    "docs": "\n\nThe **`SVGSwitchElement`** interface corresponds to the  element.\n\n"
  },
  "svgsymbolelement": {
    "docs": "\n\nThe **`SVGSymbolElement`** interface corresponds to the  element.\n\n"
  },
  "svgtextcontentelement": {
    "docs": "\n\nThe **`SVGTextContentElement`** interface is implemented by elements that support rendering child text content. It is inherited by various text-related interfaces, such as [SVGTextElement], [SVGTSpanElement], [SVGTRefElement], and [SVGTextPathElement].\n\n"
  },
  "svgtextelement": {
    "docs": "\n\nThe **`SVGTextElement`** interface corresponds to the  elements.\n\n"
  },
  "svgtextpathelement": {
    "docs": "\n\nThe **`SVGTextPathElement`** interface corresponds to the  element.\n\n"
  },
  "svgtextpositioningelement": {
    "docs": "\n\nThe **`SVGTextPositioningElement`** interface is implemented by elements that support attributes that position individual text glyphs. It is inherited by [SVGTextElement], [SVGTSpanElement], and [SVGTRefElement].\n\n"
  },
  "svgtitleelement": {
    "docs": "\n\nThe **`SVGTitleElement`** interface corresponds to the  element.\n\n"
  },
  "svgtransform": {
    "docs": ""
  },
  "svgtransformlist": {
    "docs": ""
  },
  "svgtrefelement": {
    "docs": "\n\nThe **`SVGTRefElement`** interface corresponds to the  elements.\n\nObject-oriented access to the attributes of the  element via the SVG DOM is not possible.\n\n"
  },
  "svgtspanelement": {
    "docs": "\n\nThe **`SVGTSpanElement`** interface represents a  element.\n\n"
  },
  "svgunittypes": {
    "docs": "\n\nThe **`SVGUnitTypes`** interface defines a commonly used set of constants used for reflecting `gradientUnits`, `patternContentUnits` and other similar attributes.\n\n"
  },
  "svguseelement": {
    "docs": ""
  },
  "svgviewelement": {
    "docs": "\n\nThe **`SVGViewElement`** interface provides access to the properties of  elements, as well as methods to manipulate them.\n\n"
  },
  "svgvkernelement": {
    "docs": "\n\nThe **`SVGVKernElement`** interface corresponds to the  elements.\n\nObject-oriented access to the attributes of the  element via the SVG DOM is not possible.\n\n"
  },
  "syncevent": {
    "docs": "\n\nThe **`SyncEvent`** interface represents a sync action that is dispatched on the [ServiceWorkerGlobalScope] of a ServiceWorker.\n\nThis interface inherits from the [ExtendableEvent] interface.\n\n",
    "properties": {
      "lastchance": "\n\nThe **`SyncEvent.lastChance`** read-only property of the\n[SyncEvent] interface returns `true` if the user agent will not\nmake further synchronization attempts after the current attempt. This is the value\npassed in the `lastChance` parameter of the\n[SyncEvent.SyncEvent] constructor.",
      "tag": "\n\nThe **`SyncEvent.tag`** read-only property of the\n[SyncEvent] interface returns the developer-defined identifier for\nthis `SyncEvent`. This is the value passed in the `tag` parameter\nof the [SyncEvent.SyncEvent] constructor."
    }
  },
  "syncmanager": {
    "docs": "\n\nThe **`SyncManager`** interface of the [ServiceWorker API](/en-US/docs/Web/API/Service_Worker_API) provides an interface for registering and listing sync registrations.",
    "properties": {
      "gettags": "\n\nThe **`SyncManager.getTags`** method of the\n[SyncManager] interface returns a list of developer-defined identifiers for\n`SyncManager` registrations.",
      "register": "\n\nThe **`SyncManager.register`** method of the [SyncManager] interface registers a synchronization event, triggering a [ServiceWorkerGlobalScope.sync_event] event inside the associated service worker as soon as network connectivity is available."
    }
  },
  "taskattributiontiming": {
    "docs": "\n\nThe **`TaskAttributionTiming`** interface returns information about the work involved in a long task and its associate frame context. The frame context, also called the container, is the iframe, embed or object that is being implicated, on the whole, for a long task.\n\nYou usually work with `TaskAttributionTiming` objects when observing [long tasks](/en-US/docs/Web/API/PerformanceLongTaskTiming).\n\n`TaskAttributionTiming` inherits from [PerformanceEntry].\n\n",
    "properties": {
      "containerid": "\n\nThe **`containerId`** readonly property of the [TaskAttributionTiming] interface returns the container's `id`\nattribute. A container is the iframe, embed or object etc. that is being implicated, on the whole, for a long task.",
      "containername": "\n\nThe **`containerName`** readonly property of the [TaskAttributionTiming] interface returns the container's `name`\nattribute. A container is the iframe, embed or object etc. that is being implicated, on the whole, for a long task.",
      "containersrc": "\n\nThe **`containerSrc`** readonly property of the [TaskAttributionTiming] interface returns the container's `src`\nattribute. A container is the iframe, embed or object etc. that is being implicated, on the whole, for a long task.",
      "containertype": "\n\nThe **`containerType`** readonly property of the [TaskAttributionTiming] interface returns the type of the container, one of `iframe`, `embed`, or `object`.",
      "tojson": "\n\nThe **`toJSON()`** method of the [TaskAttributionTiming] interface is a ; it returns a JSON representation of the [TaskAttributionTiming] object."
    }
  },
  "taskcontroller": {
    "docs": "\n\nThe **`TaskController`** interface of the [Prioritized Task Scheduling API](/en-US/docs/Web/API/Prioritized_Task_Scheduling_API) represents a controller object that can be used to both abort and change the [priority](/en-US/docs/Web/API/Prioritized_Task_Scheduling_API#task_priorities) of one or more prioritized tasks.\nIf there is no need to change task priorities, then [AbortController] can be used instead.\n\nA new `TaskController` instance is created using the [TaskController.TaskController] constructor, optionally specifying a [priority](/en-US/docs/Web/API/Prioritized_Task_Scheduling_API#task_priorities) for its associated signal (a [TaskSignal]).\nIf not specified, the signal will have a priority of [`\"user-visible\"`](/en-US/docs/Web/API/Prioritized_Task_Scheduling_API#user-visible) by default.\n\nThe controller's signal can be passed as an argument to the [Scheduler.postTask] method for one or more tasks.\nFor [mutable tasks](/en-US/docs/Web/API/Prioritized_Task_Scheduling_API#mutable_and_immutable_task_priority) (only) the task is initialized with the signal priority, and can later be changed by calling [TaskController.setPriority].\nFor immutable tasks, any priority initialized or set by the controller is ignored.\n\nTasks can be aborted by calling [AbortController.abort] on the controller.\n\n",
    "properties": {
      "setpriority": "\n\nThe **`setPriority()`** method of the [TaskController] interface can be called to set a new [priority](/en-US/docs/Web/API/Prioritized_Task_Scheduling_API#task_priorities) for this controller's [`signal`](/en-US/docs/Web/API/TaskController#taskcontroller.signal).\nIf a prioritized task is [configured](/en-US/docs/Web/API/Scheduler/postTask#signal) to use the signal, this will also change the task priority.\n\nObservers are notified of priority changes by dispatching a [`prioritychange`](/en-US/docs/Web/API/TaskSignal/prioritychange_event) event.\nThe method will only notify if the priority actually changes (the event is not fired if the priority would not be changed by the call).\n\nNote that task priority can only be changed for [tasks with mutable priorities](/en-US/docs/Web/API/Prioritized_Task_Scheduling_API#mutable_and_immutable_task_priority).\nIf the task is immutable, the function call is ignored."
    }
  },
  "taskprioritychangeevent": {
    "docs": "\n\nThe **`TaskPriorityChangeEvent`** is the interface for the [`prioritychange`](/en-US/docs/Web/API/TaskSignal/prioritychange_event) event.\n\n",
    "properties": {
      "previouspriority": "\n\nThe readonly **`previousPriority`** property of the [TaskPriorityChangeEvent] interface returns the priority of the corresponding [TaskSignal] before it was changed and this [`prioritychange`](/en-US/docs/Web/API/TaskSignal/prioritychange_event) event was emitted.\n\nThis is the value that was set in the [`TaskPriorityChangeEvent` constructor](/en-US/docs/Web/API/TaskPriorityChangeEvent/TaskPriorityChangeEvent) argument `options.previous`. <!-- link? -->\n\nThe new priority of the task can be read from `event.target.priority`."
    }
  },
  "tasksignal": {
    "docs": "\n\nThe **`TaskSignal`** interface of the [Prioritized Task Scheduling API](/en-US/docs/Web/API/Prioritized_Task_Scheduling_API) represents a signal object that allows you to communicate with a prioritized task, and abort it or change the [priority](/en-US/docs/Web/API/Prioritized_Task_Scheduling_API#task_priorities) (if required) via a [TaskController] object.\n\nAn object of this type is created, and associated with, a [TaskController].\nThe initial priority of the signal may be set by specifying it as an argument to the [TaskController.TaskController] constructor (by default it is `\"user-visible\"`).\nThe priority can be changed by calling [TaskController.setPriority] on the controller.\n\nThe signal may be passed as the `options.signal` argument in [Scheduler.postTask], after which it's associated controller can be used to abort the task.\nIf the [task priority is mutable](/en-US/docs/Web/API/Prioritized_Task_Scheduling_API#mutable_and_immutable_task_priority), the controller can also be used to change the task's priority.\nAbortable tasks that do not need the priority to change may instead specify an [AbortSignal] as the `options.signal` argument.\n\n",
    "properties": {
      "any_static": "\n\nThe **`TaskSignal.any()`** static method takes an iterable of [AbortSignal] objects and returns a [TaskSignal]. The returned task signal is aborted when any of the abort signals is aborted.\n\nWhen the task signal is aborted, its [AbortSignal.reason] property will be set to the reason of the first signal that is aborted.",
      "priority": "\n\nThe read-only **`priority`** property of the [TaskSignal] interface indicates the signal [priority](/en-US/docs/Web/API/Prioritized_Task_Scheduling_API#task_priorities).\n\nThe initial value is set in the associated [TaskController] by specifying it as an argument to the [`TaskController` constructor](/en-US/docs/Web/API/TaskController/TaskController) (by default it is `\"user-visible\"`).\nThe priority of the signal can be changed by calling [TaskController.setPriority] on the associated controller.\n\nFor [tasks with a mutable priority](/en-US/docs/Web/API/Prioritized_Task_Scheduling_API#mutable_and_immutable_task_priority), this value is used to set the initial task priority and later to change it.\nTasks with an immutable priority will ignore the value.",
      "prioritychange_event": "\n\nThe **`prioritychange`** event is sent to a [TaskSignal] if its [priority](/en-US/docs/Web/API/Prioritized_Task_Scheduling_API#task_priorities) is changed."
    }
  },
  "text": {
    "docs": "\n\nThe **`Text`** interface represents a text [Node] in a DOM tree.\n\nTo understand what a text node is, consider the following document:\n\n```html\n<html lang=\"en\" class=\"e\">\n  <head>\n    <title>Aliens?</title>\n  </head>\n  <body>\n    Why yes.\n  </body>\n</html>\n```\n\nIn that document, there are five text nodes, with the following contents:\n\n- `\"\\n    \"` (after the `<head>` start tag, a newline followed by four spaces)\n- `\"Aliens?\"` (the contents of the `title` element)\n- `\"\\n  \"` (after the `</head>` end tag, a newline followed by two spaces)\n- `\"\\n  \"` (after the `<body>` start tag, a newline followed by two spaces)\n- `\"\\n Why yes.\\n \\n\\n\"` (the contents of the `body` element)\n\nEach of those text nodes is an object that has the properties and methods documented in this article.",
    "properties": {
      "assignedslot": "\n\nThe read-only **`assignedSlot`** property of the [Text] interface\nreturns the [HTMLSlotElement] object associated with the element.",
      "splittext": "\n\nThe **`splitText()`** method of the [Text] interface\nbreaks the [Text] node into two nodes at the specified offset,\nkeeping both nodes in the tree as siblings.\n\nAfter the split, the current node contains all the content\nup to the specified offset point,\nand a newly created node of the same type contains the remaining text.\nThe newly created node is returned to the caller.\nIf the original node had a parent, the new node is inserted as the next sibling of the original node.\nIf the offset is equal to the length of the original node,\nthe newly created node has no data.\n\nSeparated text nodes can be concatenated using the [Node.normalize]\nmethod.",
      "wholetext": "\n\nThe read-only **`wholeText`** property of the [Text] interface\nreturns the full text of all [Text] nodes logically adjacent to the node.\nThe text is concatenated in document order.\nThis allows specifying any text node and obtaining all adjacent text as a single string.\n\n> **Note:** This is similar to call [Node.normalize] followed by reading the text value,\n> but without modifying the tree."
    }
  },
  "textdecoder": {
    "docs": "\n\nThe **`TextDecoder`** interface represents a decoder for a specific text encoding, such as `UTF-8`, `ISO-8859-2`, `KOI8-R`, `GBK`, etc. A decoder takes a stream of bytes as input and emits a stream of code points.\n\n",
    "properties": {
      "decode": "\n\nThe **`TextDecoder.decode()`** method returns a string containing text decoded from the buffer passed as a parameter.\n\nThe decoding method is defined in the current [TextDecoder] object.\nThis includes the expected encoding of the data, and how decoding errors are handled.",
      "encoding": "\n\nThe **`TextDecoder.encoding`** read-only property returns a string containing the name of the decoding algorithm used by the specific decoder object.\n\nThe encoding is set by the [constructor](/en-US/docs/Web/API/TextDecoder/TextDecoder) `label` parameter, and defaults to `utf-8`.",
      "fatal": "\n\nThe **`fatal`** read-only property of the [TextDecoder] interface is a `Boolean` indicating whether the error mode is fatal.\n\nIf the property is `true`, then a decoder will throw a `TypeError` if it encounters malformed data while decoding.\nIf `false`, the decoder will substitute the invalid data with the replacement character `U+FFFD` (�).\nThe value of the property is set in the [`TextDecoder()` constructor](/en-US/docs/Web/API/TextDecoder/TextDecoder).",
      "ignorebom": "\n\nThe **`ignoreBOM`** read-only property of the [TextDecoder] interface is a `Boolean` indicating whether the [byte order mark](https://www.w3.org/International/questions/qa-byte-order-mark) will be included in the output or skipped over."
    }
  },
  "textdecoderstream": {
    "docs": "\n\nThe **`TextDecoderStream`** interface of the [Encoding API] converts a stream of text in a binary encoding, such as UTF-8 etc., to a stream of strings.\nIt is the streaming equivalent of [TextDecoder].",
    "properties": {
      "encoding": "\n\nThe **`encoding`** read-only property of the [TextDecoderStream] interface returns a string containing the name of the encoding algorithm used by the specific decoder.\n\nThe encoding is set by the [constructor](/en-US/docs/Web/API/TextDecoderStream/TextDecoderStream) `label` parameter, and defaults to `utf-8`.",
      "fatal": "\n\nThe **`fatal`** read-only property of the [TextDecoderStream] interface is a `boolean` indicating if the error mode of the `TextDecoderStream` object is set to `fatal`.\n\nIf the property is `true` then a decoder will throw a `TypeError` if it encounters malformed data while decoding.\nIf `false` the decoder will substitute the invalid data with the replacement character `U+FFFD` (�).\nThe value of the property is set in the [`TextDecoderStream()` constructor](/en-US/docs/Web/API/TextDecoderStream/TextDecoderStream).",
      "ignorebom": "\n\nThe **`ignoreBOM`** read-only property of the [TextDecoderStream] interface is a `Boolean` indicating whether the [byte order mark](https://www.w3.org/International/questions/qa-byte-order-mark) will be included in the output or skipped over.",
      "readable": "\n\nThe **`readable`** read-only property of the [TextDecoderStream] interface returns a [ReadableStream].",
      "writable": "\n\nThe **`writable`** read-only property of the [TextDecoderStream] interface returns a [WritableStream]."
    }
  },
  "textencoder": {
    "docs": "\n\nThe **`TextEncoder`** interface takes a stream of code points as input and emits a stream of UTF-8 bytes.\n\n",
    "properties": {
      "encode": "\n\nThe **`TextEncoder.encode()`** method takes a string as input, and returns a `Uint8Array` containing the text given in parameters encoded with the specific method for that [TextEncoder] object.",
      "encodeinto": "\n\nThe **`TextEncoder.encodeInto()`** method takes a\nstring to encode and a destination `Uint8Array` to put resulting UTF-8 encoded text into, and returns a dictionary object indicating the\nprogress of the encoding.\nThis is potentially more performant than the older `encode()` method — especially when the target buffer is a view into a Wasm heap.",
      "encoding": "\n\nThe **`TextEncoder.encoding`** read-only property returns a string containing the name of the encoding algorithm used by the specific encoder.\n\nIt can only have the following value `utf-8`."
    }
  },
  "textencoderstream": {
    "docs": "\n\nThe **`TextEncoderStream`** interface of the [Encoding API] converts a stream of strings into bytes in the UTF-8 encoding. It is the streaming equivalent of [TextEncoder].",
    "properties": {
      "encoding": "\n\nThe **`encoding`** read-only property of the [TextEncoderStream] interface returns a\nstring containing the name of the encoding algorithm used by the current `TextEncoderStream` object.",
      "readable": "\n\nThe **`readable`** read-only property of the [TextEncoderStream] interface returns a [ReadableStream].",
      "writable": "\n\nThe **`writable`** read-only property of the [TextEncoderStream] interface returns a [WritableStream]."
    }
  },
  "textmetrics": {
    "docs": "\n\nThe **`TextMetrics`** interface represents the dimensions of a piece of text in the canvas; a `TextMetrics` instance can be retrieved using the [CanvasRenderingContext2D.measureText] method.",
    "properties": {
      "actualboundingboxascent": "\n\nThe read-only **`actualBoundingBoxAscent`** property of the [TextMetrics] interface is a `double` giving the distance from the horizontal line indicated by the [CanvasRenderingContext2D.textBaseline] attribute to the top of the bounding rectangle used to render the text, in CSS pixels.",
      "actualboundingboxdescent": "\n\nThe read-only `actualBoundingBoxDescent` property of the [TextMetrics] interface is a `double` giving the distance from the horizontal line indicated by the [CanvasRenderingContext2D.textBaseline] attribute to the bottom of the bounding rectangle used to render the text, in CSS pixels.",
      "actualboundingboxleft": "\n\nThe read-only `actualBoundingBoxLeft` property of the [TextMetrics] interface is a `double` giving the distance parallel to the baseline from the alignment point given by the [CanvasRenderingContext2D.textAlign] property to the left side of the bounding rectangle of the given text, in CSS pixels; positive numbers indicating a distance going left from the given alignment point.",
      "actualboundingboxright": "\n\nThe read-only `actualBoundingBoxRight` property of the [TextMetrics] interface is a `double` giving the distance parallel to the baseline from the alignment point given by the [CanvasRenderingContext2D.textAlign] property to the right side of the bounding rectangle of the given text, in CSS pixels.",
      "alphabeticbaseline": "\n\nThe read-only `alphabeticBaseline` property of the [TextMetrics] interface is a `double` giving the distance from the horizontal line indicated by the [CanvasRenderingContext2D.textBaseline] property to the alphabetic baseline of the line box, in CSS pixels.",
      "emheightascent": "\n\nThe read-only `emHeightAscent` property of the [TextMetrics] interface returns the distance from the horizontal line indicated by the [CanvasRenderingContext2D.textBaseline] property to the top of the _em_ square in the line box, in CSS pixels.",
      "emheightdescent": "\n\nThe read-only `emHeightDescent` property of the [TextMetrics] interface returns the distance from the horizontal line indicated by the [CanvasRenderingContext2D.textBaseline] property to the bottom of the _em_ square in the line box, in CSS pixels.",
      "fontboundingboxascent": "\n\nThe read-only `fontBoundingBoxAscent` property of the [TextMetrics] interface returns the distance from the horizontal line indicated by the [CanvasRenderingContext2D.textBaseline] attribute, to the top of the highest bounding rectangle of all the fonts used to render the text, in CSS pixels.",
      "fontboundingboxdescent": "\n\nThe read-only `fontBoundingBoxDescent` property of the [TextMetrics] interface returns the distance from the horizontal line indicated by the [CanvasRenderingContext2D.textBaseline] attribute to the bottom of the bounding rectangle of all the fonts used to render the text, in CSS pixels.",
      "hangingbaseline": "\n\nThe read-only `hangingBaseline` property of the [TextMetrics] interface is a `double` giving the distance from the horizontal line indicated by the [CanvasRenderingContext2D.textBaseline] property to the hanging baseline of the line box, in CSS pixels.",
      "ideographicbaseline": "\n\nThe read-only `ideographicBaseline` property of the [TextMetrics] interface is a `double` giving the distance from the horizontal line indicated by the [CanvasRenderingContext2D.textBaseline] property to the ideographic baseline of the line box, in CSS pixels.",
      "width": "\n\nThe read-only **`width`** property of the [TextMetrics] interface contains the text's advance width (the width of that inline box) in CSS pixels."
    }
  },
  "texttrack": {
    "docs": "\n\nThe `TextTrack` interface—part of the API for handling WebVTT (text tracks on media presentations)—describes and controls the text track associated with a particular `track` element.\n\n",
    "properties": {
      "activecues": "\n\nThe **`activeCues`** read-only property of the [TextTrack] interface returns a [TextTrackCueList] object listing the currently active cues.",
      "addcue": "\n\nThe **`addCue()`** method of the [TextTrack] interface adds a new cue to the list of cues.",
      "cuechange_event": "\n\nThe **`cuechange`** event fires when a [TextTrack] has changed the currently displaying cues. The event is fired on both the `TextTrack` and the [HTMLTrackElement] in which it's being presented, if any.",
      "cues": "\n\nThe **`cues`** read-only property of the [TextTrack] interface returns a [TextTrackCueList] object containing all of the track's cues.",
      "id": "\n\nThe **`id`** read-only property of the [TextTrack] interface returns the ID of the track if it has one.",
      "inbandmetadatatrackdispatchtype": "\n\nThe **`inBandMetadataTrackDispatchType`** read-only property of the [TextTrack] interface returns the text track's in-band metadata dispatch type of the text track represented by the [TextTrack] object.\n\nAn in-band metadata dispatch type is a string extracted from a media resource specifically for in-band metadata tracks. An example of a media resource that might have such tracks is a TV station streaming a broadcast on the web. Text Tracks may be used to include metadata for ad targeting, additional information such as recipe data during a cooking show, or trivia game data during a game show.\n\nThe value of this attribute could be used to attach these tracks to dedicated script modules as they are loaded.",
      "kind": "\n\nThe **`kind`** read-only property of the [TextTrack] interface returns the kind of text track this object represents. This decides how the track will be handled by a user agent.",
      "label": "\n\nThe **`label`** read-only property of the [TextTrack] interface returns a human-readable label for the text track, if it is available.",
      "language": "\n\nThe **`language`** read-only property of the [TextTrack] interface returns the language of the text track.\n\nThis uses the same values as the HTML [`lang`](/en-US/docs/Web/HTML/Global_attributes#lang) attribute. These values are documented in `5646, \"Tags for Identifying Languages (also known as BCP 47)\"`.",
      "mode": "\n\nThe [TextTrack] interface's\n**`mode`** property is a string specifying and controlling the\ntext track's mode: `disabled`, `hidden`, or\n`showing`. You can read this value to determine the current mode,\nand you can change this value to switch modes.\n\nSafari additionally requires the **`default`**\nboolean attribute to be set to true when implementing your own video player controls in\norder for the subtitles cues to be shown.\n\n### Value\n\nA string which indicates the track's current mode. One of:\n\n- `disabled`\n  - : The text track is currently disabled. While the track's presence is exposed in the\n    DOM, the user agent is otherwise ignoring it. No cues are active, no events are being\n    fired, and the user agent won't attempt to obtain the track's cues. This is the\n    default value, unless the text track has the [`default`](/en-US/docs/Web/HTML/Element/track#default)\n    Boolean attribute is specified, in which case the default is `showing`.\n- `hidden`\n  - : The text track is currently active but the cues aren't being displayed. If the user\n    agent hasn't tried to obtain the track's cues yet, it will do so soon (thereby\n    populating the track's [TextTrack.cues] property). The user agent is\n    keeping a list of the active cues (in the track's [TextTrack.activeCues] property) and events are being fired at the corresponding times, even\n    though the text isn't being displayed.\n- `showing`\n  - : The text track is currently enabled and is visible. If the track's cues list hasn't\n    been obtained yet, it will be soon. The [TextTrack.activeCues] list is being maintained and events are firing at the appropriate\n    times; the track's text is also being drawn appropriately based on the styling and the\n    track's [TextTrack.kind]. This is the default value if the text\n    track's [`default`](/en-US/docs/Web/HTML/Element/track#default) Boolean attribute is specified.",
      "removecue": "\n\nThe **`removeCue()`** method of the [TextTrack] interface removes a cue from the list of cues."
    }
  },
  "texttrackcue": {
    "docs": "\n\n**`TextTrackCue`** is an abstract class which is used as the basis for the various derived cue types, such as [VTTCue]; you will instead work with those derived types. These cues represent strings of text presented for some duration of time during the performance of a [TextTrack]. The cue includes the start time (the time at which the text will be displayed) and the end time (the time at which it will be removed from the display), as well as other information.\n\n",
    "properties": {
      "endtime": "\n\nThe **`endTime`** property of the [TextTrackCue] interface returns and sets the end time of the cue.",
      "enter_event": "\n\nThe **`enter`** event fires when a cue becomes active. In the case of subtitles or a caption this is when it displays over the media.",
      "exit_event": "\n\nThe **`exit`** event fires when a cue stops being active.",
      "id": "\n\nThe **`id`** property of the [TextTrackCue] interface returns and sets the identifier for this cue.",
      "pauseonexit": "\n\nThe **`pauseOnExit`** property of the [TextTrackCue] interface returns or sets the flag indicating whether playback of the media should pause when the end of the range to which this cue applies is reached.",
      "starttime": "\n\nThe **`startTime`** property of the [TextTrackCue] interface returns and sets the start time of the cue.",
      "track": "\n\nThe **`track`** read-only property of the [TextTrackCue] interface returns the [TextTrack] object that this cue belongs to."
    }
  },
  "texttrackcuelist": {
    "docs": "\n\nThe **`TextTrackCueList`** array-like object represents a dynamically updating list of [TextTrackCue] objects.\n\nThis interface has no constructor. Retrieve an instance of this object with [TextTrack.cues] which returns all of the cues in a [TextTrack] object.",
    "properties": {
      "getcuebyid": "\n\nThe **`getCueById()`** method of the [TextTrackCueList] interface returns the first [VTTCue] in the list represented by the `TextTrackCueList` object whose identifier matches the value of `id`.",
      "length": "\n\nThe **`length`** read-only property of the [TextTrackCueList] interface returns the number of cues in the list."
    }
  },
  "texttracklist": {
    "docs": "\n\nThe **`TextTrackList`** interface is used to represent a list of the text tracks defined by the `track` element, with each track represented by a separate [textTrack] object in the list.\n\nRetrieve an instance of this object with the [HTMLMediaElement.textTracks] property of an [HTMLMediaElement] object.\n\nFor a given [HTMLMediaElement] object _media_, the individual tracks can be accessed using:\n\n- `media.TextTracks[n]`, to get the n-th text track from the object's list of text tracks\n\n- the `media.textTracks`.[`getTrackById()`](/en-US/docs/Web/API/TextTrackList/getTrackById) method\n\n",
    "properties": {
      "addtrack_event": "\n\nThe **`addtrack`** event is fired when a track is added to a [`TextTrackList`](/en-US/docs/Web/API/TextTrackList).",
      "change_event": "\n\nThe **`change`** event is fired when a text track is made active or inactive, or a [TextTrackList] is otherwise changed.",
      "gettrackbyid": "\n\nThe **[TextTrackList]** method\n**`getTrackById()`** returns the first\n[TextTrack] object from the track list whose\n[`id`](/en-US/docs/Web/HTML/Global_attributes/id) matches the\nspecified string. This lets you find a specified track if you know its ID\nstring.",
      "length": "\n\nThe read-only **[TextTrackList]**\nproperty **`length`** returns the number of entries in the\n`TextTrackList`, each of which is a [TextTrack] representing\none track in the media element.\n\nA value of 0 indicates that there are no text\ntracks in the media.",
      "removetrack_event": "\n\nThe **`removetrack`** event is fired when a track is removed from a [`TextTrackList`](/en-US/docs/Web/API/TextTrackList)."
    }
  },
  "timeevent": {
    "docs": "\n\nThe **`TimeEvent`** interface, a part of [SVG SMIL](/en-US/docs/Web/SVG/SVG_animation_with_SMIL) animation, provides specific contextual information associated with Time events.\n\n"
  },
  "timeranges": {
    "docs": "\n\nWhen loading a media resource for use by an `audio` or `video` element, the **`TimeRanges`** interface is used for representing the time ranges of the media resource that have been buffered, the time ranges that have been played, and the time ranges that are seekable.\n\nA `TimeRanges` object includes one or more ranges of time, each specified by a starting time offset and an ending time offset. You reference each time range by using the `start()` and `end()` methods, passing the index number of the time range you want to retrieve.",
    "properties": {
      "end": "\n\nThe **`end()`** method of the [TimeRanges] interface returns the time offset at which a specified time range ends.",
      "length": "\n\nThe **`TimeRanges.length`** read-only property returns the\nnumber of ranges in the object.",
      "start": "\n\nThe **`start()`** method of the [TimeRanges] interface returns the time offset at which a specified time range begins."
    }
  },
  "toggleevent": {
    "docs": "\n\nThe **`ToggleEvent`** interface represents an event notifying the user when a [popover element](/en-US/docs/Web/API/Popover_API)'s state toggles between showing and hidden.\n\nIt is the event object for the `HTMLElement` [HTMLElement.beforetoggle_event] and [HTMLElement.toggle_event] events, which fire on popovers when they transition between showing and hidden (before and after, respectively).\n\n> **Note:** `ToggleEvent` is unrelated to the `HTMLDetailsElement` [HTMLDetailsElement.toggle_event] event, which fires on a `details` element when its `open`/`closed` state is toggled. Its event object is a generic [Event].",
    "properties": {
      "newstate": "\n\nThe **`newState`** read-only property of the [ToggleEvent] interface is a string representing the state the element is transitioning to.",
      "oldstate": "\n\nThe **`oldState`** read-only property of the [ToggleEvent] interface is a string representing the state the element is transitioning from."
    }
  },
  "touch": {
    "docs": "\n\nThe **`Touch`** interface represents a single contact point on a touch-sensitive device. The contact point is commonly a finger or stylus and the device may be a touchscreen or trackpad.\n\nThe [Touch.radiusX], [Touch.radiusY], and [Touch.rotationAngle] describe the area of contact between the user and the screen, the _touch area_. This can be helpful when dealing with imprecise pointing devices such as fingers. These values are set to describe an ellipse that as closely as possible matches the entire area of contact (such as the user's fingertip).\n\n> **Note:** Many of the properties' values are hardware-dependent; for example, if the device doesn't have a way to detect the amount of pressure placed on the surface, the `force` value will always be 0. This may also be the case for `radiusX` and `radiusY`; if the hardware reports only a single point, these values will be 1.",
    "properties": {
      "clientx": "\n\nThe `Touch.clientX` read-only property returns the X coordinate of the touch\npoint relative to the viewport, not including any scroll offset.",
      "clienty": "\n\nThe **`Touch.clientY`** read-only property returns the Y\ncoordinate of the touch point relative to the browser's viewport, not including any\nscroll offset.",
      "force": "\n\nThe **`Touch.force`** read-only property returns the amount of\npressure the user is applying to the touch surface for a [Touch] point.",
      "identifier": "\n\nThe **`Touch.identifier`** returns a value uniquely identifying\nthis point of contact with the touch surface. This value remains consistent for every\nevent involving this finger's (or stylus's) movement on the surface until it is lifted\noff the surface.",
      "pagex": "\n\nThe **`Touch.pageX`** read-only property returns the X\ncoordinate of the touch point relative to the viewport, including any scroll offset.",
      "pagey": "\n\nThe **`Touch.pageY`** read-only property returns the Y\ncoordinate of the touch point relative to the viewport, including any scroll offset.",
      "radiusx": "\n\nThe **`radiusX`** read-only property of the [Touch] interface returns the X radius of the ellipse that most closely circumscribes the area of contact with the touch surface. The value is in CSS pixels of the same scale as [Touch.screenX].\n\nThis value, in combination with [Touch.radiusY] and [Touch.rotationAngle] constructs an ellipse that approximates the size and shape of the area of contact between the user and the screen. This may be a relatively large ellipse representing the contact between a fingertip and the screen or a small area representing the tip of a stylus, for example.",
      "radiusy": "\n\nThe **`radiusY`** read-only property of the [Touch] interface returns the Y radius of the ellipse that most closely circumscribes the area of contact with the touch surface. The value is in CSS pixels of the same scale as [Touch.screenX].\n\nThis value, in combination with [Touch.radiusX] and [Touch.rotationAngle] constructs an ellipse that approximates the size and shape of the area of contact between the user and the screen. This may be a large ellipse representing the contact between a fingertip and the screen or a small one representing the tip of a stylus, for example.",
      "rotationangle": "\n\nThe **`rotationAngle`** read-only property of the [Touch] interface returns the rotation angle, in degrees, of the contact area ellipse defined by [Touch.radiusX] and [Touch.radiusY]. The value may be between 0 and 90. Together, these three values describe an ellipse that approximates the size and shape of the area of contact between the user and the screen. This may be a relatively large ellipse representing the contact between a fingertip and the screen or a small area representing the tip of a stylus, for example.",
      "screenx": "\n\nReturns the X coordinate of the touch point relative to the screen, not including any scroll offset.",
      "screeny": "\n\nReturns the Y coordinate of the touch point relative to the screen, not including any scroll offset.",
      "target": "\n\nThe read-only **`target`** property of the `Touch` interface returns the ([EventTarget]) on which the touch contact started when it was first placed on the surface, even if the touch point has since moved outside the interactive area of that element or even been removed from the document. Note that if the target element is removed from the document, events will still be targeted at it, and hence won't necessarily bubble up to the window or document anymore. If there is any risk of an element being removed while it is being touched, the best practice is to attach the touch listeners directly to the target."
    }
  },
  "touchevent": {
    "docs": "\n\nThe **`TouchEvent`** interface represents an [UIEvent] which is sent when the state of contacts with a touch-sensitive surface changes. This surface can be a touch screen or trackpad, for example. The event can describe one or more points of contact with the screen and includes support for detecting movement, addition and removal of contact points, and so forth.\n\nTouches are represented by the [Touch] object; each touch is described by a position, size and shape, amount of pressure, and target element. Lists of touches are represented by [TouchList] objects.\n\n",
    "properties": {
      "altkey": "\n\nThe read-only **`altKey`** property of the [TouchEvent] interface returns a boolean value indicating whether or not the <kbd>alt</kbd> (Alternate) key is enabled when the touch event is created. If the <kbd>alt</kbd> key is enabled, the attribute's value is `true`. Otherwise, it is `false`.\n\nThis property is .",
      "changedtouches": "\n\nThe **`changedTouches`** read-only property is a [TouchList] whose touch points ([Touch] objects) varies depending on the event type, as follows:\n\n- For the [Element/touchstart_event] event, it is a list of the touch points that became active with the current event.\n- For the [Element/touchmove_event] event, it is a list of the touch points that have changed since the last event.\n- For the [Element/touchend_event] event, it is a list of the touch points that have been removed from the surface (that is, the set of touch points corresponding to fingers no longer touching the surface).",
      "ctrlkey": "\n\nThe read-only **`ctrlKey`** property of the [TouchEvent] interface returns a boolean value indicating whether the <kbd>control</kbd> (Control) key is enabled when the touch event is created. If this key is enabled, the attribute's value is `true`. Otherwise, it is `false`.\n\nThis property is .",
      "metakey": "\n\nThe read-only **`metaKey`** property of the [TouchEvent] interface returns a boolean value indicating whether or not the <kbd>Meta</kbd> key is enabled when the touch event is created. If this key is enabled, the attribute's value is `true`. Otherwise, it is `false`.\n\nThis property is .\n\n> **Note:** On Macintosh keyboards, this is the <kbd>⌘ Command</kbd> key. On Windows keyboards, this is the Windows key (<kbd>⊞</kbd>).",
      "shiftkey": "\n\nThe read-only **`shiftKey`** property of the `TouchEvent` interface returns a boolean value indicating whether or not the <kbd>shift</kbd> key is enabled when the touch event is created. If this key is enabled, the attribute's value is `true`. Otherwise, it is `false`.",
      "targettouches": "\n\nThe **`targetTouches`** read-only property is a [TouchList] listing all the [Touch] objects for touch points that are still in contact with the touch surface **and** whose [Element/touchstart_event] event occurred inside the same target [element] as the current target element.",
      "touches": "\n\n**`touches`** is a read-only [TouchList] listing\nall the [Touch] objects for touch points that are currently in contact\nwith the touch surface, regardless of whether or not they've changed or what their\ntarget element was at [Element/touchstart_event] time.\n\nYou can think of it as how many separate fingers are able to be identified as touching\nthe screen.\n\n> **Note:** Touches inside the array are not necessarily ordered by order of occurrences (the\n> i-th element in the array being the i-th touch that happened). You cannot assume a specific order. To determine the order of occurrences of the touches, use the `touch` object IDs."
    }
  },
  "touchlist": {
    "docs": "\n\nThe **`TouchList`** interface represents a list of contact points on a touch surface. For example, if the user has three fingers on the touch surface (such as a screen or trackpad), the corresponding `TouchList` object would have one [Touch] object for each finger, for a total of three entries.\n\n> **Note:** This interface was an [attempt to create an unmodifiable list](https://stackoverflow.com/questions/74630989/why-use-domstringlist-rather-than-an-array/74641156#74641156) and only continues to be supported to not break code that's already using it. Modern APIs use types that wrap around ECMAScript array types instead, so you can treat them like ECMAScript arrays, and at the same time impose additional semantics on their usage (such as making their items read-only).",
    "properties": {
      "item": "\n\nThe **`item()`** method returns the [Touch]\nobject at the specified index in the [TouchList].",
      "length": "\n\nThe **`length`** read-only property indicates the number of\nitems (touch points) in a given [TouchList]."
    }
  },
  "trackevent": {
    "docs": "\n\nThe **`TrackEvent`** interface, which is part of the HTML DOM specification, is used for events which represent changes to a set of available tracks on an HTML media element; these events are `addtrack` and `removetrack`.\n\nIt's important not to confuse `TrackEvent` with the [RTCTrackEvent] interface, which is used for tracks which are part of an [RTCPeerConnection].\n\nEvents based on `TrackEvent` are always sent to one of the media track list types:\n\n- Events involving video tracks are always sent to the [VideoTrackList] found in [HTMLMediaElement.videoTracks]\n- Events involving audio tracks are always sent to the [AudioTrackList] specified in [HTMLMediaElement.audioTracks]\n- Events affecting text tracks are sent to the [TextTrackList] object indicated by [HTMLMediaElement.textTracks].\n\n",
    "properties": {
      "track": "\n\nThe read-only **`track`** property of\nthe [TrackEvent] interface specifies the media track object to which the\nevent applies.\n\nThe media track will be an [AudioTrack],\n[VideoTrack], or [TextTrack] object."
    }
  },
  "transformstream": {
    "docs": "\n\nThe **`TransformStream`** interface of the [Streams API](/en-US/docs/Web/API/Streams_API) represents a concrete implementation of the [pipe chain](/en-US/docs/Web/API/Streams_API/Concepts#pipe_chains) _transform stream_ concept.\n\nIt may be passed to the [ReadableStream.pipeThrough] method in order to transform a stream of data from one format into another.\nFor example, it might be used to decode (or encode) video frames, decompress data, or convert the stream from XML to JSON.\n\nA transformation algorithm may be provided as an optional argument to the object constructor.\nIf not supplied, data is not modified when piped through the stream.\n\n`TransformStream` is a [transferable object](/en-US/docs/Web/API/Web_Workers_API/Transferable_objects).",
    "properties": {
      "readable": "\n\nThe **`readable`** read-only property of the [TransformStream] interface returns the [ReadableStream] instance controlled by this `TransformStream`.",
      "writable": "\n\nThe **`writable`** read-only property of the [TransformStream] interface returns the [WritableStream] instance controlled by this `TransformStream`."
    }
  },
  "transformstreamdefaultcontroller": {
    "docs": "\n\nThe **`TransformStreamDefaultController`** interface of the [Streams API](/en-US/docs/Web/API/Streams_API) provides methods to manipulate the associated [ReadableStream] and [WritableStream].\n\nWhen constructing a [TransformStream], the `TransformStreamDefaultController` is created. It therefore has no constructor. The way to get an instance of `TransformStreamDefaultController` is via the callback methods of [TransformStream.TransformStream].",
    "properties": {
      "desiredsize": "`Streams API`\n\nThe **`desiredSize`** read-only property of the [TransformStreamDefaultController] interface returns the desired size to fill the queue of the associated [ReadableStream].\n\nThe internal queue of a `ReadableStream` contains chunks that have been enqueued, but not yet read. The browser determines the **desired size** to fill the stream, and it is this value returned by the `desiredSize` property.\n\nIf the `desiredSize` is `0` then the queue is full. Therefore you can use this information to [manually apply backpressure](/en-US/docs/Web/API/Streams_API/Concepts#backpressure) to manage the queue.",
      "enqueue": "`Streams API`\n\nThe **`enqueue()`** method of the [TransformStreamDefaultController] interface enqueues the given chunk in the readable side of the stream.\n\nFor more information on readable streams and chunks see [Using Readable Streams](/en-US/docs/Web/API/Streams_API/Using_readable_streams).",
      "error": "`Streams API`\n\nThe **`error()`** method of the [TransformStreamDefaultController] interface errors both sides of the stream. Any further interactions with it will fail with the given error message, and any chunks in the queue will be discarded.",
      "terminate": "`Streams API`\n\nThe **`terminate()`** method of the [TransformStreamDefaultController] interface closes the readable side and errors the writable side of the stream."
    }
  },
  "transitionevent": {
    "docs": "\n\nThe **`TransitionEvent`** interface represents events providing information related to [transitions](/en-US/docs/Web/CSS/CSS_transitions/Using_CSS_transitions).\n\n",
    "properties": {
      "elapsedtime": "\n\nThe **`TransitionEvent.elapsedTime`** read-only property is a\n`float` giving the amount of time the animation has been running, in seconds,\nwhen this event fired. This value is not affected by the \nproperty.",
      "propertyname": "\n\nThe **`propertyName`** read-only property of [TransitionEvent] objects is a string containing the name of the CSS property associated with the transition.",
      "pseudoelement": "\n\nThe **`TransitionEvent.pseudoElement`** read-only property is a\nstring, starting with `'::'`, containing the name of the [pseudo-element](/en-US/docs/Web/CSS/Pseudo-elements) the animation runs on.\nIf the transition doesn't run on a pseudo-element but on the element, an empty string:\n`''``.`"
    }
  },
  "treewalker": {
    "docs": "\n\nThe **`TreeWalker`** object represents the nodes of a document subtree and a position within them.\n\nA `TreeWalker` can be created using the [Document.createTreeWalker] method.",
    "properties": {
      "currentnode": "\n\nThe **`TreeWalker.currentNode`** property represents the\n[Node] which the [TreeWalker] is currently pointing at.",
      "filter": "\n\nThe **`TreeWalker.filter`** read-only property returns a\n`NodeFilter` that is the filtering object associated with the\n[TreeWalker].\n\nWhen creating the `TreeWalker`, the filter object is passed in as the third\nparameter, and its method `acceptNode()` is called on every\nsingle node to determine whether or not to accept it.",
      "firstchild": "\n\nThe **`TreeWalker.firstChild()`** method moves the current\n[Node] to the first _visible_ child of the current node, and returns\nthe found child. If no such child exists, it returns `null` and the current node is not changed.",
      "lastchild": "\n\nThe **`TreeWalker.lastChild()`** method moves the current\n[Node] to the last _visible_ child of the current node, and returns\nthe found child. If no such child exists, it returns `null` and the current node is not changed.",
      "nextnode": "\n\nThe **`TreeWalker.nextNode()`** method moves the current\n[Node] to the next _visible_ node in the document order, and returns\nthe found node. If no such node exists, it returns `null` and the current node is not changed.",
      "nextsibling": "\n\nThe **`TreeWalker.nextSibling()`** method moves the current\n[Node] to its next sibling, if any, and returns the found sibling. If there\nis no such node, it returns `null` and the current node is not changed.",
      "parentnode": "\n\nThe **`TreeWalker.parentNode()`** method moves the current\n[Node] to the first _visible_ ancestor node in the document order,\nand returns the found node. If no such node exists, or if it is above the\n`TreeWalker`'s _root node_, it returns `null` and the current\nnode is not changed.",
      "previousnode": "\n\nThe **`TreeWalker.previousNode()`** method moves the current\n[Node] to the previous _visible_ node in the document order, and\nreturns the found node. If no such node\nexists, or if it is before that the _root node_ defined at the object\nconstruction, it returns `null` and the current node is not changed.",
      "previoussibling": "\n\nThe **`TreeWalker.previousSibling()`** method moves the current\n[Node] to its previous sibling, if any, and returns the found sibling. If\nthere is no such node, it returns `null` and the current node is not changed.",
      "root": "\n\nThe **`TreeWalker.root`** read-only property returns the node\nthat is the root of what the TreeWalker traverses.",
      "whattoshow": "\n\nThe **`TreeWalker.whatToShow`** read-only property returns a\nbitmask that indicates the types of\n[nodes](/en-US/docs/Web/API/Node) to show. Non-matching nodes are skipped, but their\nchildren may be included, if relevant. The possible values are:\n\n<table class=\"no-markdown\">\n  <thead>\n    <tr>\n      <th>Constant</th>\n      <th>Numerical value</th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td><code>NodeFilter.SHOW_ALL</code></td>\n      <td>\n        <code>4294967295</code> (that is the max value of <code>unsigned long</code>)\n      </td>\n      <td>Shows all nodes.</td>\n    </tr>\n    <tr>\n      <td>\n        <code>NodeFilter.SHOW_ATTRIBUTE</code> \n      </td>\n      <td><code>2</code></td>\n      <td>\n        Shows attribute [Attr] nodes. This is meaningful\n        only when creating a [TreeWalker] with an\n        [Attr] node as its root; in this case, it means\n        that the attribute node will appear in the first position of the\n        iteration or traversal. Since attributes are never children of other\n        nodes, they do not appear when traversing over the document tree.\n      </td>\n    </tr>\n    <tr>\n      <td>\n        <code>NodeFilter.SHOW_CDATA_SECTION</code> \n      </td>\n      <td><code>8</code></td>\n      <td>Shows [CDATASection] nodes.</td>\n    </tr>\n    <tr>\n      <td><code>NodeFilter.SHOW_COMMENT</code></td>\n      <td><code>128</code></td>\n      <td>Shows [Comment] nodes.</td>\n    </tr>\n    <tr>\n      <td><code>NodeFilter.SHOW_DOCUMENT</code></td>\n      <td><code>256</code></td>\n      <td>Shows [Document] nodes.</td>\n    </tr>\n    <tr>\n      <td><code>NodeFilter.SHOW_DOCUMENT_FRAGMENT</code></td>\n      <td><code>1024</code></td>\n      <td>Shows [DocumentFragment] nodes.</td>\n    </tr>\n    <tr>\n      <td><code>NodeFilter.SHOW_DOCUMENT_TYPE</code></td>\n      <td><code>512</code></td>\n      <td>Shows [DocumentType] nodes.</td>\n    </tr>\n    <tr>\n      <td><code>NodeFilter.SHOW_ELEMENT</code></td>\n      <td><code>1</code></td>\n      <td>Shows [Element] nodes.</td>\n    </tr>\n    <tr>\n      <td><code>NodeFilter.SHOW_ENTITY</code> </td>\n      <td><code>32</code></td>\n      <td>Legacy, no more used.</td>\n    </tr>\n    <tr>\n      <td>\n        <code>NodeFilter.SHOW_ENTITY_REFERENCE</code>\n        \n      </td>\n      <td><code>16</code></td>\n      <td>Legacy, no more used.</td>\n    </tr>\n    <tr>\n      <td>\n        <code>NodeFilter.SHOW_NOTATION</code> \n      </td>\n      <td><code>2048</code></td>\n      <td>Legacy, no more used.</td>\n    </tr>\n    <tr>\n      <td><code>NodeFilter.SHOW_PROCESSING_INSTRUCTION</code></td>\n      <td><code>64</code></td>\n      <td>Shows [ProcessingInstruction] nodes.</td>\n    </tr>\n    <tr>\n      <td><code>NodeFilter.SHOW_TEXT</code></td>\n      <td><code>4</code></td>\n      <td>Shows [Text] nodes.</td>\n    </tr>\n  </tbody>\n</table>"
    }
  },
  "trustedhtml": {
    "docs": "`Trusted Types API`\n\nThe **`TrustedHTML`** interface of the [Trusted Types API] represents a string that a developer can insert into an [injection sink](/en-US/docs/Web/API/Trusted_Types_API#injection_sinks) that will render it as HTML. These objects are created via [TrustedTypePolicy.createHTML] and therefore have no constructor.\n\nThe value of a **TrustedHTML** object is set when the object is created and cannot be changed by JavaScript as there is no setter exposed.",
    "properties": {
      "tojson": "`Trusted Types API`\n\nThe **`toJSON()`** method of the [TrustedHTML] interface returns a JSON representation of the stored data.",
      "tostring": "`Trusted Types API`\n\nThe **`toString()`** method of the [TrustedHTML] interface returns a string which may safely inserted into an injection sink."
    }
  },
  "trustedscript": {
    "docs": "`Trusted Types API`\n\nThe **`TrustedScript`** interface of the [Trusted Types API] represents a string with an uncompiled script body that a developer can insert into an [injection sink](/en-US/docs/Web/API/Trusted_Types_API#injection_sinks) that might execute the script. These objects are created via [TrustedTypePolicy.createScript] and therefore have no constructor.\n\nThe value of a **TrustedScript** object is set when the object is created and cannot be changed by JavaScript as there is no setter exposed.",
    "properties": {
      "tojson": "`Trusted Types API`\n\nThe **`toJSON()`** method of the [TrustedScript] interface returns a JSON representation of the stored data.",
      "tostring": "`Trusted Types API`\n\nThe **`toString()`** method of the [TrustedScript] interface returns a string which may safely inserted into an [injection sink](/en-US/docs/Web/API/Trusted_Types_API#injection_sinks)."
    }
  },
  "trustedscripturl": {
    "docs": "`Trusted Types API`\n\nThe **`TrustedScriptURL`** interface of the [Trusted Types API] represents a string that a developer can insert into an [injection sink](/en-US/docs/Web/API/Trusted_Types_API#injection_sinks) that will parse it as a URL of an external script. These objects are created via [TrustedTypePolicy.createScriptURL] and therefore have no constructor.\n\nThe value of a **TrustedScriptURL** object is set when the object is created and cannot be changed by JavaScript as there is no setter exposed.",
    "properties": {
      "tojson": "`Trusted Types API`\n\nThe **`toJSON()`** method of the [TrustedScriptURL] interface returns a JSON representation of the stored data.",
      "tostring": "`Trusted Types API`\n\nThe **`toString()`** method of the [TrustedScriptURL] interface returns a string which may safely inserted into an [injection sink](/en-US/docs/Web/API/Trusted_Types_API#injection_sinks)."
    }
  },
  "trustedtypepolicy": {
    "docs": "`Trusted Types API`\n\nThe **`TrustedTypePolicy`** interface of the [Trusted Types API] defines a group of functions which create [TrustedType] objects.\n\nA `TrustedTypePolicy` object is created by [TrustedTypePolicyFactory.createPolicy] to define a policy for enforcing security rules on input. Therefore, `TrustedTypePolicy` has no constructor.",
    "properties": {
      "createhtml": "`Trusted Types API`\n\nThe **`createHTML()`** method of the [TrustedTypePolicy] interface creates a [TrustedHTML] object using a policy created by [TrustedTypePolicyFactory.createPolicy].",
      "createscript": "`Trusted Types API`\n\nThe **`createScript()`** method of the [TrustedTypePolicy] interface creates a [TrustedScript] object using a policy created by [TrustedTypePolicyFactory.createPolicy].",
      "createscripturl": "`Trusted Types API`\n\nThe **`createScriptURL()`** method of the [TrustedTypePolicy] interface creates a [TrustedScriptURL] object using a policy created by [TrustedTypePolicyFactory.createPolicy].",
      "name": "`Trusted Types API`\n\nThe **`name`** read-only property of the [TrustedTypePolicy] interface returns the name of the policy."
    }
  },
  "trustedtypepolicyfactory": {
    "docs": "`Trusted Types API`\n\nThe **`TrustedTypePolicyFactory`** interface of the [Trusted Types API] creates policies and allows the verification of Trusted Type objects against created policies.",
    "properties": {
      "createpolicy": "`Trusted Types API`\n\nThe **`createPolicy()`** method of the [TrustedTypePolicyFactory] interface creates a [TrustedTypePolicy] object that implements the rules passed as `policyOptions`.\n\n### The default policy\n\nIn Chrome a policy with a name of \"default\" creates a special policy that will be used if a string (rather than a Trusted Type object) is passed to an injection sink. This can be used in a transitional phase while moving from an application that inserted strings into injection sinks.\n\n> **Note:** The above behavior is not yet settled in the specification and may change in future.\n\n> **Warning:** A lax default policy could defeat the purpose of using Trusted Types, and therefore should be defined with strict rules to ensure it cannot be used to run dangerous code.",
      "defaultpolicy": "`Trusted Types API`\n\nThe **`defaultPolicy`** read-only property of the [TrustedTypePolicyFactory] interface returns the default [TrustedTypePolicy] or null if this is empty.\n\n> **Note:** Information about the creation and use of default policies can be found in the [`createPolicy()`](/en-US/docs/Web/API/TrustedTypePolicyFactory/createPolicy#default_policy) documentation.",
      "emptyhtml": "`Trusted Types API`\n\nThe **`emptyHTML`** read-only property of the [TrustedTypePolicyFactory] interface returns a [TrustedHTML] object containing an empty string.\n\nThis object can be used when the application requires an empty string to be inserted into an injection sink.",
      "emptyscript": "`Trusted Types API`\n\nThe **`emptyScript`** read-only property of the [TrustedTypePolicyFactory] interface returns a [TrustedScript] object containing an empty string.\n\nThis object can be used when the application requires an empty string to be inserted into an injection sink which is expecting a `TrustedScript` object.",
      "getattributetype": "`Trusted Types API`\n\nThe **`getAttributeType()`** method of the [TrustedTypePolicyFactory] interface allows web developers to check if a Trusted Type is required for an element, and if so which Trusted Type is used.",
      "getpropertytype": "`Trusted Types API`\n\nThe **`getPropertyType()`** method of the [TrustedTypePolicyFactory] interface allows web developers to check if a Trusted Type is required for an element's property.",
      "ishtml": "`Trusted Types API`\n\nThe **`isHTML()`** method of the [TrustedTypePolicyFactory] interface returns true if it is passed a valid [TrustedHTML] object.\n\n> **Note:** The purpose of the functions `isHTML()`, [TrustedTypePolicyFactory.isScript], and [TrustedTypePolicyFactory.isScriptURL] is to check if the object is a valid TrustedType object, created by a configured policy.",
      "isscript": "`Trusted Types API`\n\nThe **`isScript()`** method of the [TrustedTypePolicyFactory] interface returns true if it is passed a valid [TrustedScript] object.\n\n> **Note:** The purpose of the functions `isScript()`, [TrustedTypePolicyFactory.isHTML], and [TrustedTypePolicyFactory.isScriptURL] is to check if the object is a valid TrustedType object, created by a configured policy.",
      "isscripturl": "`Trusted Types API`\n\nThe **`isScriptURL()`** method of the [TrustedTypePolicyFactory] interface returns true if it is passed a valid [TrustedScriptURL] object.\n\n> **Note:** The purpose of the functions `isScriptURL()`, [TrustedTypePolicyFactory.isHTML], and [TrustedTypePolicyFactory.isScript] is to check if the object is a valid TrustedType object, created by a configured policy."
    }
  },
  "uievent": {
    "docs": "\n\nThe **`UIEvent`** interface represents simple user interface events.\n\n`UIEvent` derives from [Event]. Although the [UIEvent.initUIEvent] method is kept for backward compatibility, you should create a `UIEvent` object using the [UIEvent.UIEvent] constructor.\n\nSeveral interfaces are direct or indirect descendants of this one: [MouseEvent], [TouchEvent], [FocusEvent], [KeyboardEvent], [WheelEvent], [InputEvent], and [CompositionEvent].\n\n",
    "properties": {
      "detail": "\n\nThe **`UIEvent.detail`** read-only property, when non-zero, provides the current (or next, depending on the event) click count.\n\nFor [Element/click_event] or [Element/dblclick_event] events, `UIEvent.detail` is the current click count.\n\nFor [Element/mousedown_event] or [Element/mouseup_event] events, `UIEvent.detail` is _1 plus_ the current click count.\n\nFor all other [UIEvent] objects, `UIEvent.detail` is always zero.",
      "inituievent": " \n\nThe **`UIEvent.initUIEvent()`** method initializes a UI event\nonce it's been created.\n\nEvents initialized in this way must have been created with the [Document.createEvent] method. This method must be called to set the event\nbefore it is dispatched, using [EventTarget.dispatchEvent]. Once\ndispatched, it doesn't do anything anymore.\n\n> **Warning:** Do not use this method anymore as it is deprecated.\n>\n> Instead use specific event constructors, like [UIEvent.UIEvent]. The page on [Creating and triggering events](/en-US/docs/Web/Events/Creating_and_triggering_events) gives more information about the way to use these.",
      "sourcecapabilities": "\n\nThe **`sourceCapabilities`** read-only property of the [UIEvent] interface returns\nan instance of the [InputDeviceCapabilities] interface which provides\ninformation about the physical device responsible for generating a touch event. If no\ninput device was responsible for the event, it returns `null`.\n\nWhen a single user interaction with an input device generates a series of different\ninput events, the `sourceCapabilities` property for all of them will point to\nthe same instance of `InputDeviceCapabilities`. For example, when a user\nlifts their finger off of a touchscreen, several UIEvents may be generated including\n`touchend`, `mousedown`, `click`, and\n`focus`. All of these events must have the same\n`sourceCapabilities` representing the touchscreen.\n\nA device is considered \"responsible\" for an event only when that interaction is part of\nthe abstraction provided by the web platform. For example, many user agents allow a\nwindow to be resized with a mouse or a keyboard, but this detail is not exposed to the\nweb platform in any way, and so the sourceCapabilities of a resize event will typically\nbe null.",
      "view": "\n\nThe **`UIEvent.view`** read-only property returns the\n object from which the event was generated. In browsers, this\nis the [Window] object the event happened in.",
      "which": "\n\nThe **`UIEvent.which`** read-only property of the [UIEvent] interface returns a number that indicates which button was pressed on the mouse, or the numeric `keyCode` or the character code (`charCode`) of the key pressed on the keyboard."
    }
  },
  "url": {
    "docs": "\n\nThe **`URL`** interface is used to parse, construct, normalize, and encode . It works by providing properties which allow you to easily read and modify the components of a URL.\n\nYou normally create a new `URL` object by specifying the URL as a string when calling its constructor, or by providing a relative URL and a base URL. You can then easily read the parsed components of the URL or make changes to the URL.\n\nIf a browser doesn't yet support the [URL.URL] constructor, you can access a URL object using the [Window] interface's [URL] property. Be sure to check to see if any of your target browsers require this to be prefixed.\n\n",
    "properties": {
      "canparse_static": "\n\nThe **`URL.canParse()`** static method of the [URL] interface returns a boolean indicating whether or not an absolute URL, or a relative URL combined with a base URL, are parsable and valid.\n\nThis is a fast and easy alternative to constructing a `URL` within a [try...catch](/en-US/docs/Web/JavaScript/Reference/Statements/try...catch) block.\nIt returns `true` for the same values for which the [`URL()` constructor](/en-US/docs/Web/API/URL/URL) would succeed, and `false` for the values that would cause the constructor to throw.",
      "createobjecturl_static": "\n\nThe **`URL.createObjectURL()`** static\nmethod creates a string containing a URL representing the object\ngiven in the parameter.\n\nThe URL lifetime is tied to the [document]\nin the window on which it was created. The new object URL represents the specified\n[File] object or [Blob] object.\n\nTo release an object URL, call [URL.revokeObjectURL_static].\n\n`notservice`\n\n> **Note:** This feature is _not_ available in [Service Workers](/en-US/docs/Web/API/Service_Worker_API) due to its\n> potential to create memory leaks.",
      "hash": "\n\nThe **`hash`** property of the\n[URL] interface is a string containing a\n`'#'` followed by the fragment identifier of the URL.\n\nThe fragment is not [URL decoded](https://en.wikipedia.org/wiki/URL_encoding). If the URL does not\nhave a fragment identifier, this property contains an empty string — `\"\"`.\n\n",
      "host": "\n\nThe **`host`** property of the [URL] interface is\na string containing the host, that is the [URL.hostname], and then, if the  of the URL is nonempty, a\n`':'`, followed by the [URL.port] of the URL.\n\n",
      "hostname": "\n\nThe **`hostname`** property of the [URL] interface\nis a string containing the  of the URL.\n\n",
      "href": "\n\nThe **`href`** property of the [URL] interface is\na string containing the whole URL.\n\n",
      "origin": "\n\nThe **`origin`** read-only property of\nthe [URL] interface returns a string containing the\nUnicode serialization of the origin of the represented URL.\n\nThe exact structure\nvaries depending on the type of URL:\n\n- For `http` or `https` URLs, the scheme followed by\n  `'://'`, followed by the domain, followed by `':'`, followed by\n  the port (if explicitly specified, unless it is the default port - `80` and `443` respectively).\n- For `file:` URLs, the value is browser dependent.\n- for `blob:` URLs, the origin of the URL following `blob:` will\n  be used. For example, `\"blob:https://mozilla.org\"` will be returned as\n  `\"https://mozilla.org\".`\n\n",
      "password": "\n\nThe **`password`** property of the [URL] interface\nis a string containing the password specified before the domain name.\n\nIf it is set without first setting the [URL.username]\nproperty, it silently fails.\n\n",
      "pathname": "\n\nThe **`pathname`** property of the [URL] interface represents a location in a hierarchical structure. It is a string constructed from a list of path segments, each of which is prefixed by a `/` character. If the URL has no path segments, the value of its `pathname` property will be the empty string.\n\nURLs such as `https` and `http` URLs that have [hierarchical schemes](https://www.rfc-editor.org/rfc/rfc3986#section-1.2.3) (which the URL standard calls \"[special schemes](https://url.spec.whatwg.org/#special-scheme)\") always have at least one (invisible) path segment: the empty string. Thus the `pathname` value for such \"special scheme\" URLs can never be the empty string, but will instead always have a least one `/` character.\n\nFor example, the URL `https://developer.mozilla.org` has just one path segment: the empty string, so its `pathname` value is constructed by prefixing a `/` character to the empty string.\n\nSome systems define the term _slug_ to mean the final segment of a non-empty path if it identifies a page in human-readable keywords. For example, the URL `https://example.org/articles/this-that-other-outre-collection` has `this-that-other-outre-collection` as its slug.\n\nSome systems use the `;` and `=` characters to delimit parameters and parameter values applicable to a path segment. For example, with the URL `https://example.org/users;id=42/tasks;state=open?sort=modified`, a system might extract and use the path segment parameters `id=42` and `state=open` from the path segments `users;id=42` and `tasks;state=open`.\n\n",
      "port": "\n\nThe **`port`** property of the [URL] interface is\na string containing the port number of the URL.\n\n> **Note:** If an input string passed to the [`URL()`](/en-US/docs/Web/API/URL/URL) constructor doesn't contain an explicit port number (e.g., `https://localhost`) or contains a port number that's the default port number corresponding to the protocol part of the input string (e.g., `https://localhost:443`), then in the [`URL`](/en-US/docs/Web/API/URL) object the constructor returns, the value of the port property will be the empty string: `''`.\n\n",
      "protocol": "\n\nThe **`protocol`** property of the [URL] interface\nis a string representing the protocol scheme of the URL, including the\nfinal `':'`.\n\n",
      "revokeobjecturl_static": "\n\nThe **`URL.revokeObjectURL()`** static\nmethod releases an existing object URL which was previously created by calling\n[URL.createObjectURL_static].\n\nCall this method when you've finished\nusing an object URL to let the browser know not to keep the reference to the file any\nlonger.\n\n`notservice`\n\n> **Note:** This method is _not_ available in [Service Workers](/en-US/docs/Web/API/Service_Worker_API), due to\n> issues with the [Blob] interface's life cycle and the potential for leaks.",
      "search": "\n\nThe **`search`** property of the [URL] interface\nis a search string, also called a _query string_, that is a\nstring containing a `'?'` followed by the parameters of the\nURL.\n\nModern browsers provide the [URL.searchParams] property to make it easy to\nparse out the parameters from the query string.\n\n",
      "searchparams": "\n\nThe **`searchParams`** read-only property of the\n[URL] interface returns a [URLSearchParams] object allowing\naccess to the `GET` decoded query arguments contained in the URL.\n\n",
      "tojson": "\n\nThe **`toJSON()`** method of the [URL] interface\nreturns a string containing a serialized version of the URL,\nalthough in practice it seems to have the same effect as\n[URL.toString].\n\n",
      "tostring": "\n\nThe **`toString()`** method of the [URL] interface returns a\nstring containing the whole URL. It is effectively a read-only version\nof [URL.href].\n\n",
      "username": "\n\nThe **`username`** property of the [URL] interface\nis a string containing the username specified before the domain name.\n\n"
    }
  },
  "urlpattern": {
    "docs": "\n\nThe **`URLPattern`** interface of the [URL Pattern API] matches URLs or parts of URLs against a pattern. The pattern can contain capturing groups that extract parts of the matched URL.\n\nMore information about the syntax of patterns can be found on the API overview\npage: [URL Pattern API].\n\n",
    "properties": {
      "exec": "\n\nThe **`exec()`** method of the [URLPattern] interface takes a URL or\nobject of URL parts, and returns either an object containing the results of\nmatching the URL to the pattern, or `null` if the URL does not match the\npattern.\n\n",
      "hash": "\n\nThe **`hash`** read-only property of the [URLPattern] interface is a\nstring containing the pattern used to match the fragment part\nof a URL. This value may differ from the input to the constructor due to\nnormalization.\n\n",
      "hostname": "\n\nThe **`hostname`** read-only property of the [URLPattern] interface is a\nstring containing the pattern used to match the hostname part\nof a URL. This value may differ from the input to the constructor due to\nnormalization.\n\n",
      "password": "\n\nThe **`password`** read-only property of the [URLPattern] interface is a\nstring containing the pattern used to match the password part\nof a URL. This value may differ from the input to the constructor due to\nnormalization.\n\n",
      "pathname": "\n\nThe **`pathname`** read-only property of the [URLPattern] interface is a\nstring containing the pattern used to match the pathname part\nof a URL. This value may differ from the input to the constructor due to\nnormalization.\n\n",
      "port": "\n\nThe **`port`** read-only property of the [URLPattern] interface is a\nstring containing the pattern used to match the port part of a\nURL. This value may differ from the input to the constructor due to\nnormalization.\n\n",
      "protocol": "\n\nThe **`protocol`** read-only property of the [URLPattern] interface is a\nstring containing the pattern used to match the protocol part\nof a URL. This value may differ from the input to the constructor due to\nnormalization.\n\n",
      "search": "\n\nThe **`search`** read-only property of the [URLPattern] interface is a\nstring containing the pattern used to match the search part of\na URL. This value may differ from the input to the constructor due to\nnormalization.\n\n",
      "test": "\n\nThe **`test()`** method of the [URLPattern] interface takes a URL or\nobject of URL parts, and returns a boolean indicating if the given input matches\nthe current pattern.\n\n",
      "username": "\n\nThe **`username`** read-only property of the [URLPattern] interface is a\nstring containing the pattern used to match the username part\nof a URL. This value may differ from the input to the constructor due to\nnormalization.\n\n"
    }
  },
  "urlsearchparams": {
    "docs": "\n\nThe **`URLSearchParams`** interface defines utility methods to work with the query string of a URL.\n\nAn object implementing `URLSearchParams` can directly be used in a `for...of` structure to iterate over key/value pairs in the same order as they appear in the query string, for example the following two lines are equivalent:\n\n```js\nfor (const [key, value] of mySearchParams) {\n}\nfor (const [key, value] of mySearchParams.entries()) {\n}\n```\n\n",
    "properties": {
      "append": "\n\nThe **`append()`** method of the [URLSearchParams]\ninterface appends a specified key/value pair as a new search parameter.\n\nAs shown in the example below, if the same key is appended multiple times it will\nappear in the parameter string multiple times for each value.\n\n",
      "delete": "\n\nThe **`delete()`** method of the [URLSearchParams] interface deletes specified parameters and their associated value(s) from the list of all search parameters.\n\nA parameter name and optional value are used to match parameters.\nIf only a parameter name is specified, then all search parameters that match the name are deleted, along with their associated values.\nIf both a parameter name and value are specified, then all search parameters that match both the parameter name and value are deleted.\n\n",
      "entries": "\n\nThe **`entries()`** method of the\n[URLSearchParams] interface returns an\n`iterator` allowing iteration through all key/value\npairs contained in this object. The iterator returns key/value pairs in the same order as they appear in the query string. The key and value of each pair are\nstring objects.\n\n",
      "foreach": "\n\nThe **`forEach()`** method of the\n[URLSearchParams] interface allows iteration through all values contained\nin this object via a callback function.\n\n",
      "get": "\n\nThe **`get()`** method of the [URLSearchParams]\ninterface returns the first value associated to the given search parameter.\n\n",
      "getall": "\n\nThe **`getAll()`** method of the [URLSearchParams]\ninterface returns all the values associated with a given search parameter as an array.\n\n",
      "has": "\n\nThe **`has()`** method of the [URLSearchParams] interface returns a boolean value that indicates whether the specified parameter is in the search parameters.\n\nA parameter name and optional value are used to match parameters.\nIf only a parameter name is specified, then the method will return `true` if any parameters in the query string match the name, and `false` otherwise.\nIf both a parameter name and value are specified, then the method will return `true` if a parameter matches both the name and value.\n\n",
      "keys": "\n\nThe **`keys()`** method of the [URLSearchParams]\ninterface returns an `iterator` allowing iteration\nthrough all keys contained in this object. The keys are string\nobjects.\n\n",
      "set": "\n\nThe **`set()`** method of the [URLSearchParams]\ninterface sets the value associated with a given search parameter to the given value.\nIf there were several matching values, this method deletes the others. If the search\nparameter doesn't exist, this method creates it.\n\n",
      "size": "\n\nThe **`size`** read-only property of the [URLSearchParams] interface indicates the total number of search parameter entries.\n\n",
      "sort": "\n\nThe **`URLSearchParams.sort()`** method sorts all key/value\npairs contained in this object in place and returns `undefined`. The sort\norder is according to unicode code points of the keys. This method uses a stable sorting\nalgorithm (i.e. the relative order between key/value pairs with equal keys will be\npreserved).\n\n",
      "tostring": "\n\nThe **`toString()`** method of the\n[URLSearchParams] interface returns a query string suitable for use in a\nURL.\n\n> **Note:** This method returns the query string without the question mark. This is different from [`Location.search`](/en-US/docs/Web/API/Location/search), [`HTMLAnchorElement.search`](/en-US/docs/Web/API/HTMLAnchorElement/search), and [`URL.search`](/en-US/docs/Web/API/URL/search), which all include the question mark.\n\n",
      "values": "\n\nThe **`values()`** method of the [URLsearchParams]\ninterface returns an `iterator` allowing iteration\nthrough all values contained in this object. The values are string\nobjects.\n\n"
    }
  },
  "usb": {
    "docs": "\n\nThe **`USB`** interface of the [WebUSB API](/en-US/docs/Web/API/WebUSB_API) provides attributes and methods for finding and connecting USB devices from a web page.\n\nUse [navigator.usb] to get access to the `USB` object.\n\nThe USB interface inherits from [EventTarget].\n\n",
    "properties": {
      "connect_event": "\n\nThe **`connect`** event of the [USB] interface is fired whenever a paired device is connected.",
      "disconnect_event": "\n\nThe **`disconnect`** event of the [USB] interface is fired whenever a paired device is disconnected.",
      "getdevices": "\n\nThe **`getDevices`** method of the [USB] interface\nreturns a `Promise` that resolves with an array of [USBDevice]\nobjects for paired attached devices. For information on pairing devices, see\n[USB.requestDevice].",
      "requestdevice": "\n\nThe **`requestDevice()`** method of the [USB]\ninterface returns a `Promise` that resolves with an instance of\n[USBDevice] if the specified device is found. Calling this function\ntriggers the user agent's pairing flow."
    }
  },
  "usbalternateinterface": {
    "docs": "\n\nThe `USBAlternateInterface` interface of the [WebUSB API](/en-US/docs/Web/API/WebUSB_API) provides information about a particular configuration of an interface provided by the USB device. An interface includes one or more alternate settings which can configure a set of endpoints based on the operating mode of the device."
  },
  "usbconfiguration": {
    "docs": "\n\nThe `USBConfiguration` interface of the [WebUSB API](/en-US/docs/Web/API/WebUSB_API) provides information about a particular configuration of a USB device and the interfaces that it supports.",
    "properties": {
      "configurationname": "\n\nThe **`configurationName`** read-only property\nof the [USBConfiguration] interface returns the name provided by the device\nto describe this configuration. This is equal to the value of the string descriptor with\nthe index provided in the [`iConfiguration`](https://www.beyondlogic.org/usbnutshell/usb5.shtml#ConfigurationDescriptors)\nfield of the configuration descriptor defining this configuration.",
      "configurationvalue": "\n\nThe **`configurationValue`** read-only property\nof the [USBConfiguration] interface returns the configuration value of this configuration. This is equal to the\n[`bConfigurationValue`](https://www.beyondlogic.org/usbnutshell/usb5.shtml#ConfigurationDescriptors) field of the configuration descriptor provided by the device defining this configuration.",
      "interfaces": "\n\nThe **`interfaces`** read-only property of the\n[USBConfiguration] interface returns an array containing instances of the\n[USBInterface] describing each interface supported by this configuration."
    }
  },
  "usbconnectionevent": {
    "docs": "\n\nThe **`USBConnectionEvent`** interface of the [WebUSB API] is the event type passed to `USB` [USB.connect_event] and [USB.disconnect_event] events when the user agent detects that a new USB device has been connected or disconnected.\n\n",
    "properties": {
      "device": "\n\nThe **`device`** read-only property of the [USBConnectionEvent] interface returns a [USBDevice] object representing the device being connected or disconnected."
    }
  },
  "usbdevice": {
    "docs": "\n\nThe **`USBDevice`** interface of the [WebUSB API](/en-US/docs/Web/API/WebUSB_API) provides access to metadata about a paired USB device and methods for controlling it.",
    "properties": {
      "claiminterface": "\n\nThe **`claimInterface()`** method of the\n[USBDevice] interface returns a `promise` that resolves when\nthe requested interface is claimed for exclusive access.",
      "clearhalt": "\n\nThe **`clearHalt()`** method of the [USBDevice]\ninterface returns a `promise` that resolves when a halt condition is\ncleared. A halt condition is when a data transfer to or from the device has a status\nof `'stall'`, which requires the web page (the _host_ system, in USB\nterminology) to clear that condition. See the for details.",
      "close": "\n\nThe **`close()`** method of the [USBDevice]\ninterface returns a `promise` that resolves when all open interfaces are\nreleased and the device session has ended.",
      "configuration": "\n\nThe **`configuration`** read only property of the\n[USBDevice] interface returns a [USBConfiguration] object for\nthe currently selected interface for a paired USB device.",
      "configurations": "\n\nThe **`configurations`** read only property of the\n[USBDevice] interface an `array` of device-specific interfaces\nfor controlling a paired USB device.",
      "controltransferin": "\n\nThe **`controlTransferIn()`** method of the [USBDevice] interface returns a `Promise` that resolves with a [USBInTransferResult] when a command or status request has been transmitted to (received by) the USB device.",
      "controltransferout": "\n\nThe **`controlTransferOut()`** method of the [USBDevice] interface returns a `Promise` that resolves with a [USBOutTransferResult] when a command or status operation has been transmitted from the USB device.",
      "deviceclass": "\n\nThe **`deviceClass`** read only property of the\n[USBDevice] interface one of three properties that identify USB devices for\nthe purpose of loading a USB driver that will work with that device. The other two\nproperties are USBDevice.deviceSubclass and USBDevice.deviceprotocol.",
      "deviceprotocol": "\n\nThe **`deviceProtocol`** read only property of the\n[USBDevice] interface one of three properties that identify USB devices for\nthe purpose of loading a USB driver that will work with that device. The other two\nproperties are `USBDevice.deviceClass`\nand `USBDevice.deviceSubclass`.",
      "devicesubclass": "\n\nThe **`deviceSubclass`** read only property of the\n[USBDevice] interface one of three properties that identify USB devices for\nthe purpose of loading a USB driver that will work with that device. The other two\nproperties are USBDevice.deviceClass and USBDevice.deviceProtocol.",
      "deviceversionmajor": "\n\nThe **`deviceVersionMajor`** read only property of the\n[USBDevice] interface he major version number of the device in a semantic\nversioning scheme.",
      "deviceversionminor": "\n\nThe **`deviceVersionMinor`** read only property of the\n[USBDevice] interface the minor version number of the device in a semantic\nversioning scheme.",
      "deviceversionsubminor": "\n\nThe **`deviceVersionSubminor`** read only property of the\n[USBDevice] interface the patch version number of the device in a semantic\nversioning scheme.",
      "forget": "\n\nThe **`forget()`** method of the [USBDevice] interface returns a `Promise` that resolves when all pending operations are aborted, all open interfaces are released, the device session has ended, and the permission is reset.",
      "isochronoustransferin": "\n\nThe **`isochronousTransferIn()`** method of the [USBDevice] interface returns a `Promise` that resolves with a [USBIsochronousInTransferResult] when time sensitive information has been transmitted to (received by) the USB device.",
      "isochronoustransferout": "\n\nThe **`isochronousTransferOut()`** method of the\n[USBDevice] interface returns a `Promise` that resolves with a [USBIsochronousOutTransferResult] when time sensitive information has been transmitted from the USB device.",
      "manufacturername": "\n\nThe **`manufacturerName`** read only property of the\n[USBDevice] interface the of the organization that manufactured the USB\ndevice.",
      "open": "\n\nThe **`open()`** method of the [USBDevice]\ninterface returns a `promise` that resolves when a device session has\nstarted.",
      "opened": "\n\nThe **`opened`** read only property of the\n[USBDevice] interface indicates whether a session has been started with a\npaired USB device. A device must be opened before it can be controlled by a web page.",
      "productid": "\n\nThe **`productId`** read only property of the\n[USBDevice] interface the manufacturer-defined code that identifies a USB\ndevice.",
      "productname": "\n\nThe **`productName`** read only property of the\n[USBDevice] interface the manufacturer-defined name that identifies a USB\ndevice.",
      "releaseinterface": "\n\nThe **`releaseInterface()`** method of the\n[USBDevice] interface returns a `promise` that resolves when a\nclaimed interface is released from exclusive access.",
      "reset": "\n\nThe **`reset()`** method of the [USBDevice]\ninterface returns a `promise` that resolves when the device is reset and all\napp operations canceled and their promises rejected.",
      "selectalternateinterface": "\n\nThe **`selectAlternateInterface()`** method of the\n[USBDevice] interface returns a `promise` that resolves when\nthe specified alternative endpoint is selected.",
      "selectconfiguration": "\n\nThe **`selectConfiguration()`** method of the\n[USBDevice] interface returns a `promise` that resolves when\nthe specified configuration is selected.",
      "serialnumber": "\n\nThe **`serialNumber`** read only property of the\n[USBDevice] interface is the manufacturer-defined serial number for the\nspecific USB device.",
      "transferin": "\n\nThe **`transferIn()`** method of the [USBDevice]\ninterface returns a `promise` that resolves with a\n[USBInTransferResult] when bulk or interrupt data is received from the USB\ndevice.",
      "transferout": "\n\nThe **`transferOut()`** method of the [USBDevice]\ninterface returns a `promise` that resolves with a\n[USBOutTransferResult] when bulk or interrupt data is sent to the USB\ndevice.",
      "usbversionmajor": "\n\nThe **`usbVersionMajor`** read only property of the\n[USBDevice] interface is one of three properties that declare the USB\nprotocol version supported by the device. The other two properties\nare USBDevice.usbVersionMinor and USBDevice.usbVersionSubminor.",
      "usbversionminor": "\n\nThe **`usbVersionMinor`** read only property of the\n[USBDevice] interface is one of three properties that declare the USB\nprotocol version supported by the device. The other two properties\nare USBDevice.usbVersionMajor and USBDevice.usbVersionSubminor.",
      "usbversionsubminor": "\n\nThe **`usbVersionSubminor`** read only property of the\n[USBDevice] interface is one of three properties that declare the USB\nprotocol version supported by the device. The other two properties\nare USBDevice.usbVersionMajor and USBDevice.usbVersionMinor.",
      "vendorid": "\n\nThe **`vendorId`** read only property of the\n[USBDevice] interface is the official usb.org-assigned vendor ID."
    }
  },
  "usbendpoint": {
    "docs": "\n\nThe `USBEndpoint` interface of the [WebUSB API](/en-US/docs/Web/API/WebUSB_API) provides information about an endpoint provided by the USB device. An endpoint represents a unidirectional data stream into or out of a device."
  },
  "usbinterface": {
    "docs": "\n\nThe `USBInterface` interface of the [WebUSB API](/en-US/docs/Web/API/WebUSB_API) provides information about an interface provided by the USB device. An interface represents a feature of the device which implements a particular protocol and may contain endpoints for bidirectional communication."
  },
  "usbintransferresult": {
    "docs": "\n\nThe `USBInTransferResult` interface of the [WebUSB API](/en-US/docs/Web/API/WebUSB_API) provides the result from a call to the `transferIn()` and `controlTransferIn()` methods of the `USBDevice` interface. It represents the result from requesting a transfer of data from the USB device to the USB host."
  },
  "usbisochronousintransferpacket": {
    "docs": "\n\nThe `USBIsochronousInTransferPacket` interface of the [WebUSB API](/en-US/docs/Web/API/WebUSB_API) is part of the response from a call to the `isochronousTransferIn()` method of the `USBDevice` interface. It represents the status of an individual packet from a request to transfer data from the USB device to the USB host over an isochronous endpoint."
  },
  "usbisochronousintransferresult": {
    "docs": "\n\nThe `USBIsochronousInTransferResult` interface of the [WebUSB API](/en-US/docs/Web/API/WebUSB_API) provides the result from a call to the `isochronousTransferIn()` method of the `USBDevice` interface. It represents the result from requesting a transfer of data from the USB device to the USB host."
  },
  "usbisochronousouttransferpacket": {
    "docs": "\n\nThe `USBIsochronousOutTransferPacket` interface of the [WebUSB API](/en-US/docs/Web/API/WebUSB_API) is part of the response from a call to the `isochronousTransferOut()` method of the `USBDevice` interface. It represents the status of an individual packet from a request to transfer data from the USB host to the USB device over an isochronous endpoint."
  },
  "usbisochronousouttransferresult": {
    "docs": "\n\nThe `USBIsochronousOutTransferResult` interface of the [WebUSB API](/en-US/docs/Web/API/WebUSB_API) provides the result from a call to the `isochronousTransferOut()` method of the `USBDevice` interface. It represents the result from requesting a transfer of data from the USB host to the USB device."
  },
  "usbouttransferresult": {
    "docs": "\n\nThe `USBOutTransferResult` interface of the [WebUSB API](/en-US/docs/Web/API/WebUSB_API) provides the result from a call to the `transferOut()` and `controlTransferOut()` methods of the `USBDevice` interface. It represents the result from requesting a transfer of data from the USB host to the USB device."
  },
  "useractivation": {
    "docs": "\n\nThe **`UserActivation`** interface provides information about whether a user is currently interacting with the page, or has completed an interaction since page load.\n\nThis API is only available in the window context and not exposed to workers.",
    "properties": {
      "hasbeenactive": "\n\nThe read-only **`hasBeenActive`** property of the [UserActivation] interface indicates whether the current window has .",
      "isactive": "\n\nThe read-only **`isActive`** property of the [UserActivation] interface indicates whether the current window has ."
    }
  },
  "validitystate": {
    "docs": "\n\nThe **`ValidityState`** interface represents the _validity states_ that an element can be in, with respect to constraint validation. Together, they help explain why an element's value fails to validate, if it's not valid.",
    "properties": {
      "badinput": "\n\nThe read-only **`badInput`** property of a [ValidityState](/en-US/docs/Web/API/ValidityState) object indicates if the user has provided input that the browser is unable to convert. For example, if you have a number input element whose content is a string.",
      "patternmismatch": "\n\nThe read-only **`patternMismatch`** property of a **[`ValidityState`](/en-US/docs/Web/API/ValidityState)** object indicates if the value of an `input`, after having been edited by the user, does not conform to the constraints set by the element's [`pattern`](/en-US/docs/Web/HTML/Attributes/pattern) attribute.\n\nThe `patternMismatch` property will be true if and only if the following conditions are all true:\n\n- the field supports the [`pattern`](/en-US/docs/Web/HTML/Attributes/pattern) attribute — which means the `input` is of `type` `text`, `tel`, `email`, `url`, `password`, or `search`\n- the [`pattern`](/en-US/docs/Web/HTML/Attributes/pattern) attribute contains a valid regular expression\n- the `input` value doesn't conform to the constraints set by the [`pattern`](/en-US/docs/Web/HTML/Attributes/pattern) value.",
      "rangeoverflow": "\n\nThe read-only **`rangeOverflow`** property of a **[`ValidityState`](/en-US/docs/Web/API/ValidityState)** object indicates if the value of an `input`, after having been edited by the user, does not conform to the constraints set by the element's [`max`](/en-US/docs/Web/HTML/Attributes/max) attribute.\n\nIf the field is numeric in nature, including the `date`, `month`, `week`, `time`, , `number` and `range` types and a `max` value is set, if the value doesn't conform to the constraints set by the [`max`](/en-US/docs/Web/HTML/Attributes/step) value, the `rangeOverflow` property will be true.\n\nGiven the following:\n\n```html\n<input type=\"number\" min=\"20\" max=\"40\" step=\"2\" />\n```\n\nif `value > 40`, `rangeOverflow` will be true. When `true`, the element matches the  and  CSS pseudo-classes.",
      "rangeunderflow": "\n\nThe read-only **`rangeUnderflow`** property of a **[`ValidityState`](/en-US/docs/Web/API/ValidityState)** object indicates if the value of an `input`, after having been edited by the user, does not conform to the constraints set by the element's [`min`](/en-US/docs/Web/HTML/Attributes/min) attribute.\n\nIf the field is numeric in nature, including the `date`, `month`, `week`, `time`, , `number` and `range` types and a `min` value is set, if the value doesn't conform to the constraints set by the [`min`](/en-US/docs/Web/HTML/Attributes/step) value, the `rangeUnderflow` property will be true.\n\nGiven the following:\n\n```html\n<input type=\"number\" min=\"20\" max=\"40\" step=\"2\" />\n```\n\nif `value < 20`, `rangeUnderflow` will be true. When `true`, the element matches the  and  CSS pseudo-classes.",
      "stepmismatch": "\n\nThe read-only **`stepMismatch`** property of a **[`ValidityState`](/en-US/docs/Web/API/ValidityState)** object indicates if the value of an `input`, after having been edited by the user, does not conform to the constraints set by the element's `step` attribute.\n\nIf the field is numeric in nature, including the `date`, `month`, `week`, `time`, , `number` and `range` types and the step value is not `any`, if the value don't doesn't conform to the constraints set by the [`step`](/en-US/docs/Web/HTML/Attributes/step) and [`min`](/en-US/docs/Web/HTML/Attributes/min) values, then `stepMismatch` will be true. If the remainder of the form control's value less the [`min`](/en-US/docs/Web/HTML/Attributes/min) value, divided by the [`step`](/en-US/docs/Web/HTML/Attributes/step) value (which defaults to 1 if omitted) is not zero, there is a mismatch.\n\nGiven the following:\n\n```html\n<input type=\"number\" min=\"20\" max=\"40\" step=\"2\" />\n```\n\nif `(value - min) % 2 !== 0`, `stepMismatch` will be true.\n\nIf true, the element matches the  and  CSS pseudo-classes.",
      "toolong": "\n\nThe read-only **`tooLong`** property of a **[`ValidityState`](/en-US/docs/Web/API/ValidityState)** object indicates if the value of an `input` or `textarea`, after having been edited by the user, exceeds the maximum code-unit length established by the element's [`maxlength`](/en-US/docs/Web/HTML/Attributes/maxlength) attribute.",
      "tooshort": "\n\nThe read-only **`tooShort`** property of a **[`ValidityState`](/en-US/docs/Web/API/ValidityState)** object indicates if the value of an `input`, `button`, `select`, `output`, `fieldset` or `textarea`, after having been edited by the user, is less than the minimum code-unit length established by the element's `minlength` attribute.",
      "typemismatch": "\n\nThe read-only **`typeMismatch`** property of a **[`ValidityState`](/en-US/docs/Web/API/ValidityState)** object indicates if the value of an `input`, after having been edited by the user, does not conform to the constraints set by the element's [`type`](/en-US/docs/Web/HTML/Element/input#input_types) attribute.\n\nIf the `type` attribute expects specific strings, such as the `email` and `url` types and the value doesn't conform to the constraints set by the type, the `typeMismatch` property will be true.\n\nThe `email` input type expects one or more valid email addresses, depending on whether the [`multiple`](/en-US/docs/Web/HTML/Attributes/multiple) attribute is present. A valid email address includes an email prefix and a domain, with or without a top level domain. If the value of the email input is not an empty string, a single valid email address, or one or more comma separated email address if the [`multiple`](/en-US/docs/Web/HTML/Attributes/multiple) attribute is present, there is a `typeMismatch`.\n\nThe `url` input type expects one or more valid URLs, depending on whether the [`multiple`](/en-US/docs/Web/HTML/Attributes/multiple) attribute is present. A valid URL includes a protocol, optionally with an IP address, or an optional subdomain, domain, and top level domain combination. If the value of the URL input is not an empty string, a single valid URL, or one or more comma separated URLS if the [`multiple`](/en-US/docs/Web/HTML/Attributes/multiple) attribute is present, there is a `typeMismatch`.\n\n| Input type                              | Value             | Expected value                                                 |\n| --------------------------------------- | ----------------- | -------------------------------------------------------------- |\n| `email` | `x@y` or `x@y.z`  | email address, with or without [TLD](/en-US/docs/Glossary/TLD) |\n| `url`     | `x:` or `x://y.z` | protocol or full URL with protocol                             |",
      "valuemissing": "\n\nThe read-only **`valueMissing`** property of a **[`ValidityState`](/en-US/docs/Web/API/ValidityState)** object indicates if a [`required`](/en-US/docs/Web/HTML/Attributes/required) control, such as an `input`, `select`, or `textarea`, has an empty value.\n\nIf the `required` attribute is set, and no `option` is selected or a `<textarea>` or user-editable `<input>` is empty, the `valueMissing` property will be `true`. The property is only `true` if the field is required and has no value; if the field is not required, or if the field is required and has a value, the value is `false`."
    }
  },
  "videocolorspace": {
    "docs": "\n\nThe **`VideoColorSpace`** interface of the [WebCodecs API] represents the color space of a video.",
    "properties": {
      "fullrange": "`WebCodecs API`\n\nThe **`fullRange`** read-only property of the [VideoColorSpace] interface returns `true` if full-range color values are used.",
      "matrix": "`WebCodecs API`\n\nThe **`matrix`** read-only property of the [VideoColorSpace] interface returns the matrix coefficient of the video. Matrix coefficients describe the relationship between sample component values and color coordinates.",
      "primaries": "`WebCodecs API`\n\nThe **`primaries`** read-only property of the [VideoColorSpace] interface returns the color  of the video.",
      "tojson": "`WebCodecs API`\n\nThe **`toJSON()`** method of the [VideoColorSpace] interface is a _serializer_ that returns a JSON representation of the `VideoColorSpace` object.",
      "transfer": "`WebCodecs API`\n\nThe **`transfer`** read-only property of the [VideoColorSpace] interface returns the opto-electronic transfer characteristics of the video."
    }
  },
  "videodecoder": {
    "docs": "\n\nThe **`VideoDecoder`** interface of the [WebCodecs API] decodes chunks of video.\n\n",
    "properties": {
      "close": "\n\nThe **`close()`** method of the [VideoDecoder] interface ends all pending work and releases system resources.",
      "configure": "\n\nThe **`configure()`** method of the [VideoDecoder] interface enqueues a control message to configure the video decoder for decoding chunks.",
      "decode": "\n\nThe **`decode()`** method of the [VideoDecoder] interface enqueues a control message to decode a given chunk of video.",
      "decodequeuesize": "\n\nThe **`decodeQueueSize`** read-only property of the [VideoDecoder] interface returns the number of pending decode requests in the queue.",
      "dequeue_event": "\n\nThe **`dequeue`** event of the [VideoDecoder] interface fires to signal a decrease in [VideoDecoder.decodeQueueSize].\n\nThis eliminates the need for developers to use a [setTimeout] poll to determine when the queue has decreased, and more work should be queued up.",
      "flush": "\n\nThe **`flush()`** method of the [VideoDecoder] interface returns a Promise that resolves once all pending messages in the queue have been completed.",
      "isconfigsupported_static": "\n\nThe **`isConfigSupported()`** static method of the [VideoDecoder] interface checks if the given config is supported (that is, if [VideoDecoder] objects can be successfully configured with the given config).",
      "reset": "\n\nThe **`reset()`** method of the [VideoDecoder] interface resets all states including configuration, control messages in the control message queue, and all pending callbacks.",
      "state": "\n\nThe **`state`** property of the [VideoDecoder] interface returns the current state of the underlying codec."
    }
  },
  "videoencoder": {
    "docs": "\n\nThe **`VideoEncoder`** interface of the [WebCodecs API] encodes [VideoFrame] objects into [EncodedVideoChunk]s.\n\n",
    "properties": {
      "close": "\n\nThe **`close()`** method of the [VideoEncoder] interface ends all pending work and releases system resources.",
      "configure": "\n\nThe **`configure()`** method of the [VideoEncoder] interface changes the [VideoEncoder.state] of the encoder to \"configured\" and asynchronously prepares the encoder to accept [VideoEncoder]s for encoding with the specified parameters. If the encoder doesn't support the specified parameters or can't be initialized for other reasons an error will be reported via the error callback provided to the [VideoEncoder] constructor.\n\nIf the [VideoEncoder] has been previously configured, the new configuration will not be applied until all previous tasks have completed.",
      "dequeue_event": "\n\nThe **`dequeue`** event of the [VideoEncoder] interface fires to signal a decrease in [VideoEncoder.encodeQueueSize].\n\nThis eliminates the need for developers to use a [setTimeout] poll to determine when the queue has decreased, and more work should be queued up.",
      "encode": "\n\nThe **`encode()`** method of the [VideoEncoder] interface asynchronously encodes a [VideoFrame].\nEncoded data ([EncodedVideoChunk]) or an error will eventually be returned via the callbacks provided to the [VideoEncoder] constructor.",
      "encodequeuesize": "\n\nThe **`encodeQueueSize`** read-only property of the [VideoEncoder] interface returns the number of pending encode requests in the queue.",
      "flush": "\n\nThe **`flush()`** method of the [VideoEncoder] interface forces all pending encodes to complete.",
      "isconfigsupported_static": "\n\nThe **`isConfigSupported()`** static method of the [VideoEncoder] interface checks if [VideoEncoder] can be successfully configured with the given config.",
      "reset": "\n\nThe **`reset()`** method of the [VideoEncoder] interface synchronously cancels all pending encodes and callbacks, frees all underlying resources and sets the [VideoEncoder.state] to \"unconfigured\".\nAfter calling [VideoEncoder.reset], [VideoEncoder.configure] must be called before resuming [VideoEncoder.encode] calls.\n\n> **Note:** To avoid discarding frames queued via [VideoEncoder.encode], [VideoEncoder.flush] should be called and completed before calling [VideoEncoder.reset].",
      "state": "\n\nThe **`state`** read-only property of the [VideoEncoder] interface returns the current state of the underlying codec."
    }
  },
  "videoframe": {
    "docs": "\n\nThe **`VideoFrame`** interface of the [Web Codecs API](/en-US/docs/Web/API/WebCodecs_API) represents a frame of a video.\n\n`VideoFrame` is a [transferable object](/en-US/docs/Web/API/Web_Workers_API/Transferable_objects).",
    "properties": {
      "allocationsize": "\n\nThe **`allocationSize()`** method of the [VideoFrame] interface returns the number of bytes required to hold the video as filtered by options passed into the method.",
      "clone": "\n\nThe **`clone()`** method of the [VideoFrame] interface creates a new `VideoFrame` object referencing the same media resource as the original.",
      "close": "\n\nThe **`close()`** method of the [VideoFrame] interface clears all states and releases the reference to the media resource.",
      "codedheight": "\n\nThe **`codedHeight`** property of the [VideoFrame] interface returns the height of the VideoFrame in pixels, potentially including non-visible padding, and prior to considering potential ratio adjustments.",
      "codedrect": "\n\nThe **`codedRect`** property of the [VideoFrame] interface returns a [DOMRectReadOnly] with the width and height matching [VideoFrame.codedWidth] and [VideoFrame.codedHeight].",
      "codedwidth": "\n\nThe **`codedWidth`** property of the [VideoFrame] interface returns the width of the `VideoFrame` in pixels, potentially including non-visible padding, and prior to considering potential ratio adjustments.",
      "colorspace": "\n\nThe **`colorSpace`** property of the [VideoFrame] interface returns a [VideoColorSpace] object representing the color space of the video.",
      "copyto": "\n\nThe **`copyTo()`** method of the [VideoFrame] interface copies the contents of the `VideoFrame` to an `ArrayBuffer`.",
      "displayheight": "\n\nThe **`displayHeight`** property of the [VideoFrame] interface returns the height of the `VideoFrame` after applying aspect ratio adjustments.",
      "displaywidth": "\n\nThe **`displayWidth`** property of the [VideoFrame] interface returns the width of the `VideoFrame` after applying aspect ratio adjustments.",
      "duration": "\n\nThe **`duration`** property of the [VideoFrame] interface returns an integer indicating the duration of the video in microseconds.",
      "format": "\n\nThe **`format`** property of the [VideoFrame] interface returns the pixel format of the `VideoFrame`.",
      "timestamp": "\n\nThe **`timestamp`** property of the [VideoFrame] interface returns an integer indicating the timestamp of the video in microseconds.",
      "visiblerect": "\n\nThe **`visibleRect`** property of the [VideoFrame] interface returns a [DOMRectReadOnly] describing the visible rectangle of pixels for this `VideoFrame`."
    }
  },
  "videoplaybackquality": {
    "docs": "\n\nA **`VideoPlaybackQuality`** object is returned by the [HTMLVideoElement.getVideoPlaybackQuality] method and contains metrics that can be used to determine the playback quality of a video.",
    "properties": {
      "corruptedvideoframes": "\n\nThe [VideoPlaybackQuality] interface's read-only\n**`corruptedVideoFrames`** property the number of corrupted\nvideo frames that have been received since the `video` element was\nlast loaded or reloaded.",
      "creationtime": "\n\nThe read-only **`creationTime`** property on the\n[VideoPlaybackQuality] interface reports the number of milliseconds since\nthe browsing context was created this quality sample was recorded.",
      "droppedvideoframes": "\n\nThe read-only **`droppedVideoFrames`**\nproperty of the [VideoPlaybackQuality] interface returns the number of\nvideo frames which have been dropped rather than being displayed since the last time\nthe media was loaded into the [HTMLVideoElement].",
      "totalframedelay": "\n\nThe **`VideoPlaybackQuality.totalFrameDelay`** read-only\nproperty returns a `double` containing the sum of the frame delay since the\ncreation of the associated [HTMLVideoElement]. The frame delay is the\ndifference between a frame's theoretical presentation time and its effective display\ntime.",
      "totalvideoframes": "\n\nThe [VideoPlaybackQuality] interface's\n**`totalVideoFrames`** read-only property returns the total\nnumber of video frames that have been displayed or dropped since the media was\nloaded."
    }
  },
  "videotrack": {
    "docs": "\n\nThe [VideoTrack] interface represents a single video track from a `video` element.\n\nThe most common use for accessing a `VideoTrack` object is to toggle its [VideoTrack.selected] property in order to make it the active video track for its `video` element.",
    "properties": {
      "id": "\n\nThe **`id`** property contains a\nstring which uniquely identifies the track represented by the\n**[VideoTrack]**.\n\nThis ID can be used with the\n[VideoTrackList.getTrackById] method to locate a specific track within\nthe media associated with a media element.\n\nThe track ID can also be used as the fragment of a URL that loads the specific track\n(if the media supports media fragments).",
      "kind": "\n\nThe **`kind`** property contains a\nstring indicating the category of video contained in the\n**[VideoTrack]**.\n\nThe `kind` can be used\nto determine the scenarios in which specific tracks should be enabled or disabled. See\n[Video track kind strings](#video_track_kind_strings) for a list of the kinds available for video tracks.",
      "label": "\n\nThe read-only **[VideoTrack]**\nproperty **`label`** returns a string specifying the video\ntrack's human-readable label, if one is available; otherwise, it returns an empty\nstring.",
      "language": "\n\nThe read-only **[VideoTrack]**\nproperty **`language`** returns a string identifying the\nlanguage used in the video track.\n\nFor tracks that include multiple languages\n(such as a movie in English in which a few lines are spoken in other languages), this\nshould be the video's primary language.",
      "selected": "\n\nThe **[VideoTrack]** property\n**`selected`** controls whether or not a particular video\ntrack is active.",
      "sourcebuffer": "\n\nThe read-only **[VideoTrack]**\nproperty **`sourceBuffer`** returns the\n[SourceBuffer] that created the track, or null if the track was not\ncreated by a [SourceBuffer] or the [SourceBuffer] has been\nremoved from the [MediaSource.sourceBuffers] attribute of its parent\nmedia source."
    }
  },
  "videotracklist": {
    "docs": "\n\nThe **`VideoTrackList`** interface is used to represent a list of the video tracks contained within a `video` element, with each track represented by a separate [VideoTrack] object in the list.\n\nRetrieve an instance of this object with [HTMLMediaElement.videoTracks]. The individual tracks can be accessed using array syntax or functions such as `forEach()` for example.\n\n",
    "properties": {
      "addtrack_event": "\n\nThe `addtrack` event is fired when a video track is added to a [`VideoTrackList`](/en-US/docs/Web/API/VideoTrackList).",
      "change_event": "\n\nThe `change` event is fired when a video track is made active or inactive, for example by changing the track's [`selected`](/en-US/docs/Web/API/VideoTrack/selected) property.",
      "gettrackbyid": "\n\nThe **[VideoTrackList]** method\n**`getTrackById()`** returns the first\n[VideoTrack] object from the track list whose [VideoTrack.id] matches the specified string.\n\nThis lets you find a specified track if\nyou know its ID string.",
      "length": "\n\nThe read-only **[VideoTrackList]**\nproperty **`length`** returns the number of entries in the\n`VideoTrackList`, each of which is a [VideoTrack] representing\none video track in the media element.\n\nA value of 0 indicates that there are no\nvideo tracks in the media.",
      "removetrack_event": "\n\nThe `removetrack` event is fired when a video track is removed from a [`VideoTrackList`](/en-US/docs/Web/API/VideoTrackList).",
      "selectedindex": "\n\nThe read-only **[VideoTrackList]**\nproperty **`selectedIndex`** returns the index of the\ncurrently selected track, if any, or `-1` otherwise."
    }
  },
  "viewtimeline": {
    "docs": "\n\nThe **`ViewTimeline`** interface of the [Web Animations API] represents a view progress timeline (see [CSS scroll-driven animations](/en-US/docs/Web/CSS/CSS_scroll-driven_animations) for more details).\n\nPass a `ViewTimeline` instance to the [Animation.Animation] constructor or the [Element.animate] method to specify it as the timeline that will control the progress of the animation.\n\n",
    "properties": {
      "endoffset": "\n\nThe **`endOffset`** read-only property of the [ViewTimeline] interface returns a [CSSNumericValue] representing the ending (100% progress) scroll position of the timeline as an offset from the start of the overflowing section of content in the scroller.",
      "startoffset": "\n\nThe **`startOffset`** read-only property of the [ViewTimeline] interface returns a [CSSNumericValue] representing the starting (0% progress) scroll position of the timeline as an offset from the start of the overflowing section of content in the scroller.",
      "subject": "\n\nThe **`subject`** read-only property of the [ViewTimeline] interface returns a reference to the subject element whose visibility within its nearest ancestor scrollable element (scroller) is driving the progress of the timeline."
    }
  },
  "viewtransition": {
    "docs": "\n\nThe **`ViewTransition`** interface of the [View Transitions API] represents a view transition, and provides functionality to react to the transition reaching different states (e.g. ready to run the animation, or animation finished) or skip the transition altogether.\n\nThis object type is returned by the [Document.startViewTransition] method. When `startViewTransition()` is invoked, a sequence of steps is followed as explained in [The view transition process](/en-US/docs/Web/API/View_Transitions_API#the_view_transition_process). This also explains when the different promises fulfill.\n\n",
    "properties": {
      "finished": "\n\nThe **`finished`** read-only property of the\n[ViewTransition] interface is a `Promise` that fulfills once the transition animation is finished, and the new page view is visible and interactive to the user.\n\n`finished` only rejects if the callback passed to [Document.startViewTransition]throws or returns a promise that rejects, which indicates that the new state of the page wasn't created.\n\nIf a transition animation fails to start, or is skipped during the animation using [ViewTransition.skipTransition], the end state is still reached therefore `finished` still fulfills.",
      "ready": "\n\nThe **`ready`** read-only property of the\n[ViewTransition] interface is a `Promise` that fulfills once the pseudo-element tree is created and the transition animation is about to start.\n\n`ready` will reject if the transition cannot begin. This can be due to misconfiguration, for example duplicate s, or if the callback passed to [Document.startViewTransition] throws or returns a promise that rejects.",
      "skiptransition": "\n\nThe **`skipTransition()`** method of the\n[ViewTransition] interface skips the animation part of the view transition, but doesn't skip running the [Document.startViewTransition] callback that updates the DOM.",
      "updatecallbackdone": "\n\nThe **`updateCallbackDone`** read-only property of the\n[ViewTransition] interface is a `Promise` that fulfills when the promise returned by the [Document.startViewTransition]'s callback fulfills, or rejects when it rejects.\n\n`updateCallbackDone` is useful when you don't care about the success/failure of the transition animation, and just want to know if and when the DOM is updated."
    }
  },
  "virtualkeyboard": {
    "docs": "\n\nThe **`VirtualKeyboard`** interface of the [VirtualKeyboard API](/en-US/docs/Web/API/VirtualKeyboard_API) is useful on devices that have on-screen virtual keyboards, such as tablets, mobile phones, or other devices where a hardware keyboard may not be available.\n\nThe `VirtualKeyboard` interface makes it possible to opt out of the automatic way browsers handle on-screen virtual keyboards by reducing the height of the viewport to make room for the virtual keyboard. You can prevent the browser from changing the size of the viewport, detect the position and size of the virtual keyboard — adapting the layout of your web page as a follow-up — and programmatically show or hide the virtual keyboard.\n\nYou access the `VirtualKeyboard` interface by using [navigator.virtualKeyboard].\n\n",
    "properties": {
      "boundingrect": "\n\nThe **`boundingRect`** property of the [VirtualKeyboard] interface contains a [DOMRect] indicating the position and size of the on-screen virtual keyboard that overlays the web page.\n\nThe on-screen virtual keyboard will overlay the viewport when the [VirtualKeyboard_API] is used to prevent the browser from resizing the viewport automatically. This is done by setting the [VirtualKeyboard.overlaysContent] property to `true`.",
      "geometrychange_event": "\n\nThe **`geometrychange`** event of the [VirtualKeyboard]\ninterface fires when the on-screen virtual keyboard is toggled between shown and hidden states.\n\nThe `geometrychange` event is useful to detect when the virtual keyboard appears and disappears, so you can adjust the layout as appropriate. This is necessary when using the [VirtualKeyboard_API] to disable the browser's default automatic resizing of the viewport when the virtual keyboard is shown and hidden.",
      "hide": "\n\nThe **`hide()`** method of the [VirtualKeyboard] interface programmatically hides the on-screen virtual keyboard. This is useful when the page needs to implement its own virtual keyboard logic by using the [VirtualKeyboard_API].\n\nThis method only works if the currently-focused element's [`virtualKeyboardPolicy`](/en-US/docs/Web/HTML/Global_attributes/virtualkeyboardpolicy) attribute is set to `manual` and [`inputmode`](/en-US/docs/Web/HTML/Global_attributes/inputmode) isn't set to `none`.\n\nThe `hide()` method always returns `undefined` and triggers a [VirtualKeyboard.geometrychange_event] event.",
      "overlayscontent": "\n\nThe **`overlaysContent`** property of the VirtualKeyboard interface can be used to opt out of the automatic way in which browsers handle on-screen virtual keyboards by reducing the size of the viewport to make space for them.\n\nIf the `overlaysContent` property is set to `true`, the browser no longer resizes the viewport when the virtual keyboard appears. The virtual keyboard instead overlays the content of the web page, and you can adapt the page layout as appropriate using the [VirtualKeyboard_API] and your own custom CSS and JavaScript.",
      "show": "\n\nThe **`show()`** method of the [VirtualKeyboard] interface programmatically shows the on-screen virtual keyboard. This is useful when the page needs to implement its own virtual keyboard logic, especially when using the `virtualkeyboardpolicy` attribute on `contenteditable` elements as explained in [Control the virtual keyboard on `contenteditable` elements](/en-US/docs/Web/API/VirtualKeyboard_API#control_the_virtual_keyboard_on_contenteditable_elements).\n\nThis method only works if the currently-focused element is a form control — such as an `input` or `textarea` element — or if the focused element is [`contenteditable`](/en-US/docs/Web/HTML/Global_attributes/contenteditable), and the currently-focused element's [`virtualKeyboardPolicy`](/en-US/docs/Web/HTML/Global_attributes/virtualkeyboardpolicy) attribute is set to `manual` and [`inputmode`](/en-US/docs/Web/HTML/Global_attributes/inputmode) isn't set to `none`.\n\nThe `show()` method always returns `undefined` and triggers a [VirtualKeyboard.geometrychange_event] event."
    }
  },
  "visibilitystateentry": {
    "docs": "\n\nThe **`VisibilityStateEntry`** interface provides timings of page visibility state changes, i.e., when a tab changes from the foreground to the background or vice versa.\n\nThis can be used to pinpoint visibility changes on the performance timeline, and cross-reference them against other performance entries such as \"first-contentful-paint\" (see [PerformancePaintTiming]).\n\nThere are two key visibility state change times that this API reports on:\n\n- `visible`: The time when the page becomes visible (i.e. when its tab moves into the foreground).\n- `hidden`: The time when the pages become hidden (i.e. when its tab moves into the background).\n\nThe performance timeline will always have a \"`visibility-state`\" entry with a `startTime` of `0` and a `name` representing the initial page visibility state.\n\n> **Note:** Like other Performance APIs, this API extends [PerformanceEntry].\n\n"
  },
  "visualviewport": {
    "docs": "\n\nThe **`VisualViewport`** interface of the [Visual Viewport API](/en-US/docs/Web/API/Visual_Viewport_API) represents the visual viewport for a given window. For a page containing iframes, each iframe, as well as the containing page, will have a unique window object. Each window on a page will have a unique `VisualViewport` representing the properties associated with that window.\n\nYou can get a window's visual viewport using [Window.visualViewport].\n\n> **Note:** Only the top-level window has a visual viewport that's distinct from the layout viewport. Therefore, it's generally only the `VisualViewport` object of the top-level window that's useful. For an `iframe`, visual viewport metrics like [VisualViewport.width] always correspond to layout viewport metrics like [Element.clientWidth].\n\n",
    "properties": {
      "height": "\n\nThe **`height`** read-only property of the\n[VisualViewport] interface returns the height of the visual viewport, in\nCSS pixels.",
      "offsetleft": "\n\nThe **`offsetLeft`** read-only property of the\n[VisualViewport] interface returns the offset of the left edge of the\nvisual viewport from the left edge of the layout viewport in CSS pixels.",
      "offsettop": "\n\nThe **`offsetTop`** read-only property of the\n[VisualViewport] interface returns the offset of the top edge of the visual\nviewport from the top edge of the layout viewport in CSS pixels.",
      "pageleft": "\n\nThe **`pageLeft`** read-only property of the\n[VisualViewport] interface returns the x coordinate of the left edge of the\nvisual viewport relative to the initial containing block origin, in CSS pixels.",
      "pagetop": "\n\nThe **`pageTop`** read-only property of the\n[VisualViewport] interface returns the y coordinate of the top edge of the\nvisual viewport relative to the initial containing block origin, in CSS pixels.",
      "resize_event": "\n\nThe **`resize`** event of the [`VisualViewport`](/en-US/docs/Web/API/VisualViewport) interface is fired when the visual viewport is resized.",
      "scale": "\n\nThe **`scale`** read-only property of the\n[VisualViewport] interface returns the pinch-zoom scaling factor applied\nto the visual viewport.",
      "scroll_event": "\n\nThe **`scroll`** event of the [`VisualViewport`](/en-US/docs/Web/API/VisualViewport) interface is fired when the visual viewport is scrolled.",
      "width": "\n\nThe **`width`** read-only property of the\n[VisualViewport] interface returns the width of the visual viewport, in CSS\npixels."
    }
  },
  "vrdisplay": {
    "docs": "\n\nThe **`VRDisplay`** interface of the [WebVR API](/en-US/docs/Web/API/WebVR_API) represents any VR device supported by this API. It includes generic information such as device IDs and descriptions, as well as methods for starting to present a VR scene, retrieving eye parameters and display capabilities, and other important functionality.\n\n> **Note:** This interface was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nAn array of all connected VR Devices can be returned by invoking the [Navigator.getVRDisplays] method.",
    "properties": {
      "cancelanimationframe": "\n\nThe **`cancelAnimationFrame()`** method of the [VRDisplay] interface is a special implementation of [Window.cancelAnimationFrame] that unregisters callbacks registered with [VRDisplay.requestAnimationFrame].\n\n> **Note:** This method was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
      "capabilities": "\n\nThe **`capabilities`** read-only property of the [VRDisplay] interface returns a [VRDisplayCapabilities] object that indicates the various capabilities of the `VRDisplay`.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
      "depthfar": "\n\nThe **`depthFar`** property of the [VRDisplay] interface gets and sets the z-depth defining the far plane of the [eye view frustum](https://en.wikipedia.org/wiki/Viewing_frustum), i.e. the furthest viewable boundary of the scene.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nGenerally you should leave the value as is, but you might want to reduce it if you are trying to improve performance on slower computers.",
      "depthnear": "\n\nThe **`depthNear`** property of the [VRDisplay] interface gets and sets the z-depth defining the near plane of the [eye view frustum](https://en.wikipedia.org/wiki/Viewing_frustum), i.e. the nearest viewable boundary of the scene.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nGenerally you should leave the value as is, but you might want to increase it if you are trying to improve performance on slower computers, and/or your UI makes sense with the near boundary made further away.",
      "displayid": "\n\nThe **`displayId`** read-only property of the [VRDisplay] interface returns an identifier for this particular `VRDisplay`, which is also used as an association point in the [Gamepad API](/en-US/docs/Web/API/Gamepad_API) (see [Gamepad.displayId]).\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
      "displayname": "\n\nThe **`displayName`** read-only property of the [VRDisplay] interface returns a human-readable name to identify the `VRDisplay`.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nThis will generally be something like \"Oculus VR HMD (HMD)\" or \"Oculus VR HMD (Sensor)\".",
      "exitpresent": "\n\nThe **`exitPresent()`** method of the [VRDisplay] interface stops the `VRDisplay` presenting a scene.\n\n> **Note:** This method was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
      "geteyeparameters": "\n\nThe **`getEyeParameters()`** method of the [VRDisplay] interface returns the [VREyeParameters] object containing the eye parameters for the specified eye.\n\n> **Note:** This method was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
      "getframedata": "\n\nThe **`getFrameData()`** method of the [VRDisplay] interface accepts a [VRFrameData] object and populates it with the information required to render the current frame.\n\n> **Note:** This method was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nThis includes the [VRPose] and view and projection matrices for the current frame.",
      "getimmediatepose": "\n\nThe **`getImmediatePose()`** method of the [VRDisplay] interface returns a [VRPose] object defining the current pose of the `VRDisplay`, with no prediction applied.\n\n> **Note:** This method was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
      "getlayers": "\n\nThe **`getLayers()`** method of the [VRDisplay] interface returns the layers currently being presented by the `VRDisplay`.\n\n> **Note:** This method was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
      "getpose": "\n\nThe **`getPose()`** method of the [VRDisplay] interface returns a [VRPose] object defining the future predicted pose of the `VRDisplay` as it will be when the current frame is actually presented.\n\n> **Note:** This method was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n>\n> It was even deprecated there — instead, you should use [VRDisplay.getFrameData], which also provides a [VRPose] object.",
      "isconnected": "\n\nThe **`isConnected`** read-only property of the [VRDisplay] interface returns a boolean value indicating whether the `VRDisplay` is connected to the computer.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
      "ispresenting": "\n\nThe **`isPresenting`** read-only property of the [VRDisplay] interface returns a boolean value indicating whether the `VRDisplay` is currently having content presented through it.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
      "requestanimationframe": "\n\nThe **`requestAnimationFrame()`** method of the [VRDisplay] interface is a special implementation of [Window.requestAnimationFrame] containing a callback function that will be called every time a new frame of the `VRDisplay` presentation is rendered:\n\n> **Note:** This method was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\n- When the `VRDisplay` is not presenting a scene, this is functionally equivalent to [Window.requestAnimationFrame].\n- When the `VRDisplay` is presenting, the callback is called at its native refresh rate.",
      "requestpresent": "\n\nThe **`requestPresent()`** method of the [VRDisplay] interface starts the `VRDisplay` presenting a scene.\n\n> **Note:** This method was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
      "resetpose": "\n\nThe **`resetPose()`** method of the [VRDisplay] interface resets the pose for the `VRDisplay`, treating its current [VRPose.position] and [VRPose.orientation] as the \"origin/zero\" values.\n\n> **Note:** This method was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nAfter `resetPost()` has been called, future poses returned from [VRDisplay.getPose]/[VRDisplay.getImmediatePose] will describe positions relative to the `VRDisplay`'s position when `resetPose()` was last called and will treat the display's yaw when `resetPose()` was last called as the forward orientation.\n\nThe VRDisplay's reported roll and pitch do not change when `resetPose()` is called as they are relative to gravity. Calling `resetPose()` may change the [VRStageParameters.sittingToStandingTransform] matrix.",
      "stageparameters": "\n\nThe **`stageParameters`** read-only property of the [VRDisplay] interface returns a [VRStageParameters] object containing room-scale parameters, if the `VRDisplay` is capable of supporting room-scale experiences.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
      "submitframe": "\n\nThe **`submitFrame()`** method of the [VRDisplay] interface captures the current state of the [VRLayerInit] currently being presented and displays it on the `VRDisplay`.\n\n> **Note:** This method was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nThe frame should subsequently be rendered using the [VRPose] and matrices provided by the last call to [VRDisplay.getFrameData]."
    }
  },
  "vrdisplaycapabilities": {
    "docs": "\n\nThe **`VRDisplayCapabilities`** interface of the [WebVR API](/en-US/docs/Web/API/WebVR_API) describes the capabilities of a [VRDisplay] — its features can be used to perform VR device capability tests, for example can it return position information.\n\n> **Note:** This interface was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nThis interface is accessible through the [VRDisplay.capabilities] property.",
    "properties": {
      "canpresent": "\n\nThe **`canPresent`** read-only property of the [VRDisplayCapabilities] interface returns a boolean value stating whether the VR display is capable of presenting content (e.g. through an HMD).\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nThis is useful for identifying \"magic window\" devices that are capable of 6DoF tracking but for which [VRDisplay.requestPresent] is not meaningful. If `canPresent` is `false`, calls to [VRDisplay.requestPresent] will fail, and [VRDisplay.getEyeParameters] will return `null`.",
      "hasexternaldisplay": "\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nThe **`hasExternalDisplay`** read-only property of the [VRDisplayCapabilities] interface returns `true` if the VR display is separate from the device's primary display.\n\n> **Note:** If presenting VR content would obscure other content on the device, this will return `false`, in which case the application should not attempt to mirror VR content or update non-VR UI because that content will not be visible.",
      "hasorientation": "\n\nThe **`hasOrientation`** read-only property of the [VRDisplayCapabilities] interface returns `true` if the VR display can track and return orientation information.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
      "hasposition": "\n\nThe **`hasPosition`** read-only property of the [VRDisplayCapabilities] interface returns `true` if the VR display can track and return position information.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
      "maxlayers": "\n\nThe **`maxLayers`** read-only property of the [VRDisplayCapabilities] interface returns a number indicating the maximum number of [VRLayerInit]s that the VR display can present at once (e.g. the maximum length of the array that [VRDisplay.requestPresent] can accept.)\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/)."
    }
  },
  "vrdisplayevent": {
    "docs": "\n\nThe **`VRDisplayEvent`** interface of the [WebVR API](/en-US/docs/Web/API/WebVR_API) represents the event object of WebVR-related events (see the [list of WebVR window extensions](/en-US/docs/Web/API/WebVR_API#window)).\n\n> **Note:** This interface was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
    "properties": {
      "display": "\n\nThe **`display`** read-only property of the [VRDisplayEvent] interface returns the [VRDisplay] associated with this event.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
      "reason": "\n\nThe **`reason`** read-only property of the [VRDisplayEvent] interface returns a human-readable reason why the event was fired.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/)."
    }
  },
  "vreyeparameters": {
    "docs": "\n\nThe **`VREyeParameters`** interface of the [WebVR API](/en-US/docs/Web/API/WebVR_API) represents all the information required to correctly render a scene for a given eye, including field of view information.\n\n> **Note:** This interface was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nThis interface is accessible through the [VRDisplay.getEyeParameters] method.\n\n> **Warning:** The values in this interface should not be used to compute view or projection matrices. In order to ensure the widest possible hardware compatibility use the matrices provided by [VRFrameData].",
    "properties": {
      "fieldofview": "\n\nThe **`fieldOfView`** read-only property of the [VREyeParameters] interface returns a [VRFieldOfView] object describing the current field of view for the eye, which can vary as the user adjusts their interpupillary distance (IPD).\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
      "maximumfieldofview": "\n\nThe **`maximumFieldOfView`** read-only property of the [VREyeParameters] interface describes the maximum supported field of view for the current eye.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
      "minimumfieldofview": "\n\nThe **`minimumFieldOfView`** read-only property of the [VREyeParameters] interface describes the minimum supported field of view for the current eye.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
      "offset": "\n\nThe **`offset`** read-only property of the [VREyeParameters] interface represents the offset from the center point between the user's eyes to the center of the eye, measured in meters.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nThis value should represent half the user's interpupillary distance (IPD), but may also represent the distance from the center point of the headset to the center point of the lens for the given eye.",
      "renderheight": "\n\nThe **`renderHeight`** read-only property of the [VREyeParameters] interface describes the recommended render target height of each eye viewport, in pixels.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nThis is already in device pixel units, so there's no need to multiply by [Window.devicePixelRatio](/en-US/docs/Web/API/Window/devicePixelRatio) before setting to [HTMLCanvasElement.height.](/en-US/docs/Web/API/HTMLCanvasElement/height)",
      "renderwidth": "\n\nThe **`renderWidth`** read-only property of the [VREyeParameters] interface describes the recommended render target width of each eye viewport, in pixels.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nThis is already in device pixel units, so there's no need to multiply by [Window.devicePixelRatio](/en-US/docs/Web/API/Window/devicePixelRatio) before setting to [HTMLCanvasElement.width.](/en-US/docs/Web/API/HTMLCanvasElement/width)"
    }
  },
  "vrfieldofview": {
    "docs": "\n\nThe **`VRFieldOfView`** interface of the [WebVR API](/en-US/docs/Web/API/WebVR_API) represents a field of view defined by 4 different degree values describing the view from a center point.\n\n> **Note:** This interface was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
    "properties": {
      "downdegrees": "\n\nThe **`downDegrees`** read-only property of the [VRFieldOfView] interface returns the number of degrees downwards that the field of view extends in.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
      "leftdegrees": "\n\nThe **`leftDegrees`** read-only property of the [VRFieldOfView] interface returns the number of degrees to the left that the field of view extends in.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
      "rightdegrees": "\n\nThe **`rightDegrees`** read-only property of the [VRFieldOfView] interface returns the number of degrees to the right that the field of view extends in.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
      "updegrees": "\n\nThe **`upDegrees`** read-only property of the [VRFieldOfView] interface returns the number of degrees upwards that the field of view extends in.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/)."
    }
  },
  "vrframedata": {
    "docs": "\n\nThe **`VRFrameData`** interface of the [WebVR API](/en-US/docs/Web/API/WebVR_API) represents all the information needed to render a single frame of a VR scene; constructed by [VRDisplay.getFrameData].\n\n> **Note:** This interface was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
    "properties": {
      "leftprojectionmatrix": "\n\nThe **`leftProjectionMatrix`** read-only property of the [VRFrameData] interface returns a `Float32Array` representing a 4x4 matrix that describes the projection to be used for the left eye's rendering.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nThis value may be passed directly to WebGL's [WebGLRenderingContext.uniformMatrix] function.\n\n> **Warning:** It is highly recommended that applications use this matrix without modification. Failure to use this projection matrix when rendering may cause the presented frame to be distorted or badly aligned, resulting in varying degrees of user discomfort.",
      "leftviewmatrix": "\n\nThe **`leftViewMatrix`** read-only property of the [VRFrameData] interface returns a `Float32Array` representing a 4x4 matrix that describes the view transform to be used for the left eye's rendering.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nThis value may be passed directly to WebGL's [WebGLRenderingContext.uniformMatrix] function.\n\n> **Warning:** It is highly recommended that applications use this matrix when rendering.",
      "pose": "\n\nThe **`pose`** read-only property of the [VRFrameData] interface returns the [VRPose] of the [VRDisplay] at the current [VRFrameData.timestamp].\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
      "rightprojectionmatrix": "\n\nThe **`rightProjectionMatrix`** read-only property of the [VRFrameData] interface returns a `Float32Array` representing a 4x4 matrix that describes the projection to be used for the right eye's rendering.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nThis value may be passed directly to WebGL's [WebGLRenderingContext.uniformMatrix] function.\n\n> **Warning:** It is highly recommended that applications use this matrix without modification. Failure to use this projection matrix when rendering may cause the presented frame to be distorted or badly aligned, resulting in varying degrees of user discomfort.",
      "rightviewmatrix": "\n\nThe **`rightViewMatrix`** read-only property of the [VRFrameData] interface returns a `Float32Array` representing a 4x4 matrix that describes the view transform to be used for the right eye's rendering.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nThis value may be passed directly to WebGL's [WebGLRenderingContext.uniformMatrix] function.\n\n> **Warning:** It is highly recommended that applications use this matrix when rendering.",
      "timestamp": "\n\nThe **`timestamp`** read-only property of the [VRFrameData] interface returns a constantly increasing timestamp value representing the time a frame update occurred.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nTimestamps are useful for determining if position state data has been updated from the hardware. Since values are monotonically increasing, they can be compared to determine the ordering of updates — newer values will always be greater than or equal to older values.\n\nThe timestamp starts at 0 the first time [VRDisplay.getFrameData] is invoked for a given [VRDisplay]."
    }
  },
  "vrlayerinit": {
    "docs": "\n\nThe **`VRLayerInit`** dictionary of the [WebVR API](/en-US/docs/Web/API/WebVR_API) represents a content layer (an [HTMLCanvasElement] or [OffscreenCanvas]) that you want to present in a VR display.\n\n> **Note:** This dictionary was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nYou can retrieve `VRLayerInit` objects using [VRDisplay.getLayers], and present them using the [VRDisplay.requestPresent] method.",
    "properties": {
      "leftbounds": "\n\nThe **`leftBounds`** property of the [VRLayerInit] interface (dictionary) defines the left texture bounds of the canvas whose contents will be presented by the [VRDisplay].\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
      "rightbounds": "\n\nThe **`rightBounds`** property of the [VRLayerInit] interface (dictionary) defines the right texture bounds of the canvas whose contents will be presented by the [VRDisplay].\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).",
      "source": "\n\nThe **`source`** property of the [VRLayerInit] interface (dictionary) defines the canvas whose contents will be presented by the [VRDisplay].\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/)."
    }
  },
  "vrpose": {
    "docs": "\n\nThe **`VRPose`** interface of the [WebVR API](/en-US/docs/Web/API/WebVR_API) represents the state of a VR sensor at a given timestamp (which includes orientation, position, velocity, and acceleration information).\n\n> **Note:** This interface was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nThis interface is accessible through the [VRDisplay.getPose] and [VRDisplay.getFrameData] methods. [VRDisplay.getPose] is deprecated.",
    "properties": {
      "angularacceleration": "\n\nThe **`angularAcceleration`** read-only property of the [VRPose] interface returns an array representing the angular acceleration vector of the [VRDisplay] at the current timestamp, in meters per second per second.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nIn other words, the current acceleration of the sensor's rotation around the `x`, `y`, and `z` axes.",
      "angularvelocity": "\n\nThe **`angularVelocity`** read-only property of the [VRPose] interface returns an array representing the angular velocity vector of the [VRDisplay] at the current timestamp, in radians per second.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nIn other words, the current velocity at which the sensor is rotating around the `x`, `y`, and `z` axes.",
      "linearacceleration": "\n\nThe **`linearAcceleration`** read-only property of the [VRPose] interface returns an array representing the linear acceleration vector of the [VRDisplay] at the current timestamp, in meters per second per second.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nIn other words, the current acceleration of the sensor, along the `x`, `y`, and `z` axes.",
      "linearvelocity": "\n\nThe **`linearVelocity`** read-only property of the [VRPose] interface returns an array representing the linear velocity vector of the [VRDisplay] at the current timestamp, in meters per second.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nIn other words, the current velocity at which the sensor is moving along the `x`, `y`, and `z` axes.",
      "orientation": "\n\nThe **`orientation`** read-only property of the [VRPose] interface returns the orientation of the sensor at the current timestamp, as a quarternion value.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nThe value is a `Float32Array`, made up of the following values:\n\n- pitch — rotation around the X axis.\n- yaw — rotation around the Y axis.\n- roll — rotation around the Z axis.\n- w — the fourth dimension (usually 1).\n\nThe orientation yaw (rotation around the y axis) is relative to the initial yaw of the sensor when it was first read or the yaw of the sensor at the point that [VRDisplay.resetPose] was last called.",
      "position": "\n\nThe **`position`** read-only property of the [VRPose] interface returns the position of the [VRDisplay] at the current timestamp as a 3D vector.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nThe coordinate system is as follows:\n\n- Positive X is to the user's right.\n- Positive Y is up.\n- Positive Z is behind the user.\n\nPositions are measured in meters from an origin point — this point is either the position the sensor was first read at, or the position of the sensor at the point that [VRDisplay.resetPose] was last called.\n\n> **Note:** By default, all positions are given as a sitting space position. Transforming this point with [VRStageParameters.sittingToStandingTransform] — when you are working with a room display for example — converts this to a standing space position."
    }
  },
  "vrstageparameters": {
    "docs": "\n\nThe **`VRStageParameters`** interface of the [WebVR API](/en-US/docs/Web/API/WebVR_API) represents the values describing the stage area for devices that support room-scale experiences.\n\n> **Note:** This interface was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nThis interface is accessible through the [VRDisplay.stageParameters] property.",
    "properties": {
      "sittingtostandingtransform": "\n\nThe **`sittingToStandingTransform`** read-only property of the [VRStageParameters] interface contains a matrix that transforms the sitting-space view matrices of [VRFrameData] to standing-space.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nBasically, this can be passed into your WebGL code to transform the rendered view from a sitting to standing view.",
      "sizex": "\n\nThe **`sizeX`** read-only property of the [VRStageParameters] interface _returns the width_ of the play-area bounds in meters.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nThe bounds are defined as an axis-aligned rectangle on the floor, for safety purposes. Content should not require the user to move beyond these bounds; however, it is possible for the user to ignore the bounds resulting in position values outside of this rectangle. The center of the rectangle is at (0,0,0) in standing-space coordinates.",
      "sizey": "\n\nThe **`sizeY`** read-only property of the [VRStageParameters] interface _returns the depth_ of the play-area bounds in meters.\n\n> **Note:** This property was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nThe bounds are defined as an axis-aligned rectangle on the floor, for safety purposes. Content should not require the user to move beyond these bounds; however, it is possible for the user to ignore the bounds resulting in position values outside of this rectangle. The center of the rectangle is at (0,0,0) in standing-space coordinates."
    }
  },
  "vttcue": {
    "docs": "\n\nThe `VTTCue` interface—part of the API for handling WebVTT (text tracks on media presentations)—describes and controls the text track associated with a particular `track` element.\n\n",
    "properties": {
      "align": "\n\nThe **`align`** property of the [VTTCue] interface represents the alignment of all of the lines of text in the text box.",
      "getcueashtml": "\n\nThe **`getCueAsHTML()`** method of the [VTTCue] interface returns a [DocumentFragment] containing the cue content.",
      "line": "``\n\nThe **`line`** property of the [VTTCue] interface represents the cue line of this WebVTT cue.",
      "linealign": "\n\nThe **`lineAlign`** property of the [VTTCue] interface represents the alignment of this VTT cue.",
      "position": "\n\nThe **`position`** property of the [VTTCue] interface represents the indentation of the cue within the line.",
      "positionalign": "\n\nThe **`positionAlign`** property of the [VTTCue] interface is used to determine what [VTTCue.position] is anchored to.",
      "region": "\n\nThe **`region`** property of the [VTTCue] interface returns and sets the [VTTRegion] that this cue belongs to.",
      "size": "\n\nThe **`size`** property of the [VTTCue] interface represents the size of the cue as a percentage of the video size.",
      "snaptolines": "\n\nThe **`snapToLines`** property of the [VTTCue] interface is a `Boolean` indicating if the [VTTCue.line] property is an integer number of lines, or a percentage of the video size.",
      "text": "\n\nThe **`text`** property of the [VTTCue] interface represents the text contents of the cue.",
      "vertical": "\n\nThe **`vertical`** property of the [VTTCue] interface is a string representing the cue's writing direction."
    }
  },
  "vttregion": {
    "docs": "\n\nThe `VTTRegion` interface—part of the API for handling WebVTT (text tracks on media presentations)—describes a portion of the video to render a [VTTCue] onto."
  },
  "wakelock": {
    "docs": "\n\nThe **`WakeLock`** interface of the [Screen Wake Lock API] prevents device screens from dimming or locking when an application needs to keep running.\n\nThe system wake lock is exposed through the [Navigator.wakeLock] property.",
    "properties": {
      "request": "\n\nThe **`request()`** method of the\n[WakeLock] interface returns a `Promise` that resolves with a\n[WakeLockSentinel] object, which allows control over screen dimming and locking."
    }
  },
  "wakelocksentinel": {
    "docs": "\n\nThe **`WakeLockSentinel`** interface of the [Screen Wake Lock API] provides a handle to the underlying platform wake lock and can be manually released and reacquired. An `Object` representing the wake lock is returned via the [WakeLock.request] method.\n\nAn acquired `WakeLockSentinel` can be released manually via the [WakeLockSentinel.release] method, or automatically via the platform wake lock. This can happen if the document becomes inactive or looses visibility, if the device is low on power or the user turns on a power save mode. Releasing all `WakeLockSentinel` instances of a given wake lock type will cause the underlying platform wake lock to be released.\n\n",
    "properties": {
      "release": "\n\nThe **`release()`** method of the\n[WakeLockSentinel] interface releases the\n[WakeLockSentinel], returning a `Promise` that is resolved\nonce the sentinel has been successfully released.",
      "release_event": "\n\nThe **`release`** event of the [WakeLockSentinel] interface is fired when the sentinel object's handle has been released.\n\nA [WakeLockSentinel] can be released manually via the `release()` method, or\nautomatically via the platform wake lock. This can happen if the document becomes\ninactive or looses visibility, if the device is low on power or the user turns on a\npower save mode.",
      "released": "\n\nThe **`released`** read-only property of the\n[WakeLockSentinel] interface returns a boolean that indicates whether\na [WakeLockSentinel] has been released yet.",
      "type": "\n\nThe **`type`** read-only property of the\n[WakeLockSentinel] interface returns a string\nrepresentation of the currently acquired [WakeLockSentinel] type."
    }
  },
  "waveshapernode": {
    "docs": "\n\nThe **`WaveShaperNode`** interface represents a non-linear distorter.\n\nIt is an [AudioNode] that uses a curve to apply a wave shaping distortion to the signal. Beside obvious distortion effects, it is often used to add a warm feeling to the signal.\n\nA `WaveShaperNode` always has exactly one input and one output.\n\n<table class=\"properties\">\n  <tbody>\n    <tr>\n      <th scope=\"row\">Number of inputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Number of outputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count mode</th>\n      <td><code>\"max\"</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count</th>\n      <td><code>2</code> (not used in the default count mode)</td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel interpretation</th>\n      <td><code>\"speakers\"</code></td>\n    </tr>\n  </tbody>\n</table>",
    "properties": {
      "curve": "\n\nThe `curve` property of the [WaveShaperNode] interface is a `Float32Array` of numbers describing the distortion to apply.\n\nThe mid-element of the array is applied to any signal value of `0`, the first one to signal values of `-1`, and the last to signal values of `1`; values lower than `-1` or greater than `1` are treated like `-1` or `1` respectively.\n\nIf necessary, intermediate values of the distortion curve are linearly interpolated.\n\n> **Note:** The array can be a `null` value: in that case, no distortion is applied to the input signal.",
      "oversample": "\n\nThe `oversample` property of the [WaveShaperNode] interface is an enumerated value indicating if oversampling must be used. Oversampling is a technique for creating more samples (up-sampling) before applying a distortion effect to the audio signal.\n\nOnce applied, the number of samples is reduced to its initial numbers. This leads to better results by avoiding some aliasing, but comes at the expense of a lower precision shaping curve.\n\nThe possible `oversample` values are:\n\n| Value    | Effect                                                                 |\n| -------- | ---------------------------------------------------------------------- |\n| `'none'` | Do not perform any oversampling.                                       |\n| `'2x'`   | Double the amount of samples before applying the shaping curve.        |\n| `'4x'`   | Multiply by 4 the amount of samples before applying the shaping curve. |"
    }
  },
  "webgl2renderingcontext": {
    "docs": "\n\nThe **WebGL2RenderingContext** interface provides the OpenGL ES 3.0 rendering context for the drawing surface of an HTML `canvas` element.\n\nTo get an object of this interface, call [HTMLCanvasElement.getContext] on a `<canvas>` element, supplying \"webgl2\" as the argument:\n\n```js\nconst canvas = document.getElementById(\"myCanvas\");\nconst gl = canvas.getContext(\"webgl2\");\n```\n\n> **Note:** WebGL 2 is an extension to WebGL 1. The `WebGL2RenderingContext` interface implements all members of the [WebGLRenderingContext] interface. Some methods of the WebGL 1 context can accept additional values when used in a WebGL 2 context. You will find this info noted on the WebGL 1 reference pages.\n\nThe [WebGL tutorial](/en-US/docs/Web/API/WebGL_API/Tutorial) has more information, examples, and resources on how to get started with WebGL.",
    "properties": {
      "beginquery": "\n\nThe **`WebGL2RenderingContext.beginQuery()`** method of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) starts an asynchronous query. The\n`target` parameter indicates which kind of query to begin.",
      "begintransformfeedback": "\n\nThe **`WebGL2RenderingContext.beginTransformFeedback()`**\nmethod of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) starts a transform\nfeedback operation.",
      "bindbufferbase": "\n\nThe **`WebGL2RenderingContext.bindBufferBase()`** method of the\n[WebGL 2 API](/en-US/docs/Web/API/WebGL_API) binds a given\n[WebGLBuffer] to a given binding point (`target`) at a given\n`index`.",
      "bindbufferrange": "\n\nThe **`WebGL2RenderingContext.bindBufferRange()`** method of\nthe [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) binds a range of a given\n[WebGLBuffer] to a given binding point (`target`) at a given\n`index`.",
      "bindsampler": "\n\nThe **`WebGL2RenderingContext.bindSampler()`** method of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) binds a\npassed [WebGLSampler] object to the texture unit at the passed index.",
      "bindtransformfeedback": "\n\nThe **`WebGL2RenderingContext.bindTransformFeedback()`** method\nof the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) binds a\npassed [WebGLTransformFeedback] object to the current GL state.",
      "bindvertexarray": "\n\nThe **`WebGL2RenderingContext.bindVertexArray()`** method of\nthe [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) binds a\npassed [WebGLVertexArrayObject] object to the buffer.",
      "blitframebuffer": "\n\nThe **`WebGL2RenderingContext.blitFramebuffer()`** method of\nthe [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) transfers a block of pixels\nfrom the read framebuffer to the draw framebuffer. Read and draw framebuffers are bound\nusing [WebGLRenderingContext.bindFramebuffer].",
      "clearbuffer": "\n\nThe **`WebGL2RenderingContext.clearBuffer[fiuv]()`** methods of\nthe [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) clear buffers from the\ncurrently bound framebuffer.",
      "clientwaitsync": "\n\nThe **`WebGL2RenderingContext.clientWaitSync()`** method of the\n[WebGL 2 API](/en-US/docs/Web/API/WebGL_API) blocks and waits for a\n[WebGLSync] object to become signaled or a given timeout to be passed.",
      "compressedtexsubimage3d": "\n\nThe **`WebGL2RenderingContext.compressedTexSubImage3D()`**\nmethod of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies a\nthree-dimensional sub-rectangle for a texture image in a compressed format.",
      "copybuffersubdata": "\n\nThe **`WebGL2RenderingContext.copyBufferSubData()`** method of\nthe [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) copies part of the data of a\nbuffer to another buffer.",
      "copytexsubimage3d": "\n\nThe **`WebGL2RenderingContext.copyTexSubImage3D()`** method of\nthe [WebGL API](/en-US/docs/Web/API/WebGL_API) copies pixels from the current\n[WebGLFramebuffer] into an existing 3D texture sub-image.",
      "createquery": "\n\nThe **`WebGL2RenderingContext.createQuery()`** method of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) creates and initializes\n[WebGLQuery] objects, which provide ways to asynchronously query for\ninformation.",
      "createsampler": "\n\nThe **`WebGL2RenderingContext.createSampler()`** method of the\n[WebGL 2 API](/en-US/docs/Web/API/WebGL_API) creates and initializes\n[WebGLSampler] objects.",
      "createtransformfeedback": "\n\nThe **`WebGL2RenderingContext.createTransformFeedback()`**\nmethod of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) creates and\ninitializes [WebGLTransformFeedback] objects.",
      "createvertexarray": "\n\nThe **`WebGL2RenderingContext.createVertexArray()`** method of\nthe [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) creates and initializes a\n[WebGLVertexArrayObject] object that represents a vertex array object (VAO)\npointing to vertex array data and which provides names for different sets of vertex\ndata.",
      "deletequery": "\n\nThe **`WebGL2RenderingContext.deleteQuery()`** method of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) deletes a given\n[WebGLQuery] object.",
      "deletesampler": "\n\nThe **`WebGL2RenderingContext.deleteSampler()`** method of the\n[WebGL 2 API](/en-US/docs/Web/API/WebGL_API) deletes a given\n[WebGLSampler] object.",
      "deletesync": "\n\nThe **`WebGL2RenderingContext.deleteSync()`** method of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) deletes a given\n[WebGLSync] object.",
      "deletetransformfeedback": "\n\nThe **`WebGL2RenderingContext.deleteTransformFeedback()`**\nmethod of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) deletes a given\n[WebGLTransformFeedback] object.",
      "deletevertexarray": "\n\nThe **`WebGL2RenderingContext.deleteVertexArray()`** method of\nthe [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) deletes a given\n[WebGLVertexArrayObject] object.",
      "drawarraysinstanced": "\n\nThe **`WebGL2RenderingContext.drawArraysInstanced()`** method\nof the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) renders primitives from\narray data like the [WebGLRenderingContext.drawArrays]\nmethod. In addition, it can execute multiple instances of the range of elements.\n\n> **Note:** When using [WebGLRenderingContext],\n> the [ANGLE_instanced_arrays] extension can provide this method,\n> too.",
      "drawbuffers": "\n\nThe **`WebGL2RenderingContext.drawBuffers()`** method of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) defines draw buffers to which\nfragment colors are written into. The draw buffer settings are part of the state of the\ncurrently bound framebuffer or the drawingbuffer if no framebuffer is bound.",
      "drawelementsinstanced": "\n\nThe **`WebGL2RenderingContext.drawElementsInstanced()`** method\nof the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) renders primitives from\narray data like the [WebGLRenderingContext.drawElements] method. In addition, it can execute multiple instances of a set\nof elements.\n\n> **Note:** When using [WebGLRenderingContext], the [ANGLE_instanced_arrays] extension can provide this method,\n> too.",
      "drawrangeelements": "\n\nThe **`WebGL2RenderingContext.drawRangeElements()`** method of\nthe [WebGL API](/en-US/docs/Web/API/WebGL_API) renders primitives from array\ndata in a given range.",
      "endquery": "\n\nThe **`WebGL2RenderingContext.endQuery()`** method of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) marks the end of a given query\ntarget.",
      "endtransformfeedback": "\n\nThe **`WebGL2RenderingContext.endTransformFeedback()`** method\nof the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) ends a transform feedback\noperation.",
      "fencesync": "\n\nThe **`WebGL2RenderingContext.fenceSync()`** method of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) creates a new\n[WebGLSync] object and inserts it into the GL command stream.",
      "framebuffertexturelayer": "\n\nThe **`WebGL2RenderingContext.framebufferTextureLayer()`**\nmethod of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) attaches a single\nlayer of a texture to a framebuffer.\n\nThis method is similar to [WebGLRenderingContext.framebufferTexture2D],\nbut only a given single layer of the texture level is attached to the attachment point.",
      "getactiveuniformblockname": "\n\nThe **`WebGL2RenderingContext.getActiveUniformBlockName()`**\nmethod of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) retrieves the name\nof the active uniform block at a given index within a [WebGLProgram].",
      "getactiveuniformblockparameter": "\n\nThe\n**`WebGL2RenderingContext.getActiveUniformBlockParameter()`**\nmethod of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) retrieves\ninformation about an active uniform block within a [WebGLProgram].",
      "getactiveuniforms": "\n\nThe **`WebGL2RenderingContext.getActiveUniforms()`** method of\nthe [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) retrieves information about\nactive uniforms within a [WebGLProgram].",
      "getbuffersubdata": "\n\nThe **`WebGL2RenderingContext.getBufferSubData()`** method of\nthe [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) reads data from a buffer\nbinding point and writes them to an `ArrayBuffer` or\n`SharedArrayBuffer`.",
      "getfragdatalocation": "\n\nThe **`WebGL2RenderingContext.getFragDataLocation()`** method\nof the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) returns the binding of\ncolor numbers to user-defined varying out variables.",
      "getindexedparameter": "\n\nThe **`WebGL2RenderingContext.getIndexedParameter()`** method\nof the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) returns indexed\ninformation about a given `target`.",
      "getinternalformatparameter": "\n\nThe **`WebGL2RenderingContext.getInternalformatParameter()`**\nmethod of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) returns\ninformation about implementation-dependent support for internal formats.",
      "getquery": "\n\nThe **`WebGL2RenderingContext.getQuery()`** method of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) returns the currently active\n[WebGLQuery] for the `target`, or [`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null).",
      "getqueryparameter": "\n\nThe **`WebGL2RenderingContext.getQueryParameter()`** method of\nthe [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) returns parameter\ninformation of a [WebGLQuery] object.",
      "getsamplerparameter": "\n\nThe **`WebGL2RenderingContext.getSamplerParameter()`** method\nof the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) returns parameter\ninformation of a [WebGLSampler] object.",
      "getsyncparameter": "\n\nThe **`WebGL2RenderingContext.getSyncParameter()`** method of\nthe [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) returns parameter\ninformation of a [WebGLSync] object.",
      "gettransformfeedbackvarying": "\n\nThe **`WebGL2RenderingContext.getTransformFeedbackVarying()`**\nmethod of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) returns\ninformation about varying variables from [WebGLTransformFeedback] buffers.",
      "getuniformblockindex": "\n\nThe **`WebGL2RenderingContext.getUniformBlockIndex()`** method\nof the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) retrieves the index of\na uniform block within a [WebGLProgram].",
      "getuniformindices": "\n\nThe **`WebGL2RenderingContext.getUniformIndices()`** method of\nthe [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) retrieves the indices of a\nnumber of uniforms within a [WebGLProgram].",
      "invalidateframebuffer": "\n\nThe **`WebGL2RenderingContext.invalidateFramebuffer()`** method\nof the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) invalidates the contents\nof attachments in a framebuffer.",
      "invalidatesubframebuffer": "\n\nThe **`WebGL2RenderingContext.invalidateSubFramebuffer()`**\nmethod of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) invalidates\nportions of the contents of attachments in a framebuffer.",
      "isquery": "\n\nThe **`WebGL2RenderingContext.isQuery()`** method of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) returns `true` if the\npassed object is a valid [WebGLQuery] object.",
      "issampler": "\n\nThe **`WebGL2RenderingContext.isSampler()`** method of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) returns `true` if the\npassed object is a valid [WebGLSampler] object.",
      "issync": "\n\nThe **`WebGL2RenderingContext.isSync()`** method of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) returns `true` if the\npassed object is a valid [WebGLSync] object.",
      "istransformfeedback": "\n\nThe **`WebGL2RenderingContext.isTransformFeedback()`** method\nof the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) returns `true`\nif the passed object is a valid [WebGLTransformFeedback] object.",
      "isvertexarray": "\n\nThe **`WebGL2RenderingContext.isVertexArray()`** method of the\n[WebGL API](/en-US/docs/Web/API/WebGL_API) returns `true` if the\npassed object is a valid [WebGLVertexArrayObject] object.",
      "pausetransformfeedback": "\n\nThe **`WebGL2RenderingContext.pauseTransformFeedback()`**\nmethod of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) pauses a transform\nfeedback operation.",
      "readbuffer": "\n\nThe **`WebGL2RenderingContext.readBuffer()`** method of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) selects a color buffer as the\nsource for pixels for subsequent calls to\n[WebGLRenderingContext.copyTexImage2D],\n[WebGLRenderingContext.copyTexSubImage2D],\n[WebGL2RenderingContext.copyTexSubImage3D] or\n[WebGLRenderingContext.readPixels].",
      "renderbufferstoragemultisample": "\n\nThe\n**`WebGL2RenderingContext.renderbufferStorageMultisample()`**\nmethod of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) returns creates\nand initializes a renderbuffer object's data store and allows specifying a number of\nsamples to be used.",
      "resumetransformfeedback": "\n\nThe **`WebGL2RenderingContext.resumeTransformFeedback()`**\nmethod of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) resumes a\ntransform feedback operation.",
      "samplerparameter": "\n\nThe **`WebGL2RenderingContext.samplerParameter[if]()`** methods\nof the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) set\n[WebGLSampler] parameters.",
      "teximage3d": "\n\nThe **`WebGLRenderingContext.texImage3D()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies a three-dimensional\ntexture image.",
      "texstorage2d": "\n\nThe **`WebGL2RenderingContext.texStorage2D()`** method of the\n[WebGL API](/en-US/docs/Web/API/WebGL_API) specifies all levels of\ntwo-dimensional texture storage.",
      "texstorage3d": "\n\nThe **`WebGL2RenderingContext.texStorage3D()`** method of the\n[WebGL API](/en-US/docs/Web/API/WebGL_API) specifies all levels of a\nthree-dimensional texture or two-dimensional array texture.",
      "texsubimage3d": "\n\nThe **`WebGL2RenderingContext.texSubImage3D()`** method of the\n[WebGL API](/en-US/docs/Web/API/WebGL_API) specifies a sub-rectangle of the\ncurrent texture.",
      "transformfeedbackvaryings": "\n\nThe **`WebGL2RenderingContext.transformFeedbackVaryings()`**\nmethod of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) specifies values\nto record in [WebGLTransformFeedback] buffers.",
      "uniform": "\n\nThe **`WebGL2RenderingContext.uniform[1234][uif][v]()`**\nmethods of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specify values of\nuniform variables.\n\n> **Note:** `ui` stands for _unsigned integer_, `i` for _integer_, `f` for _float_, and `v` for _vector_.\n> Not all combinations are valid: `u` cannot be combined with `f`.\n> See the syntax table below. Equivalent Regex: `uniform[1234](u?i|f)v?`",
      "uniformblockbinding": "\n\nThe **`WebGL2RenderingContext.uniformBlockBinding()`** method\nof the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) assigns binding points\nfor active uniform blocks.",
      "uniformmatrix": "\n\nThe **`WebGL2RenderingContext.uniformMatrix[234]x[234]fv()`**\nmethods of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) specify matrix\nvalues for uniform variables.\n\n> **Note:** There are no `2x2`, `3x3`, and `4x4` versions of\n> this method. They are abbreviated in `2`, `3`, and\n> `4`, respectively. See the syntax below.",
      "vertexattribdivisor": "\n\nThe **`WebGL2RenderingContext.vertexAttribDivisor()`** method\nof the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) modifies the rate at\nwhich generic vertex attributes advance when rendering multiple instances of primitives\nwith [WebGL2RenderingContext.drawArraysInstanced] and\n[WebGL2RenderingContext.drawElementsInstanced].\n\n> **Note:** When using [WebGLRenderingContext], the [ANGLE_instanced_arrays] extension can provide this method,\n> too.",
      "vertexattribi": "\n\nThe **`WebGL2RenderingContext.vertexAttribI4[u]i[v]()`**\nmethods of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) specify integer\nvalues for generic vertex attributes.",
      "vertexattribipointer": "\n\nThe **`WebGL2RenderingContext.vertexAttribIPointer()`** method\nof the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) specifies integer data\nformats and locations of vertex attributes in a vertex attributes array.",
      "waitsync": "\n\nThe **`WebGL2RenderingContext.waitSync()`** method of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API) returns immediately, but waits on\nthe GL server until the given [WebGLSync] object is signaled.\n\nThe method is a no-op in the absence of the possibility of synchronizing between\nmultiple GL contexts."
    }
  },
  "webglactiveinfo": {
    "docs": "\n\nThe **WebGLActiveInfo** interface is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and represents the information returned by calling the [WebGLRenderingContext.getActiveAttrib] and [WebGLRenderingContext.getActiveUniform] methods.",
    "properties": {
      "name": "\n\nThe read-only **`WebGLActiveInfo.name`** property represents the name of the requested data returned by calling the [WebGLRenderingContext.getActiveAttrib] or [WebGLRenderingContext.getActiveUniform] methods.",
      "size": "\n\nThe read-only **`WebGLActiveInfo.size`** property is a `Number` representing the size of the requested data returned by calling the [WebGLRenderingContext.getActiveAttrib] or [WebGLRenderingContext.getActiveUniform] methods.",
      "type": "\n\nThe read-only **`WebGLActiveInfo.type`** property represents the type of the requested data returned by calling the [WebGLRenderingContext.getActiveAttrib] or [WebGLRenderingContext.getActiveUniform] methods."
    }
  },
  "webglbuffer": {
    "docs": "\n\nThe **WebGLBuffer** interface is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and represents an opaque buffer object storing data such as vertices or colors.\n\n"
  },
  "webglcontextevent": {
    "docs": "\n\nThe **WebContextEvent** interface is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and is an interface for an event that is generated in response to a status change to the WebGL rendering context.\n\n",
    "properties": {
      "statusmessage": "\n\nThe read-only **`WebGLContextEvent.statusMessage`** property contains additional event status information, or is an empty string if no additional information is available."
    }
  },
  "webglframebuffer": {
    "docs": "\n\nThe **WebGLFramebuffer** interface is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and represents a collection of buffers that serve as a rendering destination.\n\n"
  },
  "webglobject": {
    "docs": "\n\nThe **`WebGLObject`** is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and is the parent interface for all WebGL objects.\n\nThis object has no public properties or methods on its own.\n\nIf the WebGL context is lost, the internal _invalidated_ flag of all `WebGLObject` instances is set to `true`."
  },
  "webglprogram": {
    "docs": "\n\nThe **`WebGLProgram`** is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and is a combination of two compiled [WebGLShader]s consisting of a vertex shader and a fragment shader (both written in GLSL).\n\nTo create a `WebGLProgram`, call the GL context's [WebGLRenderingContext.createProgram] function. After attaching the shader programs using [WebGLRenderingContext.attachShader], you link them into a usable program. This is shown in the code below.\n\n```js\nconst program = gl.createProgram();\n\n// Attach pre-existing shaders\ngl.attachShader(program, vertexShader);\ngl.attachShader(program, fragmentShader);\n\ngl.linkProgram(program);\n\nif (!gl.getProgramParameter(program, gl.LINK_STATUS)) {\n  const info = gl.getProgramInfoLog(program);\n  throw `Could not compile WebGL program. \\n\\n${info}`;\n}\n```\n\nSee [WebGLShader] for information on creating the `vertexShader` and `fragmentShader` in the above example."
  },
  "webglquery": {
    "docs": "\n\nThe **`WebGLQuery`** interface is part of the [WebGL 2](/en-US/docs/Web/API/WebGL_API) API and provides ways to asynchronously query for information. By default, occlusion queries and primitive queries are available.\n\nAnother kind of queries are disjoint timer queries, which allow you to measure performance and profiling of your GPU. Disjoint timer queries are available with the [EXT_disjoint_timer_query] extension only.\n\nWhen working with `WebGLQuery` objects, the following methods of the [WebGL2RenderingContext] are useful:\n\n- [WebGL2RenderingContext.createQuery]\n- [WebGL2RenderingContext.deleteQuery]\n- [WebGL2RenderingContext.isQuery]\n- [WebGL2RenderingContext.beginQuery]\n- [WebGL2RenderingContext.endQuery]\n- [WebGL2RenderingContext.getQuery]\n- [WebGL2RenderingContext.getQueryParameter]"
  },
  "webglrenderbuffer": {
    "docs": "\n\nThe **WebGLRenderbuffer** interface is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and represents a buffer that can contain an image, or that can be a source or target of a rendering operation.\n\n"
  },
  "webglrenderingcontext": {
    "docs": "\n\nThe **`WebGLRenderingContext`** interface provides an interface to the OpenGL ES 2.0 graphics rendering context for the drawing surface of an HTML `canvas` element.\n\nTo get an access to a WebGL context for 2D and/or 3D graphics rendering, call [HTMLCanvasElement.getContext] on a `<canvas>` element, supplying \"webgl\" as the argument:\n\n```js\nconst canvas = document.getElementById(\"myCanvas\");\nconst gl = canvas.getContext(\"webgl\");\n```\n\nOnce you have the WebGL rendering context for a canvas, you can render within it. The [WebGL tutorial](/en-US/docs/Web/API/WebGL_API/Tutorial) has more information, examples, and resources on how to get started with WebGL.\n\nIf you require a WebGL 2.0 context, see [WebGL2RenderingContext]; this supplies access to an implementation of OpenGL ES 3.0 graphics.",
    "properties": {
      "activetexture": "\n\nThe **`WebGLRenderingContext.activeTexture()`** method of the\n[WebGL API](/en-US/docs/Web/API/WebGL_API) specifies which texture unit to\nmake active.",
      "attachshader": "\n\nThe **WebGLRenderingContext.attachShader()** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) attaches either a fragment or\nvertex [WebGLShader] to a [WebGLProgram].",
      "bindattriblocation": "\n\nThe **`WebGLRenderingContext.bindAttribLocation()`** method of\nthe [WebGL API](/en-US/docs/Web/API/WebGL_API) binds a generic vertex index\nto an attribute variable.",
      "bindbuffer": "\n\nThe **`WebGLRenderingContext.bindBuffer()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) binds a given\n[WebGLBuffer] to a target.",
      "bindframebuffer": "\n\nThe **`WebGLRenderingContext.bindFramebuffer()`** method of the\n[WebGL API](/en-US/docs/Web/API/WebGL_API) binds to the specified target the provided [WebGLFramebuffer], or, if the `framebuffer` argument is null, the default [WebGLFramebuffer], which is associated with the canvas rendering context.",
      "bindrenderbuffer": "\n\nThe **`WebGLRenderingContext.bindRenderbuffer()`** method of\nthe [WebGL API](/en-US/docs/Web/API/WebGL_API) binds a given\n[WebGLRenderbuffer] to a target, which must be\n`gl.RENDERBUFFER`.",
      "bindtexture": "\n\nThe **`WebGLRenderingContext.bindTexture()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) binds a given\n[WebGLTexture] to a target (binding point).",
      "blendcolor": "\n\nThe **`WebGLRenderingContext.blendColor()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) is used to set the source and\ndestination blending factors.",
      "blendequation": "\n\nThe **`WebGLRenderingContext.blendEquation()`** method of the\n[WebGL API](/en-US/docs/Web/API/WebGL_API) is used to set both the RGB blend\nequation and alpha blend equation to a single equation.\n\nThe blend equation determines how a new pixel is combined with a pixel already in the\n[WebGLFramebuffer].",
      "blendequationseparate": "\n\nThe **`WebGLRenderingContext.blendEquationSeparate()`** method\nof the [WebGL API](/en-US/docs/Web/API/WebGL_API) is used to set the RGB\nblend equation and alpha blend equation separately.\n\nThe blend equation determines how a new pixel is combined with a pixel already in the\n[WebGLFramebuffer].",
      "blendfunc": "\n\nThe **`WebGLRenderingContext.blendFunc()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) defines which function is used for\nblending pixel arithmetic.",
      "blendfuncseparate": "\n\nThe **`WebGLRenderingContext.blendFuncSeparate()`** method of\nthe [WebGL API](/en-US/docs/Web/API/WebGL_API) defines which function is used\nfor blending pixel arithmetic for RGB and alpha components separately.",
      "bufferdata": "\n\nThe **`WebGLRenderingContext.bufferData()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) initializes and creates the\nbuffer object's data store.",
      "buffersubdata": "\n\nThe **`WebGLRenderingContext.bufferSubData()`** method of the\n[WebGL API](/en-US/docs/Web/API/WebGL_API) updates a subset of a buffer\nobject's data store.",
      "canvas": "\n\nThe **`WebGLRenderingContext.canvas`** property is a read-only\nreference to the [HTMLCanvasElement] or [OffscreenCanvas]\nobject that is associated with the context. It might be [`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null) if it is not\nassociated with a `canvas` element or an [OffscreenCanvas]\nobject.",
      "checkframebufferstatus": "\n\nThe **`WebGLRenderingContext.checkFramebufferStatus()`** method\nof the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns the completeness\nstatus of the [WebGLFramebuffer] object.",
      "clear": "\n\nThe **`WebGLRenderingContext.clear()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) clears buffers to preset values.\n\nThe preset values can be set by [WebGLRenderingContext.clearColor], [WebGLRenderingContext.clearDepth] or\n[WebGLRenderingContext.clearStencil].\n\nThe scissor box, dithering, and buffer writemasks can affect the `clear()`\nmethod.",
      "clearcolor": "\n\nThe **`WebGLRenderingContext.clearColor()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies the color values used\nwhen clearing color buffers.\n\nThis specifies what color values to use when calling the\n[WebGLRenderingContext.clear] method. The values are clamped\nbetween 0 and 1.",
      "cleardepth": "\n\nThe **`WebGLRenderingContext.clearDepth()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies the clear value for the\ndepth buffer.\n\nThis specifies what depth value to use when calling the\n[WebGLRenderingContext.clear] method. The value is clamped\nbetween 0 and 1.",
      "clearstencil": "\n\nThe **`WebGLRenderingContext.clearStencil()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies the clear value for the\nstencil buffer.\n\nThis specifies what stencil value to use when calling the\n[WebGLRenderingContext.clear] method.",
      "colormask": "\n\nThe **`WebGLRenderingContext.colorMask()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) sets which color components to\nenable or to disable when drawing or rendering to a [WebGLFramebuffer].",
      "compileshader": "\n\nThe **WebGLRenderingContext.compileShader()** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) compiles a GLSL shader into binary\ndata so that it can be used by a [WebGLProgram].",
      "compressedteximage2d": "\n\nThe **`WebGLRenderingContext.compressedTexImage2D()`**\nand **`WebGL2RenderingContext.compressedTexImage3D()`** methods\nof the [WebGL API](/en-US/docs/Web/API/WebGL_API) specify a two- or\nthree-dimensional texture image in a compressed format.\n\nCompressed image formats must be enabled by [WebGL extensions](/en-US/docs/Web/API/WebGL_API/Using_Extensions) before\nusing these methods.",
      "compressedtexsubimage2d": "\n\nThe **`WebGLRenderingContext.compressedTexSubImage2D()`**\nmethod of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies a\ntwo-dimensional sub-rectangle for a texture image in a compressed format.\n\nCompressed image formats must be enabled by [WebGL extensions](/en-US/docs/Web/API/WebGL_API/Using_Extensions) before\nusing this method or a [WebGL2RenderingContext] must be used.",
      "copyteximage2d": "\n\nThe **`WebGLRenderingContext.copyTexImage2D()`** method of the\n[WebGL API](/en-US/docs/Web/API/WebGL_API) copies pixels from the current\n[WebGLFramebuffer] into a 2D texture image.",
      "copytexsubimage2d": "\n\nThe **`WebGLRenderingContext.copyTexSubImage2D()`** method of\nthe [WebGL API](/en-US/docs/Web/API/WebGL_API) copies pixels from the current\n[WebGLFramebuffer] into an existing 2D texture sub-image.",
      "createbuffer": "\n\nThe **`WebGLRenderingContext.createBuffer()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) creates and initializes a\n[WebGLBuffer] storing data such as vertices or colors.",
      "createframebuffer": "\n\nThe **`WebGLRenderingContext.createFramebuffer()`** method of\nthe [WebGL API](/en-US/docs/Web/API/WebGL_API) creates and initializes a\n[WebGLFramebuffer] object.",
      "createprogram": "\n\nThe **`WebGLRenderingContext.createProgram()`** method of the\n[WebGL API](/en-US/docs/Web/API/WebGL_API) creates and initializes a\n[WebGLProgram] object.",
      "createrenderbuffer": "\n\nThe **`WebGLRenderingContext.createRenderbuffer()`** method of\nthe [WebGL API](/en-US/docs/Web/API/WebGL_API) creates and initializes a\n[WebGLRenderbuffer] object.",
      "createshader": "\n\nThe [WebGLRenderingContext]\nmethod **`createShader()`** of the [WebGL API](/en-US/docs/Web/API/WebGL_API) creates a\n[WebGLShader] that can then be configured further using\n[WebGLRenderingContext.shaderSource] and\n[WebGLRenderingContext.compileShader].",
      "createtexture": "\n\nThe **`WebGLRenderingContext.createTexture()`** method of the\n[WebGL API](/en-US/docs/Web/API/WebGL_API) creates and initializes a\n[WebGLTexture] object.",
      "cullface": "\n\nThe **`WebGLRenderingContext.cullFace()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies whether or not front-\nand/or back-facing polygons can be culled.",
      "deletebuffer": "\n\nThe **`WebGLRenderingContext.deleteBuffer()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) deletes a given\n[WebGLBuffer]. This method has no effect if the buffer has already been\ndeleted. Normally you don't need to call this method yourself, when the buffer object is dereferenced it will be marked as free.",
      "deleteframebuffer": "\n\nThe **`WebGLRenderingContext.deleteFramebuffer()`** method of\nthe [WebGL API](/en-US/docs/Web/API/WebGL_API) deletes a given\n[WebGLFramebuffer] object. This method has no effect if the frame buffer\nhas already been deleted.",
      "deleteprogram": "\n\nThe **`WebGLRenderingContext.deleteProgram()`** method of the\n[WebGL API](/en-US/docs/Web/API/WebGL_API) deletes a given\n[WebGLProgram] object. This method has no effect if the program has already\nbeen deleted.",
      "deleterenderbuffer": "\n\nThe **`WebGLRenderingContext.deleteRenderbuffer()`** method of\nthe [WebGL API](/en-US/docs/Web/API/WebGL_API) deletes a given\n[WebGLRenderbuffer] object. This method has no effect if the render buffer\nhas already been deleted.",
      "deleteshader": "\n\nThe **`WebGLRenderingContext.deleteShader()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) marks a given\n[WebGLShader] object for deletion. It will then be deleted whenever the\nshader is no longer in use. This method has no effect if the shader has already been\ndeleted, and the [WebGLShader] is automatically marked for deletion when it\nis destroyed by the garbage collector.",
      "deletetexture": "\n\nThe **`WebGLRenderingContext.deleteTexture()`** method of the\n[WebGL API](/en-US/docs/Web/API/WebGL_API) deletes a given\n[WebGLTexture] object. This method has no effect if the texture has already\nbeen deleted.",
      "depthfunc": "\n\nThe **`WebGLRenderingContext.depthFunc()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies a function that compares\nincoming pixel depth to the current depth buffer value.",
      "depthmask": "\n\nThe **`WebGLRenderingContext.depthMask()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) sets whether writing into the depth\nbuffer is enabled or disabled.",
      "depthrange": "\n\nThe **`WebGLRenderingContext.depthRange()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies the depth range mapping\nfrom normalized device coordinates to window or viewport coordinates.",
      "detachshader": "\n\nThe **WebGLRenderingContext.detachShader()** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) detaches a previously\nattached [WebGLShader] from a [WebGLProgram].",
      "disable": "\n\nThe **`WebGLRenderingContext.disable()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) disables specific WebGL\ncapabilities for this context.",
      "disablevertexattribarray": "\n\nThe **`WebGLRenderingContext.disableVertexAttribArray()`**\nmethod of the [WebGL API](/en-US/docs/Web/API/WebGL_API) turns the generic\nvertex attribute array off at a given index position.",
      "drawarrays": "\n\nThe **`WebGLRenderingContext.drawArrays()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) renders primitives from array data.",
      "drawelements": "\n\nThe **`WebGLRenderingContext.drawElements()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) renders primitives from array data.",
      "drawingbuffercolorspace": "\n\nThe **`WebGLRenderingContext.drawingBufferColorSpace`** property specifies the color space of the WebGL drawing buffer. Along with the default (`srgb`), the `display-p3` color space can be used.\n\nSee [`WebGLRenderingContext.unpackColorSpace`](/en-US/docs/Web/API/WebGLRenderingContext/unpackColorSpace) for specifying the color space for textures.",
      "drawingbufferheight": "\n\nThe read-only **`WebGLRenderingContext.drawingBufferHeight`**\nproperty represents the actual height of the current drawing buffer. It should match the\n`height` attribute of the `canvas` element associated with\nthis context, but might differ if the implementation is not able to provide the\nrequested height.",
      "drawingbufferwidth": "\n\nThe read-only **`WebGLRenderingContext.drawingBufferWidth`**\nproperty represents the actual width of the current drawing buffer. It should match the\n`width` attribute of the `canvas` element associated with\nthis context, but might differ if the implementation is not able to provide the\nrequested width.",
      "enable": "\n\nThe **`WebGLRenderingContext.enable()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) enables specific WebGL capabilities\nfor this context.",
      "enablevertexattribarray": "\n\nThe [WebGLRenderingContext] method\n**`enableVertexAttribArray()`**, part of the [WebGL API](/en-US/docs/Web/API/WebGL_API), turns on the generic vertex\nattribute array at the specified index into the list of attribute arrays.\n\n> **Note:** You can disable the attribute array by calling\n> [WebGLRenderingContext.disableVertexAttribArray].\n\nIn WebGL, values that apply to a specific vertex are stored in [attributes](/en-US/docs/Web/API/WebGL_API/Data#attributes). These are only\navailable to the JavaScript code and the vertex shader. Attributes are referenced by an\nindex number into the list of attributes maintained by the GPU. Some vertex attribute\nindices may have predefined purposes, depending on the platform and/or the GPU. Others\nare assigned by the WebGL layer when you create the attributes.\n\nEither way, since attributes cannot be used unless enabled, and are disabled by\ndefault, you need to call `enableVertexAttribArray()` to enable individual\nattributes so that they can be used. Once that's been done, other methods can be used to\naccess the attribute, including [WebGLRenderingContext.vertexAttribPointer], [WebGLRenderingContext.vertexAttrib], and [WebGLRenderingContext.getVertexAttrib].",
      "finish": "\n\nThe **`WebGLRenderingContext.finish()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) blocks execution until all\npreviously called commands are finished.",
      "flush": "\n\nThe **`WebGLRenderingContext.flush()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) empties different buffer commands,\ncausing all commands to be executed as quickly as possible.",
      "framebufferrenderbuffer": "\n\nThe **`WebGLRenderingContext.framebufferRenderbuffer()`**\nmethod of the [WebGL API](/en-US/docs/Web/API/WebGL_API) attaches a\n[WebGLRenderbuffer] object to a [WebGLFramebuffer] object.",
      "framebuffertexture2d": "\n\nThe **`WebGLRenderingContext.framebufferTexture2D()`** method\nof the [WebGL API](/en-US/docs/Web/API/WebGL_API) attaches a texture to a\n[WebGLFramebuffer].",
      "frontface": "\n\nThe **`WebGLRenderingContext.frontFace()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies whether polygons are\nfront- or back-facing by setting a winding orientation.",
      "generatemipmap": "\n\nThe **`WebGLRenderingContext.generateMipmap()`** method of the\n[WebGL API](/en-US/docs/Web/API/WebGL_API) generates a set of mipmaps for a\n[WebGLTexture] object.\n\nMipmaps are used to create distance with objects. A higher-resolution mipmap is used\nfor objects that are closer, and a lower-resolution mipmap is used for objects that are\nfarther away. It starts with the resolution of the texture image and halves the\nresolution until a 1x1 dimension texture image is created.",
      "getactiveattrib": "\n\nThe **`WebGLRenderingContext.getActiveAttrib()`** method of the\n[WebGL API](/en-US/docs/Web/API/WebGL_API) returns a\n[WebGLActiveInfo] object containing size, type, and name of a vertex\nattribute. It is generally used when querying unknown attributes either for debugging or\ngeneric library creation.",
      "getactiveuniform": "\n\nThe **`WebGLRenderingContext.getActiveUniform()`** method of\nthe [WebGL API](/en-US/docs/Web/API/WebGL_API) returns a\n[WebGLActiveInfo] object containing size, type, and name of a uniform\nattribute. It is generally used when querying unknown uniforms either for debugging or\ngeneric library creation.",
      "getattachedshaders": "\n\nThe **`WebGLRenderingContext.getAttachedShaders()`** method of\nthe [WebGL API](/en-US/docs/Web/API/WebGL_API) returns a list of\n[WebGLShader] objects attached to a [WebGLProgram].",
      "getattriblocation": "\n\nThe **`WebGLRenderingContext.getAttribLocation()`** method of\nthe [WebGL API](/en-US/docs/Web/API/WebGL_API) returns the location of an\nattribute variable in a given [WebGLProgram].",
      "getbufferparameter": "\n\nThe **`WebGLRenderingContext.getBufferParameter()`** method of\nthe [WebGL API](/en-US/docs/Web/API/WebGL_API) returns information about the\nbuffer.",
      "getcontextattributes": "\n\nThe **`WebGLRenderingContext.getContextAttributes()`** method\nreturns a `WebGLContextAttributes` object that contains the actual context\nparameters. Might return [`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null), if the context is lost.",
      "geterror": "\n\nThe **`WebGLRenderingContext.getError()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns error information.",
      "getextension": "\n\nThe **`WebGLRenderingContext.getExtension()`** method enables a\n[WebGL](/en-US/docs/Web/API/WebGL_API) extension.",
      "getframebufferattachmentparameter": "\n\nThe\n**`WebGLRenderingContext.getFramebufferAttachmentParameter()`**\nmethod of the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns information\nabout a framebuffer's attachment.",
      "getparameter": "\n\nThe **`WebGLRenderingContext.getParameter()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns a value for the passed\nparameter name.",
      "getprograminfolog": "\n\nThe **WebGLRenderingContext.getProgramInfoLog** returns the information\nlog for the specified [WebGLProgram] object. It contains errors that\noccurred during failed linking or validation of `WebGLProgram` objects.",
      "getprogramparameter": "\n\nThe **`WebGLRenderingContext.getProgramParameter()`** method of\nthe [WebGL API](/en-US/docs/Web/API/WebGL_API) returns information about the\ngiven program.",
      "getrenderbufferparameter": "\n\nThe **`WebGLRenderingContext.getRenderbufferParameter()`**\nmethod of the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns information\nabout the renderbuffer.",
      "getshaderinfolog": "\n\nThe **WebGLRenderingContext.getShaderInfoLog** returns the information log\nfor the specified [WebGLShader] object. It contains warnings, debugging and\ncompile information.",
      "getshaderparameter": "\n\nThe **`WebGLRenderingContext.getShaderParameter()`** method of\nthe [WebGL API](/en-US/docs/Web/API/WebGL_API) returns information about the\ngiven shader.",
      "getshaderprecisionformat": "\n\nThe\n**`WebGLRenderingContext.getShaderPrecisionFormat()`** method of\nthe [WebGL API](/en-US/docs/Web/API/WebGL_API) returns a new\n[WebGLShaderPrecisionFormat] object describing the range and precision for\nthe specified shader numeric format.",
      "getshadersource": "\n\nThe **`WebGLRenderingContext.getShaderSource()`** method of the\n[WebGL API](/en-US/docs/Web/API/WebGL_API) returns the source code of a\n[WebGLShader] as a string.",
      "getsupportedextensions": "\n\nThe **`WebGLRenderingContext.getSupportedExtensions()`** method\nreturns a list of all the supported [WebGL](/en-US/docs/Web/API/WebGL_API)\nextensions.",
      "gettexparameter": "\n\nThe **`WebGLRenderingContext.getTexParameter()`** method of the\n[WebGL API](/en-US/docs/Web/API/WebGL_API) returns information about the\ngiven texture.",
      "getuniform": "\n\nThe **`WebGLRenderingContext.getUniform()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns the value of a uniform\nvariable at a given location.",
      "getuniformlocation": "\n\nPart of the [WebGL API](/en-US/docs/Web/API/WebGL_API), the [WebGLRenderingContext] method\n**`getUniformLocation()`** returns the location of a\nspecific **uniform** variable which is part of a given\n[WebGLProgram].\n\nThe uniform variable is returned as a\n[WebGLUniformLocation] object, which is an opaque identifier used to\nspecify where in the GPU's memory that uniform variable is located.\n\nOnce you have the uniform's location, you can access the uniform itself using one of\nthe other uniform access methods, passing in the uniform location as one of the\ninputs:\n\n- [WebGLRenderingContext.getUniform]\n  - : Returns the value of the uniform at the given location.\n  <!-- markdownlint-disable MD052 -- text in code block is misidentified as image -->\n- [`WebGLRenderingContext.uniform[1234][fi][v]()`](/en-US/docs/Web/API/WebGLRenderingContext/uniform)\n  - : Sets the uniform's value to the specified value, which may be a single floating\n    point or integer number, or a 2-4 component vector specified either as a list of\n    values or as a `Float32Array` or `Int32Array`.\n    <!-- markdownlint-disable MD052 — text in code block is misidentified as image -->\n- [`WebGLRenderingContext.uniformMatrix[234][fv]()`](/en-US/docs/Web/API/WebGLRenderingContext/uniformMatrix)\n  - : Sets the uniform's value to the specified matrix, possibly with transposition. The\n    value is represented as a sequence of `GLfloat` values or as a\n    `Float32Array`.\n\nThe uniform itself is declared in the shader program using GLSL.",
      "getvertexattrib": "\n\nThe **`WebGLRenderingContext.getVertexAttrib()`** method of the\n[WebGL API](/en-US/docs/Web/API/WebGL_API) returns information about a vertex\nattribute at a given position.",
      "getvertexattriboffset": "\n\nThe **`WebGLRenderingContext.getVertexAttribOffset()`** method\nof the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns the address of a\nspecified vertex attribute.",
      "hint": "\n\nThe **`WebGLRenderingContext.hint()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies hints for certain\nbehaviors. The interpretation of these hints depend on the implementation.",
      "isbuffer": "\n\nThe **`WebGLRenderingContext.isBuffer()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns `true` if the\npassed [WebGLBuffer] is valid and `false` otherwise.",
      "iscontextlost": "\n\nThe\n**`WebGLRenderingContext.isContextLost()`** method returns a\nboolean value indicating whether or not the WebGL context has been lost and\nmust be re-established before rendering can resume.",
      "isenabled": "\n\nThe **`WebGLRenderingContext.isEnabled()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) tests whether a specific WebGL\ncapability is enabled or not for this context.\n\nBy default, all capabilities except `gl.DITHER` are\n**disabled**.",
      "isframebuffer": "\n\nThe **`WebGLRenderingContext.isFramebuffer()`** method of the\n[WebGL API](/en-US/docs/Web/API/WebGL_API) returns `true` if the\npassed [WebGLFramebuffer] is valid and `false` otherwise.",
      "isprogram": "\n\nThe **`WebGLRenderingContext.isProgram()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns `true` if the\npassed [WebGLProgram] is valid, `false` otherwise.",
      "isrenderbuffer": "\n\nThe **`WebGLRenderingContext.isRenderbuffer()`** method of the\n[WebGL API](/en-US/docs/Web/API/WebGL_API) returns `true` if the\npassed [WebGLRenderbuffer] is valid and `false` otherwise.",
      "isshader": "\n\nThe **`WebGLRenderingContext.isShader()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns `true` if the\npassed [WebGLShader] is valid, `false` otherwise.",
      "istexture": "\n\nThe **`WebGLRenderingContext.isTexture()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns `true` if the\npassed [WebGLTexture] is valid and `false` otherwise.",
      "linewidth": "\n\nThe **`WebGLRenderingContext.lineWidth()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) sets the line width of rasterized\nlines.\n\n> **Warning:** The webgl spec, based on the OpenGL ES 2.0/3.0 specs points out that the minimum and\n> maximum width for a line is implementation defined. The maximum minimum width is\n> allowed to be 1.0. The minimum maximum width is also allowed to be 1.0. Because of\n> these implementation defined limits it is not recommended to use line widths other\n> than 1.0 since there is no guarantee any user's browser will display any other width.\n>\n> As of January 2017 most implementations of WebGL only support a minimum of 1 and a\n> maximum of 1 as the technology they are based on has these same limits.",
      "linkprogram": "\n\nThe [WebGLRenderingContext] interface's\n**`linkProgram()`** method links a given\n[WebGLProgram], completing the process of preparing the GPU code for the\nprogram's fragment and vertex shaders.",
      "makexrcompatible": "\n\nThe [WebGLRenderingContext] method\n**`makeXRCompatible()`** ensures that the rendering context\ndescribed by the `WebGLRenderingContext` is ready to render the scene for the\nimmersive [WebXR](/en-US/docs/Web/API/WebXR_Device_API) device on which it\nwill be displayed. If necessary, the [WebGL](/en-US/docs/Web/API/WebGL_API)\nlayer may reconfigure the context to be ready to render to a different device than it\noriginally was.\n\nThis is useful if you have an application which can start out being presented on a\nstandard 2D display but can then be transitioned to a 3D immersion system.",
      "pixelstorei": "\n\nThe **`WebGLRenderingContext.pixelStorei()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies the pixel storage modes.",
      "polygonoffset": "\n\nThe **`WebGLRenderingContext.polygonOffset()`** method of the\n[WebGL API](/en-US/docs/Web/API/WebGL_API) specifies the scale factors and\nunits to calculate depth values.\n\nThe offset is added before the depth test is performed and before the value is written\ninto the depth buffer.",
      "readpixels": "\n\nThe **`WebGLRenderingContext.readPixels()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) reads a block of pixels from a\nspecified rectangle of the current color framebuffer into a `TypedArray` or a `DataView` object.",
      "renderbufferstorage": "\n\nThe **`WebGLRenderingContext.renderbufferStorage()`** method of\nthe [WebGL API](/en-US/docs/Web/API/WebGL_API) creates and initializes a\nrenderbuffer object's data store.",
      "samplecoverage": "\n\nThe **`WebGLRenderingContext.sampleCoverage()`** method of the\n[WebGL API](/en-US/docs/Web/API/WebGL_API) specifies multi-sample coverage\nparameters for anti-aliasing effects.",
      "scissor": "\n\nThe **`WebGLRenderingContext.scissor()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) sets a scissor box, which limits\nthe drawing to a specified rectangle.",
      "shadersource": "\n\nThe **`WebGLRenderingContext.shaderSource()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) sets the source code of a\n[WebGLShader].",
      "stencilfunc": "\n\nThe **`WebGLRenderingContext.stencilFunc()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) sets the front and back function\nand reference value for stencil testing.\n\nStenciling enables and disables drawing on a per-pixel basis. It is typically used in\nmultipass rendering to achieve special effects.",
      "stencilfuncseparate": "\n\nThe **`WebGLRenderingContext.stencilFuncSeparate()`** method of\nthe [WebGL API](/en-US/docs/Web/API/WebGL_API) sets the front and/or back\nfunction and reference value for stencil testing.\n\nStencilling enables and disables drawing on a per-pixel basis. It is typically used in\nmultipass rendering to achieve special effects.",
      "stencilmask": "\n\nThe **`WebGLRenderingContext.stencilMask()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) controls enabling and disabling of\nboth the front and back writing of individual bits in the stencil planes.\n\nThe [WebGLRenderingContext.stencilMaskSeparate] method can set front and\nback stencil writemasks to different values.",
      "stencilmaskseparate": "\n\nThe **`WebGLRenderingContext.stencilMaskSeparate()`** method of\nthe [WebGL API](/en-US/docs/Web/API/WebGL_API) controls enabling and\ndisabling of front and/or back writing of individual bits in the stencil planes.\n\nThe [WebGLRenderingContext.stencilMask] method can set both, the front\nand back stencil writemasks to one value at the same time.",
      "stencilop": "\n\nThe **`WebGLRenderingContext.stencilOp()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) sets both the front and back-facing\nstencil test actions.",
      "stencilopseparate": "\n\nThe **`WebGLRenderingContext.stencilOpSeparate()`** method of\nthe [WebGL API](/en-US/docs/Web/API/WebGL_API) sets the front and/or\nback-facing stencil test actions.",
      "teximage2d": "\n\nThe **`WebGLRenderingContext.texImage2D()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies a two-dimensional texture\nimage.",
      "texparameter": "\n\nThe **`WebGLRenderingContext.texParameter[fi]()`** methods of\nthe [WebGL API](/en-US/docs/Web/API/WebGL_API) set texture parameters.",
      "texsubimage2d": "\n\nThe **`WebGLRenderingContext.texSubImage2D()`** method of the\n[WebGL API](/en-US/docs/Web/API/WebGL_API) specifies a sub-rectangle of the\ncurrent texture.",
      "uniform": "\n\nThe **`WebGLRenderingContext.uniform[1234][fi][v]()`** methods\nof the [WebGL API](/en-US/docs/Web/API/WebGL_API) specify values of uniform\nvariables. All active uniform variables defined in a program object are initialized to 0\nwhen the program object is linked successfully. They retain the values assigned to them\nby a call to this method until the next successful link operation occurs on the program\nobject, when they are once again initialized to 0.\n\n> **Note:** Many of the functions described here have expanded WebGL 2 interfaces, which can be\n> found under\n> [`WebGL2RenderingContext.uniform[1234][uif][v]()`](/en-US/docs/Web/API/WebGL2RenderingContext/uniform).",
      "uniformmatrix": "\n\nThe **`WebGLRenderingContext.uniformMatrix[234]fv()`** methods\nof the [WebGL API](/en-US/docs/Web/API/WebGL_API) specify matrix values for\nuniform variables.\n\nThe three versions of this method (`uniformMatrix2fv()`,\n`uniformMatrix3fv()`, and `uniformMatrix4fv()`) take as the input\nvalue 2-component, 3-component, and 4-component square matrices, respectively. They are\nexpected to have 4, 9 or 16 floats.",
      "unpackcolorspace": "\n\nThe **`WebGLRenderingContext.unpackColorSpace`** property specifies the color space to convert to when importing textures. Along with the default (`srgb`), the `display-p3` color space can be used.\n\nTexture image sources can be the following:\n\n- [`ImageBitmap`](/en-US/docs/Web/API/ImageBitmap)\n- [`ImageData`](/en-US/docs/Web/API/ImageData)\n- [`HTMLImageElement`](/en-US/docs/Web/API/HTMLImageElement)\n- [`HTMLCanvasElement`](/en-US/docs/Web/API/HTMLCanvasElement)\n- [`HTMLVideoElement`](/en-US/docs/Web/API/HTMLVideoElement)\n- [`OffscreenCanvas`](/en-US/docs/Web/API/OffscreenCanvas)\n- [`VideoFrame`](/en-US/docs/Web/API/VideoFrame)\n\nTextures are imported using the [`WebGLRenderingContext.texImage2D()`](/en-US/docs/Web/API/WebGLRenderingContext/texImage2D) and [`WebGLRenderingContext.texSubImage2D()`](/en-US/docs/Web/API/WebGLRenderingContext/texSubImage2D) methods and conversion to the specified `unpackColorSpace` color space happens during import.\n\nNote that this doesn't apply to [`HTMLImageElement`](/en-US/docs/Web/API/HTMLImageElement) when the `UNPACK_COLORSPACE_CONVERSION_WEBGL` pixel storage parameter is set to `NONE`.",
      "useprogram": "\n\nThe **`WebGLRenderingContext.useProgram()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) sets the specified\n[WebGLProgram] as part of the current rendering state.",
      "validateprogram": "\n\nThe **`WebGLRenderingContext.validateProgram()`** method of the\n[WebGL API](/en-US/docs/Web/API/WebGL_API) validates a\n[WebGLProgram]. It checks if it is successfully linked and if it can be\nused in the current WebGL state.",
      "vertexattrib": "\n\nThe **`WebGLRenderingContext.vertexAttrib[1234]f[v]()`**\nmethods of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specify constant\nvalues for generic vertex attributes.",
      "vertexattribpointer": "\n\nThe\n**`WebGLRenderingContext.vertexAttribPointer()`** method of the\n[WebGL API](/en-US/docs/Web/API/WebGL_API) binds the buffer currently bound\nto `gl.ARRAY_BUFFER` to a generic vertex attribute of the current vertex\nbuffer object and specifies its layout.",
      "viewport": "\n\nThe **`WebGLRenderingContext.viewport()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) sets the viewport, which specifies\nthe affine transformation of x and y from normalized device coordinates to window\ncoordinates."
    }
  },
  "webglsampler": {
    "docs": "\n\nThe **`WebGLSampler`** interface is part of the [WebGL 2](/en-US/docs/Web/API/WebGL_API) API and stores sampling parameters for [WebGLTexture] access inside of a shader.\n\nWhen working with `WebGLSampler` objects, the following methods of the [WebGL2RenderingContext] are useful:\n\n- [WebGL2RenderingContext.createSampler]\n- [WebGL2RenderingContext.deleteSampler]\n- [WebGL2RenderingContext.isSampler]\n- [WebGL2RenderingContext.bindSampler]\n- [WebGL2RenderingContext.getSamplerParameter]"
  },
  "webglshader": {
    "docs": "\n\nThe **WebGLShader** is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and can either be a vertex or a fragment shader. A [WebGLProgram] requires both types of shaders.\n\n"
  },
  "webglshaderprecisionformat": {
    "docs": "\n\nThe **WebGLShaderPrecisionFormat** interface is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and represents the information returned by calling the [WebGLRenderingContext.getShaderPrecisionFormat] method.",
    "properties": {
      "precision": "\n\nThe read-only **`WebGLShaderPrecisionFormat.precision`** property returns the number of bits of precision that can be represented.\n\nFor integer formats this value is always 0.",
      "rangemax": "\n\nThe read-only **`WebGLShaderPrecisionFormat.rangeMax`** property returns the base 2 log of the absolute value of the maximum value that can be represented.",
      "rangemin": "\n\nThe read-only **`WebGLShaderPrecisionFormat.rangeMin`** property returns the base 2 log of the absolute value of the minimum value that can be represented."
    }
  },
  "webglsync": {
    "docs": "\n\nThe **`WebGLSync`** interface is part of the [WebGL 2](/en-US/docs/Web/API/WebGL_API) API and is used to synchronize activities between the GPU and the application.\n\nWhen working with `WebGLSync` objects, the following methods of the [WebGL2RenderingContext] are useful:\n\n- [WebGL2RenderingContext.fenceSync]\n- [WebGL2RenderingContext.deleteSync]\n- [WebGL2RenderingContext.isSync]\n- [WebGL2RenderingContext.clientWaitSync]\n- [WebGL2RenderingContext.waitSync]\n- [WebGL2RenderingContext.getSyncParameter]"
  },
  "webgltexture": {
    "docs": "\n\nThe **WebGLTexture** interface is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and represents an opaque texture object providing storage and state for texturing operations.\n\n"
  },
  "webgltransformfeedback": {
    "docs": "\n\nThe **`WebGLTransformFeedback`** interface is part of the [WebGL 2](/en-US/docs/Web/API/WebGL_API) API and enables transform feedback, which is the process of capturing primitives generated by vertex processing. It allows to preserve the post-transform rendering state of an object and resubmit this data multiple times.\n\nWhen working with `WebGLTransformFeedback` objects, the following methods of the [WebGL2RenderingContext] are useful:\n\n- [WebGL2RenderingContext.createTransformFeedback]\n- [WebGL2RenderingContext.deleteTransformFeedback]\n- [WebGL2RenderingContext.isTransformFeedback]\n- [WebGL2RenderingContext.bindTransformFeedback]\n- [WebGL2RenderingContext.beginTransformFeedback]\n- [WebGL2RenderingContext.endTransformFeedback]\n- [WebGL2RenderingContext.pauseTransformFeedback]\n- [WebGL2RenderingContext.resumeTransformFeedback]\n- [WebGL2RenderingContext.transformFeedbackVaryings]\n- [WebGL2RenderingContext.getTransformFeedbackVarying]"
  },
  "webgluniformlocation": {
    "docs": "\n\nThe **WebGLUniformLocation** interface is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and represents the location of a uniform variable in a shader program."
  },
  "webglvertexarrayobject": {
    "docs": "\n\nThe **`WebGLVertexArrayObject`** interface is part of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API), represents vertex array objects (VAOs) pointing to vertex array data, and provides names for different sets of vertex data.\n\nWhen working with `WebGLVertexArrayObject` objects, the following methods are useful:\n\n- [WebGL2RenderingContext.createVertexArray]\n- [WebGL2RenderingContext.deleteVertexArray]\n- [WebGL2RenderingContext.isVertexArray]\n- [WebGL2RenderingContext.bindVertexArray]\n\n> **Note:** The [OES_vertex_array_object] extension allows you to use vertex array objects in a WebGL 1 context."
  },
  "webkitpoint": {
    "docs": "\n\n**`Point`** is an interface which represents a point in 2-dimensional space. It is non-standard, not broadly compatible, and should not be used.\n\n> **Note:** Although it is not directly related to this defunct interface, you are probably looking for [DOMPoint]."
  },
  "websocket": {
    "docs": "\n\nThe `WebSocket` object provides the API for creating and managing a [WebSocket](/en-US/docs/Web/API/WebSockets_API) connection to a server, as well as for sending and receiving data on the connection.\n\nTo construct a `WebSocket`, use the [`WebSocket()`](/en-US/docs/Web/API/WebSocket/WebSocket) constructor.\n\n",
    "properties": {
      "binarytype": "\n\nThe **`WebSocket.binaryType`** property controls the type of\nbinary data being received over the WebSocket connection.",
      "bufferedamount": "\n\nThe **`WebSocket.bufferedAmount`** read-only property returns\nthe number of bytes of data that have been queued using calls to [`send()`](/en-US/docs/Web/API/WebSocket/send) but\nnot yet transmitted to the network. This value resets to zero once all queued data has\nbeen sent. This value does not reset to zero when the connection is closed; if you keep\ncalling [`send()`](/en-US/docs/Web/API/WebSocket/send), this will continue to climb.",
      "close": "\n\nThe **`WebSocket.close()`** method closes the\n[WebSocket] connection or connection attempt, if any. If the connection is\nalready `CLOSED`, this method does nothing.\n\n> **Note:** The process of closing the connection begins with a [closing handshake](https://www.rfc-editor.org/rfc/rfc6455.html#section-1.4), and the `close()` method does not discard previously-sent messages before starting that closing handshake; even if the user agent is still busy sending those messages, the handshake will only start after the messages are sent.",
      "close_event": "\n\nThe `close` event is fired when a connection with a `WebSocket` is closed.",
      "error_event": "\n\nThe `error` event is fired when a connection with a `WebSocket` has been closed due to an error (some data couldn't be sent for example).",
      "extensions": "\n\nThe **`WebSocket.extensions`** read-only property returns the\nextensions selected by the server. This is currently only the empty string or a list of\nextensions as negotiated by the connection.",
      "message_event": "\n\nThe `message` event is fired when data is received through a `WebSocket`.",
      "open_event": "\n\nThe `open` event is fired when a connection with a `WebSocket` is opened.",
      "protocol": "\n\nThe **`WebSocket.protocol`** read-only property returns the\nname of the sub-protocol the server selected; this will be one of the strings specified\nin the `protocols` parameter when creating the [WebSocket]\nobject, or the empty string if no connection is established.",
      "readystate": "\n\nThe **`WebSocket.readyState`** read-only property returns the\ncurrent state of the [WebSocket] connection.",
      "send": "\n\nThe **`WebSocket.send()`** method enqueues the specified data\nto be transmitted to the server over the WebSocket connection, increasing the value of\n`bufferedAmount` by the number of bytes needed to contain the data. If the\ndata can't be sent (for example, because it needs to be buffered but the buffer is\nfull), the socket is closed automatically.\nThe browser will throw an exception if you call `send()` when the connection is in the `CONNECTING` state. If you call `send()` when the connection is in the `CLOSING` or `CLOSED` states, the browser will silently discard the data.",
      "url": "\n\nThe **`WebSocket.url`** read-only property returns the absolute\nURL of the [WebSocket] as resolved by the constructor."
    }
  },
  "webtransport": {
    "docs": "\n\nThe **`WebTransport`** interface of the [WebTransport API] provides functionality to enable a user agent to connect to an HTTP/3 server, initiate reliable and unreliable transport in either or both directions, and close the connection once it is no longer needed.\n\n",
    "properties": {
      "close": "\n\nThe **`close()`** method of the [WebTransport] interface closes an ongoing WebTransport session.\n\n",
      "closed": "\n\nThe **`closed`** read-only property of the [WebTransport] interface returns a promise that resolves when the transport is closed.\n\n",
      "congestioncontrol": "\n\nThe **`congestionControl`** read-only property of the [WebTransport] interface indicates the application's preference for either high throughput or low-latency when sending data.\n\nThe value is set in the [`WebTransport()` constructor options](/en-US/docs/Web/API/WebTransport/WebTransport#congestioncontrol).\n\n",
      "createbidirectionalstream": "\n\nThe **`createBidirectionalStream()`** method of the [WebTransport] interface asynchronously opens and returns a bidirectional stream.\n\nThe method returns a `Promise` that resolves to a [WebTransportBidirectionalStream] object, which has `readable` and `writable` properties that can be used to reliably read from and write to the server.\n\"Reliable\" means that transmission and order of data are guaranteed.\nThis provides slower delivery (albeit faster than with WebSockets) than [WebTransport.datagrams], but is needed in situations where reliability and ordering are important, like chat applications.\n\nThe relative order in which queued bytes are emptied from created streams can be specified using the `sendOrder` option.\nIf set, queued bytes in streams with a higher send order are guaranteed to be sent before queued bytes for streams with a lower send order.\nIf the order number is not set then the order in which bytes are sent is implementation dependent.\nNote however that even though bytes from higher send-order streams are sent first, they may not arrive first.\n\n",
      "createunidirectionalstream": "\n\nThe **`createUnidirectionalStream()`** method of the [WebTransport] interface asynchronously opens a unidirectional stream.\n\nThe method returns a `Promise` that resolves to a [WritableStream] object, which can be used to reliably write data to the server.\n\n<!-- Note, returns a `WebTransportSendStream` according to spec, but not yet implemented -->\n\n\"Reliable\" means that transmission and order of data are guaranteed. This provides slower delivery (albeit faster than with WebSockets) than [WebTransport.datagrams], but is needed in situations where reliability and ordering are important, like chat applications.\n\nThe relative order in which queued bytes are emptied from created streams can be specified using the `sendOrder` option.\nIf set, queued bytes in streams with a higher send order are guaranteed to be sent before queued bytes for streams with a lower send order.\nIf the order number is not set then the order in which bytes are sent is implementation dependent.\nNote however that even though bytes from higher send-order streams are sent first, they may not arrive first.\n\n",
      "datagrams": "\n\nThe **`datagrams`** read-only property of the [WebTransport] interface returns a [WebTransportDatagramDuplexStream] instance that can be used to send and receive datagrams — unreliable data transmission.\n\n\"Unreliable\" means that transmission of data is not guaranteed, nor is arrival in a specific order. This is fine in some situations and provides very fast delivery. For example, you might want to transmit regular game state updates where each message supersedes the last one that arrives, and order is not important.\n\n",
      "getstats": "\n\nThe **`getStats()`** method of the [WebTransport] interface asynchronously returns an object containing HTTP/3 connection statistics.\n\n",
      "incomingbidirectionalstreams": "\n\nThe **`incomingBidirectionalStreams`** read-only property of the [WebTransport] interface represents one or more bidirectional streams opened by the server. Returns a [ReadableStream] of [WebTransportBidirectionalStream] objects. Each one can be used to reliably read data from the server and write data back to it.\n\n\"Reliable\" means that transmission and order of data are guaranteed. This provides slower delivery (albeit faster than with WebSockets) than [WebTransport.datagrams], but is needed in situations where reliability and ordering are important, like chat applications.\n\n",
      "incomingunidirectionalstreams": "\n\nThe **`incomingUnidirectionalStreams`** read-only property of the [WebTransport] interface represents one or more unidirectional streams opened by the server. Returns a [ReadableStream] of [WebTransportReceiveStream] objects. Each one can be used to reliably read data from the server.\n\n\"Reliable\" means that transmission and order of data are guaranteed. This provides slower delivery (albeit faster than with WebSockets) than [WebTransport.datagrams], but is needed in situations where reliability and ordering are important, like chat applications.\n\n",
      "ready": "\n\nThe **`ready`** read-only property of the [WebTransport] interface returns a promise that resolves when the transport is ready to use.\n\n",
      "reliability": "\n\nThe **`reliability`** read-only property of the [WebTransport] interface indicates whether the connection supports reliable transports only, or whether it also supports unreliable transports (such as UDP).\n\n"
    }
  },
  "webtransportbidirectionalstream": {
    "docs": "\n\nThe **`WebTransportBidirectionalStream`** interface of the [WebTransport API] represents a bidirectional stream created by a server or a client that can be used for reliable transport. Provides access to a [WebTransportReceiveStream] for reading incoming data, and a [WebTransportSendStream] for writing outgoing data.\n\n",
    "properties": {
      "readable": "\n\nThe **`readable`** read-only property of the [WebTransportBidirectionalStream] interface returns a [WebTransportReceiveStream] instance that can be used to reliably read incoming data.\n\n",
      "writable": "\n\nThe **`writable`** read-only property of the [WebTransportBidirectionalStream] interface returns a [WebTransportSendStream] instance that can be used to write outgoing data.\n\n"
    }
  },
  "webtransportdatagramduplexstream": {
    "docs": "\n\nThe **`WebTransportDatagramDuplexStream`** interface of the [WebTransport API] represents a duplex stream that can be used for unreliable transport of datagrams between client and server. Provides access to a [ReadableStream] for reading incoming datagrams, a [WritableStream] for writing outgoing datagrams, and various settings and statistics related to the stream.\n\nThis is accessed via the [WebTransport.datagrams] property.\n\n\"Unreliable\" means that transmission of data is not guaranteed, nor is arrival in a specific order. This is fine in some situations and provides very fast delivery. For example, you might want to transmit regular game state updates where each message supersedes the last one that arrives, and order is not important.\n\n",
    "properties": {
      "incominghighwatermark": "\n\nThe **`incomingHighWaterMark`** property of the [WebTransportDatagramDuplexStream] interface gets or sets the high water mark for incoming chunks of data — this is the maximum size, in chunks, that the incoming [ReadableStream]'s internal queue can reach before it is considered full. See [Internal queues and queuing strategies](/en-US/docs/Web/API/Streams_API/Concepts#internal_queues_and_queuing_strategies) for more information.\n\n",
      "incomingmaxage": "\n\nThe **`incomingMaxAge`** property of the [WebTransportDatagramDuplexStream] interface gets or sets the maximum age for incoming datagrams, in milliseconds.\n\n",
      "maxdatagramsize": "\n\nThe **`maxDatagramSize`** read-only property of the [WebTransportDatagramDuplexStream] interface returns the maximum allowable size of outgoing datagrams, in bytes, that can be written to [WebTransportDatagramDuplexStream.writable].\n\n",
      "outgoinghighwatermark": "\n\nThe **`outgoingHighWaterMark`** property of the [WebTransportDatagramDuplexStream] interface gets or sets the high water mark for outgoing chunks of data — this is the maximum size, in chunks, that the outgoing [WritableStream]'s internal queue can reach before it is considered full. See [Internal queues and queuing strategies](/en-US/docs/Web/API/Streams_API/Concepts#internal_queues_and_queuing_strategies) for more information.\n\n",
      "outgoingmaxage": "\n\nThe **`outgoingMaxAge`** property of the [WebTransportDatagramDuplexStream] interface gets or sets the maximum age for outgoing datagrams, in milliseconds.\n\n",
      "readable": "\n\nThe **`readable`** read-only property of the [WebTransportDatagramDuplexStream] interface returns a [ReadableStream] instance that can be used to unreliably read incoming datagrams from the stream.\n\n\"Unreliably\" means that transmission of data is not guaranteed, nor is arrival in a specific order. This is fine in some situations and provides very fast delivery. For example, you might want to transmit regular game state updates where each message supersedes the last one that arrives, and order is not important.\n\n",
      "writable": "\n\nThe **`writable`** read-only property of the [WebTransportDatagramDuplexStream] interface returns a [WritableStream] instance that can be used to unreliably write outgoing datagrams to the stream.\n\n\"Unreliably\" means that transmission of data is not guaranteed, nor is arrival in a specific order. This is fine in some situations and provides very fast delivery. For example, you might want to transmit regular game state updates where each message supersedes the last one that arrives, and order is not important.\n\n"
    }
  },
  "webtransporterror": {
    "docs": "\n\nThe **`WebTransportError`** interface of the [WebTransport API] represents an error related to the API, which can arise from server errors, network connection problems, or client-initiated abort operations (for example, arising from a [WritableStream.abort] call).\n\n",
    "properties": {
      "source": "\n\nThe **`source`** read-only property of the [WebTransportError] interface returns an enumerated value indicating the source of the error.\n\n",
      "streamerrorcode": "\n\nThe **`streamErrorCode`** read-only property of the [WebTransportError] interface returns a number in the range 0-255 indicating the application protocol error code for this error, or `null` if one is not available.\n\n"
    }
  },
  "webtransportreceivestream": {
    "docs": "\n\nThe `WebTransportReceiveStream` interface of the [WebTransport API] is a [ReadableStream] that can be used to read from an incoming unidirectional or bidirectional [WebTransport] stream.\n\nThe stream is a [readable byte stream](/en-US/docs/Web/API/Streams_API/Using_readable_byte_streams) of [`Uint8Array`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Uint8Array), and can be consumed using either a BYOB reader ([`ReadableStreamBYOBReader`](/en-US/docs/Web/API/ReadableStreamBYOBReader)) or the default reader ([`ReadableStreamDefaultReader`](/en-US/docs/Web/API/ReadableStreamDefaultReader)).\n\nObjects of this type are not constructed directly.\nInstead they are obtained using the [`WebTransport.incomingUnidirectionalStream`](/en-US/docs/Web/API/WebTransport/incomingUnidirectionalStreams) property.\n\n`WebTransportReceiveStream` is a [transferable object](/en-US/docs/Web/API/Web_Workers_API/Transferable_objects).\n\n",
    "properties": {
      "getstats": "\n\nThe **`getStats()`** method of the [WebTransportReceiveStream] interface asynchronously returns an object containing statistics for the current stream.\n\nThe statistics include the total number of ordered bytes that have arrived on this stream (ignoring network overhead, up until the first missing byte) and the total number that have been read by the application.\nIt therefore provides a measure of how quickly the application is consuming bytes from the server on this particular stream.\n\n"
    }
  },
  "webtransportsendstream": {
    "docs": "\n\nThe `WebTransportSendStream` interface of the [WebTransport API] is a specialized [WritableStream] that is used to send outbound data in both unidirectional or bidirectional [WebTransport] streams.\n\nThe send stream is a [writable stream](/en-US/docs/Web/API/Streams_API/Using_writable_streams) of [`Uint8Array`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Uint8Array), that can be written to in order to send data to a server.\nIt additionally provides streaming features such as setting the send order, and getting stream statistics.\n\nObjects of this type are not constructed directly.\nWhen creating a unidirectional stream the [WebTransport.createUnidirectionalStream] returns an object of this type for sending data.\nWhen creating a bidirectional stream using [WebTransport.createBidirectionalStream], the method returns a [WebTransportBidirectionalStream], and the send stream object can be obtained from its [WebTransportBidirectionalStream.writable] property.\nWhen a bidirectional stream is initiated by the remote end, an object of this type can similarly be obtained using [WebTransport.incomingBidirectionalStreams].\n\n`WebTransportSendStream` is a [transferable object](/en-US/docs/Web/API/Web_Workers_API/Transferable_objects).\n\n",
    "properties": {
      "getstats": "\n\nThe **`getStats()`** method of the [WebTransportSendStream] interface asynchronously returns an object containing statistics for the current stream.\n\nThe statistics include the total number of bytes written to the stream, the number that have been sent (ignoring packet overhead), and the number of bytes that have been set at least once, and the number that have been acknowledged (up until the first sequentially-ordered non-acknowledged byte).\nIt therefore provides a measure of how quickly the application is sending bytes to the server on this particular stream.\n\n",
      "sendorder": "\n\nThe **`sendOrder`** property of the [WebTransportSendStream] interface indicates the send priority of this stream relative to other streams for which the value has been set.\n\nQueued bytes are sent first for streams that have a higher value.\nIf not set, the send order depends on the implementation.\n\n"
    }
  },
  "wgsllanguagefeatures": {
    "docs": "\n\nThe **`WGSLLanguageFeatures`** interface of the [WebGPU API] is a [setlike](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Set) object that reports the [WGSL language extensions](https://gpuweb.github.io/gpuweb/wgsl/#language-extension) supported by the WebGPU implementation.\n\nThe `WGSLLanguageFeatures` object is accessed via the [GPU.wgslLanguageFeatures] property.\n\n> **Note:** Not all WGSL language extensions are available to WebGPU in all browsers that support the API. We recommend you thoroughly test any extensions you choose to use.\n\n"
  },
  "wheelevent": {
    "docs": "\n\nThe **`WheelEvent`** interface represents events that occur due to the user moving a mouse wheel or similar input device.\n\n> **Note:** This is the standard wheel event interface to use. Old versions of browsers implemented the non-standard and non-cross-browser-compatible `MouseWheelEvent` and [MouseScrollEvent] interfaces. Use this interface and avoid the non-standard ones.\n\n> **Note:** Do not confuse the [Element/wheel_event] event with the [Element/scroll_event] event. The default action of a `wheel` event is implementation-defined. Thus, a `wheel` event doesn't necessarily dispatch a `scroll` event. Even when it does, that doesn't mean that the `delta*` values in the `wheel` event necessarily reflect the content's scrolling direction. Therefore, do not rely on `delta*` properties to get the content's scrolling direction. Instead, detect value changes to [Element.scrollLeft] and [Element.scrollTop] of the target in the `scroll` event.\n\n",
    "properties": {
      "deltamode": "\n\nThe **`WheelEvent.deltaMode`** read-only property returns an\n`unsigned long` representing the unit of the delta values scroll amount.\nPermitted values are:\n\n| Constant          | Value  | Description                               |\n| ----------------- | ------ | ----------------------------------------- |\n| `DOM_DELTA_PIXEL` | `0x00` | The delta values are specified in pixels. |\n| `DOM_DELTA_LINE`  | `0x01` | The delta values are specified in lines.  |\n| `DOM_DELTA_PAGE`  | `0x02` | The delta values are specified in pages.  |",
      "deltax": "\n\nThe **`WheelEvent.deltaX`** read-only property is a\n`double` representing the horizontal scroll amount in the\n[WheelEvent.deltaMode] unit.",
      "deltay": "\n\nThe **`WheelEvent.deltaY`** read-only property is a\n`double` representing the vertical scroll amount in the\n[WheelEvent.deltaMode] unit.",
      "deltaz": "\n\nThe **`WheelEvent.deltaZ`** read-only property is a\n`double` representing the scroll amount along the z-axis, in the\n[WheelEvent.deltaMode] unit."
    }
  },
  "window": {
    "docs": "\n\nThe **`Window`** interface represents a window containing a  document; the `document` property points to the [DOM document](/en-US/docs/Web/API/Document) loaded in that window.\n\nA window for a given document can be obtained using the [document.defaultView] property.\n\nA global variable, `window`, representing the window in which the script is running, is exposed to JavaScript code.\n\nThe `Window` interface is home to a variety of functions, namespaces, objects, and constructors which are not necessarily directly associated with the concept of a user interface window. However, the `Window` interface is a suitable place to include these items that need to be globally available. Many of these are documented in the [JavaScript Reference](/en-US/docs/Web/JavaScript/Reference) and the [DOM Reference](/en-US/docs/Web/API/Document_Object_Model).\n\nIn a tabbed browser, each tab is represented by its own `Window` object; the global `window` seen by JavaScript code running within a given tab always represents the tab in which the code is running. That said, even in a tabbed browser, some properties and methods still apply to the overall window that contains the tab, such as [Window.resizeTo] and [Window.innerHeight]. Generally, anything that can't reasonably pertain to a tab pertains to the window instead.\n\n",
    "properties": {
      "afterprint_event": "\n\nThe **`afterprint`** event is fired after the associated document has started printing or the print preview has been closed.\n\nThe [Window.beforeprint_event] and `afterprint` events allow pages to change their content before printing starts (perhaps to remove a banner, for example) and then revert those changes after printing has completed. In general, you should prefer the use of a [`@media print`](/en-US/docs/Web/CSS/CSS_media_queries/Using_media_queries#targeting_media_types) CSS at-rule, but it may be necessary to use these events in some cases.",
      "alert": "\n\n`window.alert()` instructs the browser to display a dialog with an optional message, and to wait until the user dismisses the dialog.\n\nUnder some conditions — for example, when the user switches tabs — the browser may not actually display a dialog, or may not wait for the user to dismiss the dialog.",
      "appinstalled_event": "\n\nThe **`appinstalled`** event of the [Web Manifest API](/en-US/docs/Web/Manifest) is fired when the browser has successfully installed a page as an application.\n\nThis event is not cancelable and does not bubble.",
      "back": "\n\nThe obsolete and non-standard method `back()` on the [window]\ninterface returns the window to the previous item in the history. This was a\nFirefox-specific method and was removed in Firefox 31.\n\n> **Note:** Use the standard [history.back] method instead.",
      "beforeinstallprompt_event": "\n\nThe **`beforeinstallprompt`** event fires when the browser has detected that a website can be [installed as a Progressive Web App](/en-US/docs/Web/Progressive_web_apps/Guides/Making_PWAs_installable).\n\nThere's no guaranteed time this event is fired, but it usually happens on page load.\n\nThe typical use for this event is when a web app wants to provide its own in-app UI inviting the user to install the app, rather than the generic one provided by the browser. This enables the app to provide more context about the app, explaining to the user why they might want to install it.\n\nIn this scenario, the handler for this event will:\n\n- Keep a reference to the [BeforeInstallPromptEvent] object that's passed into it\n- Reveal its in-app installation UI (this should be hidden by default, because not all browsers will support installation).\n\nWhen the user uses the in-app installation UI to install the app, the in-app installation UI calls the [BeforeInstallPromptEvent.prompt] method of the retained `BeforeInstallPromptEvent` object to show the installation prompt.",
      "beforeprint_event": "\n\nThe **`beforeprint`** event is fired when the associated document is about to be printed or previewed for printing.\n\nThe [Window.afterprint_event] and `beforeprint` events allow pages to change their content before printing starts (perhaps to remove a banner, for example) and then revert those changes after printing has completed. In general, you should prefer the use of a [`@media print`](/en-US/docs/Web/CSS/CSS_media_queries/Using_media_queries#targeting_media_types) CSS at-rule, but it may be necessary to use these events in some cases.",
      "beforeunload_event": "\n\nThe **`beforeunload`** event is fired when the current window, contained document, and associated resources are about to be unloaded. The document is still visible and the event is still cancelable at this point.\n\nThe main use case for this event is to trigger a browser-generated confirmation dialog that asks users to confirm if they _really_ want to leave the page when they try to close or reload it, or navigate somewhere else. This is intended to help prevent loss of unsaved data.\n\nThe dialog can be triggered in the following ways:\n\n- Calling the event object's [Event.preventDefault] method.\n- Setting the event object's [BeforeUnloadEvent.returnValue] property to a non-empty string value or any other [truthy](/en-US/docs/Glossary/Truthy) value.\n- Returning any truthy value from the event handler function, e.g. `return \"string\"`. Note that this only works when the function is attached via the `onbeforeunload` property, not the [EventTarget.addEventListener] method. This behavior is consistent across modern versions of Firefox, Safari, and Chrome.\n\nThe last two mechanisms are legacy features; best practice is to trigger the dialog by invoking `preventDefault()` on the event object, while also setting `returnValue` to support legacy cases.",
      "blur": "\n\nShifts focus away from the window.",
      "blur_event": "\n\nThe **`blur`** event fires when an element has lost focus.\n\nThe opposite of `blur` is [Window/focus_event].\n\nThis event is not cancelable and does not bubble.",
      "cancelanimationframe": "\n\nThe **`window.cancelAnimationFrame()`** method cancels an\nanimation frame request previously scheduled through a call to\n[window.requestAnimationFrame].",
      "cancelidlecallback": "\n\nThe **`window.cancelIdleCallback()`** method cancels a callback\npreviously scheduled with [window.requestIdleCallback].",
      "captureevents": " \n\nThe **`Window.captureEvents()`** method does nothing.\n\n> **Note:** This is an method long removed from the specification. It is kept in browsers to prevent code breakage but does nothing.",
      "clearimmediate": " \n\nThis method clears the action specified by [window.setImmediate].",
      "close": "\n\nThe **`Window.close()`** method closes the current window, or\nthe window on which it was called.\n\nThis method can only be called on windows that were opened by a script using the\n[Window.open] method, or on top-level windows that have a single history entry. If the window doesn't match these requirements, an error\nsimilar to this one appears in the console:\n`Scripts may not close windows that were not opened by script.`\n\nNote also that `close()` has no effect when called on [Window]\nobjects returned by\n[`HTMLIFrameElement.contentWindow`](/en-US/docs/Web/API/HTMLIFrameElement/contentWindow).",
      "closed": "\n\nThe **`Window.closed`** read-only property indicates whether\nthe referenced window is closed or not.",
      "confirm": "\n\n`window.confirm()` instructs the browser to display a dialog with an optional message, and to wait until the user either confirms or cancels the dialog.\n\nUnder some conditions — for example, when the user switches tabs — the browser may not actually display a dialog, or may not wait for the user to confirm or cancel the dialog.",
      "console": "\n\nThe **`Window.console`** property returns a reference to the [console] object, which provides methods for logging information to the browser's console. These methods are intended for debugging purposes only and should not be relied on for presenting information to end users.",
      "copy_event": "\n\nThe **`copy`** event fires when the user initiates a copy action through the browser's user interface.\n\nThe original target for this event is the [Element] that was the intended target of the copy action. You can listen for this event on the [Window] interface to handle it in the capture or bubbling phases. For full details on this event please see the page on the [Element: copy event](/en-US/docs/Web/API/Element/copy_event).",
      "credentialless": "\n\nThe **`window.credentialless`** read-only property returns a boolean that indicates whether the current document was loaded inside a credentialless `iframe`, meaning that it is loaded in a new, ephemeral context.\n\nThis context doesn't have access to the network, cookies, and storage data associated with its origin. It uses a new context local to the top-level document lifetime. In return, the  (COEP) embedding rules can be lifted, so documents with COEP set can embed third-party documents that do not.\n\nSee [IFrame credentialless](/en-US/docs/Web/Security/IFrame_credentialless) for a deeper explanation.",
      "customelements": "\n\nThe **`customElements`** read-only property of the [Window] interface returns a reference to the [CustomElementRegistry] object, which can be used to register new [custom elements](/en-US/docs/Web/API/Web_components/Using_custom_elements) and get information about previously registered custom elements.",
      "cut_event": "\n\nThe **`cut`** event is fired when the user has initiated a \"cut\" action through the browser's user interface.\n\nThe original target for this event is the [Element] that was the intended target of the cut action. You can listen for this event on the [Window] interface to handle it in the capture or bubbling phases. For full details on this event please see the page on the [Element: cut event](/en-US/docs/Web/API/Element/cut_event).",
      "devicemotion_event": "\n\nThe **`devicemotion`** event is fired at a regular interval and indicates the amount of physical force of acceleration the device is receiving at that time. It also provides information about the rate of rotation, if available.\n\nThis event is not cancelable and does not bubble.",
      "deviceorientation_event": "\n\nThe **`deviceorientation`** event is fired when fresh data is available from an orientation sensor about the current orientation of the device as compared to the Earth coordinate frame. This data is gathered from a magnetometer inside the device.\n\nSee [Orientation and motion data explained](/en-US/docs/Web/API/Device_orientation_events/Orientation_and_motion_data_explained) for details.\n\nThis event is not cancelable and does not bubble.",
      "deviceorientationabsolute_event": "\n\nThe **`deviceorientationabsolute`** event is fired when absolute device orientation changes.\n\nThis event is not cancelable and does not bubble.",
      "devicepixelratio": "\n\nThe **`devicePixelRatio`** of\n[Window] interface returns the ratio of the resolution in _physical\npixels_ to the resolution in _CSS pixels_ for the current display\ndevice.\n\nThis value could also be interpreted as the ratio of pixel sizes: the\nsize of one _CSS pixel_ to the size of one _physical pixel_. In simpler\nterms, this tells the browser how many of the screen's actual pixels should be used to\ndraw a single CSS pixel.\n\nThis is useful when dealing with the difference between rendering on a standard display\nversus a HiDPI or Retina display, which use more screen pixels to draw the same objects,\nresulting in a sharper image.\n\nYou can use [Window.matchMedia] to check if the\nvalue of `devicePixelRatio` changes (which can happen, for example, if the\nuser drags the window to a display with a different pixel density). See\n[the example below](#monitoring_screen_resolution_or_zoom_level_changes).",
      "document": "\n\n**`window.document`** returns a reference to the [document](/en-US/docs/Web/API/Document) contained in the window.",
      "documentpictureinpicture": "\n\nThe **`documentPictureInPicture`** read-only property of the\n[Window] interface returns a reference to the [DocumentPictureInPicture] object for the current document context.",
      "dump": " \n\nThe **`Window.dump()`** method logs messages to the browser's standard output (`stdout`). If the browser was started from a terminal, output sent to `dump()` will appear in the terminal.\n\nOutput from `dump()` is _not_ sent to the browser's developer tools console. To log to the developer tools console, use [`console.log()`](/en-US/docs/Web/API/console/log_static).",
      "error_event": "\n\nThe `error` event is fired on a [Window] object when a resource failed to load or couldn't be used — for example if a script has an execution error.",
      "event": "\n\nThe read-only [Window] property **`event`** returns the [Event] which is currently being handled by the site's code. Outside the context of an event handler, the value is always `undefined`.\n\nYou _should_ avoid using this property in new code, and should instead use the [Event] passed into the event handler function. This property is not universally supported and even when supported introduces potential fragility to your code.\n\n> **Note:** This property can be fragile, in that there may be situations in which the returned `Event` is not the expected value. In addition, `Window.event` is not accurate for events dispatched within .",
      "external": " \n\nThe `external` property of the [Window] API returns an instance of the `External` interface, which was intended to contain functions related to adding external search providers to the browser. However, this is now deprecated, and the contained methods are now dummy functions that do nothing as per spec.",
      "find": "\n\n> **Note:** Support for `Window.find()` might change in future\n> versions of Gecko. See [Firefox bug 672395](https://bugzil.la/672395).\n\nThe **`Window.find()`** method finds a string in a window sequentially.",
      "focus": "\n\nMakes a request to bring the window to the front. It may fail due to user settings and the window isn't guaranteed to be frontmost before this method returns.",
      "focus_event": "\n\nThe **`focus`** event fires when an element has received focus.\n\nThe opposite of `focus` is [Window/blur_event].\n\nThis event is not cancelable and does not bubble.",
      "forward": " \n\nMoves the window one document forward in history. This was a Firefox-specific method and was removed in Firefox 31.\n\n> **Note:** Use the standard [History.forward] method instead.",
      "frameelement": "\n\nThe **`Window.frameElement`** property\nreturns the element (such as `iframe` or `object`)\nin which the window is embedded.\n\n> **Note:** Despite this property's name, it works for documents embedded\n> within any embedding point, including `object`,\n> `iframe`, or `embed`.",
      "frames": "\n\nReturns the window itself, which is an array-like object, listing the direct sub-frames\nof the current window.",
      "fullscreen": "\n\nThe **`fullScreen`** property of the `Window`\ninterface indicates whether the window is displayed in full screen mode or not.",
      "gamepadconnected_event": "\n\nThe `gamepadconnected` event is fired when the browser detects that a gamepad has been connected or the first time a button/axis of the gamepad is used.\n\nThe event will not fire if disallowed by the document's  [Permissions Policy](/en-US/docs/Web/HTTP/Permissions_Policy).\n\nThis event is not cancelable and does not bubble.",
      "gamepaddisconnected_event": "\n\nThe `gamepaddisconnected` event is fired when the browser detects that a gamepad has been disconnected.\n\nThe event will not fire if disallowed by the document's  [Permissions Policy](/en-US/docs/Web/HTTP/Permissions_Policy).\n\nThis event is not cancelable and does not bubble.",
      "getcomputedstyle": "\n\nThe\n**`Window.getComputedStyle()`** method returns an object\ncontaining the values of all CSS properties of an element, after applying active\nstylesheets and resolving any basic computation those values may contain.\n\nIndividual CSS property values are accessed through APIs provided by the object, or by\nindexing with CSS property names.",
      "getdefaultcomputedstyle": "\n\nThe **`getDefaultComputedStyle()`** method gives the default [computed values](/en-US/docs/Web/CSS/computed_value) of all the CSS\nproperties of an element, ignoring author styling. That is, only user-agent and user\nstyles are taken into account.",
      "getscreendetails": "\n\nThe **`getScreenDetails()`** method of the\n[Window] interface returns a `Promise` that fulfills with a [ScreenDetails] object instance representing the details of all the screens available to the user's device.",
      "getselection": "\n\nThe **`Window.getSelection()`** method returns a\n[Selection] object representing the range of text selected by the user or\nthe current position of the caret.",
      "hashchange_event": "\n\nThe **`hashchange`** event is fired when the fragment identifier of the URL has changed (the part of the URL beginning with and following the `#` symbol).",
      "history": "\n\nThe `Window.history` read-only property returns a reference to the [History] object, which provides an interface for manipulating the browser _session history_ (pages visited in the tab or frame that the current page is loaded in).\n\nSee [Manipulating the browser history](/en-US/docs/Web/API/History_API) for examples and details. In particular, that article explains security features of the [History.pushState] and [History.replaceState] methods that you should be aware of before using them.",
      "innerheight": "\n\nThe read-only **`innerHeight`** property of the\n[Window] interface returns the interior height of the window in pixels,\nincluding the height of the horizontal scroll bar, if present.\n\nThe value of `innerHeight` is taken from the height of the window's\n. The width can be obtained using the\n[Window.innerWidth] property.",
      "innerwidth": "\n\nThe read-only [Window] property **`innerWidth`** returns the interior width of the window in pixels (that is, the width of the window's ). That includes the width of the vertical scroll bar, if one is present.\n\nSimilarly, the interior height of the window (that is, the height of the layout viewport) can be obtained using the [Window.innerHeight] property. That measurement also accounts for the height of the horizontal scroll bar, if it is visible.",
      "languagechange_event": "\n\nThe **`languagechange`** event is fired at the global scope object when the user's preferred language changes.",
      "launchqueue": "\n\nThe `launchQueue` read-only property of the [Window] interface provides access to the [LaunchQueue] class, which allows custom launch navigation handling to be implemented in a [progressive web app](/en-US/docs/Web/Progressive_web_apps) (PWA), with the handling context signified by the [`launch_handler`](/en-US/docs/Web/Manifest/launch_handler) manifest field `client_mode` value.\n\nThe custom launch navigation handling functionality is controlled by the properties of the [LaunchParams] object passed into the [LaunchQueue.setConsumer] callback function.",
      "length": "\n\nReturns the number of frames (either `frame` or\n`iframe` elements) in the window.",
      "load_event": "\n\nThe **`load`** event is fired when the whole page has loaded, including all dependent resources such as stylesheets, scripts, iframes, and images.\nThis is in contrast to [Document/DOMContentLoaded_event], which is fired as soon as the page DOM has been loaded, without waiting for resources to finish loading.\n\nThis event is not cancelable and does not bubble.\n\n> **Note:** _All events named `load` will not propagate to `Window`_, even with `bubbles` initialized to `true`. To catch `load` events on the `window`, that `load` event must be dispatched directly to the `window`.\n\n> **Note:** The `load` event that is dispatched when the main document has loaded _is_ dispatched on the `window`, but has two mutated properties: `target` is `document`, and `path` is `undefined`. These two properties are mutated due to legacy conformance.",
      "localstorage": "\n\nThe **`localStorage`** read-only property of the [window] interface allows you to access a [Storage] object for the [Document]'s ; the stored data is saved across browser sessions.\n\n`localStorage` is similar to [Window.sessionStorage], except that while `localStorage` data has no expiration time, `sessionStorage` data gets cleared when the page session ends — that is, when the page is closed. (`localStorage` data for a document loaded in a \"private browsing\" or \"incognito\" session is cleared when the last \"private\" tab is closed.)",
      "location": "\n\nThe **`Window.location`** read-only property returns a [Location] object with information about the current location of the document.\n\nThough `Window.location` is a _read-only_ `Location` object, you can also assign a string to it.\nThis means that you can work with `location` as if it were a string in most cases:\n`location = 'http://www.example.com'` is a synonym of `location.href = 'http://www.example.com'`.\n\nSee [Location] for all available properties.",
      "locationbar": "\n\nReturns the `locationbar` object.\n\nThis is one of a group of `Window` properties that contain a boolean `visible` property, that used to represent whether or not a particular part of a web browser's user interface was visible.\n\nFor privacy and interoperability reasons, the value of the `visible` property is now `false` if this `Window` is a popup, and `true` otherwise.",
      "matchmedia": "\n\nThe [Window] interface's **`matchMedia()`** method\nreturns a new [MediaQueryList] object that can then be used to determine if\nthe [document] matches the [media query](/en-US/docs/Web/CSS/CSS_media_queries/Using_media_queries) string,\nas well as to monitor the document to detect when it matches (or stops matching) that\nmedia query.",
      "menubar": "\n\nReturns the `menubar` object.\n\nThis is one of a group of `Window` properties that contain a boolean `visible` property, that used to represent whether or not a particular part of a web browser's user interface was visible.\n\nFor privacy and interoperability reasons, the value of the `visible` property is now `false` if this `Window` is a popup, and `true` otherwise.",
      "message_event": "\n\nThe `message` event is fired on a [Window] object when the window receives a message, for example from a call to [`Window.postMessage()`](/en-US/docs/Web/API/Window/postMessage) from another browsing context.\n\nThis event is not cancellable and does not bubble.",
      "messageerror_event": "\n\nThe `messageerror` event is fired on a [Window] object when it receives a message that can't be deserialized.\n\nThis event is not cancellable and does not bubble.",
      "moveby": "\n\nThe **`moveBy()`** method of the [Window]\ninterface moves the current window by a specified amount.\n\n> **Note:** This function moves the window relative to its current\n> location. In contrast, [window.moveTo] moves the window to an absolute\n> location.",
      "moveto": "\n\nThe **`moveTo()`** method of the [Window]\ninterface moves the current window to the specified coordinates.\n\n> **Note:** This function moves the window to an absolute location. In\n> contrast, [window.moveBy] moves the window relative to its current\n> location.",
      "mozinnerscreenx": "\n\nGets the X coordinate of the top-left corner of the window's viewport, in screen\ncoordinates.\n\n> **Note:** This coordinate is reported in CSS pixels, not in hardware pixels. That means it can be affected by the zoom level; to compute the actual number of physical screen pixels, you should use the `nsIDOMWindowUtils.screenPixelsPerCSSPixel` property.",
      "mozinnerscreeny": "\n\nThe `mozInnerScreenY` property of the [Window] interface returns the Y coordinate of the top-left corner of the window's viewport, in screen\ncoordinates.\n\n> **Note:** This coordinate is reported in CSS pixels, not in hardware pixels.",
      "name": "\n\nThe `Window.name` property\ngets/sets the name of the window's browsing context.",
      "navigation": "\n\nThe **`navigation`** read-only property of the [Window] interface returns the current `window`'s associated [Navigation] object.\n\nThis is the entry point for the [Navigation API].",
      "navigator": "\n\nThe **`Window.navigator`** read-only property returns a\nreference to the [Navigator] object, which has methods and properties about\nthe application running the script.",
      "offline_event": "\n\nThe **`offline`** event of the [Window] interface is fired when the browser has lost access to the network and the value of [Navigator.onLine] switches to `false`.",
      "online_event": "\n\nThe **`online`** event of the [Window] interface is fired when the browser has gained access to the network and the value of [Navigator.onLine] switches to `true`.\n\n> **Note:** This event shouldn't be used to determine the availability of a particular website. Network problems or firewalls might still prevent the website from being reached.",
      "open": "\n\nThe **`open()`** method of the [`Window`](/en-US/docs/Web/API/Window) interface loads a specified resource into a new or existing browsing context (that is, a tab, a window, or an [iframe](/en-US/docs/Web/HTML/Element/iframe)) under a specified name.",
      "opener": "\n\nThe [Window] interface's\n**`opener`** property returns a reference to the window that\nopened the window, either with [Window.open], or by navigating\na link with a [`target`](/en-US/docs/Web/HTML/Element/a#target) attribute.\n\nIn other words, if window `A` opens window `B`,\n`B.opener` returns `A`.",
      "orientation": "\n\nReturns the orientation in degrees (in 90-degree increments) of the viewport relative to the device's natural orientation.\n\nIts only possible values are `-90`, `0`, `90`, and `180`. Positive values are counterclockwise; negative values are clockwise.\n\nThis property is deprecated. Use the [Screen.orientation] property instead, available on the [window.screen] property.",
      "orientationchange_event": "\n\nThe `orientationchange` event is fired when the orientation of the device has changed.\n\nThis event is not cancelable and does not bubble.\n\nThis event is deprecated. Listen for the [ScreenOrientation.change_event] event of the [ScreenOrientation] interface instead.",
      "originagentcluster": "\n\nThe **`originAgentCluster`** read-only property of the [Window] interface returns `true` if this window belongs to an _origin-keyed [agent cluster](https://tc39.es/ecma262/#sec-agent-clusters)_: this means that the operating system has provided dedicated resources (for example an operating system process) to this window's origin that are not shared with windows from other origins.\n\nOtherwise this property returns `false`.\n\nWindows that are part of an origin-keyed agent cluster are subjects to some additional restrictions, compared with windows that are not. In particular, they cannot:\n\n- Set [Document.domain], which is a legacy feature that normally allows same-site cross-origin pages to synchronously access each other's DOM.\n- Send [`WebAssembly.Module`](/en-US/docs/WebAssembly/JavaScript_interface/Module) objects to other same-site cross-origin pages via [Window.postMessage].\n- Send `SharedArrayBuffer` or [`WebAssembly.Memory`](/en-US/docs/WebAssembly/JavaScript_interface/Memory) objects to other same-site cross-origin pages.\n\nTo request that the browser assign this window to an origin-keyed agent cluster, the server must send the  response header.\n\nNote that the origin-keyed agent cluster feature is only supported in . If a site is not a secure context, the `window.originAgentCluster` will always return `false`.",
      "outerheight": "\n\nThe **`Window.outerHeight`** read-only property returns the height in pixels of the whole browser window, including any sidebar, window chrome, and window-resizing borders/handles.",
      "outerwidth": "\n\n**`Window.outerWidth`** read-only property returns the width of the outside of the browser window. It represents the width of the whole browser window including sidebar (if expanded), window chrome and window resizing borders/handles.",
      "pagehide_event": "\n\nThe **`pagehide`** event is sent to a [Window] when the browser hides the current page in the process of presenting a different page from the session's history.\n\nFor example, when the user clicks the browser's Back button, the current page receives a `pagehide` event before the previous page is shown.",
      "pageshow_event": "\n\nThe **`pageshow`** event is sent to a [Window] when the browser displays the window's document due to navigation.\n\nThis includes:\n\n- Initially loading the page\n- Navigating to the page from another page in the same window or tab\n- Restoring a frozen page on mobile OSes\n- Returning to the page using the browser's forward or back buttons\n\n> **Note:** During the initial page load, the `pageshow` event fires _after_ the [Window/load_event] event.",
      "parent": "\n\nThe **`Window.parent`** property is a reference to the parent\nof the current window or subframe.\n\nIf a window does not have a parent, its `parent` property is a reference to\nitself.\n\nWhen a window is loaded in an `iframe`, `object`, or\n`frame`, its parent is the window with the element embedding the\nwindow.",
      "paste_event": "\n\nThe **`paste`** event is fired when the user has initiated a \"paste\" action through the browser's user interface.\n\nThe original target for this event is the [Element] that was the intended target of the paste action. You can listen for this event on the [Window] interface to handle it in the capture or bubbling phases. For full details on this event please see the page on the [Element: paste event](/en-US/docs/Web/API/Element/paste_event).",
      "personalbar": "\n\nReturns the `personalbar` object.\n\nThis is one of a group of `Window` properties that contain a boolean `visible` property, that used to represent whether or not a particular part of a web browser's user interface was visible.\n\nFor privacy and interoperability reasons, the value of the `visible` property is now `false` if this `Window` is a popup, and `true` otherwise.",
      "popstate_event": "\n\nThe **`popstate`** event of the [Window] interface is fired when the active history entry changes while the user navigates the session history. It changes the current history entry to that of the last page the user visited or, if [history.pushState] has been used to add a history entry to the history stack, that history entry is used instead.",
      "postmessage": "\n\nThe **`window.postMessage()`** method safely enables\ncross-origin communication between [Window] objects; _e.g.,_ between\na page and a pop-up that it spawned, or between a page and an iframe embedded within it.\n\nNormally, scripts on different pages are allowed to access each other if and only if\nthe pages they originate from share the same protocol, port number, and host (also known\nas the \"[same-origin policy](/en-US/docs/Web/Security/Same-origin_policy)\").\n`window.postMessage()` provides a controlled mechanism to securely circumvent this restriction (if used properly).\n\nBroadly, one window may obtain a reference to another (_e.g.,_ via\n`targetWindow = window.opener`), and then dispatch a\n[MessageEvent] on it with `targetWindow.postMessage()`. The\nreceiving window is then free to [handle this event](/en-US/docs/Web/Events/Event_handlers) as needed. The arguments passed to `window.postMessage()`\n(_i.e.,_ the \"message\") are [exposed to the receiving window through the event object](#the_dispatched_event).",
      "print": "\n\nOpens the print dialog to print the current document.\n\nIf the document is still loading when this function is called, then the document will finish loading before opening the print dialog.\n\nThis method will block while the print dialog is open.",
      "prompt": "\n\n`window.prompt()` instructs the browser to display a dialog with an optional message prompting the user to input some text, and to wait until the user either submits the text or cancels the dialog.\n\nUnder some conditions — for example, when the user switches tabs — the browser may not actually display a dialog, or may not wait for the user to submit text or to cancel the dialog.",
      "querylocalfonts": "\n\nThe **`window.queryLocalFonts()`** method returns a `Promise` that fulfills with an array of [FontData] objects representing the font faces available locally.\n\nTo use this method, the user must grant permission to access `local-fonts` (permission status can be queried via the [Permissions API]). In addition, this feature may be blocked by a [Permissions Policy](/en-US/docs/Web/HTTP/Permissions_Policy) set on your server.",
      "rejectionhandled_event": "\n\nThe **`rejectionhandled`** event is sent to the script's global scope (usually [window] but also [Worker]) whenever a rejected JavaScript `Promise` is handled late, i.e. when a handler is attached to the promise after its rejection had caused an [Window.unhandledrejection_event] event.\n\nThis can be used in debugging and for general application resiliency, in tandem with the `unhandledrejection` event, which is sent when a promise is rejected but there is no handler for the rejection at the time.",
      "releaseevents": "\n\nReleases the window from trapping events of a specific type.",
      "requestanimationframe": "\n\nThe **`window.requestAnimationFrame()`** method tells the\nbrowser you wish to perform an animation. It requests the browser to call a\nuser-supplied callback function before the next repaint.\n\nThe frequency of calls to the callback function will generally match the display\nrefresh rate. The most common refresh rate is 60hz,\n(60 cycles/frames per second), though 75hz, 120hz, and 144hz are also widely used.\n`requestAnimationFrame()` calls are paused in most browsers when running in\nbackground tabs or hidden `iframe`s, in order to improve\nperformance and battery life.\n\n> **Note:** Your callback function must call `requestAnimationFrame()` again if\n> you want to animate another frame. `requestAnimationFrame()` is one-shot.\n\n> **Warning:** Be sure always to use the first argument (or some other method for\n> getting the current time) to calculate how much the animation will progress in\n> a frame — **otherwise, the animation will run faster on high refresh-rate screens**.\n> For ways to do that, see the examples below.",
      "requestfilesystem": "\n\nThe non-standard [Window] method\n**`requestFileSystem()`** method is a Google Chrome-specific\nmethod which lets a website or app gain access to a sandboxed file system for its own\nuse. The returned [FileSystem] is then available for use with the other [file system APIs](/en-US/docs/Web/API/File_and_Directory_Entries_API).\n\n> **Note:** This method is prefixed with `webkit` in all browsers that implement it.",
      "requestidlecallback": "\n\nThe **`window.requestIdleCallback()`** method queues a function\nto be called during a browser's idle periods. This enables developers to perform\nbackground and low priority work on the main event loop, without impacting\nlatency-critical events such as animation and input response. Functions are generally\ncalled in first-in-first-out order; however, callbacks which have a `timeout`\nspecified may be called out-of-order if necessary in order to run them before the\ntimeout elapses.\n\nYou can call `requestIdleCallback()` within an idle callback function to\nschedule another callback to take place no sooner than the next pass through the event\nloop.\n\n> **Note:** A `timeout` option is strongly recommended for required work,\n> as otherwise it's possible multiple seconds will elapse before the callback is fired.",
      "resize_event": "\n\nThe **`resize`** event fires when the document view (window) has been resized.\n\nThis event is not cancelable and does not bubble.\n\nIn some earlier browsers it was possible to register `resize` event handlers on any HTML element. It is still possible to set `onresize` attributes or use [EventTarget.addEventListener] to set a handler on any element. However, `resize` events are only fired on the [Window] object (i.e. returned by [document.defaultView]). Only handlers registered on the `window` object will receive `resize` events.\n\nWhile the `resize` event fires only for the window nowadays, you can get resize notifications for other elements using the [ResizeObserver](/en-US/docs/Web/API/ResizeObserver) API.\n\nIf the resize event is triggered too many times for your application, see [Optimizing window.onresize](https://web.archive.org/web/20220714020647/https://bencentra.com/code/2015/02/27/optimizing-window-resize.html) to control the time after which the event fires.",
      "resizeby": "\n\nThe **`Window.resizeBy()`** method resizes the current window\nby a specified amount.",
      "resizeto": "\n\nThe **`Window.resizeTo()`** method dynamically resizes the\nwindow.",
      "screen": "\n\nThe [Window] property **`screen`** returns a\nreference to the screen object associated with the window. The `screen`\nobject, implementing the [Screen] interface, is a special object for\ninspecting properties of the screen on which the current window is being rendered.",
      "screenleft": "\n\nThe **`Window.screenLeft`** read-only property returns the\nhorizontal distance, in CSS pixels, from the left border of the user's browser viewport\nto the left side of the screen.\n\n> **Note:** `screenLeft` is an alias of the older\n> [Window.screenX] property. `screenLeft` was originally\n> supported only in IE but was introduced everywhere due to popularity.",
      "screentop": "\n\nThe **`Window.screenTop`** read-only property returns the\nvertical distance, in CSS pixels, from the top border of the user's browser viewport to\nthe top side of the screen.\n\n> **Note:** `screenTop` is an alias of the older\n> [Window.screenY] property. `screenTop` was originally\n> supported only in IE but was introduced everywhere due to popularity.",
      "screenx": "\n\nThe **`Window.screenX`** read-only property returns the\nhorizontal distance, in CSS pixels, of the left border of the user's browser viewport to\nthe left side of the screen.\n\n> **Note:** An alias of `screenX` was implemented across modern\n> browsers in more recent times — [Window.screenLeft]. This was originally\n> supported only in IE but was introduced everywhere due to popularity.",
      "screeny": "\n\nThe **`Window.screenY`** read-only property returns the vertical distance, in CSS pixels, of the top border of the user's browser viewport to the top edge of the screen.\n\n> **Note:** An alias of `screenY` was implemented across modern browsers in more recent times — [Window.screenTop]. This was originally supported only in IE but was introduced everywhere due to popularity.",
      "scroll": "\n\nThe **`Window.scroll()`** method scrolls the window to a\nparticular place in the document.",
      "scrollbars": "\n\nReturns the `scrollbars` object.\n\nThis is one of a group of `Window` properties that contain a boolean `visible` property, that used to represent whether or not a particular part of a web browser's user interface was visible.\n\nFor privacy and interoperability reasons, the value of the `visible` property is now `false` if this `Window` is a popup, and `true` otherwise.",
      "scrollby": "\n\nThe **`Window.scrollBy()`** method scrolls the document in the\nwindow by the given amount.",
      "scrollbylines": " \n\nThe **`Window.scrollByLines()`** method scrolls the document by\nthe specified number of lines.",
      "scrollbypages": " \n\nThe **`Window.scrollByPages()`** method scrolls the current\ndocument by the specified number of pages.",
      "scrollmaxx": " \n\nThe **`Window.scrollMaxX`** read-only property returns the\nmaximum number of pixels that the document can be scrolled horizontally.",
      "scrollmaxy": " \n\nThe **`Window.scrollMaxY`** read-only property returns the\nmaximum number of pixels that the document can be scrolled vertically.",
      "scrollto": "\n\n**`Window.scrollTo()`** scrolls to a particular set of\ncoordinates in the document.",
      "scrollx": "\n\nThe read-only **`scrollX`** property of the\n[Window] interface returns the number of pixels that the document is\ncurrently scrolled horizontally. This value is subpixel precise in modern browsers,\nmeaning that it isn't necessarily a whole number. You can get the number of pixels the\ndocument is scrolled vertically from the [Window.scrollY]\nproperty.",
      "scrolly": "\n\nThe read-only **`scrollY`** property\nof the [Window] interface returns the number of pixels that the document\nis currently scrolled vertically.\n\nThis value is subpixel precise in modern\nbrowsers, meaning that it isn't necessarily a whole number. You can get the number of\npixels the document is scrolled horizontally from the [Window.scrollX] property.",
      "self": "\n\nThe **`Window.self`** read-only property returns the window itself, as a . It can be used with dot notation on a `window` object (that is, `window.self`) or standalone (`self`). The advantage of the standalone notation is that a similar notation exists for non-window contexts, such as in [Worker]. By using `self`, you can refer to the global scope in a way that will work not only in a window context (`self` will resolve to `window.self`) but also in a worker context (`self` will then resolve to [WorkerGlobalScope.self]).",
      "sessionstorage": "\n\nThe read-only **`sessionStorage`**\nproperty accesses a session [Storage] object for the current\n. `sessionStorage` is similar to\n[Window.localStorage]; the difference is that while data\nin `localStorage` doesn't expire, data in `sessionStorage` is\ncleared when the _page session_ ends.\n\n- Whenever a document is loaded in a particular tab in the browser, a unique page\n  session gets created and assigned to that particular tab. That page session is valid\n  only for that particular tab.\n- A page session lasts as long as the tab or the browser is open, and survives over\n  page reloads and restores.\n- **Opening a page in a new tab or window creates a new session with the value\n  of the top-level browsing context, which differs from how session cookies\n  work.**\n- Opening multiple tabs/windows with the same URL creates `sessionStorage`\n  for each tab/window.\n- Duplicating a tab copies the tab's `sessionStorage` into the new\n  tab.\n- Closing a tab/window ends the session and clears objects in\n  `sessionStorage`.\n\nData stored in `sessionStorage` **is specific to the protocol of the\npage**. In particular, data stored by a script on a site accessed with HTTP\n(e.g., [http://example.com](https://example.com)) is\nput in a different `sessionStorage` object from the same site accessed with\nHTTPS (e.g., <https://example.com>).\n\nThe keys and the values are _always_ in the UTF-16 string\nformat, which uses two bytes per character. As with objects, integer keys are\nautomatically converted to strings.",
      "setimmediate": " \n\nThis method is used to break up long running operations and run a callback function immediately after the browser has completed other operations such as events and display updates.",
      "setresizable": " \n\nThis method does nothing; it is a no-op. It is solely kept for compatibility with Netscape 4.x.",
      "sharedstorage": "\n\nThe global read-only **`sharedStorage`** property returns the [WindowSharedStorage] object for the current origin. This is the main entry point for writing data to shared storage using the [Shared Storage API](/en-US/docs/Web/API/Shared_Storage_API).\n\n> **Note:** `sharedStorage` is not available inside workers. It is implemented by [`Window`](/en-US/docs/Web/API/Window#scheduler) and is also available in shared storage worklets (see [SharedStorageWorkletGlobalScope.sharedStorage], which returns [WorkletSharedStorage]).",
      "showdirectorypicker": "\n\nThe **`showDirectoryPicker()`** method of the\n[Window] interface displays a directory picker which allows the user to\nselect a directory.",
      "showmodaldialog": "\n\n> **Warning:** This feature has been removed. Please fix your websites and applications.\n>\n> This method was removed in Chrome 43 and Firefox 56.\n\nThe **`Window.showModalDialog()`**\ncreated and displayed a modal dialog box containing a specified HTML document.",
      "showopenfilepicker": "\n\nThe **`showOpenFilePicker()`** method of the\n[Window] interface shows a file picker that allows a user to select a file\nor multiple files and returns a handle for the file(s).",
      "showsavefilepicker": "\n\nThe **`showSaveFilePicker()`** method of the\n[Window] interface shows a file picker that allows a user to save a file.\nEither by selecting an existing file, or entering a name for a new file.",
      "sidebar": " \n\n> **Warning:** This non-standard Firefox-only alias of the [`window.external`](/en-US/docs/Web/API/Window/external) property [has been removed](#browser_compatibility).\n\nReturns a sidebar object which contains several methods for registering add-ons with the browser.",
      "sizetocontent": "\n\nThe **`Window.sizeToContent()`** method sizes the window\naccording to its content. In order for it to work, the DOM content should be loaded when\nthis function is called—for example, once the [Document/DOMContentLoaded_event] event has\nbeen thrown.\n\nSince Firefox 20, the minimal size of the window is clamped to prevent the window from\nbeing too small for the user to interact with.",
      "speechsynthesis": "\n\nThe `speechSynthesis` read-only property of the Window object returns a [SpeechSynthesis] object, which is the entry point into using [Web Speech API](/en-US/docs/Web/API/Web_Speech_API) speech synthesis functionality.",
      "status": "\n\nThe **`status`** property of the\n[Window] interface was originally intended to set the text in the status\nbar at the bottom of the browser window. However, the HTML standard now requires\nsetting `window.status` to have no effect on the text displayed in the\nstatus bar.",
      "statusbar": "\n\nReturns the `statusbar` object.\n\nThis is one of a group of `Window` properties that contain a boolean `visible` property, that used to represent whether or not a particular part of a web browser's user interface was visible.\n\nFor privacy and interoperability reasons, the value of the `visible` property is now `false` if this `Window` is a popup, and `true` otherwise.",
      "stop": "\n\nThe **`window.stop()`** stops further resource loading in the current\nbrowsing context, equivalent to the stop button in the browser.\n\nBecause of how scripts are executed, this method cannot interrupt its parent\ndocument's loading, but it will stop its images, new windows, and other still-loading\nobjects.",
      "storage_event": "\n\nThe **`storage`** event of the [Window] interface fires when a storage area (`localStorage` or `sessionStorage`) has been modified in the context of another document.\n\nThis event is not cancelable and does not bubble.\n\n> **Note:** This won't work on the same page that is making the changes — it is really a way for other pages on the domain using the storage to sync any changes that are made. Pages on other domains can't access the same storage objects.",
      "toolbar": "\n\nReturns the `toolbar` object.\n\nThis is one of a group of `Window` properties that contain a boolean `visible` property, that used to represent whether or not a particular part of a web browser's user interface was visible.\n\nFor privacy and interoperability reasons, the value of the `visible` property is now `false` if this `Window` is a popup, and `true` otherwise.",
      "top": "\n\nReturns a reference to the topmost window in the window hierarchy.",
      "unhandledrejection_event": "\n\nThe **`unhandledrejection`** event is sent to the global scope of a script when a JavaScript `Promise` that has no rejection handler is rejected; typically, this is the [window], but may also be a [Worker].\n\nThis is useful for debugging and for providing fallback error handling for unexpected situations.",
      "unload_event": "\n\n> **Warning:** Developers should avoid using this event. See \"Usage notes\" below.\n\nThe **`unload`** event is fired when the document or a child resource is being unloaded.\n\nIt is fired after:\n\n- [Window/beforeunload_event] (cancelable event)\n- [Window/pagehide_event]\n\nThe document is in the following state:\n\n- All the resources still exist (img, iframe etc.)\n- Nothing is visible anymore to the end user\n- UI interactions are ineffective ([window.open], [window.alert], [window.confirm], etc.)\n- An error won't stop the unloading workflow\n\nPlease note that the unload event also follows the document tree: parent frame unload will happen **before** child frame `unload` (see example below).",
      "updatecommands": "\n\nUpdates the state of commands of the current chrome window (UI).",
      "visualviewport": "\n\nThe **`visualViewport`** read-only property of the\n[Window] interface returns a [VisualViewport] object\nrepresenting the visual viewport for a given window.",
      "vrdisplayactivate_event": "\n\nThe **`vrdisplayactivate`** event of the [WebVR API](/en-US/docs/Web/API/WebVR_API) is fired when a VR display is able to be presented to, for example if an HMD has been moved to bring it out of standby, or woken up by being put on.\n\n> **Note:** This event was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nThis event is not cancelable and does not bubble.",
      "vrdisplayconnect_event": "\n\nThe **`vrdisplayconnect`** event of the [WebVR API](/en-US/docs/Web/API/WebVR_API) is fired when a compatible VR display is connected to the computer.\n\n> **Note:** This event was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nThis event is not cancelable and does not bubble.",
      "vrdisplaydeactivate_event": "\n\nThe **`vrdisplaydeactivate`** event of the [WebVR API](/en-US/docs/Web/API/WebVR_API) is fired when a VR display can no longer be presented to, for example if an HMD has gone into standby or sleep mode due to a period of inactivity.\n\n> **Note:** This event was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nThis event is not cancelable and does not bubble.",
      "vrdisplaydisconnect_event": "\n\nThe **`vrdisplaydisconnect`** event of the [WebVR API](/en-US/docs/Web/API/WebVR_API) is fired when a compatible VR display is disconnected from the computer.\n\nThis event is not cancelable and does not bubble.",
      "vrdisplaypresentchange_event": "\n\nThe **`vrdisplaypresentchange`** event of the [WebVR API](/en-US/docs/Web/API/WebVR_API) is fired when the presenting state of a VR display changes — i.e. goes from presenting to not presenting, or vice versa.\n\n> **Note:** This event was part of the old [WebVR API](https://immersive-web.github.io/webvr/spec/1.1/). It has been superseded by the [WebXR Device API](https://immersive-web.github.io/webxr/).\n\nThis event is not cancelable and does not bubble.",
      "webkitconvertpointfromnodetopage": "\n\nGiven a [WebKitPoint] specified in a particular DOM [Node]'s coordinate system, the [Window] method **`webkitConvertPointFromNodeToPage()`** returns a `Point` which specifies the same position in the page's coordinate system. This method is non-standard and _should not be used_.\n\n> **Warning:** Please review the [Browser compatibility](#browser_compatibility) section before using this method, as it's not widely supported (nor is the [WebKitPoint] object it uses).",
      "webkitconvertpointfrompagetonode": "\n\nGiven a [WebKitPoint] specified in the page's coordinate system, the\n[Window] method **`webkitConvertPointFromPageToNode()`**\nreturns a `Point` object specifying the same location in the coordinate\nsystem of the specified DOM [Node].\n\n> **Warning:** Please review the [Browser compatibility](#browser_compatibility) section before using this method,\n> as it's not widely supported (nor is the [WebKitPoint] object it uses)."
    }
  },
  "windowclient": {
    "docs": "\n\nThe `WindowClient` interface of the [ServiceWorker API](/en-US/docs/Web/API/Service_Worker_API) represents the scope of a service worker client that is a document in a browsing context, controlled by an active worker. The service worker client independently selects and uses a service worker for its own loading and sub-resources.\n\n",
    "properties": {
      "ancestororigins": "\n\nThe **`ancestorOrigins`** read-only property of the [WindowClient] interface is an array of strings listing the origins of all ancestors of the browsing context represented by this `WindowClient` in reverse order.\n\nThe first element in the array is the origin of this window's parent, and the last element is the origin of the top-level browsing context. If this window is itself a top-level browsing context, then `ancestorOrigins` is an empty array.",
      "focus": "\n\nThe **`focus()`** method of the [WindowClient]\ninterface gives user input focus to the current client and returns a\n`Promise` that resolves to the existing\n[WindowClient].",
      "focused": "\n\nThe **`focused`** read-only property of the\n[WindowClient] interface is a boolean value that indicates whether\nthe current client has focus.",
      "navigate": "\n\nThe **`navigate()`** method of the [WindowClient]\ninterface loads a specified URL into a controlled client page then returns a\n`Promise` that resolves to the existing [WindowClient].",
      "visibilitystate": "\n\nThe **`visibilityState`** read-only property of the\n[WindowClient] interface indicates the visibility of the current client.\nThis value can be one of `\"hidden\"`, `\"visible\"`, or\n`\"prerender\"`."
    }
  },
  "windowcontrolsoverlay": {
    "docs": "\n\nThe **`WindowControlsOverlay`** interface of the [Window Controls Overlay API](/en-US/docs/Web/API/Window_Controls_Overlay_API) exposes information about the geometry\nof the title bar area in desktop Progressive Web Apps, and an event to know whenever it changes. This interface is accessible from [Navigator.windowControlsOverlay].\n\n",
    "properties": {
      "geometrychange_event": "\n\nThe `geometrychange` event is fired when the position, size, or visibility of a Progressive Web App's title bar area changes.\n\nThis only applies to Progressive Web Apps installed on desktop operating systems and use the [Window Controls Overlay API](/en-US/docs/Web/API/Window_Controls_Overlay_API).",
      "gettitlebararearect": "\n\nThe **`getTitlebarAreaRect()`** method of the [WindowControlsOverlay] interface queries the current geometry of the title bar area of the Progressive Web App window.\n\nThis only applies to Progressive Web Apps installed on desktop operating systems and which use the [Window Controls Overlay API](/en-US/docs/Web/API/Window_Controls_Overlay_API).",
      "visible": "\n\nThe **`visible`** read-only property of the [WindowControlsOverlay] interface returns a  that indicates whether the window controls overlay is visible or not.\n\nThe window controls overlay is not be visible if:\n\n- The Web App Manifest's [`display_override`](/en-US/docs/Web/Manifest/display_override) member is not set to `window-controls-overlay`.\n- Or, if the user has opted-out of the feature."
    }
  },
  "windowcontrolsoverlaygeometrychangeevent": {
    "docs": "\n\nThe **`WindowControlsOverlayGeometryChangeEvent`** interface of the [Window Controls Overlay API](/en-US/docs/Web/API/Window_Controls_Overlay_API) is passed to [WindowControlsOverlay/geometrychange_event] when the size or visibility of a desktop Progress Web App's title bar region changes.\n\n",
    "properties": {
      "titlebararearect": "\n\nThe **`titlebarAreaRect`** read-only property of the [WindowControlsOverlayGeometryChangeEvent] interface is a [DOMRect] representing the position and size of the area occupied by the title bar in a desktop-installed Progressive Web App.",
      "visible": "\n\nThe **`visible`** read-only property of the [WindowControlsOverlayGeometryChangeEvent] interface is a boolean flag that indicates whether the window controls overlay is visible or not in a desktop-installed Progressive Web App.\n\nIf the user opts-out of the [Window Controls Overlay](/en-US/docs/Web/API/Window_Controls_Overlay_API) feature, the default title bar appears and the window controls buttons do not appear as an overlay, in which case the `visible` flag is false."
    }
  },
  "windowsharedstorage": {
    "docs": "\n\nThe **`WindowSharedStorage`** interface of the [Shared Storage API] represents the shared storage for a particular origin within a standard browsing context.\n\n`WindowSharedStorage` is accessed via [Window.sharedStorage].\n\n",
    "properties": {
      "run": "\n\nThe **`run()`** method of the\n[WindowSharedStorage] interface executes a [run operation](/en-US/docs/Web/API/SharedStorageRunOperation) that is registered in a module added to the current origin's [SharedStorageWorklet].\n\n> **Note:** The [Run output gate](/en-US/docs/Web/API/Shared_Storage_API#run) is intended as a generic way to process some shared storage data.",
      "selecturl": "\n\nThe **`selectURL()`** method of the\n[WindowSharedStorage] interface executes a [URL Selection operation](/en-US/docs/Web/API/SharedStorageSelectURLOperation) that is registered in a module added to the current origin's [SharedStorageWorklet].\n\n> **Note:** The [URL Selection output gate](/en-US/docs/Web/API/Shared_Storage_API#url_selection) is used to select a URL from a provided list to display to the user, based on shared storage data.",
      "worklet": "\n\nThe **`worklet`** read-only property of the\n[WindowSharedStorage] interface contains the [SharedStorageWorklet] instance representing the shared storage worklet for the current origin.\n\n`SharedStorageWorklet` contains the [Worklet.addModule] method, which is used to add a module to the shared storage worklet."
    }
  },
  "worker": {
    "docs": "\n\nThe **`Worker`** interface of the [Web Workers API](/en-US/docs/Web/API/Web_Workers_API) represents a background task that can be created via script, which can send messages back to its creator.\n\nCreating a worker is done by calling the `Worker(\"path/to/worker/script\")` constructor.\n\nWorkers may themselves spawn new workers, as long as those workers are hosted at the same [origin](/en-US/docs/Web/Security/Same-origin_policy) as the parent page.\n\nNote that not all interfaces and functions are available to web workers. See [Functions and classes available to Web Workers](/en-US/docs/Web/API/Web_Workers_API/Functions_and_classes_available_to_workers) for details.\n\n",
    "properties": {
      "error_event": "\n\nThe **`error`** event of the [Worker] interface fires when an error occurs in the worker.",
      "message_event": "\n\nThe `message` event is fired on a [Worker] object when the worker's parent receives a message from its worker (i.e. when the worker sends a message using [`DedicatedWorkerGlobalScope.postMessage()`](/en-US/docs/Web/API/DedicatedWorkerGlobalScope/postMessage)).\n\nThis event is not cancellable and does not bubble.",
      "messageerror_event": "\n\nThe `messageerror` event is fired on a [Worker] object when it receives a message that can't be deserialized.\n\nThis event is not cancellable and does not bubble.",
      "postmessage": "\n\nThe **`postMessage()`** method of the [Worker] interface sends a message to the worker. The first parameter is the data to send to the worker. The data may be any JavaScript object that can be handled by the [structured clone algorithm](/en-US/docs/Web/API/Web_Workers_API/Structured_clone_algorithm).\n\nThe [Worker] `postMessage()` method delegates to the [MessagePort] [MessagePort.postMessage] method, which adds a task on the event loop corresponding to the receiving [MessagePort].\n\nThe `Worker` can send back information to the thread that spawned it using the [DedicatedWorkerGlobalScope.postMessage] method.",
      "terminate": "\n\nThe **`terminate()`** method of the [Worker] interface immediately terminates the [Worker]. This does not offer the worker an opportunity to finish its operations; it is stopped at once."
    }
  },
  "workerglobalscope": {
    "docs": "\n\nThe **`WorkerGlobalScope`** interface of the [Web Workers API](/en-US/docs/Web/API/Web_Workers_API) is an interface representing the scope of any worker. Workers have no browsing context; this scope contains the information usually conveyed by [Window] objects — in this case event handlers, the console or the associated [WorkerNavigator] object. Each `WorkerGlobalScope` has its own event loop.\n\nThis interface is usually specialized by each worker type: [DedicatedWorkerGlobalScope] for dedicated workers, [SharedWorkerGlobalScope] for shared workers, and [ServiceWorkerGlobalScope] for [ServiceWorker](/en-US/docs/Web/API/Service_Worker_API). The `self` property returns the specialized scope for each context.\n\n",
    "properties": {
      "dump": "\n\nThe **`WorkerGlobalScope.dump()`** method logs messages to the browser's standard output (`stdout`). If the browser was started from a terminal, output sent to `dump()` will appear in the terminal. This is the same as [Window.dump], but for workers.\n\nOutput from `dump()` is _not_ sent to the browser's developer tools console. To log to the developer tools console, use [`console.log()`](/en-US/docs/Web/API/console/log_static).",
      "error_event": "\n\nThe **`error`** event of the [WorkerGlobalScope] interface fires when an error occurs in the worker.",
      "fonts": "\n\nThe **`fonts`** property of the [WorkerGlobalScope] interface returns the [FontFaceSet] interface of the worker.\n\nThis property is part of the [CSS Font Loading API](/en-US/docs/Web/API/CSS_Font_Loading_API).",
      "importscripts": "\n\nThe **`importScripts()`** method of the [WorkerGlobalScope] interface synchronously imports one or more scripts into the worker's scope.",
      "languagechange_event": "\n\nThe **`languagechange`** event is fired at the global scope object when the user's preferred language changes.\n\nThis event is not cancelable and does not bubble.",
      "location": "\n\nThe **`location`** read-only property of the [WorkerGlobalScope] interface returns the [WorkerLocation] associated with the worker. It is a specific location object, mostly a subset of the [Location] for browsing scopes, but adapted to workers.",
      "navigator": "\n\nThe **`navigator`** read-only property of the [WorkerGlobalScope] interface returns the [WorkerNavigator] associated with the worker. It is a specific navigator object, mostly a subset of the [Navigator] for browsing scopes, but adapted to workers.",
      "offline_event": "\n\nThe **`offline`** event of the [WorkerGlobalScope] fires when the device loses connection to the internet.",
      "online_event": "\n\nThe **`online`** event of the [WorkerGlobalScope] fires when the device reconnects to the internet.",
      "rejectionhandled_event": "\n\nThe **`rejectionhandled`** event is sent to the script's global scope (typically [WorkerGlobalScope]) whenever a rejected `Promise` is handled late, i.e., when a handler is attached to the promise after its rejection had caused an [WorkerGlobalScope.unhandledrejection_event] event.\n\nThis can be used in debugging and for general application resiliency, in tandem with the `unhandledrejection` event, which is sent when a promise is rejected but there is no handler for the rejection at the time.",
      "securitypolicyviolation_event": "\n\nThe **`securitypolicyviolation`** event is fired when a [Content Security Policy](/en-US/docs/Web/HTTP/CSP) is violated in a worker.\n\nThe handler can be assigned using the `onsecuritypolicyviolation` event handler property or using [EventTarget.addEventListener].",
      "self": "\n\nThe **`self`** read-only property of the [WorkerGlobalScope] interface returns a reference to the `WorkerGlobalScope` itself. Most of the time it is a specific scope like [DedicatedWorkerGlobalScope], [SharedWorkerGlobalScope], or [ServiceWorkerGlobalScope].",
      "unhandledrejection_event": "\n\nThe **`unhandledrejection`** event is sent to the global scope (typically [WorkerGlobalScope]) of a script when a `Promise` that has no rejection handler is rejected.\n\nThis is useful for debugging and for providing fallback error handling for unexpected situations."
    }
  },
  "workerlocation": {
    "docs": "\n\nThe **`WorkerLocation`** interface defines the absolute location of the script executed by the [Worker]. Such an object is initialized for each worker and is available via the [WorkerGlobalScope.location] property obtained by calling `self.location`.\n\nThis interface is only visible from inside a JavaScript script executed in the context of a Web worker.",
    "properties": {
      "hash": "\n\nThe **`hash`** property of a [WorkerLocation] object returns the [URL.hash] part of the worker's location.",
      "host": "\n\nThe **`host`** property of a [WorkerLocation] object returns the [URL.host] part of the worker's location.",
      "hostname": "\n\nThe **`hostname`** property of a [WorkerLocation] object returns the [URL.hostname] part of the worker's location.",
      "href": "\n\nThe **`href`** property of a [WorkerLocation] object returns a string containing the serialized [URL] for the worker's location.",
      "origin": "\n\nThe **`origin`** property of a [WorkerLocation] object returns the worker's [URL.origin].",
      "pathname": "\n\nThe **`pathname`** property of a [WorkerLocation] object returns the [URL.pathname] part of the worker's location.",
      "port": "\n\nThe **`port`** property of a [WorkerLocation] object returns the [URL.port] part of the worker's location.",
      "protocol": "\n\nThe **`protocol`** property of a [WorkerLocation] object returns the [URL.protocol] part of the worker's location.",
      "search": "\n\nThe **`search`** property of a [WorkerLocation] object returns the [URL.search] part of the worker's location.",
      "tostring": "\n\nThe **`toString()`**  method of a [WorkerLocation] object returns a string containing the serialized [URL] for the worker's location. It is a synonym for [WorkerLocation.href]."
    }
  },
  "workernavigator": {
    "docs": "\n\nThe **`WorkerNavigator`** interface represents a subset of the [Navigator] interface allowed to be accessed from a [Worker]. Such an object is initialized for each worker and is available via the [WorkerGlobalScope.navigator] property.",
    "properties": {
      "appcodename": " \n\nThe value of the **`WorkerNavigator.appCodeName`** property is\nalways \"`Mozilla`\", in any browser. This property is kept only for\ncompatibility purposes.\n\n> **Note:** Do not rely on this property to return a real\n> product name. All browsers return \"`Mozilla`\" as the value of this property.",
      "appname": " \n\nThe value of the **`WorkerNavigator.appName`** property is always\n\"`Netscape`\", in any browser. This property is kept only for compatibility\npurposes.\n\n> **Note:** Do not rely on this property to return a real browser name. All browsers return \"`Netscape`\" as the value of this property.",
      "appversion": " \n\nReturns either \"`4.0`\" or a string representing version information about\nthe browser.\n\n> **Note:** Do not rely on this property to return the correct browser version.",
      "clearappbadge": "\n\nThe **`clearAppBadge()`** method of the [WorkerNavigator] interface clears a badge on the current app's icon by setting it to `nothing`. The value `nothing` indicates that no badge is currently set, and the status of the badge is _cleared_.",
      "connection": "\n\nThe **`WorkerNavigator.connection`** read-only property returns\na [NetworkInformation] object containing information about the system's\nconnection, such as the current bandwidth of the user's device or whether the connection\nis metered. This could be used to select high definition content or low definition\ncontent based on the user's connection.",
      "devicememory": "\n\nThe **`deviceMemory`** read-only\nproperty of the [WorkerNavigator] interface returns the approximate amount of\ndevice memory in gigabytes.\n\nThe reported value is imprecise to curtail . It's approximated by\nrounding down to the nearest power of 2, then dividing that number by 1024. It is then\nclamped within lower and upper bounds to protect the privacy of owners of very low-memory or\nhigh-memory devices.",
      "globalprivacycontrol": "\n\nThe **`WorkerNavigator.globalPrivacyControl`** read-only property returns the user's Global Privacy Control setting for the current website.\nThis setting indicates whether the user consents to the website or service selling or sharing their personal information with third parties.\n\nThe value of the property reflects that of the  HTTP header.",
      "gpu": "\n\nThe **`gpu`** read-only property of the [WorkerNavigator] interface returns the [GPU] object for the current worker context, which is the entry point for the [WebGPU_API].",
      "hardwareconcurrency": "\n\nThe **`navigator.hardwareConcurrency`** read-only property\nreturns the number of logical processors available to run threads on the user's\ncomputer.",
      "language": "\n\nThe **`WorkerNavigator.language`** read-only property returns\na string representing the preferred language of the user, usually the language of the\nbrowser UI.",
      "languages": "\n\nThe **`WorkerNavigator.languages`** read-only property\nreturns an array of strings representing the user's preferred\nlanguages. The language is described using language tags according to\n`5646, \"Tags for Identifying Languages (also known as BCP 47)\"`. In the returned\narray they are ordered by preference with the most preferred language first.\n\nThe value of [WorkerNavigator.language] is the\nfirst element of the returned array.\n\nWhen its value changes, as the user's preferred languages are changed a\n[Window.languagechange_event] event is fired on the [WorkerGlobalScope] object.\n\nThe `Accept-Language` HTTP header in every HTTP request from the user's\nbrowser uses the same value for the `navigator.languages` property except for\nthe extra `qvalues` (quality values) field (e.g. `en-US;q=0.8`).",
      "locks": "\n\nThe **`locks`** read-only property of\nthe [WorkerNavigator] interface returns a [LockManager]\nobject which provides methods for requesting a new [Lock] object and\nquerying for an existing `Lock` object.",
      "mediacapabilities": "\n\nThe read-only **`WorkerNavigator.mediaCapabilities`** property\nreturns a [MediaCapabilities] object that can expose information about the\ndecoding and encoding capabilities for a given format and output capabilities as defined\nby the [Media Capabilities API](/en-US/docs/Web/API/Media_Capabilities_API).",
      "online": "\n\nReturns the online status of the browser. The property returns a boolean value, with `true` meaning online and `false` meaning offline. The property sends updates whenever the browser's ability to connect to the network changes. The update occurs when the user follows links or when a script requests a remote page.\n\nFor example, the property should return `false` when users click links soon after they lose internet connection.\n\nBrowsers implement this property differently.\n\nIn Chrome and Safari, if the browser is not able to connect to a local area network (LAN) or a router, it is offline; all other conditions return `true`. So while you can assume that the browser is offline when it returns a `false` value, you cannot assume that a true value necessarily means that the browser can access the internet. You could be getting false positives, such as in cases where the computer is running a virtualization software that has virtual ethernet adapters that are always\n\"connected.\" Therefore, if you really want to determine the online status of the browser, you should develop additional means for checking. To learn more, see the 2011 article, [Working Off the Grid](https://developer.chrome.com/docs/workbox/service-worker-overview/).\n\nIn Firefox, switching the browser to offline mode sends a `false` value.",
      "permissions": "\n\nThe **`WorkerNavigator.permissions`** read-only property\nreturns a [Permissions] object that can be used to query and update\npermission status of APIs covered by the [Permissions API](/en-US/docs/Web/API/Permissions_API).",
      "platform": " \n\nReturns a string representing the platform of the browser. The specification allows\nbrowsers to always return the empty string, so don't rely on this property to get a\nreliable answer.",
      "product": " \n\nThe value of the **`WorkerNavigator.product`** property is always\n\"`Gecko`\", in any browser. This property is kept only for compatibility\npurposes.\n\n> **Note:** Do not rely on this property to return a real product name. All browsers return \"`Gecko`\" as the value of this property.",
      "serial": "\n\nThe **`serial`** read-only property of the [WorkerNavigator] interface returns a [Serial] object which represents the entry point into the [Web Serial API].\n\nWhen getting, the same instance of the [Serial] object will always be returned.",
      "serviceworker": "\n\nThe **`serviceWorker`** read-only property of the [WorkerNavigator] interface returns the [ServiceWorkerContainer] object for the [associated document](https://html.spec.whatwg.org/multipage/browsers.html#concept-document-window), which provides access to registration, removal, upgrade, and communication with the [ServiceWorker].\n\nThe feature may not be available in private mode.",
      "setappbadge": "\n\nThe **`setAppBadge()`** method of the [WorkerNavigator] interface sets a badge on the icon associated with this app. If a value is passed to the method, this will be set as the value of the badge. Otherwise the badge will display as a dot, or other indicator as defined by the platform.",
      "storage": "\n\nThe **`storage`** read-only property of the [WorkerNavigator] interface\nreturns the singleton [StorageManager] object used to\naccess the overall storage capabilities of the browser for the current site or app.\nThe returned object lets you examine and configure persistence of data stores and\nlearn approximately how much more space your browser has available for local storage\nuse.",
      "usb": "\n\nThe **`usb`** read-only property of the [WorkerNavigator] interface returns a [USB] object for the current document, providing access to [WebUSB API](/en-US/docs/Web/API/WebUSB_API) functionality.",
      "useragent": "\n\nThe **`WorkerNavigator.userAgent`** read-only property returns the\nuser agent string for the current browser.\n\n> **Note:** The specification asks browsers to provide as little information via this field as\n> possible. Never assume that the value of this property will stay the same in future\n> versions of the same browser. Try not to use it at all, or only for current and past\n> versions of a browser. New browsers may start using the same UA, or part of it, as an\n> older browser: you really have no guarantee that the browser agent is indeed the one\n> advertised by this property.\n>\n> Also keep in mind that users of a browser can change the value of this field if they\n> want (UA spoofing).\n\nBrowser identification based on detecting the user agent string is\n**unreliable** and **is not recommended**, as the user agent\nstring is user configurable. For example:\n\n- In Firefox, you can change the preference `general.useragent.override` in\n  `about:config`. Some Firefox extensions do that; however, this only changes\n  the HTTP header that gets sent, and doesn't affect browser detection performed by\n  JavaScript code.\n- Opera 6+ allows users to set the browser identification string via a menu.",
      "useragentdata": "\n\nThe **`userAgentData`** read-only property of the [WorkerNavigator] interface returns an [NavigatorUAData] object\nwhich can be used to access the ."
    }
  },
  "worklet": {
    "docs": "\n\nThe **`Worklet`** interface is a lightweight version of [Worker] and gives developers access to low-level parts of the rendering pipeline.\n\nWith Worklets, you can run JavaScript and [WebAssembly](/en-US/docs/WebAssembly) code to do graphics rendering or audio processing where high performance is required.\n\nWorklets allow static import of [ECMAScript modules](/en-US/docs/Web/JavaScript/Guide/Modules), if supported, using [`import`](/en-US/docs/Web/JavaScript/Reference/Statements/import).\nDynamic import is disallowed by the specification — calling [`import()`](/en-US/docs/Web/JavaScript/Reference/Operators/import) will throw.",
    "properties": {
      "addmodule": "\n\nThe **`addModule()`** method of the\n[Worklet] interface loads the module in the given JavaScript file and\nadds it to the current `Worklet`."
    }
  },
  "workletglobalscope": {
    "docs": "\n\nThe **`WorkletGlobalScope`** interface is an abstract class that specific worklet scope classes inherit from. Each `WorkletGlobalScope` defines a new global environment.\n\n> **Note:** You don't normally need to interact with this interface. It is a base interface intended to be subclassed. You will encounter the subclasses [AudioWorkletGlobalScope] inside [AudioWorklet] objects, or [PaintWorkletGlobalScope] inside CSS paint [Worklet] objects."
  },
  "workletsharedstorage": {
    "docs": "\n\nThe **`WorkletSharedStorage`** interface of the [Shared Storage API] represents the shared storage for a particular origin within a worklet context.\n\n`WorkletSharedStorage` is accessed via [SharedStorageWorkletGlobalScope.sharedStorage].\n\n",
    "properties": {
      "context": "\n\nThe **`context`** read-only property of the [WorkletSharedStorage] interface contains contextual data passed into the shared storage worklet from the associated browsing context via the [FencedFrameConfig.setSharedStorageContext] method.",
      "entries": "\n\nThe **`entries()`** method of the\n[WorkletSharedStorage] interface returns an [async iterator](/en-US/docs/Web/JavaScript/Reference/Global_Objects/AsyncIterator). The iterator provides an array of `[key, value]` pairs corresponding to the enumerable properties of a `WorkletSharedStorage` instance. The order of these pairs is similar to that in a [`for...in`](/en-US/docs/Web/JavaScript/Reference/Statements/for...in) loop, though a `for...in` loop also enumerates properties from the prototype chain.",
      "get": "\n\nThe **`get()`** method of the\n[WorkletSharedStorage] interface retrieves a value from shared storage.",
      "keys": "\n\nThe **`keys()`** method of the\n[WorkletSharedStorage] interface returns an [async iterator](/en-US/docs/Web/JavaScript/Reference/Global_Objects/AsyncIterator), which contains the keys for each item in a `WorkletSharedStorage` instance.",
      "length": "\n\nThe **`length()`** method of the\n[WorkletSharedStorage] interface returns the number of entries currently stored in shared storage for the current origin.",
      "remainingbudget": "\n\nThe **`remainingBudget()`** method of the\n[WorkletSharedStorage] interface returns the remaining navigation budget for the current origin.\n\nThe navigation budget is the number of entropy bits permitted inside a `fencedframe` due to the [WindowSharedStorage.selectURL] calls per origin every 24 hours. This is not the same as the number of navigations; rather, it is based on the number of potential navigations in each call. Each time a `selectURL()` navigation occurs, the corresponding origin's budget decreases by the logarithm (base 2) of the number of URL choices.\n\nNavigation budget is a mechanism designed to limit the rate of leakage of cross-site data to the destination pages navigated to in [fenced frames](/en-US/docs/Web/API/Fenced_Frame_API)."
    }
  },
  "writablestream": {
    "docs": "\n\nThe **`WritableStream`** interface of the [Streams API](/en-US/docs/Web/API/Streams_API) provides a standard abstraction for writing streaming data to a destination, known as a sink.\nThis object comes with built-in backpressure and queuing.\n\n`WritableStream` is a [transferable object](/en-US/docs/Web/API/Web_Workers_API/Transferable_objects).",
    "properties": {
      "abort": "\n\nThe **`abort()`** method of the [WritableStream] interface aborts the stream, signaling that the producer can no longer successfully write to the stream and it is to be immediately moved to an error state, with any queued writes discarded.",
      "close": "\n\nThe **`close()`** method of the [WritableStream] interface closes the associated stream. All chunks written before this method is called are sent before the returned promise is fulfilled.\n\nThis is equivalent to getting a [WritableStreamDefaultWriter] with [WritableStream.getWriter], calling [WritableStreamDefaultWriter.close] on it.",
      "getwriter": "\n\nThe **`getWriter()`** method of the [WritableStream] interface returns a new instance of [WritableStreamDefaultWriter] and locks the stream to that instance.\nWhile the stream is locked, no other writer can be acquired until this one is released.",
      "locked": "\n\nThe **`locked`** read-only property of the [WritableStream] interface returns a boolean indicating whether the `WritableStream` is locked to a writer."
    }
  },
  "writablestreamdefaultcontroller": {
    "docs": "\n\nThe **`WritableStreamDefaultController`** interface of the [Streams API](/en-US/docs/Web/API/Streams_API) represents a controller allowing control of a [WritableStream]'s state. When constructing a `WritableStream`, the underlying sink is given a corresponding `WritableStreamDefaultController` instance to manipulate.",
    "properties": {
      "error": "\n\nThe **`error()`** method of the\n[WritableStreamDefaultController] interface causes any future interactions\nwith the associated stream to error.\n\nThis method is rarely used, since usually it suffices to return a rejected promise from\none of the underlying sink's methods. However, it can be useful for suddenly shutting\ndown a stream in response to an event outside the normal lifecycle of interactions with\nthe underlying sink.",
      "signal": "\n\nThe read-only **`signal`** property of the [WritableStreamDefaultController] interface returns the [AbortSignal] associated with the controller."
    }
  },
  "writablestreamdefaultwriter": {
    "docs": "\n\nThe **`WritableStreamDefaultWriter`** interface of the [Streams API](/en-US/docs/Web/API/Streams_API) is the object returned by [WritableStream.getWriter] and once created locks the writer to the `WritableStream` ensuring that no other streams can write to the underlying sink.",
    "properties": {
      "abort": "\n\nThe **`abort()`** method of the\n[WritableStreamDefaultWriter] interface aborts the stream, signaling that\nthe producer can no longer successfully write to the stream and it is to be immediately\nmoved to an error state, with any queued writes discarded.\n\nIf the writer is active, the `abort()` method behaves the same as that for\nthe associated stream ([WritableStream.abort]). If not, it returns a\nrejected promise.",
      "close": "\n\nThe **`close()`** method of the\n[WritableStreamDefaultWriter] interface closes the associated writable\nstream.\n\nThe underlying sink will finish processing any previously-written chunks, before\ninvoking the close behavior. During this time any further attempts to write will fail\n(without erroring the stream).",
      "closed": "\n\nThe **`closed`** read-only property of the\n[WritableStreamDefaultWriter] interface returns a\n`Promise` that fulfills if the stream becomes closed, or rejects if\nthe stream errors or the writer's lock is released.",
      "desiredsize": "\n\nThe **`desiredSize`** read-only property of the\n[WritableStreamDefaultWriter] interface returns the desired size required\nto fill the stream's internal queue.",
      "ready": "\n\nThe **`ready`** read-only property of the\n[WritableStreamDefaultWriter] interface returns a `Promise`\nthat resolves when the desired size of the stream's internal queue transitions from\nnon-positive to positive, signaling that it is no longer applying backpressure.",
      "releaselock": "\n\nThe **`releaseLock()`** method of the\n[WritableStreamDefaultWriter] interface releases the writer's lock on the\ncorresponding stream. After the lock is released, the writer is no longer active. If the\nassociated stream is errored when the lock is released, the writer will appear errored\nin the same way from now on; otherwise, the writer will appear closed.",
      "write": "\n\nThe **`write()`** method of the\n[WritableStreamDefaultWriter] interface writes a passed chunk of data to a\n[WritableStream] and its underlying sink, then returns a\n`Promise` that resolves to indicate the success or failure of the write\noperation.\n\nNote that what \"success\" means is up to the underlying sink; it might indicate that the\nchunk has been accepted, and not necessarily that it is safely saved to its ultimate\ndestination."
    }
  },
  "xmldocument": {
    "docs": "\n\nThe **XMLDocument** interface represents an XML document. It inherits from the generic [Document] and does not add any specific methods or properties to it: nevertheless, several algorithms behave differently with the two types of documents.\n\n"
  },
  "xmlhttprequest": {
    "docs": "\n\n`XMLHttpRequest` (XHR) objects are used to interact with servers. You can retrieve data from a URL without having to do a full page refresh. This enables a Web page to update just part of a page without disrupting what the user is doing.\n\nDespite its name, `XMLHttpRequest` can be used to retrieve any type of data, not just XML.\n\nIf your communication needs to involve receiving event data or message data from a server, consider using [server-sent events](/en-US/docs/Web/API/Server-sent_events) through the [EventSource] interface. For full-duplex communication, [WebSockets](/en-US/docs/Web/API/WebSockets_API) may be a better choice.\n\n`notservice`",
    "properties": {
      "abort": "\n\nThe **`XMLHttpRequest.abort()`** method aborts the request if\nit has already been sent. When a request is aborted, its\n[XMLHttpRequest.readyState] is changed to\n`XMLHttpRequest.UNSENT` (0) and the request's\n[XMLHttpRequest.status] code is set to 0.",
      "abort_event": "\n\nThe `abort` event is fired when a request has been aborted, for example because the program called [XMLHttpRequest.abort].",
      "channel": "\n\nXMLHttpRequest.channel is an `nsIChannel` that used by the object when performing the request. This is `null` if the channel hasn't been created yet. In the case of a multi-part request, this is the initial channel, not the different parts in the multi-part request. **Requires elevated privileges to access.**",
      "error_event": "\n\nThe `error` event is fired when the request encountered an error.",
      "getallresponseheaders": "\n\nThe [XMLHttpRequest] method\n**`getAllResponseHeaders()`** returns all the response\nheaders, separated by , as a string, or returns `null`\nif no response has been received.\n\nIf a network error happened, an empty string\nis returned.\n\n> **Note:** For multipart requests, this returns the headers from the\n> _current_ part of the request, not from the original channel.",
      "getresponseheader": "\n\nThe [XMLHttpRequest] method\n**`getResponseHeader()`** returns the string containing the\ntext of a particular header's value.\n\nIf there are multiple response headers\nwith the same name, then their values are returned as a single concatenated string,\nwhere each value is separated from the previous one by a pair of comma and space. The\n`getResponseHeader()` method returns the value as a UTF byte sequence.\n\n> **Note:** The search for the header name is case-insensitive.\n\nIf you need to get the raw string of all of the headers, use the\n[XMLHttpRequest.getAllResponseHeaders] method,\nwhich returns the entire raw header string.",
      "load_event": "\n\nThe `load` event is fired when an [XMLHttpRequest] transaction completes successfully.",
      "loadend_event": "\n\nThe **`loadend`** event is fired when a request has completed, whether successfully (after [XMLHttpRequest/load_event]) or unsuccessfully (after [XMLHttpRequest/abort_event] or [XMLHttpRequest/error_event]).",
      "loadstart_event": "\n\nThe **`loadstart`** event is fired when a request has started to load data.",
      "mozanon": "\n\n**`XMLHttpRequest.mozAnon`** is a boolean. If true, the request will be sent without cookies or authentication headers.",
      "mozbackgroundrequest": "\n\n> **Note:** This method is not available from Web content. It requires elevated privileges to access.\n\n**`XMLHttpRequest.mozBackgroundRequest`** is a Boolean, indicating if the object represents a background service request. If `true`, no load group is associated with the request, with security dialogs prevented from being shown to the user.\n\nIn cases in where a security dialog (such as authentication or a bad certificate notification) would normally be shown, this request fails instead.\n\n> **Note:** This property must be set before calling `open()`.",
      "mozsystem": "\n\n**`mozSystem`** is a boolean. If true, the same origin policy is not enforced on the request.",
      "open": "\n\nThe [XMLHttpRequest] method **`open()`**\ninitializes a newly-created request, or re-initializes an existing one.\n\n> **Note:** Calling this method for an already active request\n> (one for which `open()` has already been called) is the equivalent of calling\n> [XMLHttpRequest.abort].",
      "overridemimetype": "\n\nThe [XMLHttpRequest] method\n**`overrideMimeType()`** specifies a MIME type other than the\none provided by the server to be used instead when interpreting the data being\ntransferred in a request.\n\nThis may be used, for example, to force a stream to\nbe treated and parsed as `\"text/xml\"`, even if the server does not report it\nas such. This method must be called before calling [XMLHttpRequest.send].",
      "progress_event": "\n\nThe **`progress`** event is fired periodically when a request receives more data.",
      "readystate": "\n\nThe **XMLHttpRequest.readyState** property returns the state an XMLHttpRequest client is in. An XHR client exists in one of the following states:\n\n| Value | State              | Description                                                     |\n| ----- | ------------------ | --------------------------------------------------------------- |\n| `0`   | `UNSENT`           | Client has been created. `open()` not called yet.               |\n| `1`   | `OPENED`           | `open()` has been called.                                       |\n| `2`   | `HEADERS_RECEIVED` | `send()` has been called, and headers and status are available. |\n| `3`   | `LOADING`          | Downloading; `responseText` holds partial data.                 |\n| `4`   | `DONE`             | The operation is complete.                                      |\n\n- UNSENT\n  - : The XMLHttpRequest client has been created, but the open() method hasn't been called yet.\n- OPENED\n  - : open() method has been invoked. During this state, the request headers can be set using the [setRequestHeader()](/en-US/docs/Web/API/XMLHttpRequest/setRequestHeader) method and the [send()](/en-US/docs/Web/API/XMLHttpRequest/send) method can be called which will initiate the fetch.\n- HEADERS_RECEIVED\n  - : send() has been called, all redirects (if any) have been followed and the response headers have been received.\n- LOADING\n  - : Response's body is being received. If [`responseType`](/en-US/docs/Web/API/XMLHttpRequest/responseType) is \"text\" or empty string, [`responseText`](/en-US/docs/Web/API/XMLHttpRequest/responseText) will have the partial text response as it loads.\n- DONE\n  - : The fetch operation is complete. This could mean that either the data transfer has been completed successfully or failed.",
      "readystatechange_event": "\n\nThe `readystatechange` event is fired whenever the [XMLHttpRequest.readyState] property of the [XMLHttpRequest] changes.\n\n> **Warning:** This should not be used with synchronous requests and must\n> not be used from native code.",
      "response": "\n\nThe [XMLHttpRequest]\n**`response`** property returns the response's body content as\nan `ArrayBuffer`, a [Blob], a [Document],\na JavaScript `Object`, or a string, depending on the value\nof the request's [XMLHttpRequest.responseType]\nproperty.",
      "responsetext": "\n\nThe read-only [XMLHttpRequest] property\n**`responseText`** returns the text received from a server\nfollowing a request being sent.",
      "responsetype": "\n\nThe [XMLHttpRequest] property\n**`responseType`** is an enumerated string value specifying\nthe type of data contained in the response.\n\nIt also lets the author change the\nresponse type. If an empty string is set as the value of `responseType`, the\ndefault value of `text` is used.",
      "responseurl": "\n\nThe read-only **`XMLHttpRequest.responseURL`** property returns the serialized URL of the response or the empty string if the URL is `null`. If the URL is returned, any URL fragment present in the URL will be stripped away. The value of `responseURL` will be the final URL obtained after any redirects.",
      "responsexml": "\n\nThe **`XMLHttpRequest.responseXML`** read-only property returns\na [Document] containing the HTML or XML retrieved by the request; or\n`null` if the request was unsuccessful, has not yet been sent, or if the data\ncan't be parsed as XML or HTML.\n\n> **Note:** The name `responseXML` is an artifact of this\n> property's history; it works for both HTML and XML.\n\nUsually, the response is parsed as \"`text/xml`\". If the\n[XMLHttpRequest.responseType] is set to\n\"`document`\" and the request was made asynchronously, instead the response is\nparsed as \"`text/html`\". `responseXML` is `null` for\nany other types of data, as well as for [`data:` URLs](/en-US/docs/Web/HTTP/Basics_of_HTTP/Data_URLs).\n\nIf the server doesn't specify the  as\n\"`text/xml`\" or \"`application/xml`\", you can use\n[XMLHttpRequest.overrideMimeType] to parse it as XML anyway.\n\nThis property isn't available to workers.",
      "send": "\n\nThe [XMLHttpRequest] method\n**`send()`** sends the request to the server.\n\nIf the\nrequest is asynchronous (which is the default), this method returns as soon as the\nrequest is sent and the result is delivered using events. If the request is synchronous,\nthis method doesn't return until the response has arrived.\n\n`send()` accepts an optional parameter which lets you specify the request's\nbody; this is primarily used for requests such as `PUT`. If the request\nmethod is `GET` or `HEAD`, the `body`\nparameter is ignored and the request body is set to `null`.\n\nIf no `Accept` header has been set using the\n[XMLHttpRequest.setRequestHeader], an\n`Accept` header with the type `\"*/*\"` (any type) is sent.",
      "setrequestheader": "\n\nThe [XMLHttpRequest] method **`setRequestHeader()`** sets the value of an HTTP request header.\nWhen using `setRequestHeader()`, you must call it after calling [XMLHttpRequest.open], but before calling [XMLHttpRequest.send].\nIf this method is called several times with the same header, the values are merged into one single request header.\n\nEach time you call `setRequestHeader()` after the first time you call it, the specified text is appended to the end of the existing header's content.\n\nIf no `Accept` header has been set using this, an `Accept` header with the type `\"*/*\"` is sent with the request when [XMLHttpRequest.send] is called.\n\nFor security reasons, there are several  whose values are controlled by the user agent. Any attempt to set a value for one of those headers from frontend JavaScript code will be ignored without warning or error.\n\nIn addition, the [`Authorization`](/en-US/docs/Web/HTTP/Headers/Authorization) HTTP header may be added to a request, but will be removed if the request is redirected cross-origin.\n\n> **Note:** For your custom fields, you may encounter a \"**not allowed by Access-Control-Allow-Headers in preflight response**\" exception when you send requests across domains.\n> In this situation, you need to set up the  in your response header at server side.",
      "status": "\n\nThe read-only **`XMLHttpRequest.status`** property returns the numerical HTTP [status code](/en-US/docs/Web/HTTP/Status) of the `XMLHttpRequest`'s response.\n\nBefore the request completes, the value of `status` is 0. Browsers also report a status of 0 in case of `XMLHttpRequest` errors.",
      "statustext": "\n\nThe read-only **`XMLHttpRequest.statusText`** property returns a string containing the response's status message as returned by the HTTP server. Unlike [`XMLHTTPRequest.status`](/en-US/docs/Web/API/XMLHttpRequest/status) which indicates a numerical status code, this property contains the _text_ of the response status, such as \"OK\" or \"Not Found\". If the request's [`readyState`](/en-US/docs/Web/API/XMLHttpRequest/readyState) is in `UNSENT` or `OPENED` state, the value of `statusText` will be an empty string.\n\nIf the server response doesn't explicitly specify a status text, `statusText` will assume the default value \"OK\".\n\n> **Note:** Responses over an HTTP/2 connection will always have an empty string as status message as HTTP/2 does not support them.",
      "timeout": "\n\nThe **`XMLHttpRequest.timeout`** property is an `unsigned long` representing the number of milliseconds a request can take before automatically being terminated. The default value is 0, which means there is no timeout. Timeout shouldn't be used for synchronous XMLHttpRequests requests used in a  or it will throw an `InvalidAccessError` exception. When a timeout happens, a [timeout](/en-US/docs/Web/API/XMLHttpRequest/timeout_event) event is fired.\n\n> **Note:** You may not use a timeout for synchronous requests with an owning window.\n\n[Using a timeout with an asynchronous request](/en-US/docs/Web/API/XMLHttpRequest_API/Synchronous_and_Asynchronous_Requests#example_using_a_timeout).",
      "timeout_event": "\n\nThe **`timeout`** event is fired when progression is terminated due to preset time expiring.",
      "upload": "\n\nThe [XMLHttpRequest] `upload` property returns an [XMLHttpRequestUpload] object that can be observed to monitor an upload's progress.\n\nIt is an opaque object, but because it's also an [XMLHttpRequestEventTarget], event listeners can be attached to track its process.\n\n> **Note:** Attaching event listeners to this object prevents the request from being a \"simple request\" and will cause a preflight request to be issued if cross-origin; see [CORS](/en-US/docs/Web/HTTP/CORS). Because of this, event listeners need to be registered before calling [XMLHttpRequest.send] or upload events won't be dispatched.\n\n> **Note:** The spec also seems to indicate that event listeners should be attached after [XMLHttpRequest.open]. However, browsers are buggy on this matter, and often need the listeners to be registered _before_ [XMLHttpRequest.open] to work.\n\nThe following events can be triggered on an upload object and used to monitor the upload:\n\n<table class=\"no-markdown\">\n  <thead>\n    <tr>\n      <th>Event</th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>[XMLHttpRequestUpload/loadstart_event]</td>\n      <td>The upload has begun.</td>\n    </tr>\n    <tr>\n      <td>[XMLHttpRequestUpload/progress_event]</td>\n      <td>\n        Periodically delivered to indicate the amount of progress made so far.\n      </td>\n    </tr>\n    <tr>\n      <td>[XMLHttpRequestUpload/abort_event]</td>\n      <td>The upload operation was aborted.</td>\n    </tr>\n    <tr>\n      <td>[XMLHttpRequestUpload/error_event]</td>\n      <td>The upload failed due to an error.</td>\n    </tr>\n    <tr>\n      <td>[XMLHttpRequestUpload/load_event]</td>\n      <td>The upload completed successfully.</td>\n    </tr>\n    <tr>\n      <td>[XMLHttpRequestUpload/timeout_event]</td>\n      <td>\n        The upload timed out because a reply did not arrive within the time\n        interval specified by the\n        [XMLHttpRequest.timeout].\n      </td>\n    </tr>\n    <tr>\n      <td>[XMLHttpRequestUpload/loadend_event]</td>\n      <td>\n        The upload finished. This event does not differentiate between success\n        or failure, and is sent at the end of the upload regardless of the\n        outcome. Prior to this event, one of <code>load</code>,\n        <code>error</code>, <code>abort</code>, or <code>timeout</code> will\n        already have been delivered to indicate why the upload ended.\n      </td>\n    </tr>\n  </tbody>\n</table>",
      "withcredentials": "\n\nThe **`XMLHttpRequest.withCredentials`** property is a boolean value that indicates whether or not cross-site `Access-Control` requests should be made using credentials such as cookies, authorization headers or TLS client certificates. Setting `withCredentials` has no effect on same-origin requests.\n\nIn addition, this flag is also used to indicate when cookies are to be ignored in the response. The default is `false`. `XMLHttpRequest` responses from a different domain cannot set cookie values for their own domain unless `withCredentials` is set to `true` before making the request. The third-party cookies obtained by setting `withCredentials` to true will still honor same-origin policy and hence can not be accessed by the requesting script through [document.cookie](/en-US/docs/Web/API/Document/cookie) or from response headers.\n\n> **Note:** This never affects same-origin requests.\n\n> **Note:** `XMLHttpRequest` responses from a different domain _cannot_ set cookie values for their own domain unless `withCredentials` is set to `true` before making the request, regardless of `Access-Control-` header values."
    }
  },
  "xmlhttprequesteventtarget": {
    "docs": "\n\n`XMLHttpRequestEventTarget` is the interface that describes the event handlers shared on [XMLHttpRequest] and [XMLHttpRequestUpload].\n\nYou don't use `XMLHttpRequestEventTarget` directly; instead you interact with the sub classes."
  },
  "xmlhttprequestupload": {
    "docs": "\n\nThe **`XMLHttpRequestUpload`** interface represents the upload process for a specific [XMLHttpRequest]. It is an _opaque_ object that represents the underlying, browser-dependent, upload process. It is an [XMLHttpRequestEventTarget] and can be obtained by calling [XMLHttpRequest.upload].\n\n`notservice`\n\n",
    "properties": {
      "abort_event": "\n\nThe `abort` event is fired at [XMLHttpRequestUpload] when a request has been aborted, for example because the program called [XMLHttpRequest.abort].",
      "error_event": "\n\nThe `error` event is fired when the request encountered an error.",
      "load_event": "\n\nThe `load` event is fired when an [XMLHttpRequestUpload] transaction completes successfully.",
      "loadend_event": "\n\nThe **`loadend`** event is fired when a request has completed, whether successfully (after [XMLHttpRequestUpload/load_event]) or unsuccessfully (after [XMLHttpRequestUpload/abort_event] or [XMLHttpRequestUpload/error_event]).\n\nThe `loadend` event is also sent when the request has been interrupted (by a [XMLHttpRequestUpload/timeout_event], an [XMLHttpRequestUpload/abort_event], or an [XMLHttpRequestUpload/error_event]). In such cases, both the `loaded` and `total` value of the event will be 0.",
      "loadstart_event": "\n\nThe **`loadstart`** event is fired when a request has started to load data.",
      "progress_event": "\n\nThe **`progress`** event is fired periodically when a request receives more data.",
      "timeout_event": "\n\nThe **`timeout`** event is fired when progression is terminated due to preset time expiring."
    }
  },
  "xmlserializer": {
    "docs": "\n\nThe `XMLSerializer` interface provides the [XMLSerializer.serializeToString] method to construct an XML string representing a  tree.",
    "properties": {
      "serializetostring": "\n\nThe [XMLSerializer] method\n**`serializeToString()`** constructs a string representing the\nspecified  tree in  form."
    }
  },
  "xpathevaluator": {
    "docs": "\n\nThe `XPathEvaluator` interface allows to compile and evaluate  expressions.",
    "properties": {
      "createexpression": "\n\nThis method compiles an [XPathExpression] which can then be used for\n(repeated) evaluations of the  expression.",
      "creatensresolver": "\n\nThis method adapts any DOM node to resolve namespaces so that an XPath expression can\nbe easily evaluated relative to the context of the node where it appeared within the\ndocument.\n\nThis adapter works like the DOM Level 3 method [Node.lookupNamespaceURI] in resolving the namespace URI from a given prefix using\nthe current information available in the node's hierarchy at the time the method is\ncalled, also correctly resolving the implicit `xml` prefix.",
      "evaluate": "\n\nThe `evaluate()` method of the [XPathEvaluator] interface\nexecutes an XPath expression on the given node or document and returns an\n[XPathResult]."
    }
  },
  "xpathexception": {
    "docs": "\n\nIn the [DOM XPath API](/en-US/docs/Web/XPath) the **`XPathException`** interface represents exception conditions that can be encountered while performing XPath operations.",
    "properties": {
      "code": "\n\nThe **`code`** read-only property of the\n[XPathException] interface returns a `short` that contains one\nof the [error code constants](/en-US/docs/Web/API/XPathException#constants)."
    }
  },
  "xpathexpression": {
    "docs": "\n\nThis interface is a compiled XPath expression that can be evaluated on a document or specific node to return information from its  tree.\n\nThis is useful when an expression will be reused in an application, because it is just compiled once and all namespace prefixes which occur within the expression are preresolved.\n\nObjects of this type are created by calling [XPathEvaluator.createExpression].",
    "properties": {
      "evaluate": "\n\nThe **`evaluate()`** method of the\n[XPathExpression] interface executes an [XPath](/en-US/docs/Web/XPath) expression on the given node or document and\nreturns an [XPathResult]."
    }
  },
  "xpathnsresolver": {
    "docs": "\n\nThe `XPathNSResolver` interface permits prefix strings in an  expression to be properly bound to namespace URI strings.\n\nThe [XPathEvaluator] interface can construct an implementation of `XPathNSResolver` from a node, or the interface may be implemented by any application.",
    "properties": {
      "lookupnamespaceuri": "\n\nThe `lookupNamespaceURI` method looks up the namespace URI associated to the\ngiven namespace prefix within an  expression evaluated by the\n[XPathEvaluator] interface."
    }
  },
  "xpathresult": {
    "docs": "\n\nThe **`XPathResult`** interface represents the results generated by evaluating an XPath expression within the context of a given node.\n\nSince XPath expressions can result in a variety of result types, this interface makes it possible to determine and handle the type and value of the result.",
    "properties": {
      "booleanvalue": "\n\nThe read-only **`booleanValue`** property of the\n[XPathResult] interface returns the boolean value of a result with\n[XPathResult.resultType] being `BOOLEAN_TYPE`.\n\n",
      "invaliditeratorstate": "\n\nThe read-only **`invalidIteratorState`** property of the\n[XPathResult] interface signifies that the iterator has become invalid. It\nis `true` if [XPathResult.resultType] is\n`UNORDERED_NODE_ITERATOR_TYPE` or `ORDERED_NODE_ITERATOR_TYPE` and\nthe document has been modified since this result was returned.\n\n",
      "iteratenext": "\n\nThe **`iterateNext()`** method of the\n[XPathResult] interface iterates over a node set result and returns the\nnext node from it or `null` if there are no more nodes.",
      "numbervalue": "\n\nThe read-only **`numberValue`** property of the\n[XPathResult] interface returns the numeric value of a result with\n[XPathResult.resultType] being `NUMBER_TYPE`.\n\n",
      "resulttype": "\n\nThe read-only **`resultType`** property of the\n[XPathResult] interface represents the type of the result, as defined by\nthe type constants.\n\n",
      "singlenodevalue": "\n\nThe read-only **`singleNodeValue`** property of the\n[XPathResult] interface returns a [Node] value or\n`null` in case no node was matched of a result with\n[XPathResult.resultType] being `ANY_UNORDERED_NODE_TYPE` or\n`FIRST_ORDERED_NODE_TYPE`.",
      "snapshotitem": "\n\nThe **`snapshotItem()`** method of the\n[XPathResult] interface returns an item of the snapshot collection or\n`null` in case the index is not within the range of nodes. Unlike the\niterator result, the snapshot does not become invalid, but may not correspond to the\ncurrent document if it is mutated.",
      "snapshotlength": "\n\nThe read-only **`snapshotLength`** property of the\n[XPathResult] interface represents the number of nodes in the result\nsnapshot.\n\n",
      "stringvalue": "\n\nThe read-only **`stringValue`** property of the\n[XPathResult] interface returns the string value of a result with\n[XPathResult.resultType] being `STRING_TYPE`.\n\n"
    }
  },
  "xranchor": {
    "docs": "\n\nThe **`XRAnchor`** interface creates anchors which keep track of the pose that is fixed relative to the real world. With anchors, you can specify poses in the world that need to be updated to correctly reflect the evolving understanding of the world, such that the poses remain aligned with the same place in the physical world. That helps to build an illusion that the placed objects are really present in the user's environment.",
    "properties": {
      "anchorspace": "\n\nThe read-only **`anchorSpace`** property of the [XRAnchor] interface returns an [XRSpace] object to locate the anchor relative to other `XRSpace` objects. It can be passed to [XRFrame.getPose] subsequently.",
      "delete": "\n\nThe **`delete()`** method of the [XRAnchor] interface removes an anchor. This can be useful when an application is no longer interested in receiving updates to an anchor."
    }
  },
  "xranchorset": {
    "docs": "\n\nThe **`XRAnchorSet`** interface exposes a collection of anchors. Its instances are returned by [XRFrame.trackedAnchors] and are [`Set`-like objects](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Set#set-like_browser_apis)."
  },
  "xrboundedreferencespace": {
    "docs": "\n\nThe [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API)'s **`XRBoundedReferenceSpace`** interface describes a virtual world [reference space](/en-US/docs/Web/API/WebXR_Device_API/Geometry) which has preset boundaries. This extends [XRReferenceSpace], which describes an essentially unrestricted space around the viewer's position. These bounds are defined using an array of points, each of which defines a vertex in a polygon inside which the user is allowed to move.\n\nThis is typically used when the XR system is capable of tracking the user's physical movement within a limited distance of their starting position. The specified bounds may, in fact, describe the shape and size of the room the user is located in, in order to let the WebXR site or application prevent the user from colliding with the walls or other obstacles in the real world. At a minimum, the boundaries indicate the area in which the XR device is capable of tracking the user's movement. See the article [Using bounded reference spaces](/en-US/docs/Web/API/WebXR_Device_API/Bounded_reference_spaces) for details on how bounded spaces work and why they're useful.\n\n",
    "properties": {
      "boundsgeometry": "\n\nThe read-only [XRBoundedReferenceSpace]\nproperty **`boundsGeometry`** is an array of\n[DOMPointReadOnly] objects which specifies the points making up a polygon\ninside which the viewer is allowed to move. Each point is treated as a\ntwo-dimensional point, and must be located at ground level (that is,\nits `y` coordinate must be 0).\n\nThis boundary is typically configured by the user, using the software that controls\ntheir XR hardware. This may be done by walking the border of the space they wish to use,\nor by drawing the shape of their room using their XR input device. Theoretically, a more\nadvanced system might use sensors or other detection methods to determine the bounds of\na dedicated XR room (notice how we carefully don't call it a holodeck?)."
    }
  },
  "xrcompositionlayer": {
    "docs": "\n\nThe **`XRCompositionLayer`** interface of the [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API) is a base class that defines a set of common properties and behaviors for WebXR layer types. It is not constructable on its own.\n\nSeveral layer types inherit from `XRCompositionLayer`:\n\n- [XREquirectLayer]\n- [XRCubeLayer]\n- [XRCylinderLayer]\n- [XRProjectionLayer]\n- [XRQuadLayer]\n\n`XRCompositionLayer` itself inherits from the general [XRLayer] class (which inherits from [EventTarget]).\n\n",
    "properties": {
      "blendtexturesourcealpha": "\n\nThe **`blendTextureSourceAlpha`** property of the [XRCompositionLayer] interface is a boolean enabling the layer's texture .",
      "destroy": "\n\nThe **`destroy()`** method of the [XRCompositionLayer] interface deletes the references to the underlying graphics library for the layer. It also sets the color textures and depth stencil texture arrays to an empty array.",
      "layout": "\n\nThe read-only **`layout`** property of the [XRCompositionLayer] interface is the layout type of the layer.\n\nTo specify the layout type of a layer, use one of the layer creation methods and their `layout` option:\n\n- [XRWebGLBinding.createQuadLayer]\n- [XRWebGLBinding.createCylinderLayer]\n- [XRWebGLBinding.createEquirectLayer]\n- [XRWebGLBinding.createCubeLayer]",
      "miplevels": "\n\nThe read-only **`mipLevels`** property of the [XRCompositionLayer] interface is a layer's number of mip levels in the color and texture data. See also [Mipmap](https://en.wikipedia.org/wiki/Mipmap) on Wikipedia.\n\nThe desired number of mip levels can be specified when creating layers. However, if the user agent can't create the requested number, it can create less. Use `mipLevels` to determine the actual number of mip levels for a layer.\n\nThe `viewPixelWidth` and `viewPixelHeight` need to be powers of two as they get successively halved at each mip level.",
      "needsredraw": "\n\nThe read-only **`needsRedraw`** property of the [XRCompositionLayer] interface is a boolean signaling that the layer should be re-rendered in the next frame.\n\nThe need for redrawing can occur when the underlying resources of a layer are lost due to textures that might have been freed by the compositor under the hood. This might happen when the device falls asleep or when the browser switches context (to an operating system dialog or similar) and then comes back.\n\nRedrawing is not a problem for layers which are updated with every frame. However, for layers updated infrequently, or for static layers (where you can only draw once after creation or after a `redraw` event), the layer's content might be lost and need to be redrawn. If the layer's resources are lost, the `needsRedraw` property will be `true` and a `redraw` event is fired on the layer."
    }
  },
  "xrcpudepthinformation": {
    "docs": " \n\nThe **`XRCPUDepthInformation`** interface contains depth information from the CPU (returned by [XRFrame.getDepthInformation]).\n\nThis interface inherits properties from its parent, [XRDepthInformation].",
    "properties": {
      "data": "\n\nThe _read-only_ **`data`** property of the [XRCPUDepthInformation] interface is an `ArrayBuffer` containing depth-buffer information in raw format.\n\nThe data is stored in row-major format, without padding, with each entry corresponding to distance from the view's near plane to the users' environment, in unspecified units. The size of each data entry and the type is determined by [XRSession.depthDataFormat]. The values can be converted from unspecified units to meters by multiplying them by [XRDepthInformation.rawValueToMeters]. The [XRDepthInformation.normDepthBufferFromNormView] property can be used to transform from normalized view coordinates (an origin in the top left corner of the view, with X axis growing to the right, and Y axis growing downward) into the depth buffer's coordinate system.",
      "getdepthinmeters": "\n\nThe **`getDepthInMeters()`** method of the [XRCPUDepthInformation] interface returns the depth in meters at (x, y) in normalized view coordinates (origin in the top left corner)."
    }
  },
  "xrcubelayer": {
    "docs": "\n\nThe **`XRCubeLayer`** interface of the [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API) is a layer that renders directly from a [cubemap](https://en.wikipedia.org/wiki/Cube_mapping) and projects it onto the inside faces of a cube.\n\n`XRCubeLayer` requires the `layers` feature to be enabled for the [XRSession]. You can request it in [XRSystem.requestSession].\n\nTo create a new `XRCubeLayer`, call [XRWebGLBinding.createCubeLayer].\n\nTo present layers to the XR device, add them to the `layers` render state using [XRSession.updateRenderState].\n\n",
    "properties": {
      "orientation": "\n\nThe **`orientation`** property of the [XRCubeLayer] interface represents the orientation relative to the `space` property.",
      "redraw_event": "\n\nThe `redraw` event is sent to the `XRCubeLayer` object when the underlying resources of the layer are lost or when the XR Compositor can no longer reproject the layer. If this event is sent, authors should redraw the content of the layer in the next XR animation frame.\n\nSee also the [XRCompositionLayer.needsRedraw] property which is also available to `XRCubeLayer` objects through inheritance from [XRCompositionLayer].",
      "space": "\n\nThe **`space`** property of the [XRCubeLayer] interface represents the layer's spatial relationship with the user's physical environment."
    }
  },
  "xrcylinderlayer": {
    "docs": "\n\nThe **`XRCylinderLayer`** interface of the [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API) is a layer that takes up a curved rectangular space in the virtual environment. Only the front of the layer is visible.\n\n`XRCylinderLayer` requires the `layers` feature to be enabled for the [XRSession]. You can request it in [XRSystem.requestSession].\n\nTo create a new `XRCylinderLayer`, call either:\n\n- [XRWebGLBinding.createCylinderLayer] for a WebGL opaque texture layer, or\n- [XRMediaBinding.createCylinderLayer] for an HTML `video` playback layer.\n\nTo present layers to the XR device, add them to the `layers` render state using [XRSession.updateRenderState].\n\n",
    "properties": {
      "aspectratio": "\n\nThe **`aspectRatio`** property of the [XRCylinderLayer] interface represents the ratio of the visible cylinder section. It is the ratio of the width of the visible section of the cylinder divided by its height. The width is calculated by multiplying the [XRCylinderLayer.radius] with the [XRCylinderLayer.centralAngle].",
      "centralangle": "\n\nThe **`centralAngle`** property of the [XRCylinderLayer] interface represents the angle in radians of the visible section of the cylinder.",
      "radius": "\n\nThe **`radius`** property of the [XRCylinderLayer] interface represents the radius of the cylinder.",
      "redraw_event": "\n\nThe `redraw` event is sent to the `XRCylinderLayer` object when the underlying resources of the layer are lost or when the XR Compositor can no longer reproject the layer. If this event is sent, authors should redraw the content of the layer in the next XR animation frame.\n\nSee also the [XRCompositionLayer.needsRedraw] property which is also available to `XRCylinderLayer` objects through inheritance from [XRCompositionLayer].",
      "space": "\n\nThe **`space`** property of the [XRCylinderLayer] interface represents the layer's spatial relationship with the user's physical environment.",
      "transform": "\n\nThe **`transform`** property of the [XRCylinderLayer] interface represents the offset and orientation relative to the layer's [XRCylinderLayer.space]."
    }
  },
  "xrdepthinformation": {
    "docs": " \n\nThe **`XRDepthInformation`** interface contains information about the distance from the user's device to the real-world geometry in the user's environment.\n\nThis interface is the parent of:\n\n- [XRCPUDepthInformation]\n  - : Depth information from the CPU (returned by [XRFrame.getDepthInformation]).\n- [XRWebGLDepthInformation]\n  - : Depth information from WebGL (returned by [XRWebGLBinding.getDepthInformation]).\n\nYou will usually interact with these child interfaces. However, `XRDepthInformation` provides some useful properties that are inherited:",
    "properties": {
      "height": "\n\nThe _read-only_ **`height`** property of the [XRDepthInformation] interface contains the height of the depth buffer (number of rows).",
      "normdepthbufferfromnormview": "\n\nThe _read-only_ **`normDepthBufferFromNormView`** property of the [XRDepthInformation] interface contains the 3D geometric transform that needs to be applied when indexing into the depth buffer.",
      "rawvaluetometers": "\n\nThe _read-only_ **`rawValueToMeters`** property of the [XRDepthInformation] interface contains the scale factor by which the raw depth values must be multiplied in order to get the depths in meters.\n\nFor CPU depth information, see also the [XRCPUDepthInformation.getDepthInMeters] method.",
      "width": "\n\nThe _read-only_ **`width`** property of the [XRDepthInformation] interface contains the width of the depth buffer (number of columns)."
    }
  },
  "xrequirectlayer": {
    "docs": "\n\nThe **`XREquirectLayer`** interface of the [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API) is a layer that maps [equirectangular](https://en.wikipedia.org/wiki/Equirectangular_projection) coded data onto the inside of a sphere.\n\n`XREquirectLayer` requires the `layers` feature to be enabled for the [XRSession]. You can request it in [XRSystem.requestSession].\n\nTo create a new `XREquirectLayer`, call either:\n\n- [XRWebGLBinding.createEquirectLayer] for a WebGL opaque texture layer, or\n- [XRMediaBinding.createEquirectLayer] for an HTML `video` playback layer.\n\nTo present layers to the XR device, add them to the `layers` render state using [XRSession.updateRenderState].\n\n",
    "properties": {
      "centralhorizontalangle": "\n\nThe **`centralHorizontalAngle`** property of the [XREquirectLayer] interface represents the central horizontal angle in radians for the sphere.",
      "lowerverticalangle": "\n\nThe **`lowerVerticalAngle`** property of the [XREquirectLayer] interface represents the lower vertical angle in radians for the sphere.",
      "radius": "\n\nThe **`radius`** property of the [XREquirectLayer] interface represents the radius of the sphere.",
      "redraw_event": "\n\nThe `redraw` event is sent to the `XREquirectLayer` object when the underlying resources of the layer are lost or when the XR Compositor can no longer reproject the layer. If this event is sent, authors should redraw the content of the layer in the next XR animation frame.\n\nSee also the [XRCompositionLayer.needsRedraw] property which is also available to `XREquirectLayer` objects through inheritance from [XRCompositionLayer].",
      "space": "\n\nThe **`space`** property of the [XREquirectLayer] interface represents the layer's spatial relationship with the user's physical environment.",
      "transform": "\n\nThe **`transform`** property of the [XREquirectLayer] interface represents the offset and orientation relative to the layer's [XREquirectLayer.space].",
      "upperverticalangle": "\n\nThe **`upperVerticalAngle`** property of the [XREquirectLayer] interface represents the upper vertical angle in radians for the sphere."
    }
  },
  "xrframe": {
    "docs": "\n\nA [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API) **`XRFrame`** object is passed into the [XRSession.requestAnimationFrame] callback function and provides access to the information needed in order to render a single frame of animation for an [XRSession] describing a VR or AR scene. Events which communicate the tracking state of objects also provide an `XRFrame` reference as part of their structure.\n\nIn addition to providing a reference to the [XRSession] for which this frame is to be rendered, the [XRFrame.getViewerPose] method is provided to obtain the [XRViewerPose] describing the viewer's position and orientation in space, and [XRFrame.getPose] can be used to create an [XRPose] describing the relative position of one [XRSpace] relative to another.",
    "properties": {
      "createanchor": "\n\nThe **`createAnchor()`** method of the [XRFrame] interface creates a free-floating [XRAnchor] which will be fixed relative to the real world.\n\nSee [XRHitTestResult.createAnchor] for creating an anchor from a hit test result that is attached to a real-world object.",
      "filljointradii": "\n\nThe **`fillJointRadii()`** method of the [XRFrame] interface populates a `Float32Array` with radii for a list of hand joint spaces and returns `true` if successful for all spaces.",
      "fillposes": "\n\nThe **`fillPoses()`** method of the [XRFrame] interface populates a `Float32Array` with the matrices of the poses relative to a given base space and returns `true` if successful for all spaces.",
      "getdepthinformation": "\n\nThe **`getDepthInformation()`** method of the [XRFrame] interface returns an [XRCPUDepthInformation] object containing CPU depth information for the active and animated frame.",
      "gethittestresults": "\n\nThe **`getHitTestResults()`** method of the [XRFrame] interface returns an array of [XRHitTestResult] objects containing hit test results for a given [XRHitTestSource].",
      "gethittestresultsfortransientinput": "\n\nThe **`getHitTestResultsForTransientInput()`** method of the [XRFrame] interface returns an array of [XRTransientInputHitTestResult] objects containing transient input hit test results for a given [XRTransientInputHitTestSource].",
      "getjointpose": "\n\nThe **`getJointPose()`** method of the [XRFrame] interface returns an [XRJointPose] object providing the pose of a hand joint (see [XRHand]) relative to a given base space.",
      "getlightestimate": "\n\nThe **`getLightEstimate()`** method of the [XRFrame] interface returns an [XRLightEstimate] object containing estimated lighting values for a given [XRLightProbe].",
      "getpose": "\n\nThe [XRFrame] method **`getPose()`** returns the relative position and\norientation—the pose—of one [XRSpace] to that of another space. With this, you can observe the motion of objects relative to each other and to fixed locations throughout the scene.\n\nFor example, to get the position of a controller relative to the viewer's head, you would compare the controller's [XRInputSource.gripSpace] to the [XRReferenceSpace] of type `viewer`.",
      "getviewerpose": "\n\nThe **`getViewerPose()`** method, a member of the [XRFrame] interface, returns a [XRViewerPose] object which describes the viewer's pose (position and orientation) relative to the specified reference space.\n\nSee the [XRFrame.getPose] method for a way to calculate a pose that represents the difference between two spaces.",
      "session": "\n\nAn `XRFrame` object's _read-only_ **`session`** property returns the [XRSession] object that generated the frame.",
      "trackedanchors": "\n\nThe read-only **`trackedAnchor`** property of the [XRFrame] interface returns an [XRAnchorSet] object containing all anchors still tracked in the frame."
    }
  },
  "xrhand": {
    "docs": "\n\nThe **`XRHand`** interface is pair iterator (an ordered map) with the key being the hand joints and the value being an [XRJointSpace].\n\n`XRHand` is returned by [XRInputSource.hand]."
  },
  "xrhittestresult": {
    "docs": "\n\nThe **`XRHitTestResult`** interface of the [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API) contains a single result of a hit test. You can get an array of `XRHitTestResult` objects for a frame by calling [XRFrame.getHitTestResults].",
    "properties": {
      "createanchor": "\n\nThe **`createAnchor()`** method of the [XRHitTestResult] interface creates an [XRAnchor] from a hit test result that is attached to a real-world object.",
      "getpose": "\n\nThe **`getPose()`** method of the [XRHitTestResult] interface returns the [XRPose] of the hit test result relative to the given base space."
    }
  },
  "xrhittestsource": {
    "docs": "\n\nThe **`XRHitTestSource`** interface of the [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API) handles hit test subscriptions. You can get an `XRHitTestSource` object by using the [XRSession.requestHitTestSource] method.\n\nThis object doesn't itself contain hit test results, but it is used to compute hit tests for each [XRFrame] by calling [XRFrame.getHitTestResults], which returns [XRHitTestResult] objects.",
    "properties": {
      "cancel": "\n\nThe **`cancel()`** method of the [XRHitTestSource] interface unsubscribes a hit test."
    }
  },
  "xrinputsource": {
    "docs": "\n\nThe [WebXR Device API's](/en-US/docs/Web/API/WebXR_Device_API) **`XRInputSource`** interface describes a single source of control input which is part of the user's WebXR-compatible virtual or augmented reality system. The device is specific to the platform being used, but provides the direction in which it is being aimed and optionally may generate events if the user triggers performs actions using the device.",
    "properties": {
      "gamepad": "\n\nThe read-only [XRInputSource] property **`gamepad`** returns a [Gamepad] object describing the state of the buttons and axes on the XR input source, if it is a gamepad or comparable device. If the device isn't a gamepad-like device, this property's value is `null`.\n\nThe [Gamepad] instance returned behaves as described by the [Gamepad API](/en-US/docs/Web/API/Gamepad_API). However, there are a few things to note:\n\n- `Gamepad` instances belonging to `XRInputSource` are not included in the array returned by [navigator.getGamepads]. Gamepads are strictly associated with the WebXR hardware and are not general-purpose gaming devices.\n- [Gamepad.id] is an empty string (`\"\"`)\n- [Gamepad.index] is `-1`\n- [Gamepad.connected] is `true` until the `XRInputSource` is removed from the list of active XR input sources or the [XRSession] is ended.\n- If an axis reported by [Gamepad.axes] represents an axis of a touchpad, the value is 0 when the associated [GamepadButton.touched] property is `false`.\n- [Gamepad.mapping] returns \"xr-standard\".",
      "gripspace": "\n\nThe read-only [XRInputSource] property **`gripSpace`** returns an [XRSpace] whose native origin tracks the pose used to render virtual objects so they appear to be held in (or part of) the user's hand. For example, if a user were holding a virtual straight rod, the native origin of this `XRSpace` would be located at the approximate center of mass of the user's fist.",
      "hand": "\n\nThe read-only **`hand`** property of the [XRInputSource] interface is a [XRHand] object providing access to a hand-tracking device.",
      "handedness": "\n\nThe read-only [XRInputSource] property\n**`handedness`** indicates which of the user's hands the WebXR\ninput source is associated with, or if it's not associated with a hand at all.",
      "profiles": "\n\nThe read-only [XRInputSource] property **`profiles`** returns an array of strings, each describing a configuration profile for the input source. The profile strings are listed in order of specificity, with the most specific profile listed first.\n\n> **Note:** The `profiles` list is always empty when the WebXR\n> session is in inline mode.",
      "targetraymode": "\n\nThe read-only [XRInputSource]\nproperty **`targetRayMode`** indicates the method by which the\ntarget ray for the input source should be generated and how it should be presented to\nthe user.\n\nTypically a target ray is drawn from the source of the targeting system along the target ray in the direction in which the user is looking or pointing. The style of the ray is generally up to you, as is the method for indicating the endpoint of the ray. The targeted point or object might be indicated by drawing a shape or highlighting the targeted surface or object.\n\nA target ray emitted by a hand controller:\n\n![A screenshot showing a target ray being emitted by a hand controller](example-target-ray.gif)\n\nThe target ray can be anything from a simple line (ideally fading over distance) to an animated effect, such as the science-fiction \"phaser\" style shown in the screenshot above.",
      "targetrayspace": "\n\nThe read-only [XRInputSource] property\n**`targetRaySpace`** returns an [XRSpace]\n(typically an [XRReferenceSpace]) representing the position and\norientation of the target ray in the virtual space. Its native origin tracks\nthe position of the origin point of the target ray, and its orientation indicates the\norientation of the controller device itself. These values, interpreted in the context of\nthe input source's [XRInputSource.targetRayMode], can be\nused both to fully interpret the device as an input source.\n\nTo obtain an `XRSpace` representing the input controller's position and\norientation in virtual space, use the [XRInputSource.gripSpace] property."
    }
  },
  "xrinputsourcearray": {
    "docs": "\n\nThe interface **`XRInputSourceArray`** represents a _live_ list of WebXR input sources, and is used as the return value of the [XRSession] property [XRSession.inputSources]. Each entry is an [XRInputSource] representing one input device connected to the WebXR system.\n\nIn addition to being able to access the input sources in the list using standard array notation (that is, with index numbers inside square brackets), methods are available to allow the use of iterators and the [XRInputSourceArray.forEach] method is also available.",
    "properties": {
      "entries": "\n\nThe [XRInputSourceArray] interface's\n**`entries()`** method returns a JavaScript\n[`iterator`](/en-US/docs/Web/JavaScript/Reference/Iteration_protocols)\nwhich can then be used to iterate over the key/value pairs in the input source\narray. Each item in the array is an [XRInputSource] object.\n\nMost frequently, you will use this in tandem with statements such as\n[`for...of`](/en-US/docs/Web/JavaScript/Reference/Statements/for...of).",
      "foreach": "\n\nThe [XRInputSourceArray]\nmethod **`forEach()`** executes the specified callback once for\neach input source in the array, starting at index 0 and progressing until the end of the\nlist.",
      "keys": "\n\nThe **`keys()`** method in the\n[XRInputSourceArray] interface returns a \n[`iterator`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Iterator)\nwhich can then be used to iterate over the keys used to reference each item in the array\nof input sources.",
      "length": "\n\nThe read-only **`length`** property returns an integer value\nindicating the number of items in the input source list represented by\nthe [XRInputSourceArray] object.",
      "values": "\n\nThe [XRInputSourceArray]\nmethod **`values()`** returns a \n[`iterator`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Iterator)\nthat can walk over the list of [XRInputSource] objects contained in the\narray, from first to last."
    }
  },
  "xrinputsourceevent": {
    "docs": " \n\nThe [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API)'s **`XRInputSourceEvent`** interface describes an event which has occurred on a WebXR user input device such as a hand controller, gaze tracking system, or motion tracking system. More specifically, they represent a change in the state of an [XRInputSource].\n\nTo learn more about handling inputs in a WebXR project, see the article [Inputs and input sources](/en-US/docs/Web/API/WebXR_Device_API/Inputs).\n\n",
    "properties": {
      "frame": "\n\nThe read-only [XRInputSourceEvent] property\n**`frame`** specifies an [XRFrame] object\nrepresenting the event frame during which a [WebXR](/en-US/docs/Web/API/WebXR_Device_API) user input occurred.\nThis may thus be an event which occurred in the past rather than a current or impending\nevent.",
      "inputsource": "\n\nThe [XRInputSourceEvent] interface's read-only\n**`inputSource`** property specifies the\n[XRInputSource] which generated the input event. This information\nlets you handle the event appropriately given the particulars of the user input device\nbeing manipulated."
    }
  },
  "xrinputsourceschangeevent": {
    "docs": " \n\nThe WebXR Device API interface **`XRInputSourcesChangeEvent`** is used to represent the [XRSession.inputsourceschange_event] event sent to an [XRSession] when the set of available WebXR input controllers changes.\n\n",
    "properties": {
      "added": "\n\nThe read-only [XRInputSourcesChangeEvent]\nproperty [XRInputSourcesChangeEvent.added] is a list of zero or\nmore input sources, each identified using an [XRInputSource] object,\nwhich have been newly made available for use.",
      "removed": "\n\nThe read-only [XRInputSourcesChangeEvent] property [XRInputSourcesChangeEvent.removed] is an array of\nzero or more [XRInputSource] objects representing the input sources that have been removed from the [XRSession].",
      "session": "\n\nThe [XRInputSourcesChangeEvent] property\n[XRInputSourcesChangeEvent.session] specifies the\n[XRSession] to which the input source list change event applies."
    }
  },
  "xrjointpose": {
    "docs": "\n\nThe **`XRJointPose`** interface is an [XRPose] with additional information about the size of the skeleton joint it represents.\n\n",
    "properties": {
      "radius": "\n\nThe read-only **`radius`** property of the [XRJointPose] interface indicates the radius (distance from skin) for a joint."
    }
  },
  "xrjointspace": {
    "docs": "\n\nThe **`XRJointSpace`** interface is an [XRSpace] and represents the position and orientation of an [XRHand] joint.\n\n",
    "properties": {
      "jointname": "\n\nThe read-only **`jointName`** property of the [XRJointSpace] interface contains the name of the joint it tracks."
    }
  },
  "xrlayer": {
    "docs": "\n\nThe **`XRLayer`** interface of the [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API) is the base class for WebXR layer types. It inherits methods from [EventTarget].\n\n"
  },
  "xrlayerevent": {
    "docs": " \n\nThe **`XRLayerEvent`** interface of the [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API) is the event type for events related to a change of state of an [XRLayer] object. These events occur, for example, when the layer needs to be redrawn.\n\n",
    "properties": {
      "layer": "\n\nThe **`layer`** property of the [XRLayerEvent] interface is a reference to the [XRLayer] which generated the event."
    }
  },
  "xrlightestimate": {
    "docs": " \n\nThe **`XRLightEstimate`** interface of the [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API) provides the estimated lighting values for an [XRLightProbe] at the time represented by an [XRFrame].\n\nTo get an `XRLightEstimate` object, call the [XRFrame.getLightEstimate] method.",
    "properties": {
      "primarylightdirection": "\n\nThe _read-only_ **`primaryLightDirection`** property of the [XRLightEstimate] interface returns a [DOMPointReadOnly] representing the direction to the primary light source from the `probeSpace` of an [XRLightProbe].",
      "primarylightintensity": "\n\nThe _read-only_ **`primaryLightIntensity`** property of the [XRLightEstimate] interface returns a [DOMPointReadOnly] representing the intensity of the primary light source from the `probeSpace` of an [XRLightProbe].",
      "sphericalharmonicscoefficients": "\n\nThe _read-only_ **`sphericalHarmonicsCoefficients`** property of the [XRLightEstimate] interface returns a `Float32Array` containing 9 spherical harmonics coefficients.\n\nSpherical harmonic lighting is a technique that uses spherical functions instead of standard lighting equations. See [Wikipedia](https://en.wikipedia.org/wiki/Spherical_harmonic_lighting) for more information."
    }
  },
  "xrlightprobe": {
    "docs": " \n\nThe **`XRLightProbe`** interface of the [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API) contains lighting information at a given point in the user's environment. You can get an `XRLighting` object using the [XRSession.requestLightProbe] method.\n\nThis object doesn't itself contain lighting values, but it is used to collect lighting states for each [XRFrame]. See [XRLightEstimate] for the estimated lighting values for an `XRLightProbe`.\n\n",
    "properties": {
      "probespace": "\n\nThe _read-only_ **`probeSpace`** property of the [XRLightProbe] interface returns an [XRSpace] tracking the position and orientation that the lighting estimations are relative to.",
      "reflectionchange_event": "\n\nThe WebXR **`reflectionchange`** event fires each time the estimated reflection cube map changes. This happens in response to use movements through different lighting conditions or to direct changes to lighting itself. This event is not cancelable."
    }
  },
  "xrmediabinding": {
    "docs": " \n\nThe **`XRMediaBinding`** interface is used to create layers that display the content of an [HTMLVideoElement].\n\n> **Note:**\n> Only the video frames will be displayed in the layer. Video controls need to be implemented separately and must be drawn in another layer.",
    "properties": {
      "createcylinderlayer": "\n\nThe **`createCylinderLayer()`** method of the [XRMediaBinding] interface returns an [XRCylinderLayer] object which is a layer that takes up a curved rectangular space in the virtual environment.",
      "createequirectlayer": "\n\nThe **`createEquirectLayer()`** method of the [XRMediaBinding] interface returns an [XREquirectLayer] object which is a layer that maps an equirectangular coded data onto the inside of a sphere.",
      "createquadlayer": "\n\nThe **`createQuadLayer()`** method of the [XRMediaBinding] interface returns an [XRQuadLayer] object which is a layer that takes up a flat rectangular space in the virtual environment."
    }
  },
  "xrpose": {
    "docs": "\n\n`XRPose` is a [WebXR API](/en-US/docs/Web/API/WebXR_Device_API) interface representing a position and orientation in the 3D space, relative to the [XRSpace] within which it resides. The `XRSpace`—which is either an [XRReferenceSpace] or an [XRBoundedReferenceSpace]—defines the coordinate system used for the pose and, in the case of an [XRViewerPose], its underlying views.\n\nTo obtain the `XRPose` for the `XRSpace` used as the local coordinate system of an object, call [XRFrame.getPose], specifying that local `XRSpace` and the space to which you wish to convert:\n\n```js\nthePose = xrFrame.getPose(localSpace, baseSpace);\n```\n\nThe pose for a viewer (or camera) is represented by the [XRViewerPose] subclass of `XRPose`. This is obtained using [XRFrame.getViewerPose] instead of `getPose()`, specifying a reference space which has been adjusted to position and orient the node to provide the desired viewing position and angle:\n\n```js\nviewerPose = xrFrame.getViewerPose(adjReferenceSpace);\n```\n\nHere, `adjReferenceSpace` is a reference space which has been updated using the base frame of reference for the frame and any adjustments needed to position the viewer based on movement or rotation which is being supplied from a source other than the XR device, such as keyboard or mouse inputs.\n\nSee the article [Movement, orientation, and motion](/en-US/docs/Web/API/WebXR_Device_API/Movement_and_motion) for further details and an example with thorough explanations of what's going on.",
    "properties": {
      "angularvelocity": "\n\nThe `angularVelocity` read-only property of the\n[XRPose] interface is a [DOMPointReadOnly] describing\nthe angular velocity in radians per second relative to the base\n[XRSpace].",
      "emulatedposition": "\n\nThe `emulatedPosition` read-only attribute of the\n[XRPose] interface is a Boolean value indicating whether or not both the\n[XRRigidTransform.position] component of the pose's\n[XRPose.transform] is directly taken from the XR device, or\nit's simulated or computed based on other sources.",
      "linearvelocity": "\n\nThe `linearVelocity` read-only property of the\n[XRPose] interface is a [DOMPointReadOnly] describing\nthe linear velocity in meters per second relative to the base\n[XRSpace].",
      "transform": "\n\nThe `transform` read-only attribute of the\n[XRPose] interface is a [XRRigidTransform] object providing\nthe position and orientation of the pose relative to the base [XRSpace]\nas specified when the pose was obtained by calling\n[XRFrame.getPose]."
    }
  },
  "xrprojectionlayer": {
    "docs": "\n\nThe **`XRProjectionLayer`** interface of the [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API) is a layer that fills the entire view of the observer and is refreshed close to the device's native frame rate.\n\n`XRProjectionLayer` is supported by all [XRSession] objects (no `layers` feature descriptor is needed).\n\nTo create a new `XRProjectionLayer`, call [XRWebGLBinding.createProjectionLayer].\nTo present layers to the XR device, add them to the `layers` render state using [XRSession.updateRenderState].\n\n`XRProjectionLayer` objects don't have an associated [XRSpace], because they render to the full frame.\n\n",
    "properties": {
      "fixedfoveation": "\n\nThe **`fixedFoveation`** property of the [XRProjectionLayer] interface is a number indicating the amount of foveation used by the XR compositor for the layer. Fixed Foveated Rendering (FFR) renders the edges of the eye textures at a lower resolution than the center and reduces the GPU load.\n\nIt is most useful for low-contrast textures such as background images, but less for high-contrast ones such as text or detailed images. Authors can adjust the level on a per-frame basis to achieve the best tradeoff between performance and visual quality.",
      "ignoredepthvalues": "\n\nThe read-only **`ignoreDepthValues`** property of the [XRProjectionLayer] interface is a boolean indicating if the XR compositor is not making use of depth buffer values when rendering the layer.",
      "texturearraylength": "\n\nThe read-only **`textureArrayLength`** property of the [XRProjectionLayer] interface indicates layer's layer count for array textures when using `texture-array` as the `textureType`.\n\nThe projection layer's layer count for array textures is determined by the user agent or the device. It is reported in the [XRSubImage], which can only be accessed inside the frame loop. If you want to manage your own depth buffers and don't want to wait for first frame after layer creation to determine the required dimensions for those buffers, the `textureArrayLength` property allows access to layer count for array textures outside the frame loop. Allocation of these buffers can happen directly after layer creation.",
      "textureheight": "\n\nThe read-only **`textureHeight`** property of the [XRProjectionLayer] interface indicates the height in pixels of the color textures of this layer.\n\nThe projection layer's texture height is determined by the user agent or the device. It is reported in the [XRSubImage], which can only be accessed inside the frame loop. If you want to manage your own depth buffers and don't want to wait for first frame after layer creation to determine the required dimensions for those buffers, the `textureHeight` property allows access to layer texture height outside the frame loop. Allocation of these buffers can happen directly after layer creation.",
      "texturewidth": "\n\nThe read-only **`textureWidth`** property of the [XRProjectionLayer] interface indicates the width in pixels of the color textures of this layer.\n\nThe projection layer's texture width is determined by the user agent or the device. It is reported in the [XRSubImage], which can only be accessed inside the frame loop. If you want to manage your own depth buffers and don't want to wait for first frame after layer creation to determine the required dimensions for those buffers, the `textureWidth` property allows access to layer texture width outside the frame loop. Allocation of these buffers can happen directly after layer creation."
    }
  },
  "xrquadlayer": {
    "docs": "\n\nThe **`XRQuadLayer`** interface of the [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API) is a layer that takes up a flat rectangular space in the virtual environment. An `XRQuadLayer` has no thickness. It is a two-dimensional object positioned and oriented in 3D space. The position of a quad refers to the center of the quad. Only the front of the layer is visible.\n\n`XRQuadLayer` requires the `layers` feature to be enabled for the [XRSession]. You can request it in [XRSystem.requestSession].\n\nTo create a new `XRQuadLayer`, call either:\n\n- [XRWebGLBinding.createQuadLayer] for a WebGL opaque texture quad layer, or\n- [XRMediaBinding.createQuadLayer] for an HTML `video` playback quad layer.\n\nTo present layers to the XR device, add them to the `layers` render state using [XRSession.updateRenderState].\n\n",
    "properties": {
      "height": "\n\nThe **`height`** property of the [XRQuadLayer] interface represents the height of the layer in meters.",
      "redraw_event": "\n\nThe `redraw` event is sent to the `XRQuadLayer` object when the underlying resources of the layer are lost or when the XR Compositor can no longer reproject the layer. If this event is sent, authors should redraw the content of the layer in the next XR animation frame.\n\nSee also the [XRCompositionLayer.needsRedraw] property which is also available to `XRQuadLayer` objects through inheritance from [XRCompositionLayer].",
      "space": "\n\nThe **`space`** property of the [XRQuadLayer] interface represents the layer's spatial relationship with the user's physical environment.",
      "transform": "\n\nThe **`transform`** property of the [XRQuadLayer] interface represents the offset and orientation relative to the layer's [XRQuadLayer.space].",
      "width": "\n\nThe **`width`** property of the [XRQuadLayer] interface represents the width of the layer in meters."
    }
  },
  "xrray": {
    "docs": " \n\nThe **`XRRay`** interface of the [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API) is a geometric ray described by an origin point and a direction vector.\n\n`XRRay` objects can be passed to [XRSession.requestHitTestSource] or [XRSession.requestHitTestSourceForTransientInput] to perform hit testing.",
    "properties": {
      "direction": "\n\nThe _read-only_ **`direction`** property of the [XRRay] interface is a [DOMPointReadOnly] representing the ray's 3-dimensional directional vector, normalized to a [unit vector](https://en.wikipedia.org/wiki/Unit_vector) with a length of 1.0.",
      "matrix": "\n\nThe _read-only_ **`matrix`** property of the [XRRay] interface is a transform that can be used to position objects along the `XRRay`. This is a 4 by 4 matrix given as a 16 element `Float32Array` in column major order.\n\nThe transform from a ray originates at [0, 0, 0] and extends down the negative z-axis to the ray described by the `XRRay`'s `origin` and `direction`.",
      "origin": "\n\nThe _read-only_ **`origin`** property of the [XRRay] interface is a [DOMPointReadOnly] representing the 3-dimensional point in space that the ray originates from, in meters."
    }
  },
  "xrreferencespace": {
    "docs": "\n\nThe WebXR Device API's **`XRReferenceSpace`** interface describes the coordinate system for a specific tracked entity or object within the virtual world using a specified tracking behavior. The tracking behavior is defined by the selected [reference space type](#reference_space_types). It expands upon the base class, [XRSpace], by adding support for several different tracking behaviors as well as to request a new reference space which describes the offset transform between the tracked object and another location in the world.\n\nAll reference spaces—with the sole exception being bounded reference spaces—are described using the `XRReferenceSpace` type. Bounded spaces are implemented as [XRBoundedReferenceSpace] objects. These are special spaces which let you establish a perimeter within which it's \"safe\" for the viewer to move. For XR systems that allow the user to physically move around, such as those that track movement with a real-world camera, this boundary establishes the edges of the area the user is able to move around in, whether due to physical obstacles or due to limitations of the XR hardware. See the article [Using bounded reference spaces to protect the viewer](/en-US/docs/Web/API/WebXR_Device_API/Bounded_reference_spaces) for more on using boundaries to keep the user from colliding with obstacles both physical and virtual.\n\n",
    "properties": {
      "getoffsetreferencespace": "\n\nThe [XRReferenceSpace]\ninterface's **`getOffsetReferenceSpace()`** method returns a\nnew reference space object which describes the relative difference in position between\nthe object on which the method is called and a given point in 3D space. The\nobject returned by `getOffsetReferenceSpace()` is an\n[XRReferenceSpace] if called on an `XRReferenceSpace`, or an\n[XRBoundedReferenceSpace] if called on an object of that type.\n\nIn other words, when you have an object in 3D space and need to position another object\nrelative to that one, you can call `getOffsetReferenceSpace()`, passing into\nit the position and orientation you want the second object to have\n_relative to the position and orientation of the object on which you call `getOffsetReferenceSpace()`_.\n\nThen, when drawing the scene, you can use the offset reference space to not only\nposition objects relative to one another, but to apply the needed transforms to render\nobjects properly based upon the viewer's position. This is demonstrated in the example\n[Implementing rotation based on non-XR inputs](#implementing_rotation_based_on_non-xr_inputs), which demonstrates a way to\nuse this method to let the user use their mouse to pitch and yaw their viewing angle.",
      "reset_event": "\n\nThe **`reset`** event is sent to an [XRReferenceSpace] object when a discontinuity is detected in either the native origin or the effective origin, causing a jump in the position or orientation of objects oriented using the reference space. This is common when the user calibrates or recalibrates an XR device, or if the device automatically changes its origin after losing tracking of the user, then re-gaining it.\n\nIn the case of [XRBoundedReferenceSpace] objects, the `reset` event can also be fired when the [XRBoundedReferenceSpace.boundsGeometry] changes.\n\nIn either case, the event is sent before any WebXR animation frames which make use of the new origin are executed.\n\nThis event is not cancelable."
    }
  },
  "xrreferencespaceevent": {
    "docs": "\n\nThe [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API) interface **`XRReferenceSpaceEvent`** represents an event sent to an [XRReferenceSpace]. Currently, the only event that uses this type is the [XRReferenceSpace.reset_event] event.\n\n",
    "properties": {
      "referencespace": "\n\nThe read-only [XRReferenceSpaceEvent] property\n**`referenceSpace`** specifies the reference space which is the\noriginator of the event.",
      "transform": "\n\nThe read-only [XRReferenceSpaceEvent] property\n**`transform`** indicates the position and orientation of the\naffected [XRReferenceSpaceEvent.referenceSpace]'s\nnative origin after the changes the event represents are applied. The\n`transform` is defined using the old coordinate system, which allows it to be\nused to convert coordinates from the pre-event coordinate system to the post-event\ncoordinate system."
    }
  },
  "xrrenderstate": {
    "docs": "\n\nThe **`XRRenderState`** interface of the [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API) contains configurable values which affect how the imagery generated by an [XRSession] gets composited. These properties include the range of distances from the viewer within which content should be rendered, the vertical field of view (for inline presentations), and a reference to the [XRWebGLLayer] being used as the target for rendering the scene prior to it being presented on the XR device's display or displays.\n\nWhen you apply changes using the `XRSession` method [XRSession.updateRenderState], the specified changes take effect after the current animation frame has completed, but before the next one begins.",
    "properties": {
      "baselayer": "\n\nThe read-only **`baseLayer`** property of the\n[XRRenderState] interface returns the [XRWebGLLayer] instance\nthat is the source of bitmap images and a description of how the image is to be rendered\nin the device.\n\nThis property is read-only; however, you can indirectly change its\nvalue using [XRSession.updateRenderState].",
      "depthfar": "\n\nThe **`depthFar`** read-only property of the\n[XRRenderState] interface returns the distance in meters of the far clip\nplane from the viewer.",
      "depthnear": "\n\nThe **`depthNear`** read-only property of the\n[XRRenderState] interface returns the distance in meters of the near clip\nplane from the viewer.",
      "inlineverticalfieldofview": "\n\nThe read-only **`inlineVerticalFieldOfView`**\nproperty of the [XRRenderState] interface returns the default vertical\nfield of view for `\"inline\"` sessions and `null` for all immersive\nsessions.",
      "layers": "\n\nThe read-only **`layers`** property of the [XRRenderState] interface is an ordered array containing [XRLayer] objects that are displayed by the XR compositor."
    }
  },
  "xrrigidtransform": {
    "docs": "\n\nThe **`XRRigidTransform`** is a [WebXR API](/en-US/docs/Web/API/WebXR_Device_API) interface that represents the 3D geometric transform described by a position and orientation.\n\n`XRRigidTransform` is used to specify transforms throughout the WebXR APIs, including:\n\n- The offset and orientation relative to the parent reference space to use when creating a new reference space with [XRReferenceSpace.getOffsetReferenceSpace].\n- The [XRView.transform] of an [XRView].\n- The [XRPose.transform] of an [XRPose].\n- The [XRReferenceSpaceEvent] event's [XRReferenceSpaceEvent.transform] property, as found in the [XRReferenceSpace.reset_event] event received by an [XRReferenceSpace].\n\nUsing `XRRigidTransform` in these places rather than bare arrays that provide the matrix data has an advantage. It automatically computes the inverse of the transform and even caches it making subsequent requests significantly faster.",
    "properties": {
      "inverse": "\n\nThe read-only **`inverse`** property\nof the [XRRigidTransform] interface returns another\n[XRRigidTransform] object which is the inverse of its owning\ntransform. That is, you can always get the inverse of any\n`XRRigidTransform` using its `inverse` property, instead of having\nto explicitly generate it.",
      "matrix": "\n\nThe read-only [XRRigidTransform] property\n**`matrix`** returns the transform\nmatrix represented by the object. The returned matrix can then be premultiplied with a\ncolumn vector to rotate the\nvector by the 3D rotation specified by the [XRRigidTransform.orientation], then translate\nit by the [XRRigidTransform.position].",
      "orientation": "\n\nThe read-only [XRRigidTransform] property\n**`orientation`** is a [DOMPointReadOnly]\ncontaining a normalized  (also called a **unit\nquaternion** or **[versor](https://en.wikipedia.org/wiki/Versor)**)\nspecifying the rotational component of the transform represented by the object.\nIf you specify a quaternion whose length is not exactly 1.0 meters, it will be\nnormalized for you.",
      "position": "\n\nThe read-only [XRRigidTransform] property\n**`position`** is a [DOMPointReadOnly] object which\nprovides the 3D point, specified in meters, describing the translation component of the\ntransform."
    }
  },
  "xrsession": {
    "docs": "\n\nThe [WebXR Device API]'s **`XRSession`** interface represents an ongoing XR session, providing methods and properties used to interact with and control the session. To open a WebXR session, use the [XRSystem] interface's [XRSystem.requestSession] method.\n\nWith `XRSession` methods, you can poll the viewer's position and orientation (the [XRViewerPose]), gather information about the user's environment, and present imagery to the user. `XRSession` supports both inline and immersive virtual and augmented reality modes.\n\n",
    "properties": {
      "cancelanimationframe": "\n\nThe **`cancelAnimationFrame()`** method of\nthe [XRSession] interface cancels an animation frame which was previously\nrequested by calling [XRSession.requestAnimationFrame].",
      "depthdataformat": "\n\nThe _read-only_ **`depthDataFormat`** property of an `immersive-ar`\n[XRSession] describes which depth sensing data format is used.",
      "depthusage": "\n\nThe _read-only_ **`depthUsage`** property of an `immersive-ar`\n[XRSession] describes which depth-sensing usage is used.",
      "domoverlaystate": "\n\nThe _read-only_ **`domOverlayState`** property of an `immersive-ar`\n[XRSession] provides information about the DOM overlay, if the feature is enabled.",
      "end": "\n\nThe **`end()`** method shuts down the\n[XRSession] on which it's called, returning a promise which resolves once\nthe session has fully shut down.",
      "end_event": "\n\nAn `end` event is fired at an [XRSession] object when the WebXR session has ended, either because the web application has chosen to stop the session, or because the  terminated the session.",
      "environmentblendmode": "\n\nThe [XRSession] interface's _read-only_ **`environmentBlendMode`**\nproperty identifies if, and to what degree, the computer-generated imagery is overlaid atop the real world.\n\nThis is used to differentiate between fully-immersive VR sessions and AR sessions which render\nover a pass-through image of the real world, possibly partially transparently.",
      "inputsources": "\n\nThe read-only **`inputSources`** property of the\n[XRSession] interface returns an [XRInputSourceArray] object\nwhich lists all controllers and input devices which are expressly associated with the\nXR device and are currently available. These controllers may include handheld\ncontrollers, XR-equipped gloves, optically tracked hands, and gaze-based input methods.\nKeyboards, gamepads, and mice are _not_ considered WebXR input sources.\n\n> **Note:** Traditional gamepad controllers are supported using the [Gamepad API](/en-US/docs/Web/API/Gamepad_API).",
      "inputsourceschange_event": "\n\nThe **`inputsourceschange`** event is sent to an [XRSession] when the set of available WebXR input devices changes.",
      "interactionmode": "\n\nThe [XRSession] interface's _read-only_ **`interactionMode`** property\ndescribes the best space (according to the user agent) for the application to draw an interactive UI for the current session.",
      "preferredreflectionformat": "\n\nThe _read-only_ **`preferredReflectionFormat`** property of the [XRSession] interface returns this session's preferred reflection format used for lighting estimation texture data.",
      "renderstate": "\n\nThe\n_read-only_ **`renderState`** property of an\n[XRSession] object indicates the returns a [XRRenderState]\nobject describing how the user's environment which should be rendered. The\ninformation provided covers the minimum and maximum distance at which to render objects,\nthe vertical field of view to use when rendering the in the `inline` session\nmode, and the [XRWebGLLayer] to render into for inline composition.\n\nWhile this property is read only, you can call the [XRSession] method\n[XRSession.updateRenderState] to make changes.",
      "requestanimationframe": "\n\nThe [XRSession]\nmethod **`requestAnimationFrame()`**, much like the\n[Window] method of the same name, schedules a callback to be executed the\nnext time the browser is ready to paint the session's virtual environment to the XR\ndisplay. The specified callback is executed once before the next repaint; if\nyou wish for it to be executed for the following repaint, you must\ncall `requestAnimationFrame()` again. This can be done from within the\ncallback itself.\n\nThe callback takes two parameters as inputs: an [XRFrame] describing the\nstate of all tracked objects for the session, and a timestamp you can use to compute\nany animation updates needed.\n\nYou can cancel a previously scheduled animation by calling\n[XRSession.cancelAnimationFrame].\n\n> **Note:** Despite the obvious similarities between these methods and the\n> global [Window.requestAnimationFrame] function\n> provided by the `Window` interface, you _must not_ treat these as\n> interchangeable. There is _no_ guarantee that the latter will work at all while\n> an immersive XR session is underway.",
      "requesthittestsource": "\n\nThe **`requestHitTestSource()`** method of the\n[XRSession] interface returns a `Promise` that resolves with an [XRHitTestSource] object that can be passed to [XRFrame.getHitTestResults].",
      "requesthittestsourcefortransientinput": "\n\nThe **`requestHitTestSourceForTransientInput()`** method of the\n[XRSession] interface returns a `Promise` that resolves with an [XRTransientInputHitTestSource] object that can be passed to [XRFrame.getHitTestResultsForTransientInput].",
      "requestlightprobe": "\n\nThe **`requestLightProbe()`** method of the\n[XRSession] interface returns a `Promise` that resolves with an [XRLightProbe] object that estimates lighting information at a given point in the user's environment.",
      "requestreferencespace": "\n\nThe **`requestReferenceSpace()`** method of the\n[XRSession] interface returns a `promise` that resolves with\nan instance of either [XRReferenceSpace]\nor [XRBoundedReferenceSpace] as appropriate given the type of reference\nspace requested.",
      "select_event": "\n\nThe WebXR **`select`** event is sent to an [XRSession] when one of the session's input sources has completed a [primary action](/en-US/docs/Web/API/WebXR_Device_API/Inputs#primary_action).\n\nThe [Element.beforexrselect_event] is fired before this event and can prevent this event from being raised.",
      "selectend_event": "\n\nThe WebXR event **`selectend`** is sent to an [XRSession] when one of its input sources ends its [primary action](/en-US/docs/Web/API/WebXR_Device_API/Inputs#primary_actions) or when an input source that's in the process of handling an ongoing primary action is disconnected without successfully completing the action.\n\nThe [Element.beforexrselect_event] is fired before this event and can prevent this event from being raised.",
      "selectstart_event": "\n\nThe [WebXR](/en-US/docs/Web/API/WebXR_Device_API) **`selectstart`** event is sent to an [XRSession] when the user begins a [primary action](/en-US/docs/Web/API/WebXR_Device_API/Inputs#primary_action) on one of its input sources.\n\nThe [Element.beforexrselect_event] is fired before this event and can prevent this event from being raised.",
      "squeeze_event": "\n\nThe WebXR **`squeeze`** event is sent to an [XRSession] when one of the session's input sources has completed a [primary squeeze action](/en-US/docs/Web/API/WebXR_Device_API/Inputs#primary_squeeze_actions). Examples of common kinds of primary action are users pressing triggers or buttons, tapping a touchpad, speaking a command, or performing a recognizable gesture when using a video tracking system or handheld controller with an accelerometer.\n\nFor details on how the [XRSession.squeezestart_event], `squeeze`, and [XRSession.squeezeend_event] events work, and how you should react to them, see [Inputs and input sources](/en-US/docs/Web/API/WebXR_Device_API/Inputs#input_sources).",
      "squeezeend_event": "\n\nThe WebXR event **`squeezeend`** is sent to an [XRSession] when one of its input sources ends its [primary action](/en-US/docs/Web/API/WebXR_Device_API/Inputs#primary_squeeze_actions) or when an input source that's in the process of handling an ongoing primary action is disconnected without successfully completing the action.\n\nPrimary squeeze actions include things like users pressing triggers or buttons, tapping a touchpad, speaking a command, or performing a recognizable gesture when using a video tracking system or handheld controller with an accelerometer.",
      "squeezestart_event": "\n\nThe [WebXR](/en-US/docs/Web/API/WebXR_Device_API) event **`squeezestart`** is sent to an [XRSession] when the user begins a [primary squeeze action](/en-US/docs/Web/API/WebXR_Device_API/Inputs#primary_squeeze_actions) on one of its input sources.\n\nPrimary squeeze actions are actions which are meant to represent gripping or squeezing using your hands, and may be simulated using triggers on hand controllers.",
      "updaterenderstate": "\n\nThe `updateRenderState()` method of the [XRSession] interface of the [WebXR API](/en-US/docs/Web/API/WebXR_Device_API) schedules changes to be applied to the active render state ([XRRenderState]) prior to rendering of the next frame.",
      "visibilitychange_event": "\n\nThe **`visibilitychange`** event is sent to an [XRSession] to inform it when it becomes visible or hidden, or when it becomes visible but not currently focused. Upon receiving the event, you can check the value of the session's [XRSession.visibilityState] property to determine the new visibility state.",
      "visibilitystate": "\n\nThe _read-only_ **`visibilityState`** property of the\n[XRSession] interface is a string indicating whether the WebXR content is\ncurrently visible to the user, and if it is, whether it's the primary focus.\n\nEvery time the visibility state changes, a\n[XRSession.visibilitychange_event] event is fired on the\n[XRSession] object."
    }
  },
  "xrsessionevent": {
    "docs": "\n\nThe [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API)'s **`XRSessionEvent`** interface describes an event which indicates the change of the state of an [XRSession]. These events occur, for example, when the session ends or the visibility of its context changes.\n\n",
    "properties": {
      "session": "\n\nThe read-only [XRSessionEvent] interface's\n**`session`** property indicates which\n[XRSession] the event is about."
    }
  },
  "xrspace": {
    "docs": "\n\nThe **`XRSpace`** interface of the [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API) is an abstract interface providing a common basis for every class which represents a virtual coordinate system within the virtual world, in which its origin corresponds to a physical location. Spatial data in WebXR is always expressed relative to an object based upon one of the descendant interfaces of `XRSpace`, at the time at which a given [XRFrame] takes place.\n\nNumeric values such as pose positions are thus coordinates in the corresponding `XRSpace`, relative to that space's origin.\n\n> **Note:** The `XRSpace` interface is never used directly; instead, all spaces are created using one of the interfaces based on `XRSpace`. At this time, those are [XRReferenceSpace], [XRBoundedReferenceSpace], and [XRJointSpace].\n\n"
  },
  "xrsubimage": {
    "docs": " \n\nThe **`XRSubImage`** interface of the [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API) represents what viewport of the GPU texture to use for rendering.",
    "properties": {
      "viewport": "\n\nThe read-only **`viewport`** property of the [XRSubImage] interface represents the [XRViewport] that is used when rendering the sub image."
    }
  },
  "xrsystem": {
    "docs": "\n\nThe [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API) interface **`XRSystem`** provides methods which let you get access to an [XRSession] object representing a WebXR session. With that `XRSession` in hand, you can use it to interact with the Augmented Reality (AR) or Virtual Reality (VR) device.\n\n",
    "properties": {
      "devicechange_event": "\n\nA **`devicechange`** event is fired on an [XRSystem] object whenever the availability of immersive XR devices has changed; for example, a VR headset or AR goggles have been connected or disconnected. It's a generic [Event] with no added properties.\n\n> **Note:** Not to be confused with the [MediaDevices] [MediaDevices.devicechange_event] event.",
      "issessionsupported": "\n\nThe [XRSystem] method\n**`isSessionSupported()`** returns a promise which resolves to\n`true` if the specified WebXR session mode is supported by the user's WebXR\ndevice. Otherwise, the promise resolves with `false`.\n\nIf no devices are available or the browser doesn't have permission\nto use the XR device, the promise is rejected with an appropriate\n[DOMException].",
      "requestsession": "\n\nThe **[XRSystem]** interface's\n**`requestSession()`** method returns a `promise`\nwhich resolves to an [XRSession] object through which you can manage the\nrequested type of WebXR session.\n\nWhile only one immersive VR session can be active at a time, multiple\ninline sessions can be in progress at once."
    }
  },
  "xrtransientinputhittestresult": {
    "docs": " \n\nThe **`XRTransientInputHitTestResult`** interface of the [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API) contains an array of results of a hit test for transient input, grouped by input source.\n\nYou can get an array of `XRHitTestResult` objects for a frame by calling [XRFrame.getHitTestResultsForTransientInput].",
    "properties": {
      "inputsource": "\n\nThe _read-only_ **`inputSource`** property of the [XRTransientInputHitTestResult] interface represents an [XRInputSource] object that was used to compute the [XRTransientInputHitTestResult.results] array.",
      "results": "\n\nThe _read-only_ **`results`** property of the [XRTransientInputHitTestResult] interface represents an array of [XRHitTestResult] objects containing the hit test results for the input source, ordered by the distance along the ray used to perform the hit test, with the closest result at position 0."
    }
  },
  "xrtransientinputhittestsource": {
    "docs": " \n\nThe **`XRTransientInputHitTestSource`** interface of the [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API) handles transient input hit test subscriptions. You can get an `XRTransientInputHitTestSource` object by calling the [XRSession.requestHitTestSourceForTransientInput].\n\nThis object doesn't itself contain transient input hit test results, but it is used to compute hit tests for each [XRFrame] by calling [XRFrame.getHitTestResultsForTransientInput], which returns [XRTransientInputHitTestResult] objects.",
    "properties": {
      "cancel": "\n\nThe **`cancel()`** method of the [XRTransientInputHitTestSource] interface unsubscribes a transient input hit test."
    }
  },
  "xrview": {
    "docs": "\n\nThe [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API)'s **`XRView`** interface describes a single view into the XR scene for a specific frame, providing orientation and position information for the viewpoint. You can think of it as a description of a specific eye or camera and how it views the world. A 3D frame will involve two views, one for each eye, separated by an appropriate distance which approximates the distance between the viewer's eyes. This allows the two views, when projected in isolation into the appropriate eyes, to simulate a 3D world.",
    "properties": {
      "eye": "\n\nThe [XRView] interface's read-only **`eye`**\nproperty is a string indicating which eye's viewpoint the `XRView` represents: `left` or\n`right`. For views which represent neither eye, such as monoscopic views,\nthis property's value is `none`.",
      "isfirstpersonobserver": "\n\nThe [XRView] interface's read-only **`isFirstPersonObserver`** property is a boolean indicating if the `XRView` is a first-person observer view.\n\nTo create video recordings of AR device cameras, you can't simply use one of the rendered eyes, as there often will be a physical offset. Some devices expose a secondary view, the first-person observer view, which has an `eye` of `none`.\n\nTo receive a first-person observer view, you need to enable the \"secondary-views\" feature descriptor explicitly (typically as an optional feature). See [XRSystem.requestSession] for details.\n\nThe `isFirstPersonObserver` property then allows you to check which secondary view is a first-person observer view.",
      "projectionmatrix": "\n\nThe [XRView] interface's read-only\n**`projectionMatrix`** property specifies the projection matrix\nto apply to the underlying view. This should be used to integrate perspective to\neverything in the scene, in order to ensure the result is consistent with what the eye\nexpects to see.\n\n> **Note:** Failure to apply proper perspective, or inconsistencies\n> in perspective, may result in possibly serious user discomfort or distress.",
      "recommendedviewportscale": "\n\nThe read-only **`recommendedViewportScale`** property of the [XRView] interface is the recommended viewport scale value that you can use for [XRView.requestViewportScale] if the user agent has such a recommendation; [`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null) otherwise.",
      "requestviewportscale": "\n\nThe **`requestViewportScale()`** method of the [XRView] interface requests that the user agent sets the requested viewport scale for this viewport to the given value. This is used for dynamic viewport scaling which allows rendering to a subset of the WebXR viewport using a scale factor that can be changed every animation frame.",
      "transform": "\n\nThe read-only **`transform`** property of the\n[XRView] interface is an [XRRigidTransform] object which\nprovides the position and orientation of the viewpoint relative to the\n[XRReferenceSpace] specified when the\n[XRFrame.getViewerPose] method was called to obtain the view object.\n\nWith the `transform`, you can then position the view as a camera within the\n3D scene. If you instead need the more traditional view matrix, you can get using\n`view.transform.inverse.matrix`; this gets the underlying\n[XRRigidTransform.matrix] of the transform's\n[XRRigidTransform.inverse]."
    }
  },
  "xrviewerpose": {
    "docs": "\n\nThe WebXR Device API interface **`XRViewerPose`** represents the pose (the position and orientation) of a viewer's point of view on the scene. Each `XRViewerPose` can have multiple views to represent, for example, the slight separation between the left and right eye.\n\nThis view can represent anything from the point-of-view of a user's XR headset to the viewpoint represented by a player's movement of an avatar using mouse and keyboard, presented on the screen, to a virtual camera capturing the scene for a spectator.\n\n",
    "properties": {
      "views": "\n\nThe read-only [XRViewerPose] property **`views`**\nreturns an array which contains every [XRView] which must be rendered in\norder to fully represent the scene from the viewpoint defined by the viewer pose. For\nmonoscopic devices, this array contains a single view.\n\n> **Warning:** There is no guarantee that the number of views will\n> remain constant over the lifetime of an [XRSession]. For each frame, you\n> should always use the current length of this array rather than caching the value.\n\nStereo views require two views to render properly, with the left eye's view having its\n[XRView.eye] set to the string `left` and the right eye's\nview a value of `right`."
    }
  },
  "xrviewport": {
    "docs": "\n\nThe WebXR Device API's **`XRViewport`** interface provides properties used to describe the size and position of the current viewport within the [XRWebGLLayer] being used to render the 3D scene.",
    "properties": {
      "height": "\n\nThe read-only [XRViewport] property\n**`height`** specifies the height, in pixels, of the viewport\nonto the drawing surface within which the WebXR view is to be rendered. Along\nwith [XRViewport.width] and the origin point given by\n[XRViewport.x] and [XRViewport.y], this defines the\narea within which rendered content will be drawn.",
      "width": "\n\nThe read-only [XRViewport] property\n**`width`** specifies the width of the viewport, in pixels,\nonto the drawing surface the 3D scene is to be rendered into. This is defined\nusing this property along with the viewport's [XRViewport.height]\nand its origin given by its properties [XRViewport.x] and\n[XRViewport.y].",
      "x": "\n\nThe read-only [XRViewport] interface's\n**`x`** property indicates the offset from the left edge of\nthe destination surface (typically a [XRWebGLLayer] to the left edge of\nthe viewport within the surface into which WebXR content is to be rendered. The\nviewport's [XRViewport.y] property identifies the `y`\ncomponent of the origin, and its is given by the [XRViewPort.width] and [XRViewport.height] properties.",
      "y": "\n\nThe read-only [XRViewport] interface's\n**`y`** property indicates the offset from the bottom edge of\nthe destination surface (typically a [XRWebGLLayer] to the bottom edge of\nthe viewport within the surface into which WebXR content is to be rendered. The\nviewport's [XRViewport.x] property identifies the `x`\ncomponent of the origin, and its is given by the [XRViewPort.width] and [XRViewport.height] properties."
    }
  },
  "xrwebglbinding": {
    "docs": " \n\nThe **`XRWebGLBinding`** interface is used to create layers that have a GPU backend.",
    "properties": {
      "createcubelayer": "\n\nThe **`createCubeLayer()`** method of the [XRWebGLBinding] interface returns an [XRCubeLayer] object, which is a layer that renders directly from a [cubemap](https://en.wikipedia.org/wiki/Cube_mapping), and projects it onto the inside faces of a cube.",
      "createcylinderlayer": "\n\nThe **`createCylinderLayer()`** method of the [XRWebGLBinding] interface returns an [XRCylinderLayer] object, which is a layer that takes up a curved rectangular space in the virtual environment.",
      "createequirectlayer": "\n\nThe **`createEquirectLayer()`** method of the [XRWebGLBinding] interface returns an [XREquirectLayer] object, which is a layer that maps [equirectangular](https://en.wikipedia.org/wiki/Equirectangular_projection) coded data onto the inside of a sphere.",
      "createprojectionlayer": "\n\nThe **`createProjectionLayer()`** method of the [XRWebGLBinding] interface returns an [XRProjectionLayer] object which is a layer that fills the entire view of the observer and is refreshed close to the device's native frame rate.",
      "createquadlayer": "\n\nThe **`createQuadLayer()`** method of the [XRWebGLBinding] interface returns an [XRQuadLayer] object which is a layer that takes up a flat rectangular space in the virtual environment.",
      "getdepthinformation": "\n\nThe **`getDepthInformation()`** method of the [XRWebGLBinding] interface returns an [XRWebGLDepthInformation] object containing WebGL depth information.",
      "getreflectioncubemap": "\n\nThe **`getReflectionCubeMap()`** method of the [XRWebGLBinding] interface returns a [WebGLTexture] object containing a reflection cube map texture.\n\nThe texture format is specified by the session's `reflectionFormat`. See the `options` parameter on [XRSession.requestLightProbe] and [XRSession.preferredReflectionFormat] for more details. By default, the `srgba8` format is used. When using a `rgba16f` format, you need to be within a WebGL 2.0 context or enable the [OES_texture_half_float] extension within WebGL 1.0 contexts.",
      "getsubimage": "\n\nThe **`getSubImage()`** method of the [XRWebGLBinding] interface returns a [XRWebGLSubImage] object representing the WebGL texture to render.",
      "getviewsubimage": "\n\nThe **`getViewSubImage()`** method of the [XRWebGLBinding] interface returns a [XRWebGLSubImage] object representing the WebGL texture to render for a view.",
      "nativeprojectionscalefactor": "\n\nThe read-only **`nativeProjectionScaleFactor`** property of the [XRWebGLBinding] interface represents the scaling factor by which the projection layer's resolution is multiplied by to get the native resolution of the WebXR device's frame buffer.\n\nFor more details, see [XRWebGLLayer.getNativeFramebufferScaleFactor_static]."
    }
  },
  "xrwebgldepthinformation": {
    "docs": " \n\nThe **`XRWebGLDepthInformation`** interface contains depth information from the GPU/WebGL (returned by [XRWebGLBinding.getDepthInformation]).\n\nThis interface inherits properties from its parent, [XRDepthInformation].",
    "properties": {
      "texture": "\n\nThe _read-only_ **`texture`** property of the [XRWebGLDepthInformation] interface is a [WebGLTexture] containing depth buffer information as an opaque texture."
    }
  },
  "xrwebgllayer": {
    "docs": "\n\nThe **`XRWebGLLayer`** interface of the WebXR Device API provides a linkage between the WebXR device (or simulated XR device, in the case of an inline session) and a WebGL context used to render the scene for display on the device. In particular, it provides access to the WebGL framebuffer and viewport to ease access to the context.\n\nAlthough `XRWebGLLayer` is currently the only type of framebuffer layer supported by [WebGL](/en-US/docs/Web/API/WebGL_API), it's entirely possible that future updates to the WebXR specification may allow for other layer types and corresponding image sources.\n\n",
    "properties": {
      "antialias": "\n\nThe read-only [XRWebGLLayer] property\n**`antialias`** is a Boolean value which is `true`\nif the rendering layer's frame buffer supports anti-aliasing. Otherwise, this\nproperty's value is `false`. The specific anti-aliasing technique used is left\nto the  discretion and cannot be specified by\nthe website or web app.",
      "fixedfoveation": "\n\nThe **`fixedFoveation`** property of the [XRWebGLLayer] interface is a number indicating the amount of foveation used by the XR compositor. Fixed Foveated Rendering (FFR) renders the edges of the eye textures at a lower resolution than the center and reduces the GPU load.\n\nIt is most useful for low contrast textures, such as background images but less for high contrast ones such as text or detailed images. Authors can adjust the level on a per frame basis to achieve the best tradeoff between performance and visual quality.",
      "framebuffer": "\n\nThe read-only [XRWebGLLayer] property\n**`framebuffer`** is an opaque [WebGLFramebuffer]\nwhich is used to buffer the rendered image if the [XR compositor](/en-US/docs/Web/API/WebXR_Device_API/Fundamentals#the_webxr_compositor) is being used. Otherwise, this property's value is\n`null`. The opaque framebuffer is functionally nearly the same as a\nstandard WebGL framebuffer, except for the differences covered in the section\n[How opaque framebuffers are special](#how_opaque_framebuffers_are_special) below.",
      "framebufferheight": "\n\nThe read-only [XRWebGLLayer] property\n**`framebufferHeight`** indicates the height of the\nframebuffer, in pixels.\n\nYou can get the width of the framebuffer using the\n[XRWebGLLayer.framebufferWidth] property.",
      "framebufferwidth": "\n\nThe read-only [XRWebGLLayer] property\n**`framebufferWidth`** specifies the width of the framebuffer,\nin pixels.\n\nYou can get the height of the framebuffer using the\n[XRWebGLLayer.framebufferHeight] property.",
      "getnativeframebufferscalefactor_static": "\n\nThe static method\n**`XRWebGLLayer.getNativeFramebufferScaleFactor()`** returns a\nfloating-point scaling factor by which one can multiply the specified\n[XRSession]'s resolution to get the native resolution of the WebXR\ndevice's frame buffer.\n\nThis information can be used when creating a new `XRWebGLLayer` to configure\nthe `framebufferScaleFactor` in the `layerInit` configuration object\nspecified when calling the `XRWebGLLayer()` constructor. See the\n[Usage notes](#usage_notes) and [Examples](#examples) for details.\n\nIf the scaling factor is 1.0, then the frame buffer pixels and the native display\npixels are the same size. If the scaling factor is greater than zero, then the frame\nbuffer is smaller than the display's native dimensions, resulting in the output being\nup-scaled for display to the screen after rendering into the frame buffer. If the\nscaling factor is less than zero, the frame buffer is _larger_ than the native\nresolution of the display, resulting in the frame buffer's contents being scaled down\nfor display to the XR device. This can happen for display environments which use\nsuperscaling or anti-aliasing techniques to improve perceived image quality.",
      "getviewport": "\n\nThe [XRWebGLLayer] interface's\n**`getViewport()`** method returns the\n[XRViewport] that should be used to render the specified\n[XRView] into the WebGL layer. For WebXR devices which use a\nsingle framebuffer for both the left and right eyes, the returned viewport represents\nthe region of the framebuffer into which the scene should be rendered for the eye\nrepresented by the view.",
      "ignoredepthvalues": "\n\nThe read-only [XRWebGLLayer] property\n**`ignoreDepthValues`** is a Boolean value which is\n`true` if the session has been configured to ignore the values in the depth\nbuffer while rendering the scene. If the depth buffer is being used to determine the\nposition of vertices, this property is `false`.\n\nThe value of `ignoreDepthValues` can only be set when the\n[XRWebGLLayer] is instantiated, by setting the corresponding value in the [constructor's](/en-US/docs/Web/API/XRWebGLLayer/XRWebGLLayer) `options` parameter."
    }
  },
  "xrwebglsubimage": {
    "docs": " \n\nThe **`XRWebGLSubImage`** interface is used during rendering of WebGL layers.\n\n",
    "properties": {
      "colortexture": "\n\nThe read-only **`colorTexture`** property of the [XRWebGLSubImage] interface represents the color [WebGLTexture] object for the [XRCompositionLayer] to render.",
      "colortextureheight": "\n\nThe read-only **`colorTextureHeight`** property of the [XRWebGLSubImage] interface is a number representing the height in pixels of the GL attachment.",
      "colortexturewidth": "\n\nThe read-only **`colorTextureWidth`** property of the [XRWebGLSubImage] interface is a number representing the width in pixels of the GL attachment.",
      "depthstenciltexture": "\n\nThe read-only **`depthStencilTexture`** property of the [XRWebGLSubImage] interface represents the depth/stencil [WebGLTexture] object for the [XRCompositionLayer] to render.",
      "imageindex": "\n\nThe read-only **`imageIndex`** property of the [XRWebGLSubImage] interface is a number representing the offset into the texture array if the layer was requested with `texture-array`; [`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null) otherwise."
    }
  },
  "xsltprocessor": {
    "docs": "\n\nAn **`XSLTProcessor`** applies an [XSLT](/en-US/docs/Web/XSLT) stylesheet transformation to an XML document to\nproduce a new XML document as output. It has methods to load the XSLT stylesheet, to\nmanipulate `<xsl:param>` parameter values, and to apply the\ntransformation to documents.",
    "properties": {
      "basic_example": "\n\nThis first example demonstrates the basics of setting up an XSLT transformation in a browser.\nThe example takes an XML document that contains information about an article (title, list of authors and body text) and presents it in a human-readable form.\n\nThe XML document (**example.xml**) is shown below.\n\n```xml\n<?xml version=\"1.0\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"example.xsl\"?>\n<Article>\n  <Title>My Article</Title>\n  <Authors>\n    <Author>Mr. Foo</Author>\n    <Author>Mr. Bar</Author>\n  </Authors>\n  <Body>This is my article text.</Body>\n</Article>\n```\n\nThe `?xml-stylesheet` processing instruction in the XML file specifies the XSLT stylesheet to apply in its `href` attribute.\n\nThis XSL stylesheet file (**example.xsl**) is shown below:\n\n```xml\n<?xml version=\"1.0\"?>\n<xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\">\n\n  <xsl:output method=\"text\"/>\n\n  <xsl:template match=\"/\">\n    Article - <xsl:value-of select=\"/Article/Title\"/>\n    Authors: <xsl:apply-templates select=\"/Article/Authors/Author\"/>\n  </xsl:template>\n\n  <xsl:template match=\"Author\">\n    - <xsl:value-of select=\".\" />\n  </xsl:template>\n\n</xsl:stylesheet>\n```\n\nAn XSLT stylesheet starts with the `xsl:stylesheet` element, which contains all the _templates_ used to create the final output.\nThe example above has two templates - one that matches the root node and one that matches `Author` nodes.\nThe template that matches the root node outputs the article's title and then says to process all templates (via `apply-templates`) that match `Author` nodes which are children of the `Authors` node.\n\nTo try out the example:\n\n1. Create a directory in your file system and inside it create the files `example.xml` and `example.xsl` listed above\n2. [Start a local server](/en-US/docs/Learn/Common_questions/Tools_and_setup/set_up_a_local_testing_server#running_a_simple_local_http_server) in the directory containing the files.\n   This allows you to browse the files in the directory as though they were hosted on the internet.\n\n   > **Warning:** Opening the XML file directly from the file system will not work, because loading the stylesheet from the file system is a [cross-origin request](/en-US/docs/Web/HTTP/CORS), and will be disallowed by default.\n   > Hosting the XML and stylesheet on the same local server ensures that they have the same origin.\n\n3. Open **example.xml** from the browser.\n4. The browser output is then as shown below:\n\n   ```plain\n   Browser Output :\n\n       Article - My Article\n       Authors:\n       - Mr. Foo\n       - Mr. Bar\n   ```",
      "clearparameters": "\n\nThe `clearParameters()` method of the [XSLTProcessor] interface removes all parameters (`<xsl:param>`) and their values from the stylesheet imported in the processor. The `XSLTProcessor` will then use the default values specified in the XSLT stylesheet.",
      "generating_html": "\n\nOne common application of XSLT in the browser is transforming XML into HTML on the client. This example will transform the input document (example2.xml), which contains information about an article, into an HTML document.\n\nThe `<body>` element of the article now contains HTML elements (a `<b>` and `<u>` tag). The XML document contains both HTML elements and XML elements, but only one namespace is needed, namely for the XML elements. Since there is no HTML namespace, and using the XHTML namespace would force the XSL to create an XML document that would not behave like an HTML document, the `xsl:output` in the XSL Stylesheet will make sure the resulting document will be handled as HTML. For the XML elements, our own namespace is needed, `http://devedge.netscape.com/2002/de`, and it is given the prefix myNS `(xmlns:myNS=\"http://devedge.netscape.com/2002/de\")`.",
      "getparameter": "\n\nThe `getParameter()` method of the [XSLTProcessor] interface returns the value of a parameter (`<xsl:param>`) from the stylesheet imported in the processor.",
      "importstylesheet": "\n\nThe `importStylesheet()` method of the [XSLTProcessor] interface imports an XSLT stylesheet for the processor.",
      "introduction": "\n\nOne noticeable trend in W3C standards has been the effort to separate content from style. This would allow the same style to be reused for multiple content, as well as simplify maintenance and allow a quick (only modify one file) way to change the look of content.\n\nCSS (Cascade Style Sheets) was one of the first ways proposed by the W3C. CSS is a simple way to apply style rules to a web document. These style rules define how the document (the content) should be laid out. However, it has several limitations, such as lack of programming structures and ability to create complex layout models. CSS also has limited support for changing the position of an element.\n\nXSL (Extensible Stylesheet Language) Transformations are composed of two parts: XSL elements, which allow the transformation of an XML tree into another markup tree and XPath, a selection language for trees. XSLT takes an XML document (the content) and creates a brand new document based on the rules in the XSL stylesheet. This allows XSLT to add, remove and reorganize elements from the original XML document and thus allows more fine-grain control of the resulting document's structure.\n\nTransformations in XSLT are based on rules that consist of templates. Each template matches (using XPath) a certain fragment of the input XML document and then applies the substitution part on that fragment to create the new resulting document.",
      "removeparameter": "\n\nThe `removeParameter()` method of the [XSLTProcessor] interface removes the parameter (`<xsl:param>`) and its value from the stylesheet imported in the processor.",
      "reset": "\n\nThe `reset()` method of the [XSLTProcessor] interface removes all parameters (`<xsl:param>`) and the XSLT stylesheet from the processor. The `XSLTProcessor` will then be in its original state when it was created.",
      "setparameter": "\n\nThe `setParameter()` method of the [XSLTProcessor] interface sets the value of a parameter (`<xsl:param>`) in the stylesheet imported in the processor.",
      "transformtodocument": "\n\nThe `transformToDocument()` method of the [XSLTProcessor] interface transforms the provided [Node] source to a [Document] using the XSLT stylesheet associated with `XSLTProcessor`.",
      "transformtofragment": "\n\nThe `transformToFragment()` method of the [XSLTProcessor] interface transforms a provided [Node] source to a [DocumentFragment] using the XSLT stylesheet associated with the `XSLTProcessor`."
    }
  }
}
